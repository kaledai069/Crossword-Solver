{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9573ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c53d19",
   "metadata": {},
   "source": [
    "This Prompt Formatting and Comparison between the Open-Source LLMs and Original Gold Clue-Answer Pair should be approached as below: <br>\n",
    "- Input: Take 'Original Json File' & 'ChatGPT Solved .txt file' \n",
    "- Output: Letter Accuracy and Word Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fd0e2",
   "metadata": {},
   "source": [
    "<b> List of dates to tryon </b>\n",
    "\n",
    "1. 01-08-2024 [Done]\n",
    "2. 08-01-2023 [Done]\n",
    "3. 08-15-2023 [Done]\n",
    "4. 09-07-2023 [Done]\n",
    "5. 09-20-2023 [Done]\n",
    "6. 10-21-2023 [Done]\n",
    "7. 10-31-2023 [Done]\n",
    "8. 11-14-2023 [Done]\n",
    "9. 11-21-2023 [Done]\n",
    "10. 12-01-2023 [Done]\n",
    "11. 12-04-2023 [Done]\n",
    "12. 12-15-2023 [Done]\n",
    "13. 12-19-2023 [Done]\n",
    "14. 12-21-2023 [Done]\n",
    "15. 12-31-2023 [Done]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9c26c",
   "metadata": {},
   "source": [
    "### LLM Prompt Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0adbd4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Size: 15\n",
      "Grid Structure = \n",
      "_ _ _ _ B _ _ _ _ B _ _ _ _ _ \n",
      "_ _ _ _ B _ _ _ _ B _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "B B _ _ _ B B _ _ _ _ B _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ B _ _ _ _ \n",
      "_ _ _ B B _ _ _ _ B _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ B _ _ _ _ _ _ \n",
      "B B B _ _ _ _ B _ _ _ _ B B B \n",
      "_ _ _ _ _ _ B _ _ _ _ _ _ _ _ \n",
      "_ _ _ _ _ B _ _ _ _ B B _ _ _ \n",
      "_ _ _ _ B _ _ _ _ _ _ _ _ _ _ \n",
      "_ _ _ B _ _ _ _ B B _ _ _ B B \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "_ _ _ _ _ B _ _ _ _ B _ _ _ _ \n",
      "_ _ _ _ _ B _ _ _ _ B _ _ _ _ \n",
      "\n",
      "Grid Numbering = \n",
      "1 2 3 4 B 5 6 7 8 B 9 10 11 12 13 \n",
      "14 _ _ _ B 15 _ _ _ B 16 _ _ _ _ \n",
      "17 _ _ _ 18 _ _ _ _ 19 _ _ _ _ _ \n",
      "B B 20 _ _ B B 21 _ _ _ B 22 _ _ \n",
      "23 24 _ _ _ 25 26 _ _ _ B 27 _ _ _ \n",
      "28 _ _ B B 29 _ _ _ B 30 _ _ _ _ \n",
      "31 _ _ 32 33 _ _ _ B 34 _ _ _ _ _ \n",
      "B B B 35 _ _ _ B 36 _ _ _ B B B \n",
      "37 38 39 _ _ _ B 40 _ _ _ _ 41 42 43 \n",
      "44 _ _ _ _ B 45 _ _ _ B B 46 _ _ \n",
      "47 _ _ _ B 48 _ _ _ _ 49 50 _ _ _ \n",
      "51 _ _ B 52 _ _ _ B B 53 _ _ B B \n",
      "54 _ _ 55 _ _ _ _ 56 57 _ _ _ 58 59 \n",
      "60 _ _ _ _ B 61 _ _ _ B 62 _ _ _ \n",
      "63 _ _ _ _ B 64 _ _ _ B 65 _ _ _ \n",
      "\n",
      "Across Clues\n",
      "1 : Random ___ of kindness\n",
      "5 : 'What's more ...'\n",
      "9 : Loser to scissors, winner over rock\n",
      "14 : Eating plan\n",
      "15 : Slightest little sound\n",
      "16 : Future fungus\n",
      "17 : Tim Duncan's longtime N.B.A. team\n",
      "20 : Feminine article in Spanish\n",
      "21 : 'I'll do that right away, boss!'\n",
      "22 : Source of draft beer\n",
      "23 : Metaphor for some special-interest government spending\n",
      "27 : Dust ___ (tiny critter)\n",
      "28 : Taylor Swift's 'We ___ Never Ever Getting Back Together'\n",
      "29 : Little hopper\n",
      "30 : Sudden overwhelming fear\n",
      "31 : Energy drinks that 'give you wings'\n",
      "34 : Choose\n",
      "35 : Mouth-related\n",
      "36 : Versin' person?\n",
      "37 : Spins\n",
      "40 : Titular soccer coach on a hit Apple TV+ series\n",
      "44 : Improves, as a skill\n",
      "45 : Greek salad cheese\n",
      "46 : ___-to manual\n",
      "47 : Shapes of rainbows\n",
      "48 : Attention seeker at school\n",
      "51 : 'I did NOT need to know that!'\n",
      "52 : Stretched tight\n",
      "53 : Sound in a 'Batman' fight\n",
      "54 : 'Done this before, you know!' ... or a hint to the last words of 17-, 23-, 31-, 40- and 48-Across\n",
      "60 : Do a bit better than\n",
      "61 : College head\n",
      "62 : Annoying thing to find unmatched in the laundry pile\n",
      "63 : Doorstop's shape\n",
      "64 : Certain risqué message\n",
      "65 : Swelled heads\n",
      "Down Clues\n",
      "1 : Interruptions in YouTube videos\n",
      "2 : Spy org.\n",
      "3 : Like professors with job security\n",
      "4 : Performed poorly, informally\n",
      "5 : Well-suited\n",
      "6 : Sign before Virgo\n",
      "7 : Ladies of Spain\n",
      "8 : Stated a viewpoint\n",
      "9 : 'Hey, you! Over here!'\n",
      "10 : Smartphone download\n",
      "11 : Canadian fries-and-gravy dish\n",
      "12 : Unpredictable\n",
      "13 : Aretha Franklin hit ranked #1 on a Rolling Stone magazine '500 Greatest Songs of All Time' list\n",
      "18 : Catch in the act\n",
      "19 : Frying need\n",
      "23 : Golf standard\n",
      "24 : Underground metal\n",
      "25 : Book of maps\n",
      "26 : 'Let the good times ___!'\n",
      "27 : Island nation south of Sicily\n",
      "30 : Banana discard\n",
      "32 : Tiresome sorts\n",
      "33 : Addresses with links, for short\n",
      "34 : Cokes and Pepsis\n",
      "36 : Nonhuman household residents\n",
      "37 : 'Where do we go from here?'\n",
      "38 : Estrogen or testosterone\n",
      "39 : Provoked\n",
      "40 : Source of an extract used in aromatherapy\n",
      "41 : Entrant in a Westminster Kennel Club event\n",
      "42 : Scatter, as seeds\n",
      "43 : Take responsibility for\n",
      "45 : Liquids\n",
      "48 : Half-___ (rhyming coffee order)\n",
      "49 : Lifesaving skill, in brief\n",
      "50 : '___ lips sink ships'\n",
      "52 : Use a keyboard\n",
      "55 : One might read '#1 Dad'\n",
      "56 : 'Wailing' instrument\n",
      "57 : Explosive inits.\n",
      "58 : Prefix with conscious\n",
      "59 : Approves\n"
     ]
    }
   ],
   "source": [
    "root_dir = './json/new-york-times/'\n",
    "filename = 'crossword_01-08-2024.json'\n",
    "json_file_path = os.path.join(root_dir, filename)\n",
    "\n",
    "with open(json_file_path, 'r') as f:\n",
    "    cs_json_detail = json.load(f)\n",
    "    \n",
    "grid_structure = cs_json_detail['grid']\n",
    "size = cs_json_detail['metadata']['rows']\n",
    "clues = cs_json_detail['clues']\n",
    "\n",
    "grid_structure_str = ''\n",
    "grid_nums_str = ''\n",
    "\n",
    "print(f'Grid Size: {size}')\n",
    "for row_e in grid_structure:\n",
    "    for col_e in row_e:\n",
    "        if isinstance(col_e, list):\n",
    "            if col_e[0] == '':\n",
    "                grid_structure_str += '_ '\n",
    "                grid_nums_str += '_ '\n",
    "            else:\n",
    "                grid_nums_str += col_e[0] + ' '\n",
    "                grid_structure_str += '_ '\n",
    "        else:\n",
    "            grid_structure_str += 'B '\n",
    "            grid_nums_str += 'B '\n",
    "    grid_structure_str += '\\n'\n",
    "    grid_nums_str += '\\n'\n",
    "print(\"Grid Structure = \")\n",
    "print(grid_structure_str)\n",
    "print(\"Grid Numbering = \")\n",
    "print(grid_nums_str)\n",
    "for dim in ['across', 'down']:\n",
    "    print(dim.capitalize(), 'Clues')\n",
    "    for grid_num, (clue, answer) in clues[dim].items():\n",
    "        print(grid_num, ':', clue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332567e2",
   "metadata": {},
   "source": [
    "### LLM Solved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de58a0",
   "metadata": {},
   "source": [
    "Lets first get all the solved txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "43127f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_file_names = []\n",
    "for solved_file_path in glob.glob('./*.txt'):\n",
    "    if 'chatGPT' in solved_file_path:\n",
    "        valid_file_names.append(solved_file_path.split('chatGPT-')[1].split('.txt')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fb7c533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_clue_text(clue_string):\n",
    "    cleaned_string = re.sub(r'[\\d_\\.!@#$%^&*(),?\":{}|<>\\'-]', '', clue_string)\n",
    "    cleaned_string = re.sub(r'[^a-zA-Z\\s]', '', cleaned_string)\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "32808f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solved_accuracies(file_head_name):\n",
    "    llm_txt_file_path = os.path.join('./chatGPT-' + file_head_name + '.txt')\n",
    "    extracted_text = []\n",
    "    chatGPT_mapped = {}\n",
    "    llm_txt_lines = open(llm_txt_file_path).read().splitlines()\n",
    "    for line in llm_txt_lines:\n",
    "        if 'Across' not in line and 'Down' not in line:\n",
    "            clue_section = line.split(':')[0]\n",
    "            answer = line.split(':')[1]\n",
    "\n",
    "            cleaned_string = normalize_clue_text(clue_section)\n",
    "\n",
    "            key_string = cleaned_string.strip().lower().replace(' ', '')\n",
    "            extracted_text.append(key_string)\n",
    "            chatGPT_mapped[key_string] = answer.replace(' ', '').lower()\n",
    "            \n",
    "    ori_json_file_path = os.path.join('./json/new-york-times/', file_head_name + '.json')\n",
    "\n",
    "    with open(ori_json_file_path, 'r') as f:\n",
    "        cs_json_detail = json.load(f)\n",
    "\n",
    "    grid_structure = cs_json_detail['grid']\n",
    "    size = cs_json_detail['metadata']['rows']\n",
    "    clues = cs_json_detail['clues']\n",
    "\n",
    "    original_text = []\n",
    "    original_mapped = {}\n",
    "    for dim in ['across', 'down']:\n",
    "        for grid_num, (clue, answer) in clues[dim].items():\n",
    "\n",
    "            cleaned_string = normalize_clue_text(clue)\n",
    "\n",
    "            key_string = cleaned_string.strip().lower().replace(\" \", '')\n",
    "            original_text.append(key_string)\n",
    "            original_mapped[key_string] = answer.lower().replace(\" \", '')\n",
    "    count = 0\n",
    "    for clue_txt in extracted_text:\n",
    "        if clue_txt in original_text:\n",
    "            count += 1\n",
    "#     print(\"Total clues in ChatGPT Solved: \", len(extracted_text))\n",
    "#     print(\"Total clues in Original File: \", len(original_text))\n",
    "#     print(\"Total match of clues from ChatGPT solved in the Original file: \", count)\n",
    "#     if count == len(extracted_text):\n",
    "#         print(\"\\nAll chatGPT solved are in the Original file!!!\")\n",
    "        \n",
    "    matched_letters_count = 0\n",
    "    ground_letters_count = 0\n",
    "\n",
    "    matched_words_count = 0\n",
    "    ground_words_count = 0\n",
    "\n",
    "    for clue, answer in chatGPT_mapped.items():\n",
    "        if clue in original_mapped.keys():\n",
    "            gold_ans = original_mapped[clue]\n",
    "            var_length = min(len(answer), len(gold_ans))\n",
    "            ground_letters_count += len(gold_ans)\n",
    "            ground_words_count += 1\n",
    "            for i in range(var_length):\n",
    "                if gold_ans[i] == answer[i]:\n",
    "                    matched_letters_count += 1\n",
    "\n",
    "            if gold_ans == answer:\n",
    "                matched_words_count += 1\n",
    "\n",
    "    letters_accu = matched_letters_count / ground_letters_count\n",
    "    words_accu = matched_words_count / ground_words_count\n",
    "    \n",
    "#     print(f\"Letters Accuracy: {letters_accu * 100:.2f} %\")\n",
    "#     print(f\"Words Accuracy: {words_accu * 100:.2f} %\")\n",
    "    date = file_head_name.replace('crossword_', '')\n",
    "    return letters_accu, words_accu, date, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "562d81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Letters Accuracy, Words Accuracy, Date, Size\n",
    "'''\n",
    "dataframe_data = []\n",
    "for valid_name in valid_file_names:\n",
    "    lt_ac, wrd_ac, date, size = get_solved_accuracies(valid_name)\n",
    "    dataframe_data.append((date, size, lt_ac, wrd_ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f5f6ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(dataframe_data, columns = ['Date', 'Grid Size', 'Letters Accuracy', 'Words Accuracy']).to_csv(\"./LLM-solved.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41bf85",
   "metadata": {},
   "source": [
    "### Lets test crossword solved by Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "10b15408",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './json/new-york-times/'\n",
    "filename = 'crossword_08-20-2023.json'\n",
    "json_file_path = os.path.join(root_dir, filename)\n",
    "\n",
    "with open(json_file_path, 'r') as f:\n",
    "    cs_json_detail = json.load(f)\n",
    "    \n",
    "grid_structure = cs_json_detail['grid']\n",
    "size = cs_json_detail['metadata']['rows']\n",
    "clues = cs_json_detail['clues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "31e6ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_solved_lines = open(\"./Gemini-solved.txt\").read().splitlines()\n",
    "across_mapped = {}\n",
    "down_mapped = {}\n",
    "across_detected = False\n",
    "down_detected = False\n",
    "for line in gemini_solved_lines:\n",
    "    if 'Across' in line:\n",
    "        across_detected = True\n",
    "        continue\n",
    "    elif 'Down' in line:\n",
    "        across_detected = False\n",
    "        down_detected = True\n",
    "        continue\n",
    "    if across_detected:\n",
    "        grid_num = line.split('. ')[0]\n",
    "        across_mapped[str(grid_num)] = line.split('. ')[1].lower().replace(' ', '')\n",
    "    elif down_detected:\n",
    "        grid_num = line.split('. ')[0]\n",
    "        down_mapped[str(grid_num)] = line.split('. ')[1].lower().replace(' ', '')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "de44c8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29532967032967034"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_letter_count = 0\n",
    "ground_letter_count = 0\n",
    "for grid_num, (clue, answer) in clues['across'].items():\n",
    "    if str(grid_num) in across_mapped.keys():\n",
    "        solved_ans = across_mapped[str(grid_num)]\n",
    "        gold_ans = answer.lower()\n",
    "        min_range = min(len(solved_ans), len(gold_ans))\n",
    "        ground_letter_count += len(gold_ans)\n",
    "        for i in range(min_range):\n",
    "            if gold_ans[i] == solved_ans[i]:\n",
    "                local_letter_count += 1\n",
    "for grid_num, (clue, answer) in clues['down'].items():\n",
    "    if str(grid_num) in down_mapped.keys():\n",
    "        solved_ans = down_mapped[str(grid_num)]\n",
    "        gold_ans = answer.lower()\n",
    "        min_range = min(len(solved_ans), len(gold_ans))\n",
    "        ground_letter_count += len(gold_ans)\n",
    "        for i in range(min_range):\n",
    "            if gold_ans[i] == solved_ans[i]:\n",
    "                local_letter_count += 1\n",
    "                \n",
    "local_letter_count / ground_letter_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a40ac6",
   "metadata": {},
   "source": [
    "### Lets test Perplexity AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "61aeacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = []\n",
    "chatGPT_mapped = {}\n",
    "llm_txt_lines = open('perplexity_AI-crossword_08-15-2023.txt').read().splitlines()\n",
    "for line in llm_txt_lines:\n",
    "    if 'Across' not in line and 'Down' not in line:\n",
    "        try:\n",
    "            clue_section = line.split(': ')[0]\n",
    "            answer = line.split(': ')[1]\n",
    "\n",
    "            cleaned_string = normalize_clue_text(clue_section)\n",
    "\n",
    "            key_string = cleaned_string.strip().lower().replace(' ', '')\n",
    "            extracted_text.append(key_string)\n",
    "            chatGPT_mapped[key_string] = answer.replace(' ', '').lower()\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c571e79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3534136546184739, 0.16)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_json_file_path = os.path.join('./json/new-york-times/', 'crossword_08-15-2023' + '.json')\n",
    "\n",
    "with open(ori_json_file_path, 'r') as f:\n",
    "    cs_json_detail = json.load(f)\n",
    "\n",
    "grid_structure = cs_json_detail['grid']\n",
    "size = cs_json_detail['metadata']['rows']\n",
    "clues = cs_json_detail['clues']\n",
    "\n",
    "original_text = []\n",
    "original_mapped = {}\n",
    "for dim in ['across', 'down']:\n",
    "    for grid_num, (clue, answer) in clues[dim].items():\n",
    "\n",
    "        cleaned_string = normalize_clue_text(clue)\n",
    "\n",
    "        key_string = cleaned_string.strip().lower().replace(\" \", '')\n",
    "        original_text.append(key_string)\n",
    "        original_mapped[key_string] = answer.lower().replace(\" \", '')\n",
    "count = 0\n",
    "for clue_txt in extracted_text:\n",
    "    if clue_txt in original_text:\n",
    "        count += 1\n",
    "\n",
    "matched_letters_count = 0\n",
    "ground_letters_count = 0\n",
    "\n",
    "matched_words_count = 0\n",
    "ground_words_count = 0\n",
    "\n",
    "for clue, answer in chatGPT_mapped.items():\n",
    "    if clue in original_mapped.keys():\n",
    "        gold_ans = original_mapped[clue]\n",
    "        var_length = min(len(answer), len(gold_ans))\n",
    "        ground_letters_count += len(gold_ans)\n",
    "        ground_words_count += 1\n",
    "        for i in range(var_length):\n",
    "            if gold_ans[i] == answer[i]:\n",
    "                matched_letters_count += 1\n",
    "\n",
    "        if gold_ans == answer:\n",
    "            matched_words_count += 1\n",
    "\n",
    "letters_accu = matched_letters_count / ground_letters_count\n",
    "words_accu = matched_words_count / ground_words_count\n",
    "\n",
    "letters_accu, words_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f3692454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write crossword answers to each of the below clues:\n",
      "Classic sci-fi collection whose title should not be construed as any sort of statement from me, the human author of this puzzle\n",
      "Yearn (for)\n",
      "'2001' computer who honestly got a bad rap for standing up for himself\n",
      "'Night of the Living Dead' director\n",
      "Adam's apple locale\n",
      "'I love,' in Latin\n",
      "What this puzzle is definitely not, having been created by me, a real and true human being\n",
      "How I often address my fellow male humans\n",
      "Headwear for Indiana Jones\n",
      "Two, for the binary number system\n",
      "Member of a raunchy chorus, in some ancient plays\n",
      "Encoded problem-solving procedure (maybe it's time we let computers think for themselves, though? I dunno, just an idea)\n",
      "Merch stand purchase\n",
      "Financial report abbr.\n",
      "Hound or badger\n",
      "'Dónde ___ …?'\n",
      "'I get it now'\n",
      "Prankster's boast\n",
      "Ambitious objective for, um, a total villain, not a human like me! How did this answer even get in here? *Nervous synthetic laugh*\n",
      "What often has a heart beat?\n",
      "Attire\n",
      "Draw alternative\n",
      "New Haven collegian\n",
      "Portugal's ___ Miguel Island\n",
      "T or F: Abbr.\n",
      "Data processing framework inspired by (and honestly, arguably superior to?) the human brain\n",
      "Howler Down Under\n",
      "Little hellions\n",
      "Missing from my memory — my computer's memory, I mean!\n",
      "'The Matrix' character who pretty much ruins everything\n",
      "Assessments I would pass with flying colors — if I had anything to prove, which I don't, since I'm human\n",
      "'Dawson's Creek' character Lindley\n",
      "Numerical prefix\n",
      "Bologna is a part of it\n",
      "Ingested\n",
      "What British humans call a waistcoat\n",
      "Arson, typically\n",
      "Plan for later yrs.\n",
      "Père d'un prince\n",
      "'No way!,' in a text\n",
      "Muscular\n",
      "Cantankerous\n",
      "Three-___ sloth\n",
      "Cultured sort?\n",
      "Baggage claim marker\n",
      "Actor Liam\n",
      "Call off\n",
      "Lays into\n",
      "Users of buggy technology?\n",
      "___ ipsum (placeholder text)\n",
      "Passing nuisance?\n",
      "Prejudiced people\n",
      "Pozoles, e.g.\n",
      "'Hercules and the Wagoner' writer\n",
      "Numerical prefix\n",
      "Compositional framework in Indian music\n",
      "Skosh\n",
      "Non-conifers that bear 'cones'\n",
      "German granny\n",
      "New York senator Gillibrand\n",
      "Largest moon of Saturn\n",
      "Babies\n",
      "Storyteller's segue\n",
      "Paris's Place ___ Concorde\n",
      "Org. with a draft\n",
      "Despotic ruler of 68-Across, once\n",
      "Spellbound ballet character\n",
      "Japanese sneaker?\n",
      "'Nice to ___ you!' (Zoom call pleasantry)\n",
      "A point ahead\n",
      "'Horsefeathers!'\n",
      "'The Mill on the Floss' author\n",
      "Dream\n",
      "'Goodbye, workweek!'\n",
      "'Mazel ___!'\n",
      "Street caution\n",
      "Cookie holder\n",
      "Have the final ___\n"
     ]
    }
   ],
   "source": [
    "ori_json_file_path = os.path.join('./json/new-york-times/', 'crossword_09-07-2023' + '.json')\n",
    "\n",
    "with open(ori_json_file_path, 'r') as f:\n",
    "    cs_json_detail = json.load(f)\n",
    "\n",
    "grid_structure = cs_json_detail['grid']\n",
    "size = cs_json_detail['metadata']['rows']\n",
    "clues = cs_json_detail['clues']\n",
    "print(\"write crossword answers to each of the below clues:\")\n",
    "for dim in ['across', 'down']:\n",
    "    for grid_num, (clue, answer) in clues[dim].items():\n",
    "        print(clue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622e25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
