{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2e74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import puz\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219ceae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Second pass model outputs\\atlantic_crossword_test.txt\n",
      "./Second pass model outputs\\newsday_crossword_test.txt\n",
      "./Second pass model outputs\\nyt_crossword_test.txt\n",
      "./Second pass model outputs\\thelatimes_crossword_test.txt\n",
      "./Second pass model outputs\\thenewyorker_crossword_test.txt\n"
     ]
    }
   ],
   "source": [
    "all_txt_files = glob.glob('./Second pass model outputs/*.txt')\n",
    "for txt_files in all_txt_files:\n",
    "    if '_test.txt' in txt_files:\n",
    "        print(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b032100",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PUB_PATHS = {\n",
    "    'Atlantic': \"./Second pass model outputs/atlantic_crossword_test.txt\",\n",
    "    'News Day' : \"./Second pass model outputs/newsday_crossword_test.txt\",\n",
    "    \"The LA Times\" : \"./Second pass model outputs/thelatimes_crossword_test.txt\",\n",
    "    \"The New Yorker\" : \"./Second pass model outputs/thenewyorker_crossword_test.txt\"\n",
    "#     \"New York Times\" : \"./Second pass model outputs/nyt_crossword_test.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5abd116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_float(input_string):\n",
    "    pattern = r\"\\d+\\.\\d+\"\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    float_numbers = [float(match) for match in matches]\n",
    "    return float_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b264bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(lines):\n",
    "    date_pattern = r\"\\b\\d{2}/\\d{2}/\\d{4}\\b\"\n",
    "    data_dict = {}\n",
    "    new_date_math = False\n",
    "    current_date = ''\n",
    "    error_dates = []\n",
    "\n",
    "    for line in lines:\n",
    "        if 'error' in line:\n",
    "            match = re.search(date_pattern, line)\n",
    "            error_dates.append(match.group())\n",
    "\n",
    "    for line in lines:\n",
    "        match = re.match(date_pattern, line) # to match the date pattern\n",
    "\n",
    "        if match:\n",
    "            current_date = line.strip()\n",
    "            data_dict[current_date] = {}\n",
    "            data_dict[current_date]['Letter II'] = []\n",
    "            data_dict[current_date]['Word II'] = []\n",
    "\n",
    "\n",
    "        if 'Before' in line:\n",
    "            [lett_accu, word_accu] = extract_float(line)\n",
    "            data_dict[current_date]['Before Letter Accuracy'] = lett_accu\n",
    "            data_dict[current_date]['Before Word Accuracy'] = word_accu\n",
    "\n",
    "        if 'iteration:' in line:\n",
    "            lett_accu, word_accu = extract_float(line)\n",
    "            data_dict[current_date]['Letter II'].append(lett_accu)\n",
    "            data_dict[current_date]['Word II'].append(word_accu)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc86e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_data(data_dict, threshold = 85.0):\n",
    "    output_data = []\n",
    "    for date, inf_data in data_dict.items():\n",
    "\n",
    "        if len(inf_data.keys()) < 4:\n",
    "            continue\n",
    "\n",
    "        # only first pass model output exists\n",
    "        if len(inf_data['Letter II']) == 0:\n",
    "            f_pass_l_accu = round(inf_data['Before Letter Accuracy'], 2)\n",
    "            f_pass_w_accu = round(inf_data['Before Word Accuracy'], 2)\n",
    "\n",
    "            s_pass_l_accu = f_pass_l_accu\n",
    "            s_pass_w_accu = f_pass_w_accu\n",
    "            output_data.append((date, f_pass_l_accu, f_pass_w_accu, s_pass_l_accu, s_pass_w_accu))\n",
    "        else:\n",
    "            f_pass_l_accu = round(inf_data['Before Letter Accuracy'], 2)\n",
    "            f_pass_w_accu = round(inf_data['Before Word Accuracy'], 2)\n",
    "\n",
    "            s_pass_l_list = inf_data['Letter II']\n",
    "            s_pass_w_list = inf_data['Word II']\n",
    "            max_accu_index = s_pass_l_list.index(max(s_pass_l_list))\n",
    "\n",
    "            s_pass_l_accu = round(s_pass_l_list[max_accu_index], 2)\n",
    "            s_pass_w_accu = round(s_pass_w_list[max_accu_index], 2)\n",
    "\n",
    "            if s_pass_l_accu < f_pass_l_accu:\n",
    "                s_pass_l_accu = f_pass_l_accu\n",
    "                s_pass_w_accu = f_pass_w_accu\n",
    "\n",
    "            output_data.append((date, f_pass_l_accu, f_pass_w_accu, s_pass_l_accu, s_pass_w_accu))\n",
    "            \n",
    "    df = pd.DataFrame(output_data, columns = ['Date', 'First Pass Letter Accuracy', 'First Pass Word Accuracy', 'Second Pass Letter Accuracy', 'Second Pass Word Accuracy'])\n",
    "\n",
    "    # taking a heuristic that, word accuracies lower than 85 are invalid due to crossword invalidity\n",
    "    df = df[df['First Pass Word Accuracy'] > threshold]\n",
    "    \n",
    "    # first find the number of cells which has 100% accuracies`\n",
    "    pp_count_by_f_pass = len(df[df['First Pass Letter Accuracy'] == 100.0])\n",
    "    pp_count_by_s_pass = len(df[df['Second Pass Letter Accuracy'] == 100.0])\n",
    "    total_test_size = len(df)\n",
    "    \n",
    "    avg_pp_accu_f_pass = round((pp_count_by_f_pass / total_test_size) * 100, 2)\n",
    "    avg_pp_accu_s_pass = round((pp_count_by_s_pass / total_test_size) * 100, 2)\n",
    "\n",
    "    f_pass_lett = round(np.mean(df['First Pass Letter Accuracy']), 2)\n",
    "    f_pass_word = round(np.mean(df['First Pass Word Accuracy']), 2)\n",
    "\n",
    "    s_pass_lett = round(np.mean(df['Second Pass Letter Accuracy']), 2)\n",
    "    s_pass_word = round(np.mean(df['Second Pass Word Accuracy']), 2)\n",
    "    print('Total Number of puzzles: ', total_test_size)\n",
    "    print(\"Perfect Puzzle Accuracy (First Pass Model): \", avg_pp_accu_f_pass)\n",
    "    print(\"Perfect Puzzle Accuracy (Second Pass Model): \", avg_pp_accu_s_pass)\n",
    "\n",
    "    print(\"\\nLetter Accuracy (First Pass Model): \", f_pass_lett)\n",
    "    print(\"Word Accuracy (First Pass Model): \", f_pass_word)\n",
    "\n",
    "    print(\"\\nLetter Accuracy (Second Pass Model): \", s_pass_lett)\n",
    "    print(\"Word Accuracy (Second Pass Model): \", s_pass_word)\n",
    "    \n",
    "    return [f_pass_lett, f_pass_word, avg_pp_accu_f_pass, s_pass_lett, s_pass_word, avg_pp_accu_s_pass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d298a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Atlantic\n",
      "\n",
      "Total Number of puzzles:  89\n",
      "Perfect Puzzle Accuracy (First Pass Model):  76.4\n",
      "Perfect Puzzle Accuracy (Second Pass Model):  91.01\n",
      "\n",
      "Letter Accuracy (First Pass Model):  99.49\n",
      "Word Accuracy (First Pass Model):  97.8\n",
      "\n",
      "Letter Accuracy (Second Pass Model):  99.86\n",
      "Word Accuracy (Second Pass Model):  99.34\n",
      "----------------------------------------------------------------------------------------------------\n",
      "News Day\n",
      "\n",
      "Total Number of puzzles:  100\n",
      "Perfect Puzzle Accuracy (First Pass Model):  75.0\n",
      "Perfect Puzzle Accuracy (Second Pass Model):  90.0\n",
      "\n",
      "Letter Accuracy (First Pass Model):  99.73\n",
      "Word Accuracy (First Pass Model):  98.91\n",
      "\n",
      "Letter Accuracy (Second Pass Model):  99.93\n",
      "Word Accuracy (Second Pass Model):  99.66\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The LA Times\n",
      "\n",
      "Total Number of puzzles:  140\n",
      "Perfect Puzzle Accuracy (First Pass Model):  80.71\n",
      "Perfect Puzzle Accuracy (Second Pass Model):  97.14\n",
      "\n",
      "Letter Accuracy (First Pass Model):  99.81\n",
      "Word Accuracy (First Pass Model):  99.23\n",
      "\n",
      "Letter Accuracy (Second Pass Model):  99.99\n",
      "Word Accuracy (Second Pass Model):  99.93\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The New Yorker\n",
      "\n",
      "Total Number of puzzles:  79\n",
      "Perfect Puzzle Accuracy (First Pass Model):  55.7\n",
      "Perfect Puzzle Accuracy (Second Pass Model):  79.75\n",
      "\n",
      "Letter Accuracy (First Pass Model):  99.36\n",
      "Word Accuracy (First Pass Model):  97.61\n",
      "\n",
      "Letter Accuracy (Second Pass Model):  99.81\n",
      "Word Accuracy (Second Pass Model):  99.18\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thresholds = [85.0, 85.0, 0, 90.0, 80.0]\n",
    "accumulative_data = []\n",
    "for i, (publication, path) in enumerate(TEST_PUB_PATHS.items()):\n",
    "    if i == 0:\n",
    "        print('-'*100)\n",
    "    print(publication, end = '\\n\\n')\n",
    "    txt_path = TEST_PUB_PATHS[publication]\n",
    "    all_lines = open(txt_path, 'r').readlines()\n",
    "\n",
    "    data_dict = extract_data(all_lines)\n",
    "    main_data = get_df_data(data_dict, thresholds[i])\n",
    "    \n",
    "    accumulative_data.append((publication, *main_data))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bba2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_df = pd.DataFrame(accumulative_data, columns = ['Source', 'First Pass Letter Accuracy', 'First Pass Word Accuracy', 'First Pass Perfect Puzzle Accuracy', 'Second Pass Letter Accuracy', 'Second Pass Word Accuracy', 'Second Pass Perfect Puzzle Accuracy'])\n",
    "# last_df.to_csv(\"./Second pass model outputs/all_publication_inference_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b9f59",
   "metadata": {},
   "source": [
    "### Captures the Letter, Word and Perfect Puzzle Accuracies based on the Corresponding Grid Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd5d31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def puz_to_json(fname):\n",
    "    \"\"\" Converts a puzzle in .puz format to .json format\n",
    "    \"\"\"\n",
    "    p = puz.read(fname)\n",
    "    numbering = p.clue_numbering()\n",
    "\n",
    "    grid = [[None for _ in range(p.width)] for _ in range(p.height)]\n",
    "    for row_idx in range(p.height):\n",
    "        cell = row_idx * p.width\n",
    "        row_solution = p.solution[cell:cell + p.width]\n",
    "        for col_index, item in enumerate(row_solution):\n",
    "            if p.solution[cell + col_index:cell + col_index + 1] == '.':\n",
    "                grid[row_idx][col_index] = 'BLACK'\n",
    "            else:\n",
    "                grid[row_idx][col_index] = [\"\", row_solution[col_index: col_index + 1]]\n",
    "\n",
    "    across_clues = {}\n",
    "    for clue in numbering.across:\n",
    "        answer = ''.join(p.solution[clue['cell'] + i] for i in range(clue['len']))\n",
    "        across_clues[str(clue['num'])] = [clue['clue'] + ' ', ' ' + answer]\n",
    "        grid[int(clue['cell'] / p.width)][clue['cell'] % p.width][0] = str(clue['num'])\n",
    "\n",
    "    down_clues = {}\n",
    "    for clue in numbering.down:\n",
    "        answer = ''.join(p.solution[clue['cell'] + i * numbering.width] for i in range(clue['len']))\n",
    "        down_clues[str(clue['num'])] = [clue['clue'] + ' ', ' ' + answer]\n",
    "        grid[int(clue['cell'] / p.width)][clue['cell'] % p.width][0] = str(clue['num'])\n",
    "\n",
    "\n",
    "    mydict = {'metadata': {'date': None, 'rows': p.height, 'cols': p.width}, 'clues': {'across': across_clues, 'down': down_clues}, 'grid': grid}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf6dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corresponding_grid_size(data_dict, folder_name):\n",
    "    for key, value in data_dict.items():\n",
    "        puz_path = os.path.join(PUZ_DIR, folder_name, f\"crossword_{key.replace('/', '-')}.puz\")\n",
    "        if os.path.exists(puz_path):\n",
    "            puzzle = puz_to_json(puz_path)\n",
    "            no_rows = puzzle['metadata']['rows']\n",
    "            no_cols = puzzle['metadata']['cols']\n",
    "            data_dict[key]['size'] = (no_rows, no_cols)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b542eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_by_grid_size(data_dict):\n",
    "    '''\n",
    "    Sorts the given dictionary map between date and inference results according to the size \n",
    "    and creates a list of dictionary for each size possible.\n",
    "    '''\n",
    "    sorted_dictionary = defaultdict(list)\n",
    "    for date, inf_result in data_dict.items():\n",
    "        sorted_dictionary[inf_result['size']].append({'date': date, \n",
    "                                                     'result': inf_result})\n",
    "    return sorted_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "198790f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZ_DIR = \"../Crossword Scrapper/puz\"\n",
    "# publication = 'Atlantic'\n",
    "# if os.path.exists(PUZ_DIR):\n",
    "#     puz_path_list = glob.glob(os.path.join(PUZ_DIR, publication, '*.puz'))\n",
    "#     puz_path_list = [path for path in puz_path_list if '2023' in path]\n",
    "    \n",
    "# test_path = puz_path_list[0]\n",
    "# test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6587ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Atlantic\n",
      "\n",
      "[['Atlantic', (5, 5), 18, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0],\n",
      " ['Atlantic', (6, 6), 20, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0],\n",
      " ['Atlantic', (7, 7), 19, 89.47, 89.47, 98.72, 98.72, 99.74, 99.74],\n",
      " ['Atlantic', (8, 8), 14, 57.14, 100.0, 95.48, 100.0, 99.0, 100.0],\n",
      " ['Atlantic', (9, 9), 9, 55.56, 88.89, 95.71, 99.18, 99.05, 99.84],\n",
      " ['Atlantic', (11, 11), 1, 0.0, 0.0, 89.47, 94.74, 97.2, 99.07],\n",
      " ['Atlantic', (12, 12), 3, 0.0, 66.67, 93.18, 97.73, 98.4, 99.44],\n",
      " ['Atlantic', (15, 15), 5, 0.0, 40.0, 92.27, 96.95, 97.9, 99.28]]\n",
      "News Day\n",
      "\n",
      "[['News Day', (15, 15), 86, 74.42, 89.53, 98.86, 99.63, 99.71, 99.92],\n",
      " ['News Day', (21, 21), 14, 78.57, 92.86, 99.23, 99.9, 99.82, 99.98]]\n",
      "The LA Times\n",
      "\n",
      "../Crossword Scrapper/puz\\the_new_yorker\n",
      "[['The LA Times', (15, 15), 86, 74.42, 89.53, 98.86, 99.63, 99.71, 99.92],\n",
      " ['The LA Times', (21, 21), 14, 78.57, 92.86, 99.23, 99.9, 99.82, 99.98]]\n",
      "The New Yorker\n",
      "\n",
      "[['The New Yorker', (15, 15), 79, 50.63, 69.62, 96.49, 98.52, 98.98, 99.64],\n",
      " ['The New Yorker', (15, 16), 9, 44.44, 88.89, 97.14, 99.37, 99.36, 99.82],\n",
      " ['The New Yorker', (16, 16), 1, 0.0, 100.0, 91.67, 100.0, 97.88, 100.0]]\n"
     ]
    }
   ],
   "source": [
    "folder_names = ['atlantic', 'newsday', 'the_new_yorker', 'the-LA-times']\n",
    "for i, (publication, path) in enumerate(TEST_PUB_PATHS.items()):\n",
    "    if i == 0:\n",
    "        print('-'*100)\n",
    "        \n",
    "    print(publication, end = '\\n\\n')\n",
    "    txt_path = TEST_PUB_PATHS[publication]\n",
    "    all_lines = open(txt_path, 'r').readlines() # scape all the inference lines from the corresponding file\n",
    "\n",
    "    data_dict = extract_data(all_lines) # extract all the data into a dictionary\n",
    "    data_dict = find_corresponding_grid_size(data_dict, folder_names[i]) # find and add the corresponding gridsize\n",
    "    try:\n",
    "        sorted_dict_data = sort_dict_by_grid_size(data_dict) # sort and bucket the overall-data according to gridsize\n",
    "    except:\n",
    "        print(os.path.join(PUZ_DIR, folder_names[i]))\n",
    "\n",
    "    output_data = []\n",
    "    for grid_size, data_list in sorted_dict_data.items():\n",
    "        total_puzzle_by_grid_size = len(data_list)\n",
    "        accumulative_data = []\n",
    "        for data in data_list:\n",
    "            date = data['date']\n",
    "            inf_data = data['result']\n",
    "\n",
    "            if len(inf_data['Letter II']) == 0:\n",
    "                f_pass_l_accu = round(inf_data['Before Letter Accuracy'], 2)\n",
    "                f_pass_w_accu = round(inf_data['Before Word Accuracy'], 2)\n",
    "\n",
    "                s_pass_l_accu = f_pass_l_accu\n",
    "                s_pass_w_accu = f_pass_w_accu\n",
    "                accumulative_data.append((date, f_pass_l_accu, f_pass_w_accu, s_pass_l_accu, s_pass_w_accu))\n",
    "            else:\n",
    "                f_pass_l_accu = round(inf_data['Before Letter Accuracy'], 2)\n",
    "                f_pass_w_accu = round(inf_data['Before Word Accuracy'], 2)\n",
    "\n",
    "                s_pass_l_list = inf_data['Letter II']\n",
    "                s_pass_w_list = inf_data['Word II']\n",
    "                max_accu_index = s_pass_l_list.index(max(s_pass_l_list))\n",
    "\n",
    "                s_pass_l_accu = round(s_pass_l_list[max_accu_index], 2)\n",
    "                s_pass_w_accu = round(s_pass_w_list[max_accu_index], 2)\n",
    "\n",
    "                if s_pass_l_accu < f_pass_l_accu:\n",
    "                    s_pass_l_accu = f_pass_l_accu\n",
    "                    s_pass_w_accu = f_pass_w_accu\n",
    "                accumulative_data.append((date, f_pass_l_accu, f_pass_w_accu, s_pass_l_accu, s_pass_w_accu))\n",
    "\n",
    "        df = pd.DataFrame(accumulative_data, columns = ['Date', 'First Pass Letter Accuracy', 'First Pass Word Accuracy', 'Second Pass Letter Accuracy', 'Second Pass Word Accuracy'])\n",
    "\n",
    "        # taking a heuristic that, word accuracies lower than 85 are invalid due to crossword invalidity\n",
    "        df = df[df['First Pass Word Accuracy'] > 85.0]\n",
    "\n",
    "        # first find the number of cells which has 100% accuracies`\n",
    "        pp_count_by_f_pass = len(df[df['First Pass Letter Accuracy'] == 100.0])\n",
    "        pp_count_by_s_pass = len(df[df['Second Pass Letter Accuracy'] == 100.0])\n",
    "        total_grids = len(df)\n",
    "\n",
    "        avg_pp_accu_f_pass = round((pp_count_by_f_pass / total_grids) * 100, 2)\n",
    "        avg_pp_accu_s_pass = round((pp_count_by_s_pass / total_grids) * 100, 2)\n",
    "\n",
    "        f_pass_lett = round(np.mean(df['First Pass Letter Accuracy']), 2)\n",
    "        f_pass_word = round(np.mean(df['First Pass Word Accuracy']), 2)\n",
    "\n",
    "        s_pass_lett = round(np.mean(df['Second Pass Letter Accuracy']), 2)\n",
    "        s_pass_word = round(np.mean(df['Second Pass Word Accuracy']), 2)\n",
    "\n",
    "        output_data.append([publication, grid_size, total_grids, avg_pp_accu_f_pass, avg_pp_accu_s_pass, f_pass_word, s_pass_word, f_pass_lett, s_pass_lett])\n",
    "\n",
    "    sorted_data = sorted(output_data, key=lambda x: x[1])\n",
    "    pprint(sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32f95910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': None, 'rows': 15, 'cols': 16}\n",
      "../Crossword Scrapper/puz\\the_new_yorker\\crossword_09-01-2023.puz\n",
      "T | A | C | O | M | A | 0 | W | A | R | T | 0 | P | U | L | L | \n",
      " ------------------------------------------------------------\n",
      "I | S | O | B | A | R | 0 | I | N | E | E | D | A | N | A | P | \n",
      " ------------------------------------------------------------\n",
      "S | H | R | I | N | K | I | N | G | F | E | E | L | I | N | G | \n",
      " ------------------------------------------------------------\n",
      "H | E | N | S | 0 | S | O | O | 0 | R | N | A | 0 | T | E | A | \n",
      " ------------------------------------------------------------\n",
      "0 | 0 | B | P | A | 0 | T | U | B | A | 0 | L | E | S | S | 0 | \n",
      " ------------------------------------------------------------\n",
      "C | H | R | O | M | E | A | T | A | C | O | S | T | 0 | 0 | 0 | \n",
      " ------------------------------------------------------------\n",
      "R | O | E | 0 | M | R | S | 0 | A | T | M | 0 | T | C | B | Y | \n",
      " ------------------------------------------------------------\n",
      "O | R | A | T | O | R | 0 | 0 | 0 | 0 | A | Z | A | L | E | A | \n",
      " ------------------------------------------------------------\n",
      "W | A | D | E | 0 | O | B | O | 0 | A | H | A | 0 | E | A | R | \n",
      " ------------------------------------------------------------\n",
      "0 | 0 | 0 | S | H | R | U | B | S | T | A | N | D | A | R | D | \n",
      " ------------------------------------------------------------\n",
      "0 | E | T | T | U | 0 | S | I | T | E | 0 | Y | E | R | 0 | 0 | \n",
      " ------------------------------------------------------------\n",
      "A | N | A | 0 | M | E | T | 0 | R | I | O | 0 | M | A | R | T | \n",
      " ------------------------------------------------------------\n",
      "C | E | L | L | P | H | O | N | E | T | H | R | O | W | E | R | \n",
      " ------------------------------------------------------------\n",
      "T | R | E | E | H | O | U | S | E | 0 | M | A | N | A | G | E | \n",
      " ------------------------------------------------------------\n",
      "S | O | S | O | 0 | W | R | A | P | 0 | Y | E | S | Y | E | S | \n",
      " ------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for path in glob.glob(os.path.join(PUZ_DIR, 'the_new_yorker', '*puz')):\n",
    "    \n",
    "    meta_data = puz_to_json(path)['metadata']\n",
    "    if meta_data['rows'] != meta_data['cols']:\n",
    "        print(meta_data)\n",
    "        print(path)\n",
    "        grid = puz_to_json(path)['grid']\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                if grid[i][j] == 'BLACK':\n",
    "                    print(0, end = ' | ')\n",
    "                else:\n",
    "                    print(grid[i][j][1], end = ' | ')\n",
    "            print('\\n', '-'*60)\n",
    "        \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
