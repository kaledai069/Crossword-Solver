{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330f23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import seaborn as sns\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3888bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(r\"C:\\Users\\parzi\\OneDrive - Tribhuvan University\\Desktop\\Major Project\\CODE\\BCS Code\\BCS-ALL-Code\\Crossword Solver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83b20a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Second pass model outputs\\\\ByT5 Console Output.txt',\n",
       " './Second pass model outputs\\\\byt5 multi iteration data.txt',\n",
       " './Second pass model outputs\\\\T5 Console Output.txt',\n",
       " './Second pass model outputs\\\\t5 full dateaset word segment.txt',\n",
       " './Second pass model outputs\\\\t5 multi iteration 70 percentage data trained on.txt',\n",
       " './Second pass model outputs\\\\t5 multi iteration data segmented answer model.txt',\n",
       " './Second pass model outputs\\\\t5 multi iteration data segmented answer model_2.txt',\n",
       " './Second pass model outputs\\\\t5 multi iteration data word segmented.txt',\n",
       " './Second pass model outputs\\\\t5 multi iteration data.txt',\n",
       " './Second pass model outputs\\\\t5 multi iteration wod segmented 2 epochs.txt',\n",
       " './Second pass model outputs\\\\t5 training output.txt',\n",
       " './Second pass model outputs\\\\t5_small on all dataset training.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('./Second pass model outputs/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bf0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_float(input_string):\n",
    "    pattern = r\"\\d+\\.\\d+\"\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    float_numbers = [float(match) for match in matches]\n",
    "    return float_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cd40de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_data(F_NAME):\n",
    "    # F_NAME = \"byt5 multi iteration data.txt\"\n",
    "    with open(F_NAME, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    date_pattern = r\"\\b\\d{2}/\\d{2}/\\d{4}\\b\"\n",
    "    data_dict = {}\n",
    "    new_date_math = False\n",
    "    current_date = ''\n",
    "\n",
    "    for line in lines:\n",
    "        match = re.match(date_pattern, line) # to match the date pattern\n",
    "\n",
    "        if match:\n",
    "            current_date = line.strip()\n",
    "            data_dict[current_date] = {}\n",
    "            data_dict[current_date]['Letter II'] = []\n",
    "            data_dict[current_date]['Word II'] = []\n",
    "\n",
    "        if 'Before' in line:\n",
    "            [lett_accu, word_accu] = extract_float(line)\n",
    "            data_dict[current_date]['Before Letter Accuracy'] = lett_accu\n",
    "            data_dict[current_date]['Before Word Accuracy'] = word_accu\n",
    "\n",
    "        if 'iteration:' in line:\n",
    "            lett_accu, word_accu = extract_float(line)\n",
    "            data_dict[current_date]['Letter II'].append(lett_accu)\n",
    "            data_dict[current_date]['Word II'].append(word_accu)\n",
    "            \n",
    "    max_length = 0\n",
    "    for key, value in data_dict.items():\n",
    "        if len(value['Letter II']) > max_length:\n",
    "            max_length = len(value['Letter II'])\n",
    "    \n",
    "    for key, value in data_dict.items():\n",
    "        if len(value['Letter II']) == 0:\n",
    "            print(value)\n",
    "            \n",
    "    # extending all the letter and word accuracy float values to the maxm length\n",
    "    for key, value in data_dict.items():\n",
    "        if len(value['Letter II']) < max_length:\n",
    "            if len(value['Letter II']) == 0:\n",
    "                last_lett_accu = value['Before Letter Accuracy']\n",
    "                last_word_accu = value['Before Word Accuracy']\n",
    "            else:\n",
    "                last_lett_accu = value['Letter II'][-1]\n",
    "                last_word_accu = value['Word II'][-1]\n",
    "                \n",
    "            for i in range(max_length - len(value['Letter II'])):\n",
    "                data_dict[key]['Letter II'].append(last_lett_accu)\n",
    "                data_dict[key]['Word II'].append(last_word_accu)\n",
    "\n",
    "    all_letter_accu_list = []\n",
    "    all_word_accu_list = []\n",
    "\n",
    "    for key, value in data_dict.items():\n",
    "        letter_accu_list = value['Letter II'].copy()\n",
    "        letter_accu_list.insert(0, value['Before Letter Accuracy'])\n",
    "        all_letter_accu_list.append(letter_accu_list)\n",
    "\n",
    "        word_accu_list = value['Word II'].copy()\n",
    "        word_accu_list.insert(0, value['Before Word Accuracy'])\n",
    "        all_word_accu_list.append(word_accu_list)\n",
    "    \n",
    "    all_letter_accu = np.array(all_letter_accu_list)\n",
    "    all_word_accu = np.array(all_word_accu_list)\n",
    "    avg_letter_accu = np.mean(all_letter_accu, axis = 0)\n",
    "    avg_word_accu = np.mean(all_word_accu, axis = 0)\n",
    "    \n",
    "    return avg_letter_accu, avg_word_accu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec0abe",
   "metadata": {},
   "source": [
    "#### T5_small trained on full dataset with Word Segmented vs ByT5_small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3646de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Letter II': [], 'Word II': [], 'Before Letter Accuracy': 100.0, 'Before Word Accuracy': 100.0}\n",
      "{'Letter II': [], 'Word II': [], 'Before Letter Accuracy': 100.0, 'Before Word Accuracy': 100.0}\n",
      "{'Letter II': [], 'Word II': [], 'Before Letter Accuracy': 100.0, 'Before Word Accuracy': 100.0}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (24,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m byt5_letter_list, byt5_word_list \u001b[38;5;241m=\u001b[39m get_mean_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Second pass model outputs/byt5 multi iteration data.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m t5_letter_list, t5_word_list \u001b[38;5;241m=\u001b[39m get_mean_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Second pass model outputs/t5 multi iteration wod segmented 2 epochs.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 59\u001b[0m, in \u001b[0;36mget_mean_data\u001b[1;34m(F_NAME)\u001b[0m\n\u001b[0;32m     56\u001b[0m     word_accu_list\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBefore Word Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     57\u001b[0m     all_word_accu_list\u001b[38;5;241m.\u001b[39mappend(word_accu_list)\n\u001b[1;32m---> 59\u001b[0m all_letter_accu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_letter_accu_list)\n\u001b[0;32m     60\u001b[0m all_word_accu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_word_accu_list)\n\u001b[0;32m     61\u001b[0m avg_letter_accu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(all_letter_accu, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (24,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "byt5_letter_list, byt5_word_list = get_mean_data(\"./Second pass model outputs/byt5 multi iteration data.txt\")\n",
    "t5_letter_list, t5_word_list = get_mean_data(\"./Second pass model outputs/t5 multi iteration wod segmented 2 epochs.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de43732",
   "metadata": {},
   "source": [
    "#### T5_small trained on 3M dataset for 2 epoch vs ByT5_small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc245ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "byt5_letter_list, byt5_word_list = get_mean_data(\"./Result and Analysis Section/Second pass model outputs/byt5 multi iteration data.txt\")\n",
    "t5_letter_list, t5_word_list = get_mean_data(\"./Result and Analysis Section/Second pass model outputs/t5 multi iteration data word segmented.txt\")\n",
    "t5_letter_list_1, t5_word_list_1 = get_mean_data(\"./Result and Analysis Section/Second pass model outputs/t5 multi iteration data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BYT5 graphical analysis on the iterative improvement steps\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (8, 4))\n",
    "\n",
    "plt.plot(byt5_letter_list, label = 'ByT5 - Letter', color = (56/255, 135/255, 190/255))\n",
    "plt.plot(t5_letter_list, label = 'T5 - Word Segment Answers', linestyle = '-.', color = (137/255, 185/255, 220/255))\n",
    "plt.plot(t5_letter_list_1, label = 'T5 - Unsegmented Answers', linestyle = '-.', color = (137/255, 135/255, 220/255))\n",
    "\n",
    "\n",
    "plt.plot(byt5_word_list, label = 'ByT5 - Word', color = (64/255, 120/255, 7/255))\n",
    "plt.plot(t5_word_list, label = 'T5 - Word Segment', linestyle = '-.', color = (89/255, 169/255, 10/255))\n",
    "plt.plot(t5_word_list_1, label = 'T5 - Unsegmented', linestyle = '-.', color = (89/255, 79/255, 10/255))\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "custom_xticks = ['Original\\nAccuracy', '1st\\nIteration', '2nd\\nIteration', '3rd\\nIteration', '4th\\nIteration', '5th\\nIteration']\n",
    "plt.xticks(range(len(custom_xticks)), custom_xticks)\n",
    "plt.yticks(np.arange(89, 100, 1))\n",
    "plt.xlabel(\"Iterative Improvement Steps\", font = {'weight':'bold'})\n",
    "plt.ylabel(\"Accuracy (%)\", font = {'weight':'bold'})\n",
    "# plt.title(\"Byt5 as Second Pass Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f3ab7",
   "metadata": {},
   "source": [
    "#### T5_small trained one full epoch with 64 batch size, with segmented answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "byt5_letter_list, byt5_word_list = get_mean_data(\"./Second pass model outputs/byt5 multi iteration data.txt\")\n",
    "t5_letter_list, t5_word_list = get_mean_data(\"./Second pass model outputs/t5 multi iteration data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BYT5 graphical analysis on the iterative improvement steps\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (8, 4))\n",
    "\n",
    "plt.plot(byt5_letter_list, label = 'Average Letter Accuracy')\n",
    "plt.plot(byt5_word_list, label = 'Average Word Accuracy')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "custom_xticks = ['Original\\nAccuracy', '1st\\nIteration', '2nd\\nIteration', '3rd\\nIteration', '4th\\nIteration', '5th\\nIteration']\n",
    "plt.xticks(range(len(custom_xticks)), custom_xticks)\n",
    "plt.yticks(np.arange(89, 100, 1))\n",
    "\n",
    "plt.title(\"Byt5 as Second Pass Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BYT5 graphical analysis on the iterative improvement steps\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (8, 4))\n",
    "\n",
    "plt.plot(t5_letter_list, label = 'Average Letter Accuracy')\n",
    "plt.plot(t5_word_list, label = 'Average Word Accuracy')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "custom_xticks = ['Original\\nAccuracy', '1st\\nIteration', '2nd\\nIteration', '3rd\\nIteration', '4th\\nIteration', '5th\\nIteration']\n",
    "plt.xticks(range(len(custom_xticks)), custom_xticks)\n",
    "plt.yticks(np.arange(89, 100, 1))\n",
    "\n",
    "plt.title(\"T5 as Second Pass Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1901a76",
   "metadata": {},
   "source": [
    "#### Comparison between ByT5 and T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BYT5 graphical analysis on the iterative improvement steps\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (8, 4))\n",
    "\n",
    "plt.plot(byt5_letter_list, label = 'ByT5 - Average letter accuracy', color = (56/255, 135/255, 190/255))\n",
    "plt.plot(t5_letter_list, label = 'T5 - Average letter accuracy', linestyle = '-.', color = (137/255, 185/255, 220/255))\n",
    "\n",
    "plt.plot(byt5_word_list, label = 'ByT5 - Average word accuracy', color = (64/255, 120/255, 7/255))\n",
    "plt.plot(t5_word_list, label = 'T5 - Average word accuracy', linestyle = '-.', color = (89/255, 169/255, 10/255))\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "custom_xticks = ['Original\\nAccuracy', '1st\\nIteration', '2nd\\nIteration', '3rd\\nIteration', '4th\\nIteration', '5th\\nIteration']\n",
    "plt.xticks(range(len(custom_xticks)), custom_xticks)\n",
    "plt.yticks(np.arange(89, 100, 1))\n",
    "plt.xlabel(\"Iterative Improvement Steps\", font = {'weight':'bold'})\n",
    "plt.ylabel(\"Accuracy (%)\", font = {'weight':'bold'})\n",
    "# plt.title(\"Byt5 as Second Pass Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67d3df",
   "metadata": {},
   "source": [
    "#### T5_small trained with segmented answer and tokenizer set to 32 sequence length for both input (clue) & label (answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_letter_list_1, t5_word_list_1 = get_mean_data(\"./Second pass model outputs/t5 multi iteration data segmented answer model.txt\")\n",
    "\n",
    "# BYT5 graphical analysis on the iterative improvement steps\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (8, 4))\n",
    "\n",
    "plt.plot(t5_letter_list_1, label = 'Average Letter Accuracy')\n",
    "plt.plot(t5_word_list_1, label = 'Average Word Accuracy')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "custom_xticks = ['Original\\nAccuracy', '1st\\nIteration', '2nd\\nIteration', '3rd\\nIteration']\n",
    "for i in range(4, len(t5_letter_list_1)):\n",
    "    custom_xticks.append(f\"{i}th\\nIteration\")\n",
    "    \n",
    "plt.xticks(range(len(custom_xticks)), custom_xticks)\n",
    "plt.yticks(np.arange(89, 100, 1))\n",
    "\n",
    "plt.title(\"T5 as Second Pass Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87cb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_letter_list_1, t5_word_list_1 = get_mean_data(\"./Second pass model outputs/t5 multi iteration data segmented answer model_2.txt\")\n",
    "\n",
    "# BYT5 graphical analysis on the iterative improvement steps\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (8, 4))\n",
    "\n",
    "plt.plot(t5_letter_list_1, label = 'Average Letter Accuracy')\n",
    "plt.plot(t5_word_list_1, label = 'Average Word Accuracy')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "custom_xticks = ['Original\\nAccuracy', '1st\\nIteration', '2nd\\nIteration', '3rd\\nIteration']\n",
    "for i in range(4, len(t5_letter_list_1)):\n",
    "    custom_xticks.append(f\"{i}th\\nIteration\")\n",
    "    \n",
    "plt.xticks(range(len(custom_xticks)), custom_xticks)\n",
    "plt.yticks(np.arange(89, 100, 1))\n",
    "\n",
    "plt.title(\"T5 as Second Pass Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b21bf6",
   "metadata": {},
   "source": [
    "#### Analyzing all the T5_small model iterative ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe893292",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_letter_list_0, t5_word_list_0 = get_mean_data(\"./Second pass model outputs/t5 multi iteration data.txt\")\n",
    "t5_letter_list_1, t5_word_list_1 = get_mean_data(\"./Second pass model outputs/t5 multi iteration data segmented answer model.txt\")\n",
    "t5_letter_list_2, t5_word_list_2 = get_mean_data(\"./Second pass model outputs/t5 multi iteration data segmented answer model_2.txt\")\n",
    "\n",
    "# BYT5 graphical analysis on the iterative improvement steps\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize = (8, 4))\n",
    "\n",
    "plt.plot(t5_letter_list_0, label = 'T5 - Unsegmented trained 32-bit')\n",
    "# plt.plot(t5_letter_list_1, label = 'T5 - Average letter accuracy', linestyle = '-.')\n",
    "plt.plot(t5_letter_list_2, label = 'T5 - Segmented trained tokenized set', linestyle = '--')\n",
    "\n",
    "plt.plot(t5_word_list_0, label = 'ByT5 - Average word accuracy')\n",
    "# plt.plot(t5_word_list_1, label = 'ByT5 - Average word accuracy', linestyle = '-.')\n",
    "plt.plot(t5_word_list_2, label = 'ByT5 - Average word accuracy', linestyle = '--')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "custom_xticks = ['Original\\nAccuracy', '1st\\nIteration', '2nd\\nIteration', '3rd\\nIteration', '4th\\nIteration', '5th\\nIteration']\n",
    "plt.xticks(range(len(custom_xticks)), custom_xticks)\n",
    "plt.yticks(np.arange(89, 100, 1))\n",
    "plt.xlabel(\"Iterative Improvement Steps\", font = {'weight':'bold'})\n",
    "plt.ylabel(\"Accuracy (%)\", font = {'weight':'bold'})\n",
    "# plt.title(\"Byt5 as Second Pass Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70045d0",
   "metadata": {},
   "source": [
    "<b>In every test upto this point, t5_small performed bad in compared to the byt5_small fine-tuned from the BCS. So, a possible improved training strategy could be to train the t5_small again without using sequence length restriction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
