{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2e74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import puz\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219ceae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Second pass model outputs\\atlantic_crossword_test.txt\n",
      "./Second pass model outputs\\newsday_crossword_test.txt\n",
      "./Second pass model outputs\\nyt_crossword_test.txt\n",
      "./Second pass model outputs\\thelatimes_crossword_test.txt\n",
      "./Second pass model outputs\\thenewyorker_crossword_test.txt\n"
     ]
    }
   ],
   "source": [
    "all_txt_files = glob.glob('./Second pass model outputs/*.txt')\n",
    "for txt_files in all_txt_files:\n",
    "    if '_test.txt' in txt_files:\n",
    "        print(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b032100",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PUB_PATHS = {\n",
    "    'Atlantic': \"./Second pass model outputs/atlantic_crossword_test.txt\",\n",
    "    'News Day' : \"./Second pass model outputs/newsday_crossword_test.txt\",\n",
    "    \"The LA Times\" : \"./Second pass model outputs/thelatimes_crossword_test.txt\",\n",
    "    \"The New Yorker\" : \"./Second pass model outputs/thenewyorker_crossword_test.txt\",\n",
    "#     \"New York Times\" : \"./Second pass model outputs/nyt_crossword_test.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5abd116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_float(input_string):\n",
    "    pattern = r\"\\d+\\.\\d+\"\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    float_numbers = [float(match) for match in matches]\n",
    "    return float_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b264bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(lines):\n",
    "    date_pattern = r\"\\b\\d{2}/\\d{2}/\\d{4}\\b\"\n",
    "    data_dict = {}\n",
    "    new_date_math = False\n",
    "    current_date = ''\n",
    "    error_dates = []\n",
    "\n",
    "    for line in lines:\n",
    "        if 'error' in line:\n",
    "            match = re.search(date_pattern, line)\n",
    "            error_dates.append(match.group())\n",
    "\n",
    "    for line in lines:\n",
    "        match = re.match(date_pattern, line) # to match the date pattern\n",
    "\n",
    "        if match:\n",
    "            current_date = line.strip()\n",
    "            data_dict[current_date] = {}\n",
    "            data_dict[current_date]['Letter II'] = []\n",
    "            data_dict[current_date]['Word II'] = []\n",
    "\n",
    "\n",
    "        if 'Before' in line:\n",
    "            [lett_accu, word_accu] = extract_float(line)\n",
    "            data_dict[current_date]['Before Letter Accuracy'] = lett_accu\n",
    "            data_dict[current_date]['Before Word Accuracy'] = word_accu\n",
    "\n",
    "        if 'iteration:' in line:\n",
    "            lett_accu, word_accu = extract_float(line)\n",
    "            data_dict[current_date]['Letter II'].append(lett_accu)\n",
    "            data_dict[current_date]['Word II'].append(word_accu)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc86e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_data(data_dict, threshold = 85.0):\n",
    "    output_data = []\n",
    "    for date, inf_data in data_dict.items():\n",
    "\n",
    "        if len(inf_data.keys()) < 4:\n",
    "            continue\n",
    "\n",
    "        # only first pass model output exists\n",
    "        if len(inf_data['Letter II']) == 0:\n",
    "            f_pass_l_accu = round(inf_data['Before Letter Accuracy'], 2)\n",
    "            f_pass_w_accu = round(inf_data['Before Word Accuracy'], 2)\n",
    "\n",
    "            s_pass_l_accu = f_pass_l_accu\n",
    "            s_pass_w_accu = f_pass_w_accu\n",
    "            output_data.append((date, f_pass_l_accu, f_pass_w_accu, s_pass_l_accu, s_pass_w_accu))\n",
    "        else:\n",
    "            f_pass_l_accu = round(inf_data['Before Letter Accuracy'], 2)\n",
    "            f_pass_w_accu = round(inf_data['Before Word Accuracy'], 2)\n",
    "\n",
    "            s_pass_l_list = inf_data['Letter II']\n",
    "            s_pass_w_list = inf_data['Word II']\n",
    "            max_accu_index = s_pass_l_list.index(max(s_pass_l_list))\n",
    "\n",
    "            s_pass_l_accu = round(s_pass_l_list[max_accu_index], 2)\n",
    "            s_pass_w_accu = round(s_pass_w_list[max_accu_index], 2)\n",
    "\n",
    "            if s_pass_l_accu < f_pass_l_accu:\n",
    "                s_pass_l_accu = f_pass_l_accu\n",
    "                s_pass_w_accu = f_pass_w_accu\n",
    "\n",
    "            output_data.append((date, f_pass_l_accu, f_pass_w_accu, s_pass_l_accu, s_pass_w_accu))\n",
    "            \n",
    "    df = pd.DataFrame(output_data, columns = ['Date', 'First Pass Letter Accuracy', 'First Pass Word Accuracy', 'Second Pass Letter Accuracy', 'Second Pass Word Accuracy'])\n",
    "\n",
    "    # taking a heuristic that, word accuracies lower than 85 are invalid due to crossword invalidity\n",
    "    df = df[df['First Pass Word Accuracy'] > threshold]\n",
    "    \n",
    "    # first find the number of cells which has 100% accuracies`\n",
    "    pp_count_by_f_pass = len(df[df['First Pass Letter Accuracy'] == 100.0])\n",
    "    pp_count_by_s_pass = len(df[df['Second Pass Letter Accuracy'] == 100.0])\n",
    "    total_test_size = len(df)\n",
    "    \n",
    "    avg_pp_accu_f_pass = round((pp_count_by_f_pass / total_test_size) * 100, 2)\n",
    "    avg_pp_accu_s_pass = round((pp_count_by_s_pass / total_test_size) * 100, 2)\n",
    "\n",
    "    f_pass_lett = round(np.mean(df['First Pass Letter Accuracy']), 2)\n",
    "    f_pass_word = round(np.mean(df['First Pass Word Accuracy']), 2)\n",
    "\n",
    "    s_pass_lett = round(np.mean(df['Second Pass Letter Accuracy']), 2)\n",
    "    s_pass_word = round(np.mean(df['Second Pass Word Accuracy']), 2)\n",
    "    print('Total Number of puzzles: ', total_test_size)\n",
    "    print(\"Perfect Puzzle Accuracy (First Pass Model): \", avg_pp_accu_f_pass)\n",
    "    print(\"Perfect Puzzle Accuracy (Second Pass Model): \", avg_pp_accu_s_pass)\n",
    "\n",
    "    print(\"\\nLetter Accuracy (First Pass Model): \", f_pass_lett)\n",
    "    print(\"Word Accuracy (First Pass Model): \", f_pass_word)\n",
    "\n",
    "    print(\"\\nLetter Accuracy (Second Pass Model): \", s_pass_lett)\n",
    "    print(\"Word Accuracy (Second Pass Model): \", s_pass_word)\n",
    "    \n",
    "    return [f_pass_lett, f_pass_word, avg_pp_accu_f_pass, s_pass_lett, s_pass_word, avg_pp_accu_s_pass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d298a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Atlantic\n",
      "\n",
      "Total Number of puzzles:  89\n",
      "Perfect Puzzle Accuracy (First Pass Model):  76.4\n",
      "Perfect Puzzle Accuracy (Second Pass Model):  91.01\n",
      "\n",
      "Letter Accuracy (First Pass Model):  99.49\n",
      "Word Accuracy (First Pass Model):  97.8\n",
      "\n",
      "Letter Accuracy (Second Pass Model):  99.86\n",
      "Word Accuracy (Second Pass Model):  99.34\n",
      "----------------------------------------------------------------------------------------------------\n",
      "News Day\n",
      "\n",
      "Total Number of puzzles:  100\n",
      "Perfect Puzzle Accuracy (First Pass Model):  75.0\n",
      "Perfect Puzzle Accuracy (Second Pass Model):  90.0\n",
      "\n",
      "Letter Accuracy (First Pass Model):  99.73\n",
      "Word Accuracy (First Pass Model):  98.91\n",
      "\n",
      "Letter Accuracy (Second Pass Model):  99.93\n",
      "Word Accuracy (Second Pass Model):  99.66\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The LA Times\n",
      "\n",
      "Total Number of puzzles:  140\n",
      "Perfect Puzzle Accuracy (First Pass Model):  80.71\n",
      "Perfect Puzzle Accuracy (Second Pass Model):  97.14\n",
      "\n",
      "Letter Accuracy (First Pass Model):  99.81\n",
      "Word Accuracy (First Pass Model):  99.23\n",
      "\n",
      "Letter Accuracy (Second Pass Model):  99.99\n",
      "Word Accuracy (Second Pass Model):  99.93\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The New Yorker\n",
      "\n",
      "Total Number of puzzles:  79\n",
      "Perfect Puzzle Accuracy (First Pass Model):  55.7\n",
      "Perfect Puzzle Accuracy (Second Pass Model):  79.75\n",
      "\n",
      "Letter Accuracy (First Pass Model):  99.36\n",
      "Word Accuracy (First Pass Model):  97.61\n",
      "\n",
      "Letter Accuracy (Second Pass Model):  99.81\n",
      "Word Accuracy (Second Pass Model):  99.18\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thresholds = [85.0, 85.0, 0, 90.0, 80.0]\n",
    "accumulative_data = []\n",
    "for i, (publication, path) in enumerate(TEST_PUB_PATHS.items()):\n",
    "    if i == 0:\n",
    "        print('-'*100)\n",
    "    print(publication, end = '\\n\\n')\n",
    "    txt_path = TEST_PUB_PATHS[publication]\n",
    "    all_lines = open(txt_path, 'r').readlines()\n",
    "\n",
    "    data_dict = extract_data(all_lines)\n",
    "    main_data = get_df_data(data_dict, thresholds[i])\n",
    "    \n",
    "    accumulative_data.append((publication, *main_data))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bba2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_df = pd.DataFrame(accumulative_data, columns = ['Source', 'First Pass Letter Accuracy', 'First Pass Word Accuracy', 'First Pass Perfect Puzzle Accuracy', 'Second Pass Letter Accuracy', 'Second Pass Word Accuracy', 'Second Pass Perfect Puzzle Accuracy'])\n",
    "# last_df.to_csv(\"./Second pass model outputs/all_publication_inference_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd10a60c",
   "metadata": {},
   "source": [
    "### Captures the Letter, Word and Perfect Puzzle Accuracies based on the Corresponding Grid Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "085a6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def puz_to_json(fname):\n",
    "    \"\"\" Converts a puzzle in .puz format to .json format\n",
    "    \"\"\"\n",
    "    p = puz.read(fname)\n",
    "    numbering = p.clue_numbering()\n",
    "\n",
    "    grid = [[None for _ in range(p.width)] for _ in range(p.height)]\n",
    "    for row_idx in range(p.height):\n",
    "        cell = row_idx * p.width\n",
    "        row_solution = p.solution[cell:cell + p.width]\n",
    "        for col_index, item in enumerate(row_solution):\n",
    "            if p.solution[cell + col_index:cell + col_index + 1] == '.':\n",
    "                grid[row_idx][col_index] = 'BLACK'\n",
    "            else:\n",
    "                grid[row_idx][col_index] = [\"\", row_solution[col_index: col_index + 1]]\n",
    "\n",
    "    across_clues = {}\n",
    "    for clue in numbering.across:\n",
    "        answer = ''.join(p.solution[clue['cell'] + i] for i in range(clue['len']))\n",
    "        across_clues[str(clue['num'])] = [clue['clue'] + ' ', ' ' + answer]\n",
    "        grid[int(clue['cell'] / p.width)][clue['cell'] % p.width][0] = str(clue['num'])\n",
    "\n",
    "    down_clues = {}\n",
    "    for clue in numbering.down:\n",
    "        answer = ''.join(p.solution[clue['cell'] + i * numbering.width] for i in range(clue['len']))\n",
    "        down_clues[str(clue['num'])] = [clue['clue'] + ' ', ' ' + answer]\n",
    "        grid[int(clue['cell'] / p.width)][clue['cell'] % p.width][0] = str(clue['num'])\n",
    "\n",
    "\n",
    "    mydict = {'metadata': {'date': None, 'rows': p.height, 'cols': p.width}, 'clues': {'across': across_clues, 'down': down_clues}, 'grid': grid}\n",
    "    \n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99d1854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corresponding_grid_size(data_dict, folder_name, DIR):\n",
    "    dont_exist = False\n",
    "    for key, value in data_dict.items():\n",
    "        path = os.path.join(DIR)\n",
    "        path += f\"{folder_name}/crossword_{key.replace('/', '-')}.puz\"\n",
    "        if os.path.exists(path.replace('\\t', '/t')):\n",
    "            puzzle = puz_to_json(path)   \n",
    "        else:\n",
    "            dont_exist = True\n",
    "                \n",
    "        if not dont_exist:\n",
    "            no_rows = puzzle['metadata']['rows']\n",
    "            no_cols = puzzle['metadata']['cols'] \n",
    "            data_dict[key]['size'] = (no_rows, no_cols)\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a79e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_by_grid_size(data_dict):\n",
    "    '''\n",
    "    Sorts the given dictionary map between date and inference results according to the size \n",
    "    and creates a list of dictionary for each size possible.\n",
    "    '''\n",
    "    sorted_dictionary = defaultdict(list)\n",
    "    for date, inf_result in data_dict.items():\n",
    "        sorted_dictionary[inf_result['size']].append({'date': date, \n",
    "                                                     'result': inf_result})\n",
    "\n",
    "    return sorted_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7891dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_by_size(publication, sorted_dict):\n",
    "    \n",
    "    output_data = []\n",
    "    for grid_size, data_list in sorted_dict_data.items():\n",
    "        total_puzzle_by_grid_size = len(data_list)\n",
    "        accumulative_data = []\n",
    "        for data in data_list:\n",
    "            date = data['date']\n",
    "            inf_data = data['result']\n",
    "            \n",
    "            try:\n",
    "                if len(inf_data['Letter II']) == 0:\n",
    "                    f_pass_l_accu = round(inf_data['Before Letter Accuracy'], 2)\n",
    "                    f_pass_w_accu = round(inf_data['Before Word Accuracy'], 2)\n",
    "\n",
    "                    s_pass_l_accu = f_pass_l_accu\n",
    "                    s_pass_w_accu = f_pass_w_accu\n",
    "                    accumulative_data.append((date, f_pass_l_accu, f_pass_w_accu, s_pass_l_accu, s_pass_w_accu))\n",
    "                else:\n",
    "                    f_pass_l_accu = round(inf_data['Before Letter Accuracy'], 2)\n",
    "                    f_pass_w_accu = round(inf_data['Before Word Accuracy'], 2)\n",
    "\n",
    "                    s_pass_l_list = inf_data['Letter II']\n",
    "                    s_pass_w_list = inf_data['Word II']\n",
    "                    max_accu_index = s_pass_l_list.index(max(s_pass_l_list))\n",
    "\n",
    "                    s_pass_l_accu = round(s_pass_l_list[max_accu_index], 2)\n",
    "                    s_pass_w_accu = round(s_pass_w_list[max_accu_index], 2)\n",
    "\n",
    "                    if s_pass_l_accu < f_pass_l_accu:\n",
    "                        s_pass_l_accu = f_pass_l_accu\n",
    "                        s_pass_w_accu = f_pass_w_accu\n",
    "                    accumulative_data.append((date, f_pass_l_accu, f_pass_w_accu, s_pass_l_accu, s_pass_w_accu))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        df = pd.DataFrame(accumulative_data, columns = ['Date', 'First Pass Letter Accuracy', 'First Pass Word Accuracy', 'Second Pass Letter Accuracy', 'Second Pass Word Accuracy'])\n",
    "\n",
    "        # taking a heuristic that, word accuracies lower than 85 are invalid due to crossword invalidity\n",
    "        df = df[df['First Pass Word Accuracy'] > 85.0]\n",
    "\n",
    "        # first find the number of cells which has 100% accuracies`\n",
    "        pp_count_by_f_pass = len(df[df['First Pass Letter Accuracy'] == 100.0])\n",
    "        pp_count_by_s_pass = len(df[df['Second Pass Letter Accuracy'] == 100.0])\n",
    "        total_grids = len(df)\n",
    "\n",
    "        avg_pp_accu_f_pass = round((pp_count_by_f_pass / total_grids) * 100, 2)\n",
    "        avg_pp_accu_s_pass = round((pp_count_by_s_pass / total_grids) * 100, 2)\n",
    "\n",
    "        f_pass_lett = round(np.mean(df['First Pass Letter Accuracy']), 2)\n",
    "        f_pass_word = round(np.mean(df['First Pass Word Accuracy']), 2)\n",
    "\n",
    "        s_pass_lett = round(np.mean(df['Second Pass Letter Accuracy']), 2)\n",
    "        s_pass_word = round(np.mean(df['Second Pass Word Accuracy']), 2)\n",
    "\n",
    "        output_data.append([publication, grid_size, total_grids, avg_pp_accu_f_pass, avg_pp_accu_s_pass, f_pass_word, s_pass_word, f_pass_lett, s_pass_lett])\n",
    "\n",
    "    sorted_data = sorted(output_data, key=lambda x: x[1])\n",
    "    return sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22a2cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZ_DIR = \"../Crossword Scrapper/puz/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3f75171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Atlantic\n",
      "\n",
      "News Day\n",
      "\n",
      "The LA Times\n",
      "\n",
      "The New Yorker\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_by_publication = {}\n",
    "\n",
    "folder_names = ['atlantic', 'newsday', 'the-LA-times', 'the_new_yorker']\n",
    "for i, (publication, path) in enumerate(TEST_PUB_PATHS.items()):\n",
    "    if i == 0:\n",
    "        print('-'*100)\n",
    "    print(publication, end = '\\n\\n')\n",
    "    \n",
    "    txt_path = TEST_PUB_PATHS[publication]\n",
    "    # scape all the inference lines from the corresponding file\n",
    "    all_lines = open(txt_path, 'r').readlines()\n",
    "    \n",
    "    # extract all the data into a dictionary\n",
    "    data_dict = extract_data(all_lines) \n",
    "\n",
    "    # find and add the corresponding gridsize for puz files\n",
    "    data_dict = find_corresponding_grid_size(data_dict, folder_names[i], PUZ_DIR) \n",
    "\n",
    "    # sort and bucket the overall-data according to gridsize\n",
    "    sorted_dict_data = sort_dict_by_grid_size(data_dict) \n",
    "\n",
    "    sorted_data = get_data_by_size(sorted_dict_data)\n",
    "    result_by_publication[publication] = sorted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f807c",
   "metadata": {},
   "source": [
    "#### Dealing with New York Times seperately for JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc3b1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_TXT_FILE_PATH = \"./Second pass model outputs/nyt_crossword_test.txt\"\n",
    "NYT_JSON_DIR = \"../Crossword Scrapper/json/new-york-times\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53189bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_size(date):\n",
    "    path = os.path.join(NYT_JSON_DIR, f\"crossword_{date.replace('/', '-')}.json\") \n",
    "    if os.path.exists(path):\n",
    "        puzzle = json.load(open(path, 'r'))\n",
    "        no_rows = puzzle['metadata']['rows']\n",
    "        no_cols = puzzle['metadata']['cols']\n",
    "    return (no_rows, no_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28c5037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The New Yorker', (15, 15), 110, 60.0, 84.55, 97.91, 99.29, 99.44, 99.78],\n",
       " ['The New Yorker', (21, 21), 13, 30.77, 84.62, 97.63, 99.67, 99.45, 99.91]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lines = open(NYT_TXT_FILE_PATH, 'r').readlines()\n",
    "data_dict = extract_data(all_lines) \n",
    "\n",
    "filtered_dict = {}\n",
    "for date, inf_data in data_dict.items():\n",
    "    if 'Before Letter Accuracy' in inf_data.keys():\n",
    "        grid_size = get_grid_size(date)\n",
    "        inf_data['size'] = grid_size\n",
    "        filtered_dict[date] = inf_data\n",
    "        \n",
    "sorted_dict_data = sort_dict_by_grid_size(filtered_dict) \n",
    "nyt_final_data = get_data_by_size(sorted_dict_data)\n",
    "result_by_publication['New York Times'] = nyt_final_data\n",
    "nyt_final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4199edb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atlantic': [['Atlantic',\n",
       "   (5, 5),\n",
       "   18,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0,\n",
       "   100.0],\n",
       "  ['Atlantic', (6, 6), 20, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0],\n",
       "  ['Atlantic', (7, 7), 19, 89.47, 89.47, 98.72, 98.72, 99.74, 99.74],\n",
       "  ['Atlantic', (8, 8), 14, 57.14, 100.0, 95.48, 100.0, 99.0, 100.0],\n",
       "  ['Atlantic', (9, 9), 9, 55.56, 88.89, 95.71, 99.18, 99.05, 99.84],\n",
       "  ['Atlantic', (11, 11), 1, 0.0, 0.0, 89.47, 94.74, 97.2, 99.07],\n",
       "  ['Atlantic', (12, 12), 3, 0.0, 66.67, 93.18, 97.73, 98.4, 99.44],\n",
       "  ['Atlantic', (15, 15), 5, 0.0, 40.0, 92.27, 96.95, 97.9, 99.28]],\n",
       " 'News Day': [['News Day',\n",
       "   (15, 15),\n",
       "   86,\n",
       "   74.42,\n",
       "   89.53,\n",
       "   98.86,\n",
       "   99.63,\n",
       "   99.71,\n",
       "   99.92],\n",
       "  ['News Day', (21, 21), 14, 78.57, 92.86, 99.23, 99.9, 99.82, 99.98]],\n",
       " 'The LA Times': [['The LA Times',\n",
       "   (15, 15),\n",
       "   108,\n",
       "   85.19,\n",
       "   98.15,\n",
       "   99.37,\n",
       "   99.95,\n",
       "   99.84,\n",
       "   99.99],\n",
       "  ['The LA Times', (15, 16), 11, 81.82, 90.91, 98.54, 99.75, 99.6, 99.96],\n",
       "  ['The LA Times', (16, 16), 1, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0],\n",
       "  ['The LA Times', (21, 21), 20, 55.0, 95.0, 98.84, 99.93, 99.73, 99.99]],\n",
       " 'The New Yorker': [['The New Yorker',\n",
       "   (15, 15),\n",
       "   86,\n",
       "   51.16,\n",
       "   70.93,\n",
       "   96.49,\n",
       "   98.58,\n",
       "   99.0,\n",
       "   99.65],\n",
       "  ['The New Yorker', (15, 16), 2, 0.0, 100.0, 97.41, 100.0, 99.51, 100.0],\n",
       "  ['The New Yorker', (16, 15), 1, 0.0, 100.0, 94.94, 100.0, 97.94, 100.0]],\n",
       " 'New York Times': [['The New Yorker',\n",
       "   (15, 15),\n",
       "   110,\n",
       "   60.0,\n",
       "   84.55,\n",
       "   97.91,\n",
       "   99.29,\n",
       "   99.44,\n",
       "   99.78],\n",
       "  ['The New Yorker', (21, 21), 13, 30.77, 84.62, 97.63, 99.67, 99.45, 99.91]]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for publication"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
