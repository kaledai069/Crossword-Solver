***** Training *****
***** Epoch 0 *****
0it [00:00, ?it/s]Epoch: 0: Step: 1/28124, loss=38.419178, lr=0.000000
99it [00:20,  5.32it/s]Train batch 100
Avg. loss per last 100 batches: 28.223371
100it [00:20,  5.30it/s]Epoch: 0: Step: 101/28124, loss=10.539208, lr=0.000002
199it [00:38,  5.66it/s]Train batch 200
Avg. loss per last 100 batches: 5.402736
200it [00:38,  5.67it/s]Epoch: 0: Step: 201/28124, loss=4.222236, lr=0.000003
299it [00:56,  5.67it/s]Train batch 300
Avg. loss per last 100 batches: 4.183310
300it [00:56,  5.65it/s]Epoch: 0: Step: 301/28124, loss=4.167340, lr=0.000005
399it [01:13,  5.69it/s]Train batch 400
Avg. loss per last 100 batches: 4.100796
400it [01:13,  5.67it/s]Epoch: 0: Step: 401/28124, loss=4.215478, lr=0.000006
499it [01:31,  5.72it/s]Train batch 500
Avg. loss per last 100 batches: 3.963280
500it [01:31,  5.72it/s]Epoch: 0: Step: 501/28124, loss=3.835551, lr=0.000008
599it [01:48,  5.71it/s]Train batch 600
Avg. loss per last 100 batches: 3.814508
600it [01:49,  5.72it/s]Epoch: 0: Step: 601/28124, loss=3.977399, lr=0.000010
699it [02:06,  5.73it/s]Train batch 700
Avg. loss per last 100 batches: 3.738006
700it [02:06,  5.72it/s]Epoch: 0: Step: 701/28124, loss=3.587446, lr=0.000011
799it [02:24,  5.76it/s]Train batch 800
Avg. loss per last 100 batches: 3.686534
800it [02:24,  5.75it/s]Epoch: 0: Step: 801/28124, loss=3.842905, lr=0.000013
899it [02:41,  5.74it/s]Train batch 900
Avg. loss per last 100 batches: 3.640182
900it [02:41,  5.74it/s]Epoch: 0: Step: 901/28124, loss=3.694134, lr=0.000015
999it [02:59,  5.37it/s]Train batch 1000
Avg. loss per last 100 batches: 3.573045
1000it [02:59,  5.40it/s]Epoch: 0: Step: 1001/28124, loss=3.533190, lr=0.000016
1099it [03:16,  5.73it/s]Train batch 1100
Avg. loss per last 100 batches: 3.518470
1100it [03:16,  5.73it/s]Epoch: 0: Step: 1101/28124, loss=3.566299, lr=0.000018
1199it [03:34,  5.73it/s]Train batch 1200
Avg. loss per last 100 batches: 3.532483
1200it [03:34,  5.73it/s]Epoch: 0: Step: 1201/28124, loss=3.364482, lr=0.000019
1299it [03:51,  5.73it/s]Train batch 1300
Avg. loss per last 100 batches: 3.474149
1300it [03:51,  5.73it/s]Epoch: 0: Step: 1301/28124, loss=3.211582, lr=0.000020
1399it [04:09,  5.74it/s]Train batch 1400
Avg. loss per last 100 batches: 3.470386
1400it [04:09,  5.75it/s]Epoch: 0: Step: 1401/28124, loss=3.404721, lr=0.000020
1499it [04:26,  5.75it/s]Train batch 1500
Avg. loss per last 100 batches: 3.426553
1500it [04:26,  5.73it/s]Epoch: 0: Step: 1501/28124, loss=3.123876, lr=0.000020
1599it [04:44,  5.64it/s]Train batch 1600
Avg. loss per last 100 batches: 3.401080
1600it [04:44,  5.55it/s]Epoch: 0: Step: 1601/28124, loss=3.479895, lr=0.000020
1699it [05:01,  5.77it/s]Train batch 1700
Avg. loss per last 100 batches: 3.365663
1700it [05:01,  5.77it/s]Epoch: 0: Step: 1701/28124, loss=3.207223, lr=0.000020
1799it [05:19,  5.75it/s]Train batch 1800
Avg. loss per last 100 batches: 3.348362
1800it [05:19,  5.76it/s]Epoch: 0: Step: 1801/28124, loss=3.273309, lr=0.000020
1899it [05:36,  5.74it/s]Train batch 1900
Avg. loss per last 100 batches: 3.290923
1900it [05:36,  5.73it/s]Epoch: 0: Step: 1901/28124, loss=3.246665, lr=0.000020
1999it [05:54,  5.74it/s]Train batch 2000
Avg. loss per last 100 batches: 3.306811
2000it [05:54,  5.67it/s]Epoch: 0: Step: 2001/28124, loss=3.192777, lr=0.000020
2099it [06:11,  5.76it/s]Train batch 2100
Avg. loss per last 100 batches: 3.326381
2100it [06:11,  5.75it/s]Epoch: 0: Step: 2101/28124, loss=3.277846, lr=0.000020
2199it [06:29,  5.77it/s]Train batch 2200
Avg. loss per last 100 batches: 3.285854
2200it [06:29,  5.77it/s]Epoch: 0: Step: 2201/28124, loss=3.509590, lr=0.000020
2299it [06:46,  5.76it/s]Train batch 2300
Avg. loss per last 100 batches: 3.291035
2300it [06:46,  5.75it/s]Epoch: 0: Step: 2301/28124, loss=3.499640, lr=0.000020
2399it [07:04,  5.78it/s]Train batch 2400
Avg. loss per last 100 batches: 3.262753
2400it [07:04,  5.78it/s]Epoch: 0: Step: 2401/28124, loss=3.408283, lr=0.000020
2499it [07:21,  5.72it/s]Train batch 2500
Avg. loss per last 100 batches: 3.284294
2500it [07:21,  5.72it/s]Epoch: 0: Step: 2501/28124, loss=3.551919, lr=0.000020
2599it [07:39,  5.78it/s]Train batch 2600
Avg. loss per last 100 batches: 3.186476
2600it [07:39,  5.76it/s]Epoch: 0: Step: 2601/28124, loss=3.188098, lr=0.000020
2699it [07:56,  5.77it/s]Train batch 2700
Avg. loss per last 100 batches: 3.206599
2700it [07:56,  5.77it/s]Epoch: 0: Step: 2701/28124, loss=3.535095, lr=0.000020
2799it [08:13,  5.77it/s]Train batch 2800
Avg. loss per last 100 batches: 3.180760
2800it [08:14,  5.77it/s]Epoch: 0: Step: 2801/28124, loss=3.057314, lr=0.000020
2899it [08:31,  5.76it/s]Train batch 2900
Avg. loss per last 100 batches: 3.194867
2900it [08:31,  5.77it/s]Epoch: 0: Step: 2901/28124, loss=3.114016, lr=0.000020
2999it [08:49,  5.44it/s]Train batch 3000
Avg. loss per last 100 batches: 3.199882
3000it [08:49,  5.54it/s]Epoch: 0: Step: 3001/28124, loss=2.839022, lr=0.000020
3099it [09:06,  5.71it/s]Train batch 3100
Avg. loss per last 100 batches: 3.129241
3100it [09:06,  5.71it/s]Epoch: 0: Step: 3101/28124, loss=3.631913, lr=0.000020
3199it [09:23,  5.76it/s]Train batch 3200
Avg. loss per last 100 batches: 3.144854
3200it [09:24,  5.78it/s]Epoch: 0: Step: 3201/28124, loss=2.953345, lr=0.000020
3299it [09:41,  5.76it/s]Train batch 3300
Avg. loss per last 100 batches: 3.128657
3300it [09:41,  5.77it/s]Epoch: 0: Step: 3301/28124, loss=3.061141, lr=0.000020
3399it [09:58,  5.79it/s]Train batch 3400
Avg. loss per last 100 batches: 3.107570
3400it [09:58,  5.77it/s]Epoch: 0: Step: 3401/28124, loss=2.920258, lr=0.000020
3499it [10:16,  5.78it/s]Train batch 3500
Avg. loss per last 100 batches: 3.098994
3500it [10:16,  5.76it/s]Epoch: 0: Step: 3501/28124, loss=3.198486, lr=0.000020
3599it [10:33,  5.73it/s]Train batch 3600
Avg. loss per last 100 batches: 3.082633
3600it [10:33,  5.74it/s]Epoch: 0: Step: 3601/28124, loss=3.236096, lr=0.000020
3699it [10:51,  5.76it/s]Train batch 3700
Avg. loss per last 100 batches: 3.129301
3700it [10:51,  5.74it/s]Epoch: 0: Step: 3701/28124, loss=2.738615, lr=0.000020
3799it [11:08,  5.72it/s]Train batch 3800
Avg. loss per last 100 batches: 3.053636
3800it [11:08,  5.72it/s]Epoch: 0: Step: 3801/28124, loss=3.016654, lr=0.000020
3899it [11:26,  5.76it/s]Train batch 3900
Avg. loss per last 100 batches: 3.039665
3900it [11:26,  5.73it/s]Epoch: 0: Step: 3901/28124, loss=3.635763, lr=0.000020
3999it [11:43,  5.78it/s]Train batch 4000
Avg. loss per last 100 batches: 3.055372
4000it [11:43,  5.76it/s]Epoch: 0: Step: 4001/28124, loss=3.196811, lr=0.000020
4099it [12:00,  5.77it/s]Train batch 4100
Avg. loss per last 100 batches: 3.100921
4100it [12:01,  5.76it/s]Epoch: 0: Step: 4101/28124, loss=2.834065, lr=0.000020
4199it [12:18,  5.76it/s]Train batch 4200
Avg. loss per last 100 batches: 3.024418
4200it [12:18,  5.76it/s]Epoch: 0: Step: 4201/28124, loss=3.714941, lr=0.000020
4299it [12:35,  5.77it/s]Train batch 4300
Avg. loss per last 100 batches: 3.017738
4300it [12:36,  5.77it/s]Epoch: 0: Step: 4301/28124, loss=3.114778, lr=0.000020
4399it [12:53,  5.78it/s]Train batch 4400
Avg. loss per last 100 batches: 3.017864
4400it [12:53,  5.76it/s]Epoch: 0: Step: 4401/28124, loss=2.984087, lr=0.000020
4499it [13:10,  5.75it/s]Train batch 4500
Avg. loss per last 100 batches: 3.025168
4500it [13:10,  5.76it/s]Epoch: 0: Step: 4501/28124, loss=2.872352, lr=0.000020
4599it [13:28,  5.77it/s]Train batch 4600
Avg. loss per last 100 batches: 2.987402
4600it [13:28,  5.78it/s]Epoch: 0: Step: 4601/28124, loss=3.371191, lr=0.000020
4699it [13:45,  5.70it/s]Train batch 4700
Avg. loss per last 100 batches: 3.008624
4700it [13:45,  5.71it/s]Epoch: 0: Step: 4701/28124, loss=3.200890, lr=0.000020
4799it [14:02,  5.77it/s]Train batch 4800
Avg. loss per last 100 batches: 2.990419
4800it [14:03,  5.78it/s]Epoch: 0: Step: 4801/28124, loss=3.331420, lr=0.000020
4899it [14:20,  5.77it/s]Train batch 4900
Avg. loss per last 100 batches: 2.993365
4900it [14:20,  5.77it/s]Epoch: 0: Step: 4901/28124, loss=2.793576, lr=0.000020
4999it [14:37,  5.44it/s]Train batch 5000
Avg. loss per last 100 batches: 2.985569
5000it [14:38,  5.44it/s]Epoch: 0: Step: 5001/28124, loss=3.086583, lr=0.000020
5099it [14:55,  5.72it/s]Train batch 5100
Avg. loss per last 100 batches: 2.926733
5100it [14:55,  5.73it/s]Epoch: 0: Step: 5101/28124, loss=3.052579, lr=0.000020
5199it [15:12,  5.74it/s]Train batch 5200
Avg. loss per last 100 batches: 2.933365
5200it [15:12,  5.75it/s]Epoch: 0: Step: 5201/28124, loss=2.932220, lr=0.000020
5299it [15:33,  5.77it/s]Train batch 5300
Avg. loss per last 100 batches: 2.936266
5300it [15:33,  5.78it/s]Epoch: 0: Step: 5301/28124, loss=2.812525, lr=0.000020
5399it [15:51,  5.77it/s]Train batch 5400
Avg. loss per last 100 batches: 2.943543
5400it [15:51,  5.76it/s]Epoch: 0: Step: 5401/28124, loss=2.338125, lr=0.000020
5499it [16:08,  5.79it/s]Train batch 5500
Avg. loss per last 100 batches: 2.909455
5500it [16:08,  5.76it/s]Epoch: 0: Step: 5501/28124, loss=3.288175, lr=0.000020
5599it [16:26,  5.71it/s]Train batch 5600
Avg. loss per last 100 batches: 2.931656
5600it [16:26,  5.73it/s]Epoch: 0: Step: 5601/28124, loss=3.139685, lr=0.000020
5624it [16:30,  5.78it/s]Validation: Epoch: 0 Step: 5625/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.330633 sec., loss=1.770907 
Eval step: 199 , used_time=8.626400 sec., loss=2.037399 
Eval step: 299 , used_time=13.024131 sec., loss=2.717994 
Eval step: 399 , used_time=17.502880 sec., loss=2.284467 
Eval step: 499 , used_time=21.798244 sec., loss=1.942025 
Eval step: 599 , used_time=26.164360 sec., loss=2.458139 
Eval step: 699 , used_time=30.458905 sec., loss=2.508207 
Eval step: 799 , used_time=34.773492 sec., loss=1.869838 
Eval step: 899 , used_time=39.102243 sec., loss=2.018813 
Eval step: 999 , used_time=43.415699 sec., loss=2.373527 
Eval step: 1099 , used_time=47.928502 sec., loss=1.965302 
Eval step: 1199 , used_time=52.216575 sec., loss=2.211879 
Eval step: 1299 , used_time=56.563885 sec., loss=2.307733 
Eval step: 1399 , used_time=60.862555 sec., loss=1.923388 
Eval step: 1499 , used_time=65.188022 sec., loss=1.792184 
Eval step: 1599 , used_time=69.493333 sec., loss=1.941686 
Eval step: 1699 , used_time=73.834753 sec., loss=1.969244 
Eval step: 1799 , used_time=78.321129 sec., loss=1.992570 
Eval step: 1899 , used_time=82.612375 sec., loss=1.960168 
Eval step: 1999 , used_time=86.967556 sec., loss=2.717507 
Eval step: 2099 , used_time=91.269917 sec., loss=2.097895 
Eval step: 2199 , used_time=95.587500 sec., loss=2.009821 
Eval step: 2299 , used_time=99.882078 sec., loss=1.498219 
Eval step: 2399 , used_time=104.202531 sec., loss=2.475301 
Eval step: 2499 , used_time=108.619416 sec., loss=1.971064 
Eval step: 2599 , used_time=112.976315 sec., loss=2.085588 
Eval step: 2699 , used_time=117.328937 sec., loss=2.080796 
Eval step: 2799 , used_time=121.618841 sec., loss=2.471198 
Eval step: 2899 , used_time=125.931109 sec., loss=2.264308 
Eval step: 2999 , used_time=130.216052 sec., loss=1.767273 
Eval step: 3099 , used_time=134.551788 sec., loss=2.010557 
NLL Validation: loss = 2.106987. correct prediction ratio  40534/100032 ~  0.405210
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:04,  5.75it/s]Train batch 5700
Avg. loss per last 100 batches: 2.930782
5700it [19:04,  5.75it/s]Epoch: 0: Step: 5701/28124, loss=3.295976, lr=0.000020
5799it [19:21,  5.76it/s]Train batch 5800
Avg. loss per last 100 batches: 2.862662
5800it [19:21,  5.77it/s]Epoch: 0: Step: 5801/28124, loss=2.511062, lr=0.000020
5899it [19:39,  5.78it/s]Train batch 5900
Avg. loss per last 100 batches: 2.915505
5900it [19:39,  5.76it/s]Epoch: 0: Step: 5901/28124, loss=3.042263, lr=0.000020
5999it [19:56,  5.66it/s]Train batch 6000
Avg. loss per last 100 batches: 2.926405
6000it [19:56,  5.69it/s]Epoch: 0: Step: 6001/28124, loss=2.965559, lr=0.000020
6099it [20:13,  5.77it/s]Train batch 6100
Avg. loss per last 100 batches: 2.890377
6100it [20:14,  5.78it/s]Epoch: 0: Step: 6101/28124, loss=2.911946, lr=0.000020
6199it [20:31,  5.79it/s]Train batch 6200
Avg. loss per last 100 batches: 2.917392
6200it [20:31,  5.78it/s]Epoch: 0: Step: 6201/28124, loss=3.425002, lr=0.000019
6299it [20:48,  5.76it/s]Train batch 6300
Avg. loss per last 100 batches: 2.901686
6300it [20:49,  5.77it/s]Epoch: 0: Step: 6301/28124, loss=2.874525, lr=0.000019
6399it [21:06,  5.75it/s]Train batch 6400
Avg. loss per last 100 batches: 2.829173
6400it [21:06,  5.74it/s]Epoch: 0: Step: 6401/28124, loss=3.053237, lr=0.000019
6499it [21:23,  5.78it/s]Train batch 6500
Avg. loss per last 100 batches: 2.889853
6500it [21:23,  5.76it/s]Epoch: 0: Step: 6501/28124, loss=2.597365, lr=0.000019
6599it [21:41,  5.76it/s]Train batch 6600
Avg. loss per last 100 batches: 2.865605
6600it [21:41,  5.77it/s]Epoch: 0: Step: 6601/28124, loss=3.324064, lr=0.000019
6699it [21:58,  5.77it/s]Train batch 6700
Avg. loss per last 100 batches: 2.866508
6700it [21:58,  5.77it/s]Epoch: 0: Step: 6701/28124, loss=3.051207, lr=0.000019
6799it [22:16,  5.74it/s]Train batch 6800
Avg. loss per last 100 batches: 2.872643
6800it [22:16,  5.75it/s]Epoch: 0: Step: 6801/28124, loss=2.483319, lr=0.000019
6899it [22:33,  5.61it/s]Train batch 6900
Avg. loss per last 100 batches: 2.853744
6900it [22:33,  5.53it/s]Epoch: 0: Step: 6901/28124, loss=3.185421, lr=0.000019
6999it [22:50,  5.77it/s]Train batch 7000
Avg. loss per last 100 batches: 2.824677
7000it [22:51,  5.78it/s]Epoch: 0: Step: 7001/28124, loss=3.155474, lr=0.000019
7099it [23:08,  5.74it/s]Train batch 7100
Avg. loss per last 100 batches: 2.822572
7100it [23:08,  5.74it/s]Epoch: 0: Step: 7101/28124, loss=3.171067, lr=0.000019
7199it [23:25,  5.76it/s]Train batch 7200
Avg. loss per last 100 batches: 2.828009
7200it [23:26,  5.75it/s]Epoch: 0: Step: 7201/28124, loss=2.553440, lr=0.000019
7299it [23:43,  5.77it/s]Train batch 7300
Avg. loss per last 100 batches: 2.797110
7300it [23:43,  5.77it/s]Epoch: 0: Step: 7301/28124, loss=2.887650, lr=0.000019
7399it [24:00,  5.77it/s]Train batch 7400
Avg. loss per last 100 batches: 2.809879
7400it [24:00,  5.78it/s]Epoch: 0: Step: 7401/28124, loss=2.802322, lr=0.000019
7499it [24:18,  5.78it/s]Train batch 7500
Avg. loss per last 100 batches: 2.837212
7500it [24:18,  5.78it/s]Epoch: 0: Step: 7501/28124, loss=3.080710, lr=0.000019
7599it [24:35,  5.74it/s]Train batch 7600
Avg. loss per last 100 batches: 2.804696
7600it [24:35,  5.75it/s]Epoch: 0: Step: 7601/28124, loss=2.827622, lr=0.000019
7699it [24:53,  5.77it/s]Train batch 7700
Avg. loss per last 100 batches: 2.825581
7700it [24:53,  5.76it/s]Epoch: 0: Step: 7701/28124, loss=2.628437, lr=0.000019
7799it [25:10,  5.78it/s]Train batch 7800
Avg. loss per last 100 batches: 2.793579
7800it [25:10,  5.78it/s]Epoch: 0: Step: 7801/28124, loss=3.131065, lr=0.000019
7899it [25:27,  5.77it/s]Train batch 7900
Avg. loss per last 100 batches: 2.835575
7900it [25:27,  5.76it/s]Epoch: 0: Step: 7901/28124, loss=2.539071, lr=0.000019
7999it [25:45,  5.48it/s]Train batch 8000
Avg. loss per last 100 batches: 2.822203
8000it [25:45,  5.55it/s]Epoch: 0: Step: 8001/28124, loss=2.614831, lr=0.000019
8099it [26:02,  5.77it/s]Train batch 8100
Avg. loss per last 100 batches: 2.801909
8100it [26:02,  5.77it/s]Epoch: 0: Step: 8101/28124, loss=2.701790, lr=0.000019
8199it [26:20,  5.75it/s]Train batch 8200
Avg. loss per last 100 batches: 2.753906
8200it [26:20,  5.77it/s]Epoch: 0: Step: 8201/28124, loss=2.805930, lr=0.000019
8299it [26:37,  5.76it/s]Train batch 8300
Avg. loss per last 100 batches: 2.797887
8300it [26:37,  5.76it/s]Epoch: 0: Step: 8301/28124, loss=2.610990, lr=0.000019
8399it [26:55,  5.65it/s]Train batch 8400
Avg. loss per last 100 batches: 2.760029
8400it [26:55,  5.67it/s]Epoch: 0: Step: 8401/28124, loss=2.539191, lr=0.000019
8499it [27:12,  5.78it/s]Train batch 8500
Avg. loss per last 100 batches: 2.797086
8500it [27:12,  5.79it/s]Epoch: 0: Step: 8501/28124, loss=2.709732, lr=0.000019
8599it [27:29,  5.78it/s]Train batch 8600
Avg. loss per last 100 batches: 2.801510
8600it [27:30,  5.77it/s]Epoch: 0: Step: 8601/28124, loss=2.747094, lr=0.000019
8699it [27:47,  5.80it/s]Train batch 8700
Avg. loss per last 100 batches: 2.753572
8700it [27:47,  5.77it/s]Epoch: 0: Step: 8701/28124, loss=2.896774, lr=0.000019
8799it [28:04,  5.75it/s]Train batch 8800
Avg. loss per last 100 batches: 2.748890
8800it [28:04,  5.77it/s]Epoch: 0: Step: 8801/28124, loss=2.366165, lr=0.000019
8899it [28:22,  5.79it/s]Train batch 8900
Avg. loss per last 100 batches: 2.757934
8900it [28:22,  5.76it/s]Epoch: 0: Step: 8901/28124, loss=2.557741, lr=0.000019
8999it [28:39,  5.78it/s]Train batch 9000
Avg. loss per last 100 batches: 2.781540
9000it [28:39,  5.78it/s]Epoch: 0: Step: 9001/28124, loss=2.394923, lr=0.000019
9099it [28:57,  5.76it/s]Train batch 9100
Avg. loss per last 100 batches: 2.763376
9100it [28:57,  5.74it/s]Epoch: 0: Step: 9101/28124, loss=2.902407, lr=0.000019
9199it [29:14,  5.72it/s]Train batch 9200
Avg. loss per last 100 batches: 2.768296
9200it [29:14,  5.55it/s]Epoch: 0: Step: 9201/28124, loss=2.863388, lr=0.000019
9299it [29:31,  5.75it/s]Train batch 9300
Avg. loss per last 100 batches: 2.715196
9300it [29:32,  5.75it/s]Epoch: 0: Step: 9301/28124, loss=2.224877, lr=0.000019
9399it [29:49,  5.77it/s]Train batch 9400
Avg. loss per last 100 batches: 2.732682
9400it [29:49,  5.77it/s]Epoch: 0: Step: 9401/28124, loss=2.990388, lr=0.000019
9499it [30:06,  5.74it/s]Train batch 9500
Avg. loss per last 100 batches: 2.768328
9500it [30:07,  5.75it/s]Epoch: 0: Step: 9501/28124, loss=2.684675, lr=0.000019
9599it [30:24,  5.78it/s]Train batch 9600
Avg. loss per last 100 batches: 2.692764
9600it [30:24,  5.78it/s]Epoch: 0: Step: 9601/28124, loss=2.438494, lr=0.000019
9699it [30:41,  5.80it/s]Train batch 9700
Avg. loss per last 100 batches: 2.707207
9700it [30:41,  5.81it/s]Epoch: 0: Step: 9701/28124, loss=2.406028, lr=0.000019
9799it [30:59,  5.78it/s]Train batch 9800
Avg. loss per last 100 batches: 2.715260
9800it [30:59,  5.78it/s]Epoch: 0: Step: 9801/28124, loss=2.325123, lr=0.000019
9899it [31:16,  5.80it/s]Train batch 9900
Avg. loss per last 100 batches: 2.725965
9900it [31:16,  5.79it/s]Epoch: 0: Step: 9901/28124, loss=2.488484, lr=0.000019
9999it [31:33,  5.48it/s]Train batch 10000
Avg. loss per last 100 batches: 2.690147
10000it [31:34,  5.46it/s]Epoch: 0: Step: 10001/28124, loss=2.366069, lr=0.000019
10099it [31:51,  5.79it/s]Train batch 10100
Avg. loss per last 100 batches: 2.706942
10100it [31:51,  5.77it/s]Epoch: 0: Step: 10101/28124, loss=2.665566, lr=0.000019
10199it [32:08,  5.75it/s]Train batch 10200
Avg. loss per last 100 batches: 2.690167
10200it [32:08,  5.75it/s]Epoch: 0: Step: 10201/28124, loss=2.555538, lr=0.000019
10299it [32:26,  5.77it/s]Train batch 10300
Avg. loss per last 100 batches: 2.665832
10300it [32:26,  5.76it/s]Epoch: 0: Step: 10301/28124, loss=2.373184, lr=0.000019
10399it [32:43,  5.72it/s]Train batch 10400
Avg. loss per last 100 batches: 2.651471
10400it [32:43,  5.74it/s]Epoch: 0: Step: 10401/28124, loss=2.134309, lr=0.000019
10499it [33:00,  5.77it/s]Train batch 10500
Avg. loss per last 100 batches: 2.678357
10500it [33:01,  5.77it/s]Epoch: 0: Step: 10501/28124, loss=2.937981, lr=0.000019
10599it [33:18,  5.74it/s]Train batch 10600
Avg. loss per last 100 batches: 2.684411
10600it [33:18,  5.75it/s]Epoch: 0: Step: 10601/28124, loss=2.380032, lr=0.000019
10699it [33:35,  5.77it/s]Train batch 10700
Avg. loss per last 100 batches: 2.667229
10700it [33:35,  5.78it/s]Epoch: 0: Step: 10701/28124, loss=2.606392, lr=0.000019
10799it [33:53,  5.75it/s]Train batch 10800
Avg. loss per last 100 batches: 2.682363
10800it [33:53,  5.74it/s]Epoch: 0: Step: 10801/28124, loss=2.995381, lr=0.000019
10899it [34:10,  5.70it/s]Train batch 10900
Avg. loss per last 100 batches: 2.670314
10900it [34:10,  5.71it/s]Epoch: 0: Step: 10901/28124, loss=2.745294, lr=0.000019
10999it [34:28,  5.74it/s]Train batch 11000
Avg. loss per last 100 batches: 2.664581
11000it [34:28,  5.74it/s]Epoch: 0: Step: 11001/28124, loss=2.307412, lr=0.000019
11099it [34:45,  5.67it/s]Train batch 11100
Avg. loss per last 100 batches: 2.681919
11100it [34:46,  5.70it/s]Epoch: 0: Step: 11101/28124, loss=2.842792, lr=0.000019
11199it [35:03,  5.77it/s]Train batch 11200
Avg. loss per last 100 batches: 2.721832
11200it [35:03,  5.76it/s]Epoch: 0: Step: 11201/28124, loss=2.744390, lr=0.000019
11249it [35:12,  5.75it/s]Validation: Epoch: 0 Step: 11250/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.515214 sec., loss=1.775229 
Eval step: 199 , used_time=8.795280 sec., loss=1.523092 
Eval step: 299 , used_time=13.116929 sec., loss=2.153766 
Eval step: 399 , used_time=17.387786 sec., loss=2.023125 
Eval step: 499 , used_time=21.705158 sec., loss=1.921630 
Eval step: 599 , used_time=26.025219 sec., loss=2.073452 
Eval step: 699 , used_time=30.341829 sec., loss=2.259566 
Eval step: 799 , used_time=34.829668 sec., loss=1.503644 
Eval step: 899 , used_time=39.161448 sec., loss=1.750894 
Eval step: 999 , used_time=43.458341 sec., loss=1.943696 
Eval step: 1099 , used_time=47.766057 sec., loss=1.499276 
Eval step: 1199 , used_time=52.134551 sec., loss=1.877189 
Eval step: 1299 , used_time=56.402521 sec., loss=1.869759 
Eval step: 1399 , used_time=60.706739 sec., loss=1.623863 
Eval step: 1499 , used_time=65.040246 sec., loss=1.406307 
Eval step: 1599 , used_time=69.521940 sec., loss=1.669420 
Eval step: 1699 , used_time=73.873919 sec., loss=1.687535 
Eval step: 1799 , used_time=78.210043 sec., loss=1.733240 
Eval step: 1899 , used_time=82.566859 sec., loss=1.797103 
Eval step: 1999 , used_time=86.820193 sec., loss=2.304574 
Eval step: 2099 , used_time=91.076247 sec., loss=1.533520 
Eval step: 2199 , used_time=95.427583 sec., loss=1.697653 
Eval step: 2299 , used_time=99.895837 sec., loss=1.292141 
Eval step: 2399 , used_time=104.200915 sec., loss=1.864632 
Eval step: 2499 , used_time=108.464267 sec., loss=1.727333 
Eval step: 2599 , used_time=112.770521 sec., loss=1.620982 
Eval step: 2699 , used_time=117.063530 sec., loss=2.138927 
Eval step: 2799 , used_time=121.340808 sec., loss=2.119652 
Eval step: 2899 , used_time=125.643351 sec., loss=1.923920 
Eval step: 2999 , used_time=130.028336 sec., loss=1.710032 
Eval step: 3099 , used_time=134.439816 sec., loss=1.735898 
NLL Validation: loss = 1.852447. correct prediction ratio  47628/100032 ~  0.476128
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [37:41,  5.75it/s]Train batch 11300
Avg. loss per last 100 batches: 2.635038
11300it [37:41,  5.74it/s]Epoch: 0: Step: 11301/28124, loss=2.879464, lr=0.000019
11399it [37:59,  5.73it/s]Train batch 11400
Avg. loss per last 100 batches: 2.689642
11400it [37:59,  5.75it/s]Epoch: 0: Step: 11401/28124, loss=2.498377, lr=0.000019
11499it [38:16,  5.80it/s]Train batch 11500
Avg. loss per last 100 batches: 2.661680
11500it [38:16,  5.79it/s]Epoch: 0: Step: 11501/28124, loss=2.504281, lr=0.000019
11599it [38:33,  5.80it/s]Train batch 11600
Avg. loss per last 100 batches: 2.653375
11600it [38:34,  5.79it/s]Epoch: 0: Step: 11601/28124, loss=3.075341, lr=0.000019
11699it [38:51,  5.77it/s]Train batch 11700
Avg. loss per last 100 batches: 2.681005
11700it [38:51,  5.77it/s]Epoch: 0: Step: 11701/28124, loss=2.631058, lr=0.000019
11799it [39:08,  5.77it/s]Train batch 11800
Avg. loss per last 100 batches: 2.597388
11800it [39:08,  5.78it/s]Epoch: 0: Step: 11801/28124, loss=2.419690, lr=0.000019
11899it [39:26,  5.78it/s]Train batch 11900
Avg. loss per last 100 batches: 2.626064
11900it [39:26,  5.79it/s]Epoch: 0: Step: 11901/28124, loss=3.087860, lr=0.000019
11999it [39:43,  5.78it/s]Train batch 12000
Avg. loss per last 100 batches: 2.658747
12000it [39:43,  5.78it/s]Epoch: 0: Step: 12001/28124, loss=2.907777, lr=0.000019
12099it [40:00,  5.75it/s]Train batch 12100
Avg. loss per last 100 batches: 2.610595
12100it [40:01,  5.63it/s]Epoch: 0: Step: 12101/28124, loss=2.485460, lr=0.000019
12199it [40:18,  5.78it/s]Train batch 12200
Avg. loss per last 100 batches: 2.625014
12200it [40:18,  5.79it/s]Epoch: 0: Step: 12201/28124, loss=2.543556, lr=0.000019
12299it [40:35,  5.74it/s]Train batch 12300
Avg. loss per last 100 batches: 2.669001
12300it [40:35,  5.75it/s]Epoch: 0: Step: 12301/28124, loss=2.853324, lr=0.000019
12399it [40:53,  5.80it/s]Train batch 12400
Avg. loss per last 100 batches: 2.606431
12400it [40:53,  5.78it/s]Epoch: 0: Step: 12401/28124, loss=2.500112, lr=0.000019
12499it [41:10,  5.79it/s]Train batch 12500
Avg. loss per last 100 batches: 2.605686
12500it [41:10,  5.79it/s]Epoch: 0: Step: 12501/28124, loss=2.537133, lr=0.000019
12599it [41:27,  5.77it/s]Train batch 12600
Avg. loss per last 100 batches: 2.632542
12600it [41:28,  5.75it/s]Epoch: 0: Step: 12601/28124, loss=2.081872, lr=0.000019
12699it [41:45,  5.76it/s]Train batch 12700
Avg. loss per last 100 batches: 2.556598
12700it [41:45,  5.75it/s]Epoch: 0: Step: 12701/28124, loss=2.268352, lr=0.000019
12799it [42:02,  5.79it/s]Train batch 12800
Avg. loss per last 100 batches: 2.597212
12800it [42:02,  5.78it/s]Epoch: 0: Step: 12801/28124, loss=2.698102, lr=0.000019
12899it [42:20,  5.78it/s]Train batch 12900
Avg. loss per last 100 batches: 2.573761
12900it [42:20,  5.78it/s]Epoch: 0: Step: 12901/28124, loss=2.564093, lr=0.000019
12999it [42:37,  5.74it/s]Train batch 13000
Avg. loss per last 100 batches: 2.566101
13000it [42:37,  5.75it/s]Epoch: 0: Step: 13001/28124, loss=2.883865, lr=0.000019
13099it [42:54,  5.78it/s]Train batch 13100
Avg. loss per last 100 batches: 2.583791
13100it [42:55,  5.78it/s]Epoch: 0: Step: 13101/28124, loss=2.815626, lr=0.000019
13199it [43:12,  5.44it/s]Train batch 13200
Avg. loss per last 100 batches: 2.586383
13200it [43:12,  5.46it/s]Epoch: 0: Step: 13201/28124, loss=2.741065, lr=0.000019
13299it [43:29,  5.77it/s]Train batch 13300
Avg. loss per last 100 batches: 2.581839
13300it [43:29,  5.78it/s]Epoch: 0: Step: 13301/28124, loss=1.981835, lr=0.000019
13399it [43:47,  5.77it/s]Train batch 13400
Avg. loss per last 100 batches: 2.590891
13400it [43:47,  5.78it/s]Epoch: 0: Step: 13401/28124, loss=2.330255, lr=0.000019
13499it [44:04,  5.71it/s]Train batch 13500
Avg. loss per last 100 batches: 2.572529
13500it [44:04,  5.71it/s]Epoch: 0: Step: 13501/28124, loss=1.531689, lr=0.000019
13599it [44:22,  5.76it/s]Train batch 13600
Avg. loss per last 100 batches: 2.570562
13600it [44:22,  5.76it/s]Epoch: 0: Step: 13601/28124, loss=2.409366, lr=0.000019
13699it [44:39,  5.79it/s]Train batch 13700
Avg. loss per last 100 batches: 2.562498
13700it [44:39,  5.78it/s]Epoch: 0: Step: 13701/28124, loss=2.594944, lr=0.000019
13799it [44:56,  5.76it/s]Train batch 13800
Avg. loss per last 100 batches: 2.567050
13800it [44:57,  5.77it/s]Epoch: 0: Step: 13801/28124, loss=2.338535, lr=0.000019
13899it [45:14,  5.75it/s]Train batch 13900
Avg. loss per last 100 batches: 2.605319
13900it [45:14,  5.76it/s]Epoch: 0: Step: 13901/28124, loss=2.504585, lr=0.000019
13999it [45:31,  5.74it/s]Train batch 14000
Avg. loss per last 100 batches: 2.594664
14000it [45:32,  5.75it/s]Epoch: 0: Step: 14001/28124, loss=2.901135, lr=0.000019
14099it [45:49,  5.72it/s]Train batch 14100
Avg. loss per last 100 batches: 2.566741
14100it [45:49,  5.73it/s]Epoch: 0: Step: 14101/28124, loss=2.504938, lr=0.000019
14199it [46:06,  5.74it/s]Train batch 14200
Avg. loss per last 100 batches: 2.540213
14200it [46:07,  5.73it/s]Epoch: 0: Step: 14201/28124, loss=2.543375, lr=0.000019
14299it [46:24,  5.70it/s]Train batch 14300
Avg. loss per last 100 batches: 2.594642
14300it [46:24,  5.65it/s]Epoch: 0: Step: 14301/28124, loss=2.452167, lr=0.000019
14399it [46:41,  5.73it/s]Train batch 14400
Avg. loss per last 100 batches: 2.540153
14400it [46:42,  5.73it/s]Epoch: 0: Step: 14401/28124, loss=1.956938, lr=0.000019
14499it [46:59,  5.75it/s]Train batch 14500
Avg. loss per last 100 batches: 2.501511
14500it [46:59,  5.73it/s]Epoch: 0: Step: 14501/28124, loss=2.754810, lr=0.000019
14599it [47:16,  5.74it/s]Train batch 14600
Avg. loss per last 100 batches: 2.502934
14600it [47:17,  5.75it/s]Epoch: 0: Step: 14601/28124, loss=2.278691, lr=0.000019
14699it [47:34,  5.72it/s]Train batch 14700
Avg. loss per last 100 batches: 2.533577
14700it [47:34,  5.48it/s]Epoch: 0: Step: 14701/28124, loss=2.251834, lr=0.000019
14799it [47:51,  5.74it/s]Train batch 14800
Avg. loss per last 100 batches: 2.479560
14800it [47:52,  5.74it/s]Epoch: 0: Step: 14801/28124, loss=2.196433, lr=0.000019
14899it [48:09,  5.72it/s]Train batch 14900
Avg. loss per last 100 batches: 2.527185
14900it [48:09,  5.73it/s]Epoch: 0: Step: 14901/28124, loss=2.990258, lr=0.000019
14999it [48:27,  5.73it/s]Train batch 15000
Avg. loss per last 100 batches: 2.584640
15000it [48:27,  5.73it/s]Epoch: 0: Step: 15001/28124, loss=2.505473, lr=0.000019
15099it [48:44,  5.54it/s]Train batch 15100
Avg. loss per last 100 batches: 2.477659
15100it [48:44,  5.57it/s]Epoch: 0: Step: 15101/28124, loss=1.888013, lr=0.000019
15199it [49:02,  5.57it/s]Train batch 15200
Avg. loss per last 100 batches: 2.503262
15200it [49:02,  5.62it/s]Epoch: 0: Step: 15201/28124, loss=2.403099, lr=0.000019
15299it [49:19,  5.74it/s]Train batch 15300
Avg. loss per last 100 batches: 2.493631
15300it [49:19,  5.75it/s]Epoch: 0: Step: 15301/28124, loss=2.631838, lr=0.000019
15399it [49:37,  5.76it/s]Train batch 15400
Avg. loss per last 100 batches: 2.470504
15400it [49:37,  5.73it/s]Epoch: 0: Step: 15401/28124, loss=2.699115, lr=0.000019
15499it [49:54,  5.70it/s]Train batch 15500
Avg. loss per last 100 batches: 2.475932
15500it [49:54,  5.71it/s]Epoch: 0: Step: 15501/28124, loss=2.314655, lr=0.000019
15599it [50:12,  5.77it/s]Train batch 15600
Avg. loss per last 100 batches: 2.543981
15600it [50:12,  5.77it/s]Epoch: 0: Step: 15601/28124, loss=2.315395, lr=0.000019
15699it [50:29,  5.73it/s]Train batch 15700
Avg. loss per last 100 batches: 2.539035
15700it [50:29,  5.72it/s]Epoch: 0: Step: 15701/28124, loss=2.319057, lr=0.000019
15799it [50:47,  5.74it/s]Train batch 15800
Avg. loss per last 100 batches: 2.495083
15800it [50:47,  5.73it/s]Epoch: 0: Step: 15801/28124, loss=2.685813, lr=0.000019
15899it [51:04,  5.69it/s]Train batch 15900
Avg. loss per last 100 batches: 2.434559
15900it [51:04,  5.69it/s]Epoch: 0: Step: 15901/28124, loss=2.756371, lr=0.000019
15999it [51:22,  5.72it/s]Train batch 16000
Avg. loss per last 100 batches: 2.443566
16000it [51:22,  5.72it/s]Epoch: 0: Step: 16001/28124, loss=3.311821, lr=0.000018
16099it [51:39,  5.41it/s]Train batch 16100
Avg. loss per last 100 batches: 2.507289
16100it [51:39,  5.42it/s]Epoch: 0: Step: 16101/28124, loss=2.601828, lr=0.000018
16199it [51:57,  5.73it/s]Train batch 16200
Avg. loss per last 100 batches: 2.499125
16200it [51:57,  5.73it/s]Epoch: 0: Step: 16201/28124, loss=2.191976, lr=0.000018
16299it [52:14,  5.63it/s]Train batch 16300
Avg. loss per last 100 batches: 2.434774
16300it [52:14,  5.67it/s]Epoch: 0: Step: 16301/28124, loss=2.660983, lr=0.000018
16399it [52:32,  5.71it/s]Train batch 16400
Avg. loss per last 100 batches: 2.517376
16400it [52:32,  5.70it/s]Epoch: 0: Step: 16401/28124, loss=2.323050, lr=0.000018
16499it [52:49,  5.74it/s]Train batch 16500
Avg. loss per last 100 batches: 2.482223
16500it [52:50,  5.72it/s]Epoch: 0: Step: 16501/28124, loss=2.046891, lr=0.000018
16599it [53:07,  5.73it/s]Train batch 16600
Avg. loss per last 100 batches: 2.432265
16600it [53:07,  5.73it/s]Epoch: 0: Step: 16601/28124, loss=2.440951, lr=0.000018
16699it [53:24,  5.73it/s]Train batch 16700
Avg. loss per last 100 batches: 2.455547
16700it [53:24,  5.73it/s]Epoch: 0: Step: 16701/28124, loss=2.795824, lr=0.000018
16799it [53:42,  5.76it/s]Train batch 16800
Avg. loss per last 100 batches: 2.454335
16800it [53:42,  5.75it/s]Epoch: 0: Step: 16801/28124, loss=2.082405, lr=0.000018
16874it [53:55,  5.69it/s]Validation: Epoch: 0 Step: 16875/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.349173 sec., loss=1.531688 
Eval step: 199 , used_time=8.626908 sec., loss=1.436979 
Eval step: 299 , used_time=12.903128 sec., loss=1.729807 
Eval step: 399 , used_time=17.233127 sec., loss=1.697055 
Eval step: 499 , used_time=21.666498 sec., loss=1.623945 
Eval step: 599 , used_time=25.959198 sec., loss=1.909072 
Eval step: 699 , used_time=30.235216 sec., loss=2.003087 
Eval step: 799 , used_time=34.521622 sec., loss=1.578162 
Eval step: 899 , used_time=38.795639 sec., loss=1.595794 
Eval step: 999 , used_time=43.064745 sec., loss=1.645073 
Eval step: 1099 , used_time=47.387842 sec., loss=1.655013 
Eval step: 1199 , used_time=51.857625 sec., loss=1.855168 
Eval step: 1299 , used_time=56.168083 sec., loss=1.382536 
Eval step: 1399 , used_time=60.454006 sec., loss=1.335165 
Eval step: 1499 , used_time=64.753166 sec., loss=1.311505 
Eval step: 1599 , used_time=69.040383 sec., loss=1.646770 
Eval step: 1699 , used_time=73.312846 sec., loss=1.519141 
Eval step: 1799 , used_time=77.630307 sec., loss=1.484463 
Eval step: 1899 , used_time=82.097276 sec., loss=1.476810 
Eval step: 1999 , used_time=86.399463 sec., loss=1.955390 
Eval step: 2099 , used_time=90.675534 sec., loss=1.296639 
Eval step: 2199 , used_time=94.970348 sec., loss=1.519161 
Eval step: 2299 , used_time=99.256150 sec., loss=1.009824 
Eval step: 2399 , used_time=103.532933 sec., loss=1.666393 
Eval step: 2499 , used_time=107.836029 sec., loss=1.553396 
Eval step: 2599 , used_time=112.110023 sec., loss=1.647302 
Eval step: 2699 , used_time=116.606395 sec., loss=1.880356 
Eval step: 2799 , used_time=120.875536 sec., loss=1.756314 
Eval step: 2899 , used_time=125.174970 sec., loss=1.887321 
Eval step: 2999 , used_time=129.457874 sec., loss=1.445969 
Eval step: 3099 , used_time=133.727225 sec., loss=1.714023 
NLL Validation: loss = 1.679554. correct prediction ratio  52203/100032 ~  0.521863
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
16899it [56:24,  5.40it/s]Train batch 16900
Avg. loss per last 100 batches: 2.469689
16900it [56:24,  5.44it/s]Epoch: 0: Step: 16901/28124, loss=2.480399, lr=0.000018
16999it [56:41,  5.72it/s]Train batch 17000
Avg. loss per last 100 batches: 2.493482
17000it [56:42,  5.72it/s]Epoch: 0: Step: 17001/28124, loss=2.749170, lr=0.000018
17099it [56:59,  5.66it/s]Train batch 17100
Avg. loss per last 100 batches: 2.443009
17100it [56:59,  5.69it/s]Epoch: 0: Step: 17101/28124, loss=2.764112, lr=0.000018
17199it [57:17,  5.74it/s]Train batch 17200
Avg. loss per last 100 batches: 2.478057
17200it [57:17,  5.74it/s]Epoch: 0: Step: 17201/28124, loss=1.420131, lr=0.000018
17299it [57:34,  5.68it/s]Train batch 17300
Avg. loss per last 100 batches: 2.482120
17300it [57:34,  5.53it/s]Epoch: 0: Step: 17301/28124, loss=2.383255, lr=0.000018
17399it [57:51,  5.74it/s]Train batch 17400
Avg. loss per last 100 batches: 2.447264
17400it [57:52,  5.75it/s]Epoch: 0: Step: 17401/28124, loss=2.072648, lr=0.000018
17499it [58:09,  5.73it/s]Train batch 17500
Avg. loss per last 100 batches: 2.465587
17500it [58:09,  5.74it/s]Epoch: 0: Step: 17501/28124, loss=2.462111, lr=0.000018
17599it [58:26,  5.73it/s]Train batch 17600
Avg. loss per last 100 batches: 2.452442
17600it [58:27,  5.74it/s]Epoch: 0: Step: 17601/28124, loss=2.129711, lr=0.000018
17699it [58:44,  5.70it/s]Train batch 17700
Avg. loss per last 100 batches: 2.461974
17700it [58:44,  5.51it/s]Epoch: 0: Step: 17701/28124, loss=1.808058, lr=0.000018
17799it [59:01,  5.71it/s]Train batch 17800
Avg. loss per last 100 batches: 2.470780
17800it [59:02,  5.72it/s]Epoch: 0: Step: 17801/28124, loss=2.212893, lr=0.000018
17899it [59:19,  5.70it/s]Train batch 17900
Avg. loss per last 100 batches: 2.430954
17900it [59:19,  5.70it/s]Epoch: 0: Step: 17901/28124, loss=2.215989, lr=0.000018
17999it [59:37,  5.40it/s]Train batch 18000
Avg. loss per last 100 batches: 2.432226
18000it [59:37,  5.39it/s]Epoch: 0: Step: 18001/28124, loss=3.212828, lr=0.000018
18099it [59:54,  5.52it/s]Train batch 18100
Avg. loss per last 100 batches: 2.419426
18100it [59:55,  5.59it/s]Epoch: 0: Step: 18101/28124, loss=2.922324, lr=0.000018
18199it [1:00:12,  5.72it/s]Train batch 18200
Avg. loss per last 100 batches: 2.446042
18200it [1:00:12,  5.74it/s]Epoch: 0: Step: 18201/28124, loss=1.927117, lr=0.000018
18299it [1:00:29,  5.73it/s]Train batch 18300
Avg. loss per last 100 batches: 2.448884
18300it [1:00:30,  5.73it/s]Epoch: 0: Step: 18301/28124, loss=2.898247, lr=0.000018
18399it [1:00:47,  5.72it/s]Train batch 18400
Avg. loss per last 100 batches: 2.418100
18400it [1:00:47,  5.70it/s]Epoch: 0: Step: 18401/28124, loss=2.489866, lr=0.000018
18499it [1:01:05,  5.74it/s]Train batch 18500
Avg. loss per last 100 batches: 2.430963
18500it [1:01:05,  5.75it/s]Epoch: 0: Step: 18501/28124, loss=2.520238, lr=0.000018
18599it [1:01:22,  5.76it/s]Train batch 18600
Avg. loss per last 100 batches: 2.403067
18600it [1:01:22,  5.74it/s]Epoch: 0: Step: 18601/28124, loss=2.778258, lr=0.000018
18699it [1:01:39,  5.75it/s]Train batch 18700
Avg. loss per last 100 batches: 2.395538
18700it [1:01:40,  5.75it/s]Epoch: 0: Step: 18701/28124, loss=2.359426, lr=0.000018
18799it [1:01:57,  5.71it/s]Train batch 18800
Avg. loss per last 100 batches: 2.397391
18800it [1:01:57,  5.70it/s]Epoch: 0: Step: 18801/28124, loss=2.718574, lr=0.000018
18899it [1:02:15,  5.39it/s]Train batch 18900
Avg. loss per last 100 batches: 2.420048
18900it [1:02:15,  5.38it/s]Epoch: 0: Step: 18901/28124, loss=2.832196, lr=0.000018
18999it [1:02:32,  5.73it/s]Train batch 19000
Avg. loss per last 100 batches: 2.388900
19000it [1:02:32,  5.73it/s]Epoch: 0: Step: 19001/28124, loss=2.102109, lr=0.000018
19099it [1:02:50,  5.74it/s]Train batch 19100
Avg. loss per last 100 batches: 2.379235
19100it [1:02:50,  5.73it/s]Epoch: 0: Step: 19101/28124, loss=1.881544, lr=0.000018
19199it [1:03:07,  5.73it/s]Train batch 19200
Avg. loss per last 100 batches: 2.414811
19200it [1:03:07,  5.73it/s]Epoch: 0: Step: 19201/28124, loss=2.243900, lr=0.000018
19299it [1:03:25,  5.70it/s]Train batch 19300
Avg. loss per last 100 batches: 2.420038
19300it [1:03:25,  5.69it/s]Epoch: 0: Step: 19301/28124, loss=2.185786, lr=0.000018
19399it [1:03:42,  5.75it/s]Train batch 19400
Avg. loss per last 100 batches: 2.384381
19400it [1:03:42,  5.75it/s]Epoch: 0: Step: 19401/28124, loss=2.311691, lr=0.000018
19499it [1:04:00,  5.73it/s]Train batch 19500
Avg. loss per last 100 batches: 2.382208
19500it [1:04:00,  5.74it/s]Epoch: 0: Step: 19501/28124, loss=2.516165, lr=0.000018
19599it [1:04:17,  5.72it/s]Train batch 19600
Avg. loss per last 100 batches: 2.389133
19600it [1:04:17,  5.72it/s]Epoch: 0: Step: 19601/28124, loss=2.209445, lr=0.000018
19699it [1:04:35,  5.67it/s]Train batch 19700
Avg. loss per last 100 batches: 2.348567
19700it [1:04:35,  5.69it/s]Epoch: 0: Step: 19701/28124, loss=1.971583, lr=0.000018
19799it [1:04:52,  5.72it/s]Train batch 19800
Avg. loss per last 100 batches: 2.351701
19800it [1:04:53,  5.71it/s]Epoch: 0: Step: 19801/28124, loss=2.660332, lr=0.000018
19899it [1:05:10,  5.73it/s]Train batch 19900
Avg. loss per last 100 batches: 2.375804
19900it [1:05:10,  5.74it/s]Epoch: 0: Step: 19901/28124, loss=2.452660, lr=0.000018
19999it [1:05:27,  5.71it/s]Train batch 20000
Avg. loss per last 100 batches: 2.369825
20000it [1:05:28,  5.72it/s]Epoch: 0: Step: 20001/28124, loss=2.482683, lr=0.000018
20099it [1:05:45,  5.64it/s]Train batch 20100
Avg. loss per last 100 batches: 2.404194
20100it [1:05:45,  5.68it/s]Epoch: 0: Step: 20101/28124, loss=2.661388, lr=0.000018
20199it [1:06:03,  5.72it/s]Train batch 20200
Avg. loss per last 100 batches: 2.356296
20200it [1:06:03,  5.69it/s]Epoch: 0: Step: 20201/28124, loss=2.414387, lr=0.000018
20299it [1:06:20,  5.76it/s]Train batch 20300
Avg. loss per last 100 batches: 2.355407
20300it [1:06:20,  5.73it/s]Epoch: 0: Step: 20301/28124, loss=2.169421, lr=0.000018
20399it [1:06:38,  5.75it/s]Train batch 20400
Avg. loss per last 100 batches: 2.333928
20400it [1:06:38,  5.75it/s]Epoch: 0: Step: 20401/28124, loss=2.391763, lr=0.000018
20499it [1:06:55,  5.71it/s]Train batch 20500
Avg. loss per last 100 batches: 2.322692
20500it [1:06:55,  5.71it/s]Epoch: 0: Step: 20501/28124, loss=2.576289, lr=0.000018
20599it [1:07:13,  5.75it/s]Train batch 20600
Avg. loss per last 100 batches: 2.331259
20600it [1:07:13,  5.74it/s]Epoch: 0: Step: 20601/28124, loss=2.851001, lr=0.000018
20699it [1:07:30,  5.73it/s]Train batch 20700
Avg. loss per last 100 batches: 2.360413
20700it [1:07:30,  5.72it/s]Epoch: 0: Step: 20701/28124, loss=2.229684, lr=0.000018
20799it [1:07:48,  5.73it/s]Train batch 20800
Avg. loss per last 100 batches: 2.354728
20800it [1:07:48,  5.73it/s]Epoch: 0: Step: 20801/28124, loss=2.211321, lr=0.000018
20899it [1:08:05,  5.60it/s]Train batch 20900
Avg. loss per last 100 batches: 2.368326
20900it [1:08:06,  5.64it/s]Epoch: 0: Step: 20901/28124, loss=2.262265, lr=0.000018
20999it [1:08:23,  5.74it/s]Train batch 21000
Avg. loss per last 100 batches: 2.348311
21000it [1:08:23,  5.74it/s]Epoch: 0: Step: 21001/28124, loss=2.052161, lr=0.000018
21099it [1:08:40,  5.77it/s]Train batch 21100
Avg. loss per last 100 batches: 2.304250
21100it [1:08:41,  5.75it/s]Epoch: 0: Step: 21101/28124, loss=2.381121, lr=0.000018
21199it [1:08:58,  5.75it/s]Train batch 21200
Avg. loss per last 100 batches: 2.412264
21200it [1:08:58,  5.74it/s]Epoch: 0: Step: 21201/28124, loss=2.557238, lr=0.000018
21299it [1:09:16,  5.71it/s]Train batch 21300
Avg. loss per last 100 batches: 2.366581
21300it [1:09:16,  5.70it/s]Epoch: 0: Step: 21301/28124, loss=2.465497, lr=0.000018
21399it [1:09:33,  5.74it/s]Train batch 21400
Avg. loss per last 100 batches: 2.341142
21400it [1:09:33,  5.74it/s]Epoch: 0: Step: 21401/28124, loss=2.600557, lr=0.000018
21499it [1:09:51,  5.69it/s]Train batch 21500
Avg. loss per last 100 batches: 2.322389
21500it [1:09:51,  5.68it/s]Epoch: 0: Step: 21501/28124, loss=2.622830, lr=0.000018
21599it [1:10:08,  5.74it/s]Train batch 21600
Avg. loss per last 100 batches: 2.340170
21600it [1:10:08,  5.75it/s]Epoch: 0: Step: 21601/28124, loss=2.719993, lr=0.000018
21699it [1:10:26,  5.76it/s]Train batch 21700
Avg. loss per last 100 batches: 2.430608
21700it [1:10:26,  5.74it/s]Epoch: 0: Step: 21701/28124, loss=2.383735, lr=0.000018
21799it [1:10:43,  5.40it/s]Train batch 21800
Avg. loss per last 100 batches: 2.320318
21800it [1:10:43,  5.38it/s]Epoch: 0: Step: 21801/28124, loss=2.218551, lr=0.000018
21899it [1:11:01,  5.73it/s]Train batch 21900
Avg. loss per last 100 batches: 2.354570
21900it [1:11:01,  5.73it/s]Epoch: 0: Step: 21901/28124, loss=2.396313, lr=0.000018
21999it [1:11:18,  5.73it/s]Train batch 22000
Avg. loss per last 100 batches: 2.318777
22000it [1:11:18,  5.73it/s]Epoch: 0: Step: 22001/28124, loss=2.321239, lr=0.000018
22099it [1:11:36,  5.69it/s]Train batch 22100
Avg. loss per last 100 batches: 2.342368
22100it [1:11:36,  5.70it/s]Epoch: 0: Step: 22101/28124, loss=1.989148, lr=0.000018
22199it [1:11:53,  5.75it/s]Train batch 22200
Avg. loss per last 100 batches: 2.336673
22200it [1:11:53,  5.75it/s]Epoch: 0: Step: 22201/28124, loss=2.575284, lr=0.000018
22299it [1:12:11,  5.71it/s]Train batch 22300
Avg. loss per last 100 batches: 2.339032
22300it [1:12:11,  5.72it/s]Epoch: 0: Step: 22301/28124, loss=2.649546, lr=0.000018
22399it [1:12:28,  5.76it/s]Train batch 22400
Avg. loss per last 100 batches: 2.348571
22400it [1:12:28,  5.74it/s]Epoch: 0: Step: 22401/28124, loss=2.122054, lr=0.000018
22499it [1:12:46,  5.73it/s]Train batch 22500
Avg. loss per last 100 batches: 2.318117
Validation: Epoch: 0 Step: 22500/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.513831 sec., loss=1.590435 
Eval step: 199 , used_time=8.845740 sec., loss=1.567607 
Eval step: 299 , used_time=13.131174 sec., loss=1.449192 
Eval step: 399 , used_time=17.406470 sec., loss=1.537472 
Eval step: 499 , used_time=21.711868 sec., loss=1.382279 
Eval step: 599 , used_time=25.983907 sec., loss=1.883591 
Eval step: 699 , used_time=30.297920 sec., loss=1.824164 
Eval step: 799 , used_time=34.664834 sec., loss=1.595139 
Eval step: 899 , used_time=39.084016 sec., loss=1.314160 
Eval step: 999 , used_time=43.365235 sec., loss=1.616244 
Eval step: 1099 , used_time=47.638942 sec., loss=1.475715 
Eval step: 1199 , used_time=51.940259 sec., loss=1.696957 
Eval step: 1299 , used_time=56.208204 sec., loss=1.383370 
Eval step: 1399 , used_time=60.540645 sec., loss=1.172111 
Eval step: 1499 , used_time=64.813598 sec., loss=1.477444 
Eval step: 1599 , used_time=69.329398 sec., loss=1.565685 
Eval step: 1699 , used_time=73.639714 sec., loss=1.365280 
Eval step: 1799 , used_time=77.958194 sec., loss=1.304567 
Eval step: 1899 , used_time=82.242139 sec., loss=1.255896 
Eval step: 1999 , used_time=86.536521 sec., loss=1.825232 
Eval step: 2099 , used_time=90.885568 sec., loss=1.146938 
Eval step: 2199 , used_time=95.194697 sec., loss=1.473069 
Eval step: 2299 , used_time=99.717736 sec., loss=0.936026 
Eval step: 2399 , used_time=104.014634 sec., loss=1.786334 
Eval step: 2499 , used_time=108.341053 sec., loss=1.378880 
Eval step: 2599 , used_time=112.642950 sec., loss=1.426121 
Eval step: 2699 , used_time=116.916789 sec., loss=1.974270 
Eval step: 2799 , used_time=121.235212 sec., loss=1.917163 
Eval step: 2899 , used_time=125.502648 sec., loss=1.678323 
Eval step: 2999 , used_time=129.867868 sec., loss=1.354953 
Eval step: 3099 , used_time=134.303516 sec., loss=1.535620 
NLL Validation: loss = 1.567194. correct prediction ratio  55367/100032 ~  0.553493
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
22500it [1:15:07, 42.41s/it]Epoch: 0: Step: 22501/28124, loss=2.389580, lr=0.000018
22599it [1:15:24,  5.59it/s]Train batch 22600
Avg. loss per last 100 batches: 2.337298
22600it [1:15:24,  5.45it/s]Epoch: 0: Step: 22601/28124, loss=2.463774, lr=0.000018
22699it [1:15:42,  5.73it/s]Train batch 22700
Avg. loss per last 100 batches: 2.355035
22700it [1:15:42,  5.73it/s]Epoch: 0: Step: 22701/28124, loss=2.225516, lr=0.000018
22799it [1:15:59,  5.75it/s]Train batch 22800
Avg. loss per last 100 batches: 2.282463
22800it [1:15:59,  5.72it/s]Epoch: 0: Step: 22801/28124, loss=2.663036, lr=0.000018
22899it [1:16:17,  5.74it/s]Train batch 22900
Avg. loss per last 100 batches: 2.315311
22900it [1:16:17,  5.71it/s]Epoch: 0: Step: 22901/28124, loss=1.933328, lr=0.000018
22999it [1:16:34,  5.48it/s]Train batch 23000
Avg. loss per last 100 batches: 2.285015
23000it [1:16:34,  5.55it/s]Epoch: 0: Step: 23001/28124, loss=2.509388, lr=0.000018
23099it [1:16:52,  5.75it/s]Train batch 23100
Avg. loss per last 100 batches: 2.327092
23100it [1:16:52,  5.75it/s]Epoch: 0: Step: 23101/28124, loss=2.080243, lr=0.000018
23199it [1:17:09,  5.76it/s]Train batch 23200
Avg. loss per last 100 batches: 2.308249
23200it [1:17:10,  5.73it/s]Epoch: 0: Step: 23201/28124, loss=2.260957, lr=0.000018
23299it [1:17:27,  5.76it/s]Train batch 23300
Avg. loss per last 100 batches: 2.293075
23300it [1:17:27,  5.74it/s]Epoch: 0: Step: 23301/28124, loss=1.670728, lr=0.000018
23399it [1:17:44,  5.69it/s]Train batch 23400
Avg. loss per last 100 batches: 2.280839
23400it [1:17:45,  5.71it/s]Epoch: 0: Step: 23401/28124, loss=2.142211, lr=0.000018
23499it [1:18:02,  5.74it/s]Train batch 23500
Avg. loss per last 100 batches: 2.332521
23500it [1:18:02,  5.74it/s]Epoch: 0: Step: 23501/28124, loss=2.401787, lr=0.000018
23599it [1:18:19,  5.74it/s]Train batch 23600
Avg. loss per last 100 batches: 2.270449
23600it [1:18:20,  5.71it/s]Epoch: 0: Step: 23601/28124, loss=1.698256, lr=0.000018
23699it [1:18:37,  5.73it/s]Train batch 23700
Avg. loss per last 100 batches: 2.291763
23700it [1:18:37,  5.73it/s]Epoch: 0: Step: 23701/28124, loss=2.555327, lr=0.000018
23799it [1:18:54,  5.60it/s]Train batch 23800
Avg. loss per last 100 batches: 2.333262
23800it [1:18:55,  5.63it/s]Epoch: 0: Step: 23801/28124, loss=2.071637, lr=0.000018
23899it [1:19:12,  5.66it/s]Train batch 23900
Avg. loss per last 100 batches: 2.340727
23900it [1:19:12,  5.69it/s]Epoch: 0: Step: 23901/28124, loss=2.369651, lr=0.000018
23999it [1:19:29,  5.75it/s]Train batch 24000
Avg. loss per last 100 batches: 2.308017
24000it [1:19:30,  5.69it/s]Epoch: 0: Step: 24001/28124, loss=2.122506, lr=0.000018
24099it [1:19:47,  5.74it/s]Train batch 24100
Avg. loss per last 100 batches: 2.357707
24100it [1:19:47,  5.75it/s]Epoch: 0: Step: 24101/28124, loss=2.566412, lr=0.000018
24199it [1:20:04,  5.74it/s]Train batch 24200
Avg. loss per last 100 batches: 2.261628
24200it [1:20:05,  5.74it/s]Epoch: 0: Step: 24201/28124, loss=1.964729, lr=0.000018
24299it [1:20:22,  5.74it/s]Train batch 24300
Avg. loss per last 100 batches: 2.222631
24300it [1:20:22,  5.73it/s]Epoch: 0: Step: 24301/28124, loss=2.037531, lr=0.000018
24399it [1:20:39,  5.73it/s]Train batch 24400
Avg. loss per last 100 batches: 2.286005
24400it [1:20:40,  5.73it/s]Epoch: 0: Step: 24401/28124, loss=2.012932, lr=0.000018
24499it [1:20:57,  5.73it/s]Train batch 24500
Avg. loss per last 100 batches: 2.276314
24500it [1:20:57,  5.73it/s]Epoch: 0: Step: 24501/28124, loss=2.023506, lr=0.000018
24599it [1:21:15,  5.63it/s]Train batch 24600
Avg. loss per last 100 batches: 2.274443
24600it [1:21:15,  5.66it/s]Epoch: 0: Step: 24601/28124, loss=2.056362, lr=0.000018
24699it [1:21:32,  5.69it/s]Train batch 24700
Avg. loss per last 100 batches: 2.215718
24700it [1:21:32,  5.70it/s]Epoch: 0: Step: 24701/28124, loss=2.056652, lr=0.000018
24799it [1:21:50,  5.39it/s]Train batch 24800
Avg. loss per last 100 batches: 2.313499
24800it [1:21:50,  5.39it/s]Epoch: 0: Step: 24801/28124, loss=2.021327, lr=0.000018
24899it [1:22:07,  5.72it/s]Train batch 24900
Avg. loss per last 100 batches: 2.335405
24900it [1:22:07,  5.70it/s]Epoch: 0: Step: 24901/28124, loss=2.396074, lr=0.000018
24999it [1:22:25,  5.71it/s]Train batch 25000
Avg. loss per last 100 batches: 2.253401
25000it [1:22:25,  5.70it/s]Epoch: 0: Step: 25001/28124, loss=1.871578, lr=0.000018
25099it [1:22:42,  5.75it/s]Train batch 25100
Avg. loss per last 100 batches: 2.333485
25100it [1:22:42,  5.75it/s]Epoch: 0: Step: 25101/28124, loss=2.414456, lr=0.000018
25199it [1:23:00,  5.74it/s]Train batch 25200
Avg. loss per last 100 batches: 2.223806
25200it [1:23:00,  5.73it/s]Epoch: 0: Step: 25201/28124, loss=2.442446, lr=0.000018
25299it [1:23:17,  5.74it/s]Train batch 25300
Avg. loss per last 100 batches: 2.222306
25300it [1:23:17,  5.74it/s]Epoch: 0: Step: 25301/28124, loss=2.402712, lr=0.000018
25399it [1:23:35,  5.60it/s]Train batch 25400
Avg. loss per last 100 batches: 2.267298
25400it [1:23:35,  5.65it/s]Epoch: 0: Step: 25401/28124, loss=2.647323, lr=0.000018
25499it [1:23:52,  5.75it/s]Train batch 25500
Avg. loss per last 100 batches: 2.215011
25500it [1:23:52,  5.75it/s]Epoch: 0: Step: 25501/28124, loss=2.382844, lr=0.000018
25599it [1:24:10,  5.74it/s]Train batch 25600
Avg. loss per last 100 batches: 2.259473
25600it [1:24:10,  5.72it/s]Epoch: 0: Step: 25601/28124, loss=2.112859, lr=0.000018
25699it [1:24:27,  5.70it/s]Train batch 25700
Avg. loss per last 100 batches: 2.264758
25700it [1:24:28,  5.57it/s]Epoch: 0: Step: 25701/28124, loss=2.122736, lr=0.000017
25799it [1:24:45,  5.67it/s]Train batch 25800
Avg. loss per last 100 batches: 2.210184
25800it [1:24:45,  5.70it/s]Epoch: 0: Step: 25801/28124, loss=2.469080, lr=0.000017
25899it [1:25:03,  5.74it/s]Train batch 25900
Avg. loss per last 100 batches: 2.253835
25900it [1:25:03,  5.74it/s]Epoch: 0: Step: 25901/28124, loss=2.873139, lr=0.000017
25999it [1:25:20,  5.75it/s]Train batch 26000
Avg. loss per last 100 batches: 2.232995
26000it [1:25:20,  5.72it/s]Epoch: 0: Step: 26001/28124, loss=2.101623, lr=0.000017
26099it [1:25:38,  5.69it/s]Train batch 26100
Avg. loss per last 100 batches: 2.237238
26100it [1:25:38,  5.68it/s]Epoch: 0: Step: 26101/28124, loss=2.535606, lr=0.000017
26199it [1:25:55,  5.69it/s]Train batch 26200
Avg. loss per last 100 batches: 2.242094
26200it [1:25:55,  5.68it/s]Epoch: 0: Step: 26201/28124, loss=2.416312, lr=0.000017
26299it [1:26:13,  5.76it/s]Train batch 26300
Avg. loss per last 100 batches: 2.284177
26300it [1:26:13,  5.75it/s]Epoch: 0: Step: 26301/28124, loss=1.860475, lr=0.000017
26399it [1:26:30,  5.74it/s]Train batch 26400
Avg. loss per last 100 batches: 2.204435
26400it [1:26:30,  5.75it/s]Epoch: 0: Step: 26401/28124, loss=1.744888, lr=0.000017
26499it [1:26:48,  5.76it/s]Train batch 26500
Avg. loss per last 100 batches: 2.216703
26500it [1:26:48,  5.76it/s]Epoch: 0: Step: 26501/28124, loss=2.195053, lr=0.000017
26599it [1:27:05,  5.70it/s]Train batch 26600
Avg. loss per last 100 batches: 2.266503
26600it [1:27:05,  5.72it/s]Epoch: 0: Step: 26601/28124, loss=2.877775, lr=0.000017
26699it [1:27:23,  5.76it/s]Train batch 26700
Avg. loss per last 100 batches: 2.185662
26700it [1:27:23,  5.73it/s]Epoch: 0: Step: 26701/28124, loss=1.834116, lr=0.000017
26799it [1:27:40,  5.69it/s]Train batch 26800
Avg. loss per last 100 batches: 2.219697
26800it [1:27:40,  5.71it/s]Epoch: 0: Step: 26801/28124, loss=2.308371, lr=0.000017
26899it [1:27:58,  5.73it/s]Train batch 26900
Avg. loss per last 100 batches: 2.242361
26900it [1:27:58,  5.75it/s]Epoch: 0: Step: 26901/28124, loss=2.323522, lr=0.000017
26999it [1:28:15,  5.71it/s]Train batch 27000
Avg. loss per last 100 batches: 2.254227
27000it [1:28:15,  5.72it/s]Epoch: 0: Step: 27001/28124, loss=1.812208, lr=0.000017
27099it [1:28:33,  5.73it/s]Train batch 27100
Avg. loss per last 100 batches: 2.200482
27100it [1:28:33,  5.72it/s]Epoch: 0: Step: 27101/28124, loss=2.228745, lr=0.000017
27199it [1:28:50,  5.73it/s]Train batch 27200
Avg. loss per last 100 batches: 2.199038
27200it [1:28:50,  5.73it/s]Epoch: 0: Step: 27201/28124, loss=2.737333, lr=0.000017
27299it [1:29:08,  5.73it/s]Train batch 27300
Avg. loss per last 100 batches: 2.305965
27300it [1:29:08,  5.74it/s]Epoch: 0: Step: 27301/28124, loss=2.514985, lr=0.000017
27399it [1:29:25,  5.70it/s]Train batch 27400
Avg. loss per last 100 batches: 2.195092
27400it [1:29:25,  5.69it/s]Epoch: 0: Step: 27401/28124, loss=2.180241, lr=0.000017
27499it [1:29:43,  5.73it/s]Train batch 27500
Avg. loss per last 100 batches: 2.184705
27500it [1:29:43,  5.72it/s]Epoch: 0: Step: 27501/28124, loss=2.102861, lr=0.000017
27599it [1:30:00,  5.74it/s]Train batch 27600
Avg. loss per last 100 batches: 2.216016
27600it [1:30:00,  5.75it/s]Epoch: 0: Step: 27601/28124, loss=1.948002, lr=0.000017
27699it [1:30:18,  5.44it/s]Train batch 27700
Avg. loss per last 100 batches: 2.252517
27700it [1:30:18,  5.45it/s]Epoch: 0: Step: 27701/28124, loss=2.460686, lr=0.000017
27799it [1:30:35,  5.73it/s]Train batch 27800
Avg. loss per last 100 batches: 2.244159
27800it [1:30:35,  5.74it/s]Epoch: 0: Step: 27801/28124, loss=2.423467, lr=0.000017
27899it [1:30:53,  5.71it/s]Train batch 27900
Avg. loss per last 100 batches: 2.172461
27900it [1:30:53,  5.71it/s]Epoch: 0: Step: 27901/28124, loss=1.735936, lr=0.000017
27999it [1:31:10,  5.77it/s]Train batch 28000
Avg. loss per last 100 batches: 2.168357
28000it [1:31:10,  5.76it/s]Epoch: 0: Step: 28001/28124, loss=2.197582, lr=0.000017
28099it [1:31:28,  5.74it/s]Train batch 28100
Avg. loss per last 100 batches: 2.228541
28100it [1:31:28,  5.75it/s]Epoch: 0: Step: 28101/28124, loss=1.726947, lr=0.000017
28124it [1:31:32,  5.12it/s]
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.299320 sec., loss=1.371950 
Eval step: 199 , used_time=8.629208 sec., loss=1.255735 
Eval step: 299 , used_time=12.914158 sec., loss=1.213049 
Eval step: 399 , used_time=17.387674 sec., loss=1.463636 
Eval step: 499 , used_time=21.657401 sec., loss=1.529309 
Eval step: 599 , used_time=25.954534 sec., loss=1.603506 
Eval step: 699 , used_time=30.270416 sec., loss=1.821083 
Eval step: 799 , used_time=34.573079 sec., loss=1.549861 
Eval step: 899 , used_time=38.912933 sec., loss=1.430003 
Eval step: 999 , used_time=43.202951 sec., loss=1.542311 
Eval step: 1099 , used_time=47.728450 sec., loss=1.341306 
Eval step: 1199 , used_time=52.057726 sec., loss=1.709923 
Eval step: 1299 , used_time=56.325560 sec., loss=1.277000 
Eval step: 1399 , used_time=60.662324 sec., loss=1.092060 
Eval step: 1499 , used_time=64.942774 sec., loss=1.248999 
Eval step: 1599 , used_time=69.264949 sec., loss=1.235078 
Eval step: 1699 , used_time=73.566818 sec., loss=1.428046 
Eval step: 1799 , used_time=77.917523 sec., loss=1.146527 
Eval step: 1899 , used_time=82.394125 sec., loss=1.172901 
Eval step: 1999 , used_time=86.701465 sec., loss=1.875337 
Eval step: 2099 , used_time=91.041981 sec., loss=1.160881 
Eval step: 2199 , used_time=95.336207 sec., loss=1.128127 
Eval step: 2299 , used_time=99.669461 sec., loss=1.021795 
Eval step: 2399 , used_time=103.961388 sec., loss=1.780140 
Eval step: 2499 , used_time=108.288962 sec., loss=1.240668 
Eval step: 2599 , used_time=112.753099 sec., loss=1.298802 
Eval step: 2699 , used_time=117.042483 sec., loss=1.808619 
Eval step: 2799 , used_time=121.342309 sec., loss=1.448356 
Eval step: 2899 , used_time=125.615916 sec., loss=1.445302 
Eval step: 2999 , used_time=129.953934 sec., loss=1.162655 
Eval step: 3099 , used_time=134.237847 sec., loss=1.453917 
NLL Validation: loss = 1.468238. correct prediction ratio  57970/100032 ~  0.579515
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=2.744388
epoch total correct predictions=294327
***** Epoch 1 *****
0it [00:00, ?it/s]Epoch: 1: Step: 1/28124, loss=2.001601, lr=0.000017
99it [00:18,  5.73it/s]Train batch 100
Avg. loss per last 100 batches: 2.021089
100it [00:18,  5.74it/s]Epoch: 1: Step: 101/28124, loss=1.731152, lr=0.000017
199it [00:36,  5.71it/s]Train batch 200
Avg. loss per last 100 batches: 2.039339
200it [00:36,  5.71it/s]Epoch: 1: Step: 201/28124, loss=1.836170, lr=0.000017
299it [00:53,  5.71it/s]Train batch 300
Avg. loss per last 100 batches: 1.988242
300it [00:53,  5.73it/s]Epoch: 1: Step: 301/28124, loss=2.204413, lr=0.000017
399it [01:11,  5.75it/s]Train batch 400
Avg. loss per last 100 batches: 2.067818
400it [01:11,  5.74it/s]Epoch: 1: Step: 401/28124, loss=2.083366, lr=0.000017
499it [01:28,  5.75it/s]Train batch 500
Avg. loss per last 100 batches: 2.021439
500it [01:28,  5.74it/s]Epoch: 1: Step: 501/28124, loss=2.301358, lr=0.000017
599it [01:46,  5.72it/s]Train batch 600
Avg. loss per last 100 batches: 2.045909
600it [01:46,  5.71it/s]Epoch: 1: Step: 601/28124, loss=1.678285, lr=0.000017
699it [02:03,  5.75it/s]Train batch 700
Avg. loss per last 100 batches: 2.040199
700it [02:03,  5.74it/s]Epoch: 1: Step: 701/28124, loss=1.876873, lr=0.000017
799it [02:21,  5.73it/s]Train batch 800
Avg. loss per last 100 batches: 2.009880
800it [02:21,  5.75it/s]Epoch: 1: Step: 801/28124, loss=2.091685, lr=0.000017
899it [02:38,  5.76it/s]Train batch 900
Avg. loss per last 100 batches: 2.063234
900it [02:38,  5.76it/s]Epoch: 1: Step: 901/28124, loss=2.313976, lr=0.000017
999it [02:56,  5.72it/s]Train batch 1000
Avg. loss per last 100 batches: 2.041652
1000it [02:56,  5.73it/s]Epoch: 1: Step: 1001/28124, loss=1.798836, lr=0.000017
1099it [03:13,  5.48it/s]Train batch 1100
Avg. loss per last 100 batches: 2.058650
1100it [03:13,  5.54it/s]Epoch: 1: Step: 1101/28124, loss=2.423490, lr=0.000017
1199it [03:31,  5.78it/s]Train batch 1200
Avg. loss per last 100 batches: 2.037664
1200it [03:31,  5.74it/s]Epoch: 1: Step: 1201/28124, loss=2.122700, lr=0.000017
1299it [03:48,  5.75it/s]Train batch 1300
Avg. loss per last 100 batches: 2.032839
1300it [03:48,  5.75it/s]Epoch: 1: Step: 1301/28124, loss=1.673001, lr=0.000017
1399it [04:05,  5.77it/s]Train batch 1400
Avg. loss per last 100 batches: 2.035255
1400it [04:06,  5.76it/s]Epoch: 1: Step: 1401/28124, loss=1.604048, lr=0.000017
1499it [04:23,  5.70it/s]Train batch 1500
Avg. loss per last 100 batches: 1.999635
1500it [04:23,  5.72it/s]Epoch: 1: Step: 1501/28124, loss=1.710314, lr=0.000017
1599it [04:40,  5.76it/s]Train batch 1600
Avg. loss per last 100 batches: 2.036113
1600it [04:41,  5.75it/s]Epoch: 1: Step: 1601/28124, loss=1.754522, lr=0.000017
1699it [04:58,  5.72it/s]Train batch 1700
Avg. loss per last 100 batches: 1.980679
1700it [04:58,  5.71it/s]Epoch: 1: Step: 1701/28124, loss=1.996299, lr=0.000017
1799it [05:15,  5.75it/s]Train batch 1800
Avg. loss per last 100 batches: 2.016922
1800it [05:16,  5.76it/s]Epoch: 1: Step: 1801/28124, loss=1.712886, lr=0.000017
1899it [05:33,  5.74it/s]Train batch 1900
Avg. loss per last 100 batches: 2.091432
1900it [05:33,  5.73it/s]Epoch: 1: Step: 1901/28124, loss=1.761081, lr=0.000017
1999it [05:50,  5.62it/s]Train batch 2000
Avg. loss per last 100 batches: 2.046639
2000it [05:51,  5.39it/s]Epoch: 1: Step: 2001/28124, loss=2.419028, lr=0.000017
2099it [06:08,  5.74it/s]Train batch 2100
Avg. loss per last 100 batches: 2.014674
2100it [06:08,  5.73it/s]Epoch: 1: Step: 2101/28124, loss=1.837361, lr=0.000017
2199it [06:26,  5.70it/s]Train batch 2200
Avg. loss per last 100 batches: 2.001183
2200it [06:26,  5.71it/s]Epoch: 1: Step: 2201/28124, loss=2.188983, lr=0.000017
2299it [06:43,  5.75it/s]Train batch 2300
Avg. loss per last 100 batches: 2.018806
2300it [06:43,  5.72it/s]Epoch: 1: Step: 2301/28124, loss=1.987847, lr=0.000017
2399it [07:01,  5.72it/s]Train batch 2400
Avg. loss per last 100 batches: 1.979191
2400it [07:01,  5.72it/s]Epoch: 1: Step: 2401/28124, loss=2.289345, lr=0.000017
2499it [07:18,  5.73it/s]Train batch 2500
Avg. loss per last 100 batches: 1.991173
2500it [07:18,  5.73it/s]Epoch: 1: Step: 2501/28124, loss=1.910750, lr=0.000017
2599it [07:36,  5.77it/s]Train batch 2600
Avg. loss per last 100 batches: 2.027058
2600it [07:36,  5.73it/s]Epoch: 1: Step: 2601/28124, loss=2.853779, lr=0.000017
2699it [07:53,  5.77it/s]Train batch 2700
Avg. loss per last 100 batches: 1.988759
2700it [07:53,  5.75it/s]Epoch: 1: Step: 2701/28124, loss=2.287335, lr=0.000017
2799it [08:11,  5.70it/s]Train batch 2800
Avg. loss per last 100 batches: 2.017739
2800it [08:11,  5.71it/s]Epoch: 1: Step: 2801/28124, loss=1.797848, lr=0.000017
2899it [08:28,  5.76it/s]Train batch 2900
Avg. loss per last 100 batches: 2.006392
2900it [08:28,  5.75it/s]Epoch: 1: Step: 2901/28124, loss=2.137421, lr=0.000017
2999it [08:46,  5.77it/s]Train batch 3000
Avg. loss per last 100 batches: 2.044920
3000it [08:46,  5.76it/s]Epoch: 1: Step: 3001/28124, loss=1.272686, lr=0.000017
3099it [09:03,  5.62it/s]Train batch 3100
Avg. loss per last 100 batches: 2.039723
3100it [09:03,  5.66it/s]Epoch: 1: Step: 3101/28124, loss=1.451123, lr=0.000017
3199it [09:21,  5.76it/s]Train batch 3200
Avg. loss per last 100 batches: 1.996143
3200it [09:21,  5.76it/s]Epoch: 1: Step: 3201/28124, loss=1.844521, lr=0.000017
3299it [09:38,  5.75it/s]Train batch 3300
Avg. loss per last 100 batches: 2.050602
3300it [09:38,  5.74it/s]Epoch: 1: Step: 3301/28124, loss=1.436844, lr=0.000017
3399it [09:56,  5.77it/s]Train batch 3400
Avg. loss per last 100 batches: 1.955193
3400it [09:56,  5.76it/s]Epoch: 1: Step: 3401/28124, loss=1.917655, lr=0.000017
3499it [10:13,  5.78it/s]Train batch 3500
Avg. loss per last 100 batches: 2.052440
3500it [10:13,  5.77it/s]Epoch: 1: Step: 3501/28124, loss=2.024063, lr=0.000017
3599it [10:31,  5.71it/s]Train batch 3600
Avg. loss per last 100 batches: 1.994057
3600it [10:31,  5.72it/s]Epoch: 1: Step: 3601/28124, loss=1.606437, lr=0.000017
3699it [10:48,  5.75it/s]Train batch 3700
Avg. loss per last 100 batches: 2.048190
3700it [10:48,  5.74it/s]Epoch: 1: Step: 3701/28124, loss=2.094000, lr=0.000017
3799it [11:06,  5.76it/s]Train batch 3800
Avg. loss per last 100 batches: 2.013413
3800it [11:06,  5.75it/s]Epoch: 1: Step: 3801/28124, loss=1.781375, lr=0.000017
3899it [11:23,  5.76it/s]Train batch 3900
Avg. loss per last 100 batches: 1.984806
3900it [11:23,  5.77it/s]Epoch: 1: Step: 3901/28124, loss=2.113418, lr=0.000017
3999it [11:41,  5.42it/s]Train batch 4000
Avg. loss per last 100 batches: 2.025921
4000it [11:41,  5.40it/s]Epoch: 1: Step: 4001/28124, loss=2.275137, lr=0.000017
4099it [11:58,  5.76it/s]Train batch 4100
Avg. loss per last 100 batches: 2.017029
4100it [11:58,  5.76it/s]Epoch: 1: Step: 4101/28124, loss=1.715783, lr=0.000017
4199it [12:15,  5.75it/s]Train batch 4200
Avg. loss per last 100 batches: 2.008821
4200it [12:16,  5.72it/s]Epoch: 1: Step: 4201/28124, loss=1.733813, lr=0.000017
4299it [12:33,  5.73it/s]Train batch 4300
Avg. loss per last 100 batches: 1.984022
4300it [12:33,  5.73it/s]Epoch: 1: Step: 4301/28124, loss=2.604898, lr=0.000017
4399it [12:51,  5.66it/s]Train batch 4400
Avg. loss per last 100 batches: 1.987591
4400it [12:51,  5.66it/s]Epoch: 1: Step: 4401/28124, loss=2.035218, lr=0.000017
4499it [13:08,  5.74it/s]Train batch 4500
Avg. loss per last 100 batches: 1.988255
4500it [13:08,  5.73it/s]Epoch: 1: Step: 4501/28124, loss=1.959629, lr=0.000017
4599it [13:26,  5.74it/s]Train batch 4600
Avg. loss per last 100 batches: 1.966517
4600it [13:26,  5.70it/s]Epoch: 1: Step: 4601/28124, loss=1.572445, lr=0.000017
4699it [13:43,  5.74it/s]Train batch 4700
Avg. loss per last 100 batches: 1.979019
4700it [13:43,  5.75it/s]Epoch: 1: Step: 4701/28124, loss=2.341111, lr=0.000017
4799it [14:01,  5.76it/s]Train batch 4800
Avg. loss per last 100 batches: 2.001255
4800it [14:01,  5.76it/s]Epoch: 1: Step: 4801/28124, loss=1.833358, lr=0.000017
4899it [14:18,  5.77it/s]Train batch 4900
Avg. loss per last 100 batches: 2.010890
4900it [14:18,  5.75it/s]Epoch: 1: Step: 4901/28124, loss=1.552726, lr=0.000017
4999it [14:36,  5.77it/s]Train batch 5000
Avg. loss per last 100 batches: 1.982626
5000it [14:36,  5.74it/s]Epoch: 1: Step: 5001/28124, loss=1.817348, lr=0.000017
5099it [14:53,  5.73it/s]Train batch 5100
Avg. loss per last 100 batches: 2.048295
5100it [14:53,  5.74it/s]Epoch: 1: Step: 5101/28124, loss=1.719835, lr=0.000017
5199it [15:11,  5.76it/s]Train batch 5200
Avg. loss per last 100 batches: 2.004830
5200it [15:11,  5.76it/s]Epoch: 1: Step: 5201/28124, loss=1.955081, lr=0.000017
5299it [15:28,  5.75it/s]Train batch 5300
Avg. loss per last 100 batches: 1.961958
5300it [15:28,  5.76it/s]Epoch: 1: Step: 5301/28124, loss=1.616444, lr=0.000017
5399it [15:45,  5.77it/s]Train batch 5400
Avg. loss per last 100 batches: 1.972347
5400it [15:46,  5.76it/s]Epoch: 1: Step: 5401/28124, loss=2.276541, lr=0.000017
5499it [16:03,  5.74it/s]Train batch 5500
Avg. loss per last 100 batches: 1.972929
5500it [16:03,  5.75it/s]Epoch: 1: Step: 5501/28124, loss=2.038107, lr=0.000017
5599it [16:20,  5.75it/s]Train batch 5600
Avg. loss per last 100 batches: 1.969825
5600it [16:21,  5.72it/s]Epoch: 1: Step: 5601/28124, loss=2.048468, lr=0.000017
5624it [16:25,  5.72it/s]Validation: Epoch: 1 Step: 5625/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.488793 sec., loss=1.187958 
Eval step: 199 , used_time=8.766718 sec., loss=1.277973 
Eval step: 299 , used_time=13.085674 sec., loss=1.051713 
Eval step: 399 , used_time=17.354342 sec., loss=1.484725 
Eval step: 499 , used_time=21.649083 sec., loss=1.685603 
Eval step: 599 , used_time=25.918937 sec., loss=1.773358 
Eval step: 699 , used_time=30.243035 sec., loss=1.766049 
Eval step: 799 , used_time=34.723904 sec., loss=1.635142 
Eval step: 899 , used_time=38.979830 sec., loss=1.277931 
Eval step: 999 , used_time=43.300770 sec., loss=1.550680 
Eval step: 1099 , used_time=47.559862 sec., loss=1.445379 
Eval step: 1199 , used_time=51.854083 sec., loss=1.723609 
Eval step: 1299 , used_time=56.117154 sec., loss=1.272060 
Eval step: 1399 , used_time=60.386778 sec., loss=1.014247 
Eval step: 1499 , used_time=64.880504 sec., loss=1.007894 
Eval step: 1599 , used_time=69.145182 sec., loss=1.186262 
Eval step: 1699 , used_time=73.460725 sec., loss=1.315629 
Eval step: 1799 , used_time=77.734403 sec., loss=0.983365 
Eval step: 1899 , used_time=82.027988 sec., loss=1.107014 
Eval step: 1999 , used_time=86.308576 sec., loss=2.058015 
Eval step: 2099 , used_time=90.644715 sec., loss=1.110239 
Eval step: 2199 , used_time=94.924763 sec., loss=1.040300 
Eval step: 2299 , used_time=99.389935 sec., loss=0.863872 
Eval step: 2399 , used_time=103.693996 sec., loss=1.830229 
Eval step: 2499 , used_time=107.976877 sec., loss=1.025313 
Eval step: 2599 , used_time=112.273048 sec., loss=1.408117 
Eval step: 2699 , used_time=116.536235 sec., loss=1.800526 
Eval step: 2799 , used_time=120.839130 sec., loss=1.510294 
Eval step: 2899 , used_time=125.107065 sec., loss=1.329505 
Eval step: 2999 , used_time=129.544650 sec., loss=1.216783 
Eval step: 3099 , used_time=133.851014 sec., loss=1.430569 
NLL Validation: loss = 1.398902. correct prediction ratio  60126/100032 ~  0.601068
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [18:58,  5.74it/s]Train batch 5700
Avg. loss per last 100 batches: 1.997802
5700it [18:59,  5.73it/s]Epoch: 1: Step: 5701/28124, loss=2.059200, lr=0.000017
5799it [19:16,  5.63it/s]Train batch 5800
Avg. loss per last 100 batches: 1.996506
5800it [19:16,  5.46it/s]Epoch: 1: Step: 5801/28124, loss=2.571692, lr=0.000017
5899it [19:33,  5.70it/s]Train batch 5900
Avg. loss per last 100 batches: 1.954308
5900it [19:34,  5.71it/s]Epoch: 1: Step: 5901/28124, loss=1.643853, lr=0.000017
5999it [19:51,  5.77it/s]Train batch 6000
Avg. loss per last 100 batches: 1.963724
6000it [19:51,  5.77it/s]Epoch: 1: Step: 6001/28124, loss=2.217047, lr=0.000017
6099it [20:09,  5.45it/s]Train batch 6100
Avg. loss per last 100 batches: 1.967860
6100it [20:09,  5.45it/s]Epoch: 1: Step: 6101/28124, loss=2.323770, lr=0.000017
6199it [20:26,  5.77it/s]Train batch 6200
Avg. loss per last 100 batches: 1.969091
6200it [20:26,  5.75it/s]Epoch: 1: Step: 6201/28124, loss=2.389632, lr=0.000017
6299it [20:43,  5.75it/s]Train batch 6300
Avg. loss per last 100 batches: 2.037372
6300it [20:44,  5.76it/s]Epoch: 1: Step: 6301/28124, loss=1.629804, lr=0.000017
6399it [21:01,  5.74it/s]Train batch 6400
Avg. loss per last 100 batches: 1.930245
6400it [21:01,  5.74it/s]Epoch: 1: Step: 6401/28124, loss=1.671453, lr=0.000017
6499it [21:18,  5.75it/s]Train batch 6500
Avg. loss per last 100 batches: 1.927741
6500it [21:19,  5.76it/s]Epoch: 1: Step: 6501/28124, loss=1.647874, lr=0.000017
6599it [21:36,  5.77it/s]Train batch 6600
Avg. loss per last 100 batches: 1.909348
6600it [21:36,  5.74it/s]Epoch: 1: Step: 6601/28124, loss=2.196314, lr=0.000017
6699it [21:53,  5.74it/s]Train batch 6700
Avg. loss per last 100 batches: 2.004311
6700it [21:54,  5.71it/s]Epoch: 1: Step: 6701/28124, loss=2.101718, lr=0.000017
6799it [22:11,  5.76it/s]Train batch 6800
Avg. loss per last 100 batches: 1.957049
6800it [22:11,  5.76it/s]Epoch: 1: Step: 6801/28124, loss=1.436744, lr=0.000017
6899it [22:28,  5.73it/s]Train batch 6900
Avg. loss per last 100 batches: 1.940927
6900it [22:28,  5.74it/s]Epoch: 1: Step: 6901/28124, loss=2.043499, lr=0.000017
6999it [22:46,  5.74it/s]Train batch 7000
Avg. loss per last 100 batches: 1.943490
7000it [22:46,  5.74it/s]Epoch: 1: Step: 7001/28124, loss=1.740666, lr=0.000017
7099it [23:03,  5.74it/s]Train batch 7100
Avg. loss per last 100 batches: 1.954299
7100it [23:04,  5.74it/s]Epoch: 1: Step: 7101/28124, loss=2.288041, lr=0.000017
7199it [23:21,  5.70it/s]Train batch 7200
Avg. loss per last 100 batches: 2.008226
7200it [23:21,  5.70it/s]Epoch: 1: Step: 7201/28124, loss=1.562098, lr=0.000017
7299it [23:38,  5.75it/s]Train batch 7300
Avg. loss per last 100 batches: 1.952623
7300it [23:38,  5.76it/s]Epoch: 1: Step: 7301/28124, loss=2.704946, lr=0.000017
7399it [23:56,  5.76it/s]Train batch 7400
Avg. loss per last 100 batches: 1.927036
7400it [23:56,  5.65it/s]Epoch: 1: Step: 7401/28124, loss=2.350307, lr=0.000016
7499it [24:13,  5.73it/s]Train batch 7500
Avg. loss per last 100 batches: 1.905234
7500it [24:13,  5.74it/s]Epoch: 1: Step: 7501/28124, loss=2.175075, lr=0.000016
7599it [24:31,  5.76it/s]Train batch 7600
Avg. loss per last 100 batches: 1.914086
7600it [24:31,  5.74it/s]Epoch: 1: Step: 7601/28124, loss=2.046352, lr=0.000016
7699it [24:48,  5.76it/s]Train batch 7700
Avg. loss per last 100 batches: 1.942561
7700it [24:48,  5.76it/s]Epoch: 1: Step: 7701/28124, loss=1.901532, lr=0.000016
7799it [25:06,  5.72it/s]Train batch 7800
Avg. loss per last 100 batches: 1.978938
7800it [25:06,  5.72it/s]Epoch: 1: Step: 7801/28124, loss=1.958940, lr=0.000016
7899it [25:23,  5.73it/s]Train batch 7900
Avg. loss per last 100 batches: 1.891366
7900it [25:23,  5.74it/s]Epoch: 1: Step: 7901/28124, loss=2.365334, lr=0.000016
7999it [25:41,  5.76it/s]Train batch 8000
Avg. loss per last 100 batches: 1.938986
8000it [25:41,  5.75it/s]Epoch: 1: Step: 8001/28124, loss=1.805779, lr=0.000016
8099it [25:58,  5.46it/s]Train batch 8100
Avg. loss per last 100 batches: 1.946894
8100it [25:58,  5.43it/s]Epoch: 1: Step: 8101/28124, loss=2.225034, lr=0.000016
8199it [26:16,  5.73it/s]Train batch 8200
Avg. loss per last 100 batches: 1.952307
8200it [26:16,  5.73it/s]Epoch: 1: Step: 8201/28124, loss=2.232413, lr=0.000016
8299it [26:33,  5.76it/s]Train batch 8300
Avg. loss per last 100 batches: 1.944840
8300it [26:33,  5.76it/s]Epoch: 1: Step: 8301/28124, loss=1.396815, lr=0.000016
8399it [26:51,  5.75it/s]Train batch 8400
Avg. loss per last 100 batches: 1.974506
8400it [26:51,  5.76it/s]Epoch: 1: Step: 8401/28124, loss=2.232062, lr=0.000016
8499it [27:08,  5.74it/s]Train batch 8500
Avg. loss per last 100 batches: 1.961618
8500it [27:08,  5.75it/s]Epoch: 1: Step: 8501/28124, loss=2.326380, lr=0.000016
8599it [27:26,  5.76it/s]Train batch 8600
Avg. loss per last 100 batches: 1.953144
8600it [27:26,  5.76it/s]Epoch: 1: Step: 8601/28124, loss=1.793594, lr=0.000016
8699it [27:43,  5.77it/s]Train batch 8700
Avg. loss per last 100 batches: 2.004320
8700it [27:43,  5.76it/s]Epoch: 1: Step: 8701/28124, loss=1.678370, lr=0.000016
8799it [28:01,  5.77it/s]Train batch 8800
Avg. loss per last 100 batches: 1.965705
8800it [28:01,  5.76it/s]Epoch: 1: Step: 8801/28124, loss=2.040253, lr=0.000016
8899it [28:18,  5.68it/s]Train batch 8900
Avg. loss per last 100 batches: 1.975504
8900it [28:18,  5.70it/s]Epoch: 1: Step: 8901/28124, loss=1.130598, lr=0.000016
8999it [28:35,  5.75it/s]Train batch 9000
Avg. loss per last 100 batches: 1.892586
9000it [28:36,  5.68it/s]Epoch: 1: Step: 9001/28124, loss=1.835876, lr=0.000016
9099it [28:53,  5.74it/s]Train batch 9100
Avg. loss per last 100 batches: 1.987967
9100it [28:53,  5.76it/s]Epoch: 1: Step: 9101/28124, loss=1.436457, lr=0.000016
9199it [29:11,  5.74it/s]Train batch 9200
Avg. loss per last 100 batches: 1.999806
9200it [29:11,  5.73it/s]Epoch: 1: Step: 9201/28124, loss=1.759570, lr=0.000016
9299it [29:28,  5.73it/s]Train batch 9300
Avg. loss per last 100 batches: 1.944472
9300it [29:28,  5.73it/s]Epoch: 1: Step: 9301/28124, loss=2.037309, lr=0.000016
9399it [29:46,  5.75it/s]Train batch 9400
Avg. loss per last 100 batches: 1.945509
9400it [29:46,  5.75it/s]Epoch: 1: Step: 9401/28124, loss=2.126103, lr=0.000016
9499it [30:03,  5.71it/s]Train batch 9500
Avg. loss per last 100 batches: 1.947770
9500it [30:03,  5.70it/s]Epoch: 1: Step: 9501/28124, loss=2.220656, lr=0.000016
9599it [30:21,  5.74it/s]Train batch 9600
Avg. loss per last 100 batches: 1.932718
9600it [30:21,  5.72it/s]Epoch: 1: Step: 9601/28124, loss=1.749005, lr=0.000016
9699it [30:38,  5.74it/s]Train batch 9700
Avg. loss per last 100 batches: 1.947179
9700it [30:38,  5.75it/s]Epoch: 1: Step: 9701/28124, loss=2.657051, lr=0.000016
9799it [30:56,  5.74it/s]Train batch 9800
Avg. loss per last 100 batches: 1.963408
9800it [30:56,  5.74it/s]Epoch: 1: Step: 9801/28124, loss=2.317935, lr=0.000016
9899it [31:13,  5.75it/s]Train batch 9900
Avg. loss per last 100 batches: 1.929045
9900it [31:13,  5.76it/s]Epoch: 1: Step: 9901/28124, loss=1.732326, lr=0.000016
9999it [31:31,  5.74it/s]Train batch 10000
Avg. loss per last 100 batches: 1.896413
10000it [31:31,  5.75it/s]Epoch: 1: Step: 10001/28124, loss=2.139930, lr=0.000016
10099it [31:48,  5.65it/s]Train batch 10100
Avg. loss per last 100 batches: 1.922453
10100it [31:48,  5.69it/s]Epoch: 1: Step: 10101/28124, loss=1.988524, lr=0.000016
10199it [32:06,  5.77it/s]Train batch 10200
Avg. loss per last 100 batches: 1.987264
10200it [32:06,  5.75it/s]Epoch: 1: Step: 10201/28124, loss=2.289458, lr=0.000016
10299it [32:23,  5.73it/s]Train batch 10300
Avg. loss per last 100 batches: 1.916561
10300it [32:23,  5.74it/s]Epoch: 1: Step: 10301/28124, loss=2.445319, lr=0.000016
10399it [32:41,  5.76it/s]Train batch 10400
Avg. loss per last 100 batches: 1.932117
10400it [32:41,  5.74it/s]Epoch: 1: Step: 10401/28124, loss=2.348274, lr=0.000016
10499it [32:58,  5.74it/s]Train batch 10500
Avg. loss per last 100 batches: 1.933056
10500it [32:58,  5.74it/s]Epoch: 1: Step: 10501/28124, loss=1.448638, lr=0.000016
10599it [33:16,  5.73it/s]Train batch 10600
Avg. loss per last 100 batches: 1.923920
10600it [33:16,  5.73it/s]Epoch: 1: Step: 10601/28124, loss=1.852700, lr=0.000016
10699it [33:33,  5.75it/s]Train batch 10700
Avg. loss per last 100 batches: 1.952656
10700it [33:33,  5.76it/s]Epoch: 1: Step: 10701/28124, loss=1.548343, lr=0.000016
10799it [33:51,  5.76it/s]Train batch 10800
Avg. loss per last 100 batches: 1.957172
10800it [33:51,  5.77it/s]Epoch: 1: Step: 10801/28124, loss=1.586785, lr=0.000016
10899it [34:08,  5.73it/s]Train batch 10900
Avg. loss per last 100 batches: 1.860679
10900it [34:08,  5.74it/s]Epoch: 1: Step: 10901/28124, loss=2.570367, lr=0.000016
10999it [34:26,  5.38it/s]Train batch 11000
Avg. loss per last 100 batches: 1.919002
11000it [34:26,  5.33it/s]Epoch: 1: Step: 11001/28124, loss=1.574877, lr=0.000016
11099it [34:43,  5.76it/s]Train batch 11100
Avg. loss per last 100 batches: 1.920698
11100it [34:43,  5.76it/s]Epoch: 1: Step: 11101/28124, loss=2.207762, lr=0.000016
11199it [35:01,  5.75it/s]Train batch 11200
Avg. loss per last 100 batches: 1.909929
11200it [35:01,  5.76it/s]Epoch: 1: Step: 11201/28124, loss=1.619009, lr=0.000016
11249it [35:09,  5.77it/s]Validation: Epoch: 1 Step: 11250/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.278625 sec., loss=1.171161 
Eval step: 199 , used_time=8.573480 sec., loss=1.315610 
Eval step: 299 , used_time=12.865007 sec., loss=1.230252 
Eval step: 399 , used_time=17.199531 sec., loss=1.270390 
Eval step: 499 , used_time=21.687575 sec., loss=1.498609 
Eval step: 599 , used_time=25.976296 sec., loss=1.484758 
Eval step: 699 , used_time=30.288552 sec., loss=1.879629 
Eval step: 799 , used_time=34.550226 sec., loss=1.374105 
Eval step: 899 , used_time=38.859450 sec., loss=1.159450 
Eval step: 999 , used_time=43.156629 sec., loss=1.408967 
Eval step: 1099 , used_time=47.464954 sec., loss=1.371978 
Eval step: 1199 , used_time=51.936281 sec., loss=1.484058 
Eval step: 1299 , used_time=56.231880 sec., loss=1.219738 
Eval step: 1399 , used_time=60.501123 sec., loss=0.752810 
Eval step: 1499 , used_time=64.766176 sec., loss=1.047201 
Eval step: 1599 , used_time=69.072233 sec., loss=1.362475 
Eval step: 1699 , used_time=73.338933 sec., loss=1.328061 
Eval step: 1799 , used_time=77.650793 sec., loss=0.950381 
Eval step: 1899 , used_time=81.912138 sec., loss=0.937704 
Eval step: 1999 , used_time=86.395386 sec., loss=1.837213 
Eval step: 2099 , used_time=90.692170 sec., loss=0.999677 
Eval step: 2199 , used_time=95.006702 sec., loss=1.132095 
Eval step: 2299 , used_time=99.360463 sec., loss=0.828639 
Eval step: 2399 , used_time=103.665025 sec., loss=1.580541 
Eval step: 2499 , used_time=108.018299 sec., loss=1.213019 
Eval step: 2599 , used_time=112.328882 sec., loss=1.241185 
Eval step: 2699 , used_time=116.844813 sec., loss=1.623937 
Eval step: 2799 , used_time=121.135504 sec., loss=1.354091 
Eval step: 2899 , used_time=125.420735 sec., loss=1.315622 
Eval step: 2999 , used_time=129.719950 sec., loss=1.142746 
Eval step: 3099 , used_time=133.987107 sec., loss=1.489175 
NLL Validation: loss = 1.342973. correct prediction ratio  61864/100032 ~  0.618442
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [37:39,  5.72it/s]Train batch 11300
Avg. loss per last 100 batches: 1.926869
11300it [37:39,  5.74it/s]Epoch: 1: Step: 11301/28124, loss=2.624141, lr=0.000016
11399it [37:56,  5.60it/s]Train batch 11400
Avg. loss per last 100 batches: 1.898352
11400it [37:56,  5.59it/s]Epoch: 1: Step: 11401/28124, loss=2.030525, lr=0.000016
11499it [38:14,  5.75it/s]Train batch 11500
Avg. loss per last 100 batches: 1.890675
11500it [38:14,  5.75it/s]Epoch: 1: Step: 11501/28124, loss=1.863685, lr=0.000016
11599it [38:31,  5.77it/s]Train batch 11600
Avg. loss per last 100 batches: 1.892106
11600it [38:31,  5.75it/s]Epoch: 1: Step: 11601/28124, loss=2.118314, lr=0.000016
11699it [38:49,  5.75it/s]Train batch 11700
Avg. loss per last 100 batches: 1.942655
11700it [38:49,  5.74it/s]Epoch: 1: Step: 11701/28124, loss=1.553315, lr=0.000016
11799it [39:06,  5.74it/s]Train batch 11800
Avg. loss per last 100 batches: 1.899527
11800it [39:06,  5.71it/s]Epoch: 1: Step: 11801/28124, loss=1.749055, lr=0.000016
11899it [39:23,  5.76it/s]Train batch 11900
Avg. loss per last 100 batches: 1.906135
11900it [39:24,  5.73it/s]Epoch: 1: Step: 11901/28124, loss=1.669381, lr=0.000016
11999it [39:41,  5.73it/s]Train batch 12000
Avg. loss per last 100 batches: 1.886286
12000it [39:41,  5.73it/s]Epoch: 1: Step: 12001/28124, loss=2.333381, lr=0.000016
12099it [39:58,  5.73it/s]Train batch 12100
Avg. loss per last 100 batches: 1.878334
12100it [39:59,  5.72it/s]Epoch: 1: Step: 12101/28124, loss=1.790451, lr=0.000016
12199it [40:16,  5.41it/s]Train batch 12200
Avg. loss per last 100 batches: 1.949848
12200it [40:16,  5.30it/s]Epoch: 1: Step: 12201/28124, loss=2.047544, lr=0.000016
12299it [40:34,  5.73it/s]Train batch 12300
Avg. loss per last 100 batches: 1.990473
12300it [40:34,  5.72it/s]Epoch: 1: Step: 12301/28124, loss=2.368047, lr=0.000016
12399it [40:51,  5.74it/s]Train batch 12400
Avg. loss per last 100 batches: 1.896308
12400it [40:51,  5.75it/s]Epoch: 1: Step: 12401/28124, loss=2.212983, lr=0.000016
12499it [41:09,  5.75it/s]Train batch 12500
Avg. loss per last 100 batches: 1.860274
12500it [41:09,  5.75it/s]Epoch: 1: Step: 12501/28124, loss=2.520491, lr=0.000016
12599it [41:26,  5.69it/s]Train batch 12600
Avg. loss per last 100 batches: 1.984677
12600it [41:26,  5.70it/s]Epoch: 1: Step: 12601/28124, loss=1.555628, lr=0.000016
12699it [41:44,  5.73it/s]Train batch 12700
Avg. loss per last 100 batches: 1.837525
12700it [41:44,  5.73it/s]Epoch: 1: Step: 12701/28124, loss=2.134331, lr=0.000016
12799it [42:01,  5.74it/s]Train batch 12800
Avg. loss per last 100 batches: 1.925059
12800it [42:01,  5.75it/s]Epoch: 1: Step: 12801/28124, loss=1.821344, lr=0.000016
12899it [42:19,  5.74it/s]Train batch 12900
Avg. loss per last 100 batches: 1.863127
12900it [42:19,  5.75it/s]Epoch: 1: Step: 12901/28124, loss=1.930403, lr=0.000016
12999it [42:36,  5.71it/s]Train batch 13000
Avg. loss per last 100 batches: 1.911272
13000it [42:36,  5.70it/s]Epoch: 1: Step: 13001/28124, loss=2.625509, lr=0.000016
13099it [42:54,  5.47it/s]Train batch 13100
Avg. loss per last 100 batches: 1.939045
13100it [42:54,  5.46it/s]Epoch: 1: Step: 13101/28124, loss=1.402773, lr=0.000016
13199it [43:11,  5.77it/s]Train batch 13200
Avg. loss per last 100 batches: 1.894453
13200it [43:11,  5.76it/s]Epoch: 1: Step: 13201/28124, loss=1.692882, lr=0.000016
13299it [43:29,  5.75it/s]Train batch 13300
Avg. loss per last 100 batches: 1.928069
13300it [43:29,  5.75it/s]Epoch: 1: Step: 13301/28124, loss=2.306825, lr=0.000016
13399it [43:46,  5.58it/s]Train batch 13400
Avg. loss per last 100 batches: 1.881313
13400it [43:46,  5.58it/s]Epoch: 1: Step: 13401/28124, loss=1.823034, lr=0.000016
13499it [44:04,  5.73it/s]Train batch 13500
Avg. loss per last 100 batches: 1.870692
13500it [44:04,  5.74it/s]Epoch: 1: Step: 13501/28124, loss=2.077440, lr=0.000016
13599it [44:21,  5.78it/s]Train batch 13600
Avg. loss per last 100 batches: 1.907925
13600it [44:21,  5.76it/s]Epoch: 1: Step: 13601/28124, loss=2.034067, lr=0.000016
13699it [44:39,  5.74it/s]Train batch 13700
Avg. loss per last 100 batches: 1.857733
13700it [44:39,  5.74it/s]Epoch: 1: Step: 13701/28124, loss=2.448062, lr=0.000016
13799it [44:56,  5.74it/s]Train batch 13800
Avg. loss per last 100 batches: 1.964643
13800it [44:56,  5.74it/s]Epoch: 1: Step: 13801/28124, loss=2.379623, lr=0.000016
13899it [45:13,  5.75it/s]Train batch 13900
Avg. loss per last 100 batches: 1.936508
13900it [45:14,  5.75it/s]Epoch: 1: Step: 13901/28124, loss=1.515818, lr=0.000016
13999it [45:31,  5.76it/s]Train batch 14000
Avg. loss per last 100 batches: 1.889958
14000it [45:31,  5.74it/s]Epoch: 1: Step: 14001/28124, loss=1.698947, lr=0.000016
14099it [45:48,  5.72it/s]Train batch 14100
Avg. loss per last 100 batches: 1.877035
14100it [45:49,  5.71it/s]Epoch: 1: Step: 14101/28124, loss=1.686617, lr=0.000016
14199it [46:06,  5.70it/s]Train batch 14200
Avg. loss per last 100 batches: 1.896880
14200it [46:06,  5.71it/s]Epoch: 1: Step: 14201/28124, loss=1.526345, lr=0.000016
14299it [46:23,  5.77it/s]Train batch 14300
Avg. loss per last 100 batches: 1.880569
14300it [46:24,  5.77it/s]Epoch: 1: Step: 14301/28124, loss=2.166051, lr=0.000016
14399it [46:41,  5.76it/s]Train batch 14400
Avg. loss per last 100 batches: 1.808571
14400it [46:41,  5.77it/s]Epoch: 1: Step: 14401/28124, loss=1.839788, lr=0.000016
14499it [46:58,  5.76it/s]Train batch 14500
Avg. loss per last 100 batches: 1.863161
14500it [46:58,  5.76it/s]Epoch: 1: Step: 14501/28124, loss=1.570502, lr=0.000016
14599it [47:16,  5.71it/s]Train batch 14600
Avg. loss per last 100 batches: 1.837702
14600it [47:16,  5.69it/s]Epoch: 1: Step: 14601/28124, loss=1.815281, lr=0.000016
14699it [47:33,  5.75it/s]Train batch 14700
Avg. loss per last 100 batches: 1.981024
14700it [47:33,  5.75it/s]Epoch: 1: Step: 14701/28124, loss=1.645941, lr=0.000016
14799it [47:51,  5.74it/s]Train batch 14800
Avg. loss per last 100 batches: 1.870271
14800it [47:51,  5.75it/s]Epoch: 1: Step: 14801/28124, loss=1.541053, lr=0.000016
14899it [48:08,  5.77it/s]Train batch 14900
Avg. loss per last 100 batches: 1.818444
14900it [48:08,  5.76it/s]Epoch: 1: Step: 14901/28124, loss=1.902990, lr=0.000016
14999it [48:26,  5.72it/s]Train batch 15000
Avg. loss per last 100 batches: 1.893200
15000it [48:26,  5.70it/s]Epoch: 1: Step: 15001/28124, loss=1.789480, lr=0.000016
15099it [48:43,  5.48it/s]Train batch 15100
Avg. loss per last 100 batches: 1.884498
15100it [48:43,  5.49it/s]Epoch: 1: Step: 15101/28124, loss=1.832224, lr=0.000016
15199it [49:01,  5.78it/s]Train batch 15200
Avg. loss per last 100 batches: 1.873118
15200it [49:01,  5.75it/s]Epoch: 1: Step: 15201/28124, loss=2.403017, lr=0.000016
15299it [49:18,  5.76it/s]Train batch 15300
Avg. loss per last 100 batches: 1.867079
15300it [49:18,  5.76it/s]Epoch: 1: Step: 15301/28124, loss=1.757483, lr=0.000016
15399it [49:36,  5.75it/s]Train batch 15400
Avg. loss per last 100 batches: 1.903736
15400it [49:36,  5.75it/s]Epoch: 1: Step: 15401/28124, loss=1.934188, lr=0.000016
15499it [49:53,  5.76it/s]Train batch 15500
Avg. loss per last 100 batches: 1.837781
15500it [49:53,  5.76it/s]Epoch: 1: Step: 15501/28124, loss=1.230145, lr=0.000016
15599it [50:11,  5.74it/s]Train batch 15600
Avg. loss per last 100 batches: 1.838561
15600it [50:11,  5.75it/s]Epoch: 1: Step: 15601/28124, loss=1.629754, lr=0.000016
15699it [50:28,  5.76it/s]Train batch 15700
Avg. loss per last 100 batches: 1.900970
15700it [50:28,  5.74it/s]Epoch: 1: Step: 15701/28124, loss=2.083807, lr=0.000016
15799it [50:46,  5.76it/s]Train batch 15800
Avg. loss per last 100 batches: 1.879569
15800it [50:46,  5.76it/s]Epoch: 1: Step: 15801/28124, loss=1.828706, lr=0.000016
15899it [51:03,  5.78it/s]Train batch 15900
Avg. loss per last 100 batches: 1.860843
15900it [51:03,  5.75it/s]Epoch: 1: Step: 15901/28124, loss=1.789661, lr=0.000016
15999it [51:20,  5.75it/s]Train batch 16000
Avg. loss per last 100 batches: 1.829762
16000it [51:21,  5.75it/s]Epoch: 1: Step: 16001/28124, loss=1.448244, lr=0.000016
16099it [51:38,  5.74it/s]Train batch 16100
Avg. loss per last 100 batches: 1.863324
16100it [51:38,  5.73it/s]Epoch: 1: Step: 16101/28124, loss=2.178865, lr=0.000016
16199it [51:55,  5.73it/s]Train batch 16200
Avg. loss per last 100 batches: 1.932341
16200it [51:56,  5.72it/s]Epoch: 1: Step: 16201/28124, loss=2.195450, lr=0.000016
16299it [52:13,  5.77it/s]Train batch 16300
Avg. loss per last 100 batches: 1.916534
16300it [52:13,  5.78it/s]Epoch: 1: Step: 16301/28124, loss=2.180687, lr=0.000016
16399it [52:30,  5.74it/s]Train batch 16400
Avg. loss per last 100 batches: 1.860174
16400it [52:31,  5.72it/s]Epoch: 1: Step: 16401/28124, loss=2.053574, lr=0.000016
16499it [52:48,  5.77it/s]Train batch 16500
Avg. loss per last 100 batches: 1.897637
16500it [52:48,  5.76it/s]Epoch: 1: Step: 16501/28124, loss=2.163059, lr=0.000016
16599it [53:05,  5.76it/s]Train batch 16600
Avg. loss per last 100 batches: 1.862278
16600it [53:06,  5.76it/s]Epoch: 1: Step: 16601/28124, loss=1.611069, lr=0.000016
16699it [53:23,  5.78it/s]Train batch 16700
Avg. loss per last 100 batches: 1.829786
16700it [53:23,  5.76it/s]Epoch: 1: Step: 16701/28124, loss=1.763073, lr=0.000016
16799it [53:40,  5.75it/s]Train batch 16800
Avg. loss per last 100 batches: 1.848459
16800it [53:40,  5.73it/s]Epoch: 1: Step: 16801/28124, loss=3.146493, lr=0.000016
16874it [53:53,  5.74it/s]Validation: Epoch: 1 Step: 16875/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.482158 sec., loss=1.053940 
Eval step: 199 , used_time=8.787588 sec., loss=1.113360 
Eval step: 299 , used_time=13.056484 sec., loss=1.035447 
Eval step: 399 , used_time=17.335840 sec., loss=1.327631 
Eval step: 499 , used_time=21.644724 sec., loss=1.296618 
Eval step: 599 , used_time=25.912389 sec., loss=1.523198 
Eval step: 699 , used_time=30.216757 sec., loss=1.803851 
Eval step: 799 , used_time=34.674794 sec., loss=1.517025 
Eval step: 899 , used_time=38.963061 sec., loss=1.199852 
Eval step: 999 , used_time=43.231473 sec., loss=1.223299 
Eval step: 1099 , used_time=47.535627 sec., loss=1.141155 
Eval step: 1199 , used_time=51.816326 sec., loss=1.370243 
Eval step: 1299 , used_time=56.076771 sec., loss=1.160356 
Eval step: 1399 , used_time=60.381886 sec., loss=0.811228 
Eval step: 1499 , used_time=64.642656 sec., loss=0.865456 
Eval step: 1599 , used_time=69.116262 sec., loss=1.306284 
Eval step: 1699 , used_time=73.370454 sec., loss=1.217813 
Eval step: 1799 , used_time=77.655761 sec., loss=0.942462 
Eval step: 1899 , used_time=81.938284 sec., loss=0.990309 
Eval step: 1999 , used_time=86.203023 sec., loss=1.689647 
Eval step: 2099 , used_time=90.490060 sec., loss=0.905232 
Eval step: 2199 , used_time=94.769944 sec., loss=0.913723 
Eval step: 2299 , used_time=99.305369 sec., loss=0.643914 
Eval step: 2399 , used_time=103.585862 sec., loss=1.596172 
Eval step: 2499 , used_time=107.895351 sec., loss=0.993604 
Eval step: 2599 , used_time=112.175572 sec., loss=1.366050 
Eval step: 2699 , used_time=116.441976 sec., loss=1.542629 
Eval step: 2799 , used_time=120.751687 sec., loss=1.329962 
Eval step: 2899 , used_time=125.022577 sec., loss=1.183001 
Eval step: 2999 , used_time=129.469636 sec., loss=1.171684 
Eval step: 3099 , used_time=133.803024 sec., loss=1.497627 
NLL Validation: loss = 1.290390. correct prediction ratio  63566/100032 ~  0.635457
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
16899it [56:23,  5.47it/s]Train batch 16900
Avg. loss per last 100 batches: 1.840115
16900it [56:23,  5.51it/s]Epoch: 1: Step: 16901/28124, loss=1.892772, lr=0.000016
16999it [56:40,  5.44it/s]Train batch 17000
Avg. loss per last 100 batches: 1.836369
17000it [56:40,  5.53it/s]Epoch: 1: Step: 17001/28124, loss=1.875345, lr=0.000016
17099it [56:58,  5.74it/s]Train batch 17100
Avg. loss per last 100 batches: 1.827643
17100it [56:58,  5.74it/s]Epoch: 1: Step: 17101/28124, loss=1.552264, lr=0.000016
17199it [57:15,  5.77it/s]Train batch 17200
Avg. loss per last 100 batches: 1.857430
17200it [57:15,  5.77it/s]Epoch: 1: Step: 17201/28124, loss=1.576969, lr=0.000015
17299it [57:33,  5.76it/s]Train batch 17300
Avg. loss per last 100 batches: 1.848283
17300it [57:33,  5.76it/s]Epoch: 1: Step: 17301/28124, loss=1.596228, lr=0.000015
17399it [57:50,  5.65it/s]Train batch 17400
Avg. loss per last 100 batches: 1.895333
17400it [57:50,  5.66it/s]Epoch: 1: Step: 17401/28124, loss=2.245907, lr=0.000015
17499it [58:08,  5.74it/s]Train batch 17500
Avg. loss per last 100 batches: 1.886980
17500it [58:08,  5.73it/s]Epoch: 1: Step: 17501/28124, loss=2.152802, lr=0.000015
17599it [58:25,  5.77it/s]Train batch 17600
Avg. loss per last 100 batches: 1.835192
17600it [58:25,  5.73it/s]Epoch: 1: Step: 17601/28124, loss=1.344586, lr=0.000015
17699it [58:43,  5.73it/s]Train batch 17700
Avg. loss per last 100 batches: 1.814620
17700it [58:43,  5.75it/s]Epoch: 1: Step: 17701/28124, loss=2.234774, lr=0.000015
17799it [59:00,  5.74it/s]Train batch 17800
Avg. loss per last 100 batches: 1.914676
17800it [59:00,  5.74it/s]Epoch: 1: Step: 17801/28124, loss=2.070507, lr=0.000015
17899it [59:18,  5.68it/s]Train batch 17900
Avg. loss per last 100 batches: 1.864214
17900it [59:18,  5.49it/s]Epoch: 1: Step: 17901/28124, loss=1.250457, lr=0.000015
17999it [59:35,  5.74it/s]Train batch 18000
Avg. loss per last 100 batches: 1.854061
18000it [59:35,  5.75it/s]Epoch: 1: Step: 18001/28124, loss=1.375460, lr=0.000015
18099it [59:53,  5.71it/s]Train batch 18100
Avg. loss per last 100 batches: 1.796880
18100it [59:53,  5.71it/s]Epoch: 1: Step: 18101/28124, loss=2.008186, lr=0.000015
18199it [1:00:10,  5.76it/s]Train batch 18200
Avg. loss per last 100 batches: 1.802956
18200it [1:00:10,  5.73it/s]Epoch: 1: Step: 18201/28124, loss=2.053638, lr=0.000015
18299it [1:00:28,  5.74it/s]Train batch 18300
Avg. loss per last 100 batches: 1.846953
18300it [1:00:28,  5.74it/s]Epoch: 1: Step: 18301/28124, loss=1.595096, lr=0.000015
18399it [1:00:45,  5.75it/s]Train batch 18400
Avg. loss per last 100 batches: 1.883777
18400it [1:00:45,  5.75it/s]Epoch: 1: Step: 18401/28124, loss=1.755490, lr=0.000015
18499it [1:01:02,  5.75it/s]Train batch 18500
Avg. loss per last 100 batches: 1.819724
18500it [1:01:03,  5.75it/s]Epoch: 1: Step: 18501/28124, loss=1.764091, lr=0.000015
18599it [1:01:20,  5.75it/s]Train batch 18600
Avg. loss per last 100 batches: 1.838113
18600it [1:01:20,  5.73it/s]Epoch: 1: Step: 18601/28124, loss=1.865275, lr=0.000015
18699it [1:01:37,  5.74it/s]Train batch 18700
Avg. loss per last 100 batches: 1.868443
18700it [1:01:38,  5.75it/s]Epoch: 1: Step: 18701/28124, loss=2.042380, lr=0.000015
18799it [1:01:55,  5.76it/s]Train batch 18800
Avg. loss per last 100 batches: 1.885014
18800it [1:01:55,  5.75it/s]Epoch: 1: Step: 18801/28124, loss=1.678365, lr=0.000015
18899it [1:02:12,  5.74it/s]Train batch 18900
Avg. loss per last 100 batches: 1.863694
18900it [1:02:13,  5.75it/s]Epoch: 1: Step: 18901/28124, loss=2.125672, lr=0.000015
18999it [1:02:30,  5.57it/s]Train batch 19000
Avg. loss per last 100 batches: 1.840150
19000it [1:02:30,  5.61it/s]Epoch: 1: Step: 19001/28124, loss=1.575990, lr=0.000015
19099it [1:02:47,  5.75it/s]Train batch 19100
Avg. loss per last 100 batches: 1.848889
19100it [1:02:48,  5.75it/s]Epoch: 1: Step: 19101/28124, loss=1.896779, lr=0.000015
19199it [1:03:05,  5.75it/s]Train batch 19200
Avg. loss per last 100 batches: 1.822780
19200it [1:03:05,  5.74it/s]Epoch: 1: Step: 19201/28124, loss=1.952654, lr=0.000015
19299it [1:03:22,  5.76it/s]Train batch 19300
Avg. loss per last 100 batches: 1.845782
19300it [1:03:22,  5.76it/s]Epoch: 1: Step: 19301/28124, loss=1.955180, lr=0.000015
19399it [1:03:40,  5.75it/s]Train batch 19400
Avg. loss per last 100 batches: 1.886159
19400it [1:03:40,  5.73it/s]Epoch: 1: Step: 19401/28124, loss=1.671647, lr=0.000015
19499it [1:03:57,  5.68it/s]Train batch 19500
Avg. loss per last 100 batches: 1.826457
19500it [1:03:57,  5.70it/s]Epoch: 1: Step: 19501/28124, loss=2.098526, lr=0.000015
19599it [1:04:15,  5.77it/s]Train batch 19600
Avg. loss per last 100 batches: 1.861591
19600it [1:04:15,  5.77it/s]Epoch: 1: Step: 19601/28124, loss=2.167250, lr=0.000015
19699it [1:04:32,  5.76it/s]Train batch 19700
Avg. loss per last 100 batches: 1.847013
19700it [1:04:32,  5.77it/s]Epoch: 1: Step: 19701/28124, loss=1.514107, lr=0.000015
19799it [1:04:50,  5.77it/s]Train batch 19800
Avg. loss per last 100 batches: 1.859857
19800it [1:04:50,  5.77it/s]Epoch: 1: Step: 19801/28124, loss=1.829382, lr=0.000015
19899it [1:05:07,  5.51it/s]Train batch 19900
Avg. loss per last 100 batches: 1.862703
19900it [1:05:07,  5.47it/s]Epoch: 1: Step: 19901/28124, loss=1.586967, lr=0.000015
19999it [1:05:25,  5.76it/s]Train batch 20000
Avg. loss per last 100 batches: 1.791765
20000it [1:05:25,  5.75it/s]Epoch: 1: Step: 20001/28124, loss=2.010438, lr=0.000015
20099it [1:05:42,  5.76it/s]Train batch 20100
Avg. loss per last 100 batches: 1.800377
20100it [1:05:42,  5.76it/s]Epoch: 1: Step: 20101/28124, loss=1.816582, lr=0.000015
20199it [1:06:00,  5.73it/s]Train batch 20200
Avg. loss per last 100 batches: 1.827711
20200it [1:06:00,  5.75it/s]Epoch: 1: Step: 20201/28124, loss=1.704091, lr=0.000015
20299it [1:06:17,  5.74it/s]Train batch 20300
Avg. loss per last 100 batches: 1.817950
20300it [1:06:17,  5.75it/s]Epoch: 1: Step: 20301/28124, loss=1.939253, lr=0.000015
20399it [1:06:35,  5.72it/s]Train batch 20400
Avg. loss per last 100 batches: 1.879905
20400it [1:06:35,  5.71it/s]Epoch: 1: Step: 20401/28124, loss=1.875686, lr=0.000015
20499it [1:06:52,  5.73it/s]Train batch 20500
Avg. loss per last 100 batches: 1.862774
20500it [1:06:53,  5.74it/s]Epoch: 1: Step: 20501/28124, loss=2.524811, lr=0.000015
20599it [1:07:10,  5.75it/s]Train batch 20600
Avg. loss per last 100 batches: 1.866772
20600it [1:07:10,  5.73it/s]Epoch: 1: Step: 20601/28124, loss=1.432752, lr=0.000015
20699it [1:07:27,  5.71it/s]Train batch 20700
Avg. loss per last 100 batches: 1.808978
20700it [1:07:28,  5.71it/s]Epoch: 1: Step: 20701/28124, loss=2.171702, lr=0.000015
20799it [1:07:45,  5.74it/s]Train batch 20800
Avg. loss per last 100 batches: 1.799319
20800it [1:07:45,  5.74it/s]Epoch: 1: Step: 20801/28124, loss=1.781772, lr=0.000015
20899it [1:08:02,  5.75it/s]Train batch 20900
Avg. loss per last 100 batches: 1.863106
20900it [1:08:03,  5.74it/s]Epoch: 1: Step: 20901/28124, loss=1.664550, lr=0.000015
20999it [1:08:20,  5.71it/s]Train batch 21000
Avg. loss per last 100 batches: 1.854840
21000it [1:08:20,  5.71it/s]Epoch: 1: Step: 21001/28124, loss=1.477988, lr=0.000015
21099it [1:08:37,  5.75it/s]Train batch 21100
Avg. loss per last 100 batches: 1.762033
21100it [1:08:38,  5.76it/s]Epoch: 1: Step: 21101/28124, loss=2.071808, lr=0.000015
21199it [1:08:55,  5.75it/s]Train batch 21200
Avg. loss per last 100 batches: 1.844910
21200it [1:08:55,  5.75it/s]Epoch: 1: Step: 21201/28124, loss=1.947355, lr=0.000015
21299it [1:09:12,  5.74it/s]Train batch 21300
Avg. loss per last 100 batches: 1.792031
21300it [1:09:13,  5.73it/s]Epoch: 1: Step: 21301/28124, loss=1.848752, lr=0.000015
21399it [1:09:30,  5.75it/s]Train batch 21400
Avg. loss per last 100 batches: 1.820019
21400it [1:09:30,  5.75it/s]Epoch: 1: Step: 21401/28124, loss=1.755122, lr=0.000015
21499it [1:09:47,  5.75it/s]Train batch 21500
Avg. loss per last 100 batches: 1.838241
21500it [1:09:47,  5.73it/s]Epoch: 1: Step: 21501/28124, loss=1.707509, lr=0.000015
21599it [1:10:05,  5.71it/s]Train batch 21600
Avg. loss per last 100 batches: 1.788403
21600it [1:10:05,  5.70it/s]Epoch: 1: Step: 21601/28124, loss=1.899240, lr=0.000015
21699it [1:10:22,  5.72it/s]Train batch 21700
Avg. loss per last 100 batches: 1.845795
21700it [1:10:23,  5.73it/s]Epoch: 1: Step: 21701/28124, loss=1.418589, lr=0.000015
21799it [1:10:40,  5.73it/s]Train batch 21800
Avg. loss per last 100 batches: 1.815697
21800it [1:10:40,  5.73it/s]Epoch: 1: Step: 21801/28124, loss=2.149010, lr=0.000015
21899it [1:10:57,  5.37it/s]Train batch 21900
Avg. loss per last 100 batches: 1.856969
21900it [1:10:58,  5.39it/s]Epoch: 1: Step: 21901/28124, loss=2.142305, lr=0.000015
21999it [1:11:15,  5.76it/s]Train batch 22000
Avg. loss per last 100 batches: 1.831484
22000it [1:11:15,  5.74it/s]Epoch: 1: Step: 22001/28124, loss=2.100541, lr=0.000015
22099it [1:11:32,  5.71it/s]Train batch 22100
Avg. loss per last 100 batches: 1.813652
22100it [1:11:33,  5.73it/s]Epoch: 1: Step: 22101/28124, loss=1.265599, lr=0.000015
22199it [1:11:50,  5.75it/s]Train batch 22200
Avg. loss per last 100 batches: 1.828503
22200it [1:11:50,  5.73it/s]Epoch: 1: Step: 22201/28124, loss=1.710541, lr=0.000015
22299it [1:12:07,  5.70it/s]Train batch 22300
Avg. loss per last 100 batches: 1.814516
22300it [1:12:08,  5.70it/s]Epoch: 1: Step: 22301/28124, loss=1.765449, lr=0.000015
22399it [1:12:25,  5.74it/s]Train batch 22400
Avg. loss per last 100 batches: 1.814597
22400it [1:12:25,  5.73it/s]Epoch: 1: Step: 22401/28124, loss=1.824555, lr=0.000015
22499it [1:12:42,  5.74it/s]Train batch 22500
Avg. loss per last 100 batches: 1.798572
Validation: Epoch: 1 Step: 22500/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.333532 sec., loss=1.092208 
Eval step: 199 , used_time=8.628278 sec., loss=1.106439 
Eval step: 299 , used_time=12.930165 sec., loss=0.942101 
Eval step: 399 , used_time=17.249527 sec., loss=1.428919 
Eval step: 499 , used_time=21.724900 sec., loss=1.469785 
Eval step: 599 , used_time=26.043248 sec., loss=1.484093 
Eval step: 699 , used_time=30.328226 sec., loss=1.765101 
Eval step: 799 , used_time=34.632888 sec., loss=1.343952 
Eval step: 899 , used_time=38.898875 sec., loss=1.088414 
Eval step: 999 , used_time=43.206790 sec., loss=1.244207 
Eval step: 1099 , used_time=47.474648 sec., loss=1.223768 
Eval step: 1199 , used_time=51.742905 sec., loss=1.433964 
Eval step: 1299 , used_time=56.260227 sec., loss=1.047515 
Eval step: 1399 , used_time=60.530844 sec., loss=0.995070 
Eval step: 1499 , used_time=64.845310 sec., loss=0.806078 
Eval step: 1599 , used_time=69.129774 sec., loss=1.110943 
Eval step: 1699 , used_time=73.432245 sec., loss=1.208742 
Eval step: 1799 , used_time=77.740397 sec., loss=0.888871 
Eval step: 1899 , used_time=82.067654 sec., loss=0.689305 
Eval step: 1999 , used_time=86.603767 sec., loss=1.684209 
Eval step: 2099 , used_time=90.898070 sec., loss=0.966925 
Eval step: 2199 , used_time=95.229088 sec., loss=1.079990 
Eval step: 2299 , used_time=99.554033 sec., loss=0.534854 
Eval step: 2399 , used_time=103.884693 sec., loss=1.463342 
Eval step: 2499 , used_time=108.195790 sec., loss=1.071901 
Eval step: 2599 , used_time=112.504050 sec., loss=1.347037 
Eval step: 2699 , used_time=117.052082 sec., loss=1.384903 
Eval step: 2799 , used_time=121.358797 sec., loss=1.391392 
Eval step: 2899 , used_time=125.728904 sec., loss=1.050229 
Eval step: 2999 , used_time=130.011221 sec., loss=0.916876 
Eval step: 3099 , used_time=134.323733 sec., loss=1.356578 
NLL Validation: loss = 1.238832. correct prediction ratio  64777/100032 ~  0.647563
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
22500it [1:15:03, 42.41s/it]Epoch: 1: Step: 22501/28124, loss=1.308885, lr=0.000015
22599it [1:15:21,  5.73it/s]Train batch 22600
Avg. loss per last 100 batches: 1.812154
22600it [1:15:21,  5.73it/s]Epoch: 1: Step: 22601/28124, loss=2.006694, lr=0.000015
22699it [1:15:38,  5.74it/s]Train batch 22700
Avg. loss per last 100 batches: 1.823059
22700it [1:15:39,  5.74it/s]Epoch: 1: Step: 22701/28124, loss=1.496307, lr=0.000015
22799it [1:15:56,  5.75it/s]Train batch 22800
Avg. loss per last 100 batches: 1.798680
22800it [1:15:56,  5.70it/s]Epoch: 1: Step: 22801/28124, loss=1.756837, lr=0.000015
22899it [1:16:13,  5.74it/s]Train batch 22900
Avg. loss per last 100 batches: 1.785009
22900it [1:16:14,  5.74it/s]Epoch: 1: Step: 22901/28124, loss=1.803901, lr=0.000015
22999it [1:16:31,  5.76it/s]Train batch 23000
Avg. loss per last 100 batches: 1.810254
23000it [1:16:31,  5.77it/s]Epoch: 1: Step: 23001/28124, loss=2.213092, lr=0.000015
23099it [1:16:49,  5.71it/s]Train batch 23100
Avg. loss per last 100 batches: 1.848811
23100it [1:16:49,  5.72it/s]Epoch: 1: Step: 23101/28124, loss=1.926537, lr=0.000015
23199it [1:17:06,  5.67it/s]Train batch 23200
Avg. loss per last 100 batches: 1.846710
23200it [1:17:06,  5.49it/s]Epoch: 1: Step: 23201/28124, loss=1.609599, lr=0.000015
23299it [1:17:24,  5.76it/s]Train batch 23300
Avg. loss per last 100 batches: 1.852713
23300it [1:17:24,  5.75it/s]Epoch: 1: Step: 23301/28124, loss=1.502786, lr=0.000015
23399it [1:17:41,  5.70it/s]Train batch 23400
Avg. loss per last 100 batches: 1.778350
23400it [1:17:41,  5.70it/s]Epoch: 1: Step: 23401/28124, loss=1.762969, lr=0.000015
23499it [1:17:59,  5.76it/s]Train batch 23500
Avg. loss per last 100 batches: 1.761241
23500it [1:17:59,  5.74it/s]Epoch: 1: Step: 23501/28124, loss=1.486910, lr=0.000015
23599it [1:18:16,  5.73it/s]Train batch 23600
Avg. loss per last 100 batches: 1.777301
23600it [1:18:16,  5.59it/s]Epoch: 1: Step: 23601/28124, loss=2.183861, lr=0.000015
23699it [1:18:34,  5.72it/s]Train batch 23700
Avg. loss per last 100 batches: 1.811859
23700it [1:18:34,  5.73it/s]Epoch: 1: Step: 23701/28124, loss=1.845320, lr=0.000015
23799it [1:18:51,  5.73it/s]Train batch 23800
Avg. loss per last 100 batches: 1.772840
23800it [1:18:51,  5.74it/s]Epoch: 1: Step: 23801/28124, loss=1.807199, lr=0.000015
23899it [1:19:09,  5.76it/s]Train batch 23900
Avg. loss per last 100 batches: 1.771339
23900it [1:19:09,  5.77it/s]Epoch: 1: Step: 23901/28124, loss=1.927811, lr=0.000015
23999it [1:19:26,  5.58it/s]Train batch 24000
Avg. loss per last 100 batches: 1.771506
24000it [1:19:26,  5.61it/s]Epoch: 1: Step: 24001/28124, loss=2.381919, lr=0.000015
24099it [1:19:44,  5.72it/s]Train batch 24100
Avg. loss per last 100 batches: 1.829001
24100it [1:19:44,  5.72it/s]Epoch: 1: Step: 24101/28124, loss=1.405306, lr=0.000015
24199it [1:20:01,  5.74it/s]Train batch 24200
Avg. loss per last 100 batches: 1.759573
24200it [1:20:01,  5.74it/s]Epoch: 1: Step: 24201/28124, loss=1.793895, lr=0.000015
24299it [1:20:19,  5.71it/s]Train batch 24300
Avg. loss per last 100 batches: 1.765363
24300it [1:20:19,  5.72it/s]Epoch: 1: Step: 24301/28124, loss=1.250999, lr=0.000015
24399it [1:20:36,  5.73it/s]Train batch 24400
Avg. loss per last 100 batches: 1.791035
24400it [1:20:36,  5.74it/s]Epoch: 1: Step: 24401/28124, loss=2.639802, lr=0.000015
24499it [1:20:54,  5.73it/s]Train batch 24500
Avg. loss per last 100 batches: 1.786102
24500it [1:20:54,  5.74it/s]Epoch: 1: Step: 24501/28124, loss=2.075386, lr=0.000015
24599it [1:21:11,  5.73it/s]Train batch 24600
Avg. loss per last 100 batches: 1.738726
24600it [1:21:12,  5.73it/s]Epoch: 1: Step: 24601/28124, loss=1.830003, lr=0.000015
24699it [1:21:29,  5.75it/s]Train batch 24700
Avg. loss per last 100 batches: 1.805107
24700it [1:21:29,  5.74it/s]Epoch: 1: Step: 24701/28124, loss=1.902853, lr=0.000015
24799it [1:21:46,  5.54it/s]Train batch 24800
Avg. loss per last 100 batches: 1.779200
24800it [1:21:47,  5.57it/s]Epoch: 1: Step: 24801/28124, loss=1.838470, lr=0.000015
24899it [1:22:04,  5.37it/s]Train batch 24900
Avg. loss per last 100 batches: 1.736115
24900it [1:22:04,  5.36it/s]Epoch: 1: Step: 24901/28124, loss=1.371813, lr=0.000015
24999it [1:22:22,  5.73it/s]Train batch 25000
Avg. loss per last 100 batches: 1.761861
25000it [1:22:22,  5.74it/s]Epoch: 1: Step: 25001/28124, loss=2.445614, lr=0.000015
25099it [1:22:39,  5.66it/s]Train batch 25100
Avg. loss per last 100 batches: 1.803659
25100it [1:22:40,  5.65it/s]Epoch: 1: Step: 25101/28124, loss=1.872619, lr=0.000015
25199it [1:22:57,  5.67it/s]Train batch 25200
Avg. loss per last 100 batches: 1.712222
25200it [1:22:57,  5.68it/s]Epoch: 1: Step: 25201/28124, loss=1.809730, lr=0.000015
25299it [1:23:15,  5.72it/s]Train batch 25300
Avg. loss per last 100 batches: 1.786689
25300it [1:23:15,  5.74it/s]Epoch: 1: Step: 25301/28124, loss=1.516835, lr=0.000015
25399it [1:23:32,  5.73it/s]Train batch 25400
Avg. loss per last 100 batches: 1.808847
25400it [1:23:32,  5.72it/s]Epoch: 1: Step: 25401/28124, loss=1.559530, lr=0.000015
25499it [1:23:50,  5.73it/s]Train batch 25500
Avg. loss per last 100 batches: 1.803240
25500it [1:23:50,  5.73it/s]Epoch: 1: Step: 25501/28124, loss=1.117253, lr=0.000015
25599it [1:24:07,  5.71it/s]Train batch 25600
Avg. loss per last 100 batches: 1.782314
25600it [1:24:07,  5.70it/s]Epoch: 1: Step: 25601/28124, loss=1.769767, lr=0.000015
25699it [1:24:25,  5.73it/s]Train batch 25700
Avg. loss per last 100 batches: 1.791955
25700it [1:24:25,  5.73it/s]Epoch: 1: Step: 25701/28124, loss=1.273569, lr=0.000015
25799it [1:24:42,  5.49it/s]Train batch 25800
Avg. loss per last 100 batches: 1.770524
25800it [1:24:42,  5.41it/s]Epoch: 1: Step: 25801/28124, loss=1.647370, lr=0.000015
25899it [1:25:00,  5.74it/s]Train batch 25900
Avg. loss per last 100 batches: 1.809498
25900it [1:25:00,  5.74it/s]Epoch: 1: Step: 25901/28124, loss=1.887807, lr=0.000015
25999it [1:25:17,  5.69it/s]Train batch 26000
Avg. loss per last 100 batches: 1.802391
26000it [1:25:18,  5.71it/s]Epoch: 1: Step: 26001/28124, loss=1.988010, lr=0.000015
26099it [1:25:35,  5.73it/s]Train batch 26100
Avg. loss per last 100 batches: 1.760244
26100it [1:25:35,  5.71it/s]Epoch: 1: Step: 26101/28124, loss=1.386293, lr=0.000015
26199it [1:25:52,  5.74it/s]Train batch 26200
Avg. loss per last 100 batches: 1.810729
26200it [1:25:53,  5.74it/s]Epoch: 1: Step: 26201/28124, loss=1.707399, lr=0.000015
26299it [1:26:10,  5.72it/s]Train batch 26300
Avg. loss per last 100 batches: 1.777599
26300it [1:26:10,  5.72it/s]Epoch: 1: Step: 26301/28124, loss=1.716579, lr=0.000015
26399it [1:26:28,  5.74it/s]Train batch 26400
Avg. loss per last 100 batches: 1.770315
26400it [1:26:28,  5.73it/s]Epoch: 1: Step: 26401/28124, loss=1.712958, lr=0.000015
26499it [1:26:45,  5.73it/s]Train batch 26500
Avg. loss per last 100 batches: 1.761228
26500it [1:26:45,  5.73it/s]Epoch: 1: Step: 26501/28124, loss=1.592742, lr=0.000015
26599it [1:27:03,  5.73it/s]Train batch 26600
Avg. loss per last 100 batches: 1.751687
26600it [1:27:03,  5.69it/s]Epoch: 1: Step: 26601/28124, loss=1.295173, lr=0.000015
26699it [1:27:20,  5.71it/s]Train batch 26700
Avg. loss per last 100 batches: 1.782737
26700it [1:27:20,  5.72it/s]Epoch: 1: Step: 26701/28124, loss=1.317761, lr=0.000015
26799it [1:27:38,  5.73it/s]Train batch 26800
Avg. loss per last 100 batches: 1.732001
26800it [1:27:38,  5.73it/s]Epoch: 1: Step: 26801/28124, loss=2.028970, lr=0.000015
26899it [1:27:55,  5.70it/s]Train batch 26900
Avg. loss per last 100 batches: 1.742381
26900it [1:27:55,  5.70it/s]Epoch: 1: Step: 26901/28124, loss=1.472686, lr=0.000015
26999it [1:28:13,  5.72it/s]Train batch 27000
Avg. loss per last 100 batches: 1.846304
27000it [1:28:13,  5.73it/s]Epoch: 1: Step: 27001/28124, loss=1.503996, lr=0.000014
27099it [1:28:30,  5.73it/s]Train batch 27100
Avg. loss per last 100 batches: 1.821899
27100it [1:28:30,  5.72it/s]Epoch: 1: Step: 27101/28124, loss=1.677735, lr=0.000014
27199it [1:28:48,  5.68it/s]Train batch 27200
Avg. loss per last 100 batches: 1.814980
27200it [1:28:48,  5.70it/s]Epoch: 1: Step: 27201/28124, loss=1.982708, lr=0.000014
27299it [1:29:05,  5.72it/s]Train batch 27300
Avg. loss per last 100 batches: 1.793043
27300it [1:29:06,  5.72it/s]Epoch: 1: Step: 27301/28124, loss=1.685962, lr=0.000014
27399it [1:29:23,  5.74it/s]Train batch 27400
Avg. loss per last 100 batches: 1.743598
27400it [1:29:23,  5.73it/s]Epoch: 1: Step: 27401/28124, loss=1.526701, lr=0.000014
27499it [1:29:40,  5.75it/s]Train batch 27500
Avg. loss per last 100 batches: 1.742231
27500it [1:29:41,  5.73it/s]Epoch: 1: Step: 27501/28124, loss=1.677665, lr=0.000014
27599it [1:29:58,  5.71it/s]Train batch 27600
Avg. loss per last 100 batches: 1.758389
27600it [1:29:58,  5.69it/s]Epoch: 1: Step: 27601/28124, loss=1.433196, lr=0.000014
27699it [1:30:16,  5.75it/s]Train batch 27700
Avg. loss per last 100 batches: 1.760821
27700it [1:30:16,  5.75it/s]Epoch: 1: Step: 27701/28124, loss=2.015329, lr=0.000014
27799it [1:30:33,  5.65it/s]Train batch 27800
Avg. loss per last 100 batches: 1.756545
27800it [1:30:33,  5.66it/s]Epoch: 1: Step: 27801/28124, loss=1.708851, lr=0.000014
27899it [1:30:51,  5.73it/s]Train batch 27900
Avg. loss per last 100 batches: 1.766670
27900it [1:30:51,  5.74it/s]Epoch: 1: Step: 27901/28124, loss=1.556682, lr=0.000014
27999it [1:31:08,  5.74it/s]Train batch 28000
Avg. loss per last 100 batches: 1.776772
28000it [1:31:08,  5.73it/s]Epoch: 1: Step: 28001/28124, loss=1.916269, lr=0.000014
28099it [1:31:26,  5.70it/s]Train batch 28100
Avg. loss per last 100 batches: 1.790758
28100it [1:31:26,  5.65it/s]Epoch: 1: Step: 28101/28124, loss=2.161546, lr=0.000014
28124it [1:31:30,  5.12it/s]
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.436600 sec., loss=1.145057 
Eval step: 199 , used_time=8.859007 sec., loss=1.026150 
Eval step: 299 , used_time=13.142264 sec., loss=1.043614 
Eval step: 399 , used_time=17.468240 sec., loss=1.389750 
Eval step: 499 , used_time=21.752204 sec., loss=1.446734 
Eval step: 599 , used_time=26.069469 sec., loss=1.481703 
Eval step: 699 , used_time=30.379094 sec., loss=1.613756 
Eval step: 799 , used_time=34.665474 sec., loss=1.401323 
Eval step: 899 , used_time=39.158605 sec., loss=1.105002 
Eval step: 999 , used_time=43.453512 sec., loss=1.119897 
Eval step: 1099 , used_time=47.765997 sec., loss=1.136716 
Eval step: 1199 , used_time=52.049762 sec., loss=1.323058 
Eval step: 1299 , used_time=56.383754 sec., loss=1.110680 
Eval step: 1399 , used_time=60.708773 sec., loss=0.792645 
Eval step: 1499 , used_time=64.995771 sec., loss=0.808131 
Eval step: 1599 , used_time=69.487810 sec., loss=1.087627 
Eval step: 1699 , used_time=73.770100 sec., loss=1.037773 
Eval step: 1799 , used_time=78.105670 sec., loss=0.792797 
Eval step: 1899 , used_time=82.394381 sec., loss=0.856933 
Eval step: 1999 , used_time=86.709521 sec., loss=1.768127 
Eval step: 2099 , used_time=91.052339 sec., loss=0.862560 
Eval step: 2199 , used_time=95.359962 sec., loss=0.866082 
Eval step: 2299 , used_time=99.808457 sec., loss=0.436020 
Eval step: 2399 , used_time=104.185888 sec., loss=1.485973 
Eval step: 2499 , used_time=108.546648 sec., loss=1.051114 
Eval step: 2599 , used_time=112.909179 sec., loss=1.199395 
Eval step: 2699 , used_time=117.255372 sec., loss=1.535908 
Eval step: 2799 , used_time=121.598328 sec., loss=1.136725 
Eval step: 2899 , used_time=125.948326 sec., loss=1.069901 
Eval step: 2999 , used_time=130.262665 sec., loss=0.857638 
Eval step: 3099 , used_time=134.880890 sec., loss=1.271850 
NLL Validation: loss = 1.190875. correct prediction ratio  66122/100032 ~  0.661008
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=1.894694
epoch total correct predictions=447625
***** Epoch 2 *****
0it [00:00, ?it/s]Epoch: 2: Step: 1/28124, loss=1.013609, lr=0.000014
99it [00:18,  5.74it/s]Train batch 100
Avg. loss per last 100 batches: 1.514011
100it [00:18,  5.73it/s]Epoch: 2: Step: 101/28124, loss=1.921487, lr=0.000014
199it [00:35,  5.72it/s]Train batch 200
Avg. loss per last 100 batches: 1.647931
200it [00:36,  5.73it/s]Epoch: 2: Step: 201/28124, loss=0.979176, lr=0.000014
299it [00:53,  5.55it/s]Train batch 300
Avg. loss per last 100 batches: 1.555279
300it [00:53,  5.48it/s]Epoch: 2: Step: 301/28124, loss=1.885930, lr=0.000014
399it [01:11,  5.75it/s]Train batch 400
Avg. loss per last 100 batches: 1.605746
400it [01:11,  5.73it/s]Epoch: 2: Step: 401/28124, loss=1.559408, lr=0.000014
499it [01:28,  5.76it/s]Train batch 500
Avg. loss per last 100 batches: 1.583586
500it [01:28,  5.74it/s]Epoch: 2: Step: 501/28124, loss=1.535059, lr=0.000014
599it [01:46,  5.75it/s]Train batch 600
Avg. loss per last 100 batches: 1.617152
600it [01:46,  5.75it/s]Epoch: 2: Step: 601/28124, loss=1.514951, lr=0.000014
699it [02:03,  5.74it/s]Train batch 700
Avg. loss per last 100 batches: 1.542431
700it [02:03,  5.74it/s]Epoch: 2: Step: 701/28124, loss=1.221244, lr=0.000014
799it [02:21,  5.74it/s]Train batch 800
Avg. loss per last 100 batches: 1.552296
800it [02:21,  5.75it/s]Epoch: 2: Step: 801/28124, loss=1.690668, lr=0.000014
899it [02:38,  5.77it/s]Train batch 900
Avg. loss per last 100 batches: 1.566570
900it [02:38,  5.77it/s]Epoch: 2: Step: 901/28124, loss=1.268868, lr=0.000014
999it [02:56,  5.73it/s]Train batch 1000
Avg. loss per last 100 batches: 1.557944
1000it [02:56,  5.73it/s]Epoch: 2: Step: 1001/28124, loss=1.831304, lr=0.000014
1099it [03:13,  5.71it/s]Train batch 1100
Avg. loss per last 100 batches: 1.622480
1100it [03:13,  5.71it/s]Epoch: 2: Step: 1101/28124, loss=1.753212, lr=0.000014
1199it [03:31,  5.64it/s]Train batch 1200
Avg. loss per last 100 batches: 1.579324
1200it [03:31,  5.67it/s]Epoch: 2: Step: 1201/28124, loss=1.751189, lr=0.000014
1299it [03:48,  5.72it/s]Train batch 1300
Avg. loss per last 100 batches: 1.601471
1300it [03:49,  5.74it/s]Epoch: 2: Step: 1301/28124, loss=1.325757, lr=0.000014
1399it [04:06,  5.70it/s]Train batch 1400
Avg. loss per last 100 batches: 1.635075
1400it [04:06,  5.71it/s]Epoch: 2: Step: 1401/28124, loss=1.303722, lr=0.000014
1499it [04:23,  5.70it/s]Train batch 1500
Avg. loss per last 100 batches: 1.593313
1500it [04:24,  5.71it/s]Epoch: 2: Step: 1501/28124, loss=1.393567, lr=0.000014
1599it [04:41,  5.68it/s]Train batch 1600
Avg. loss per last 100 batches: 1.546948
1600it [04:41,  5.69it/s]Epoch: 2: Step: 1601/28124, loss=1.797291, lr=0.000014
1699it [04:58,  5.77it/s]Train batch 1700
Avg. loss per last 100 batches: 1.528255
1700it [04:59,  5.75it/s]Epoch: 2: Step: 1701/28124, loss=1.571913, lr=0.000014
1799it [05:16,  5.74it/s]Train batch 1800
Avg. loss per last 100 batches: 1.550867
1800it [05:16,  5.75it/s]Epoch: 2: Step: 1801/28124, loss=1.407660, lr=0.000014
1899it [05:33,  5.76it/s]Train batch 1900
Avg. loss per last 100 batches: 1.581189
1900it [05:34,  5.75it/s]Epoch: 2: Step: 1901/28124, loss=2.115503, lr=0.000014
1999it [05:51,  5.76it/s]Train batch 2000
Avg. loss per last 100 batches: 1.586014
2000it [05:51,  5.78it/s]Epoch: 2: Step: 2001/28124, loss=1.488461, lr=0.000014
2099it [06:08,  5.74it/s]Train batch 2100
Avg. loss per last 100 batches: 1.627144
2100it [06:09,  5.74it/s]Epoch: 2: Step: 2101/28124, loss=1.678939, lr=0.000014
2199it [06:26,  5.74it/s]Train batch 2200
Avg. loss per last 100 batches: 1.561876
2200it [06:26,  5.72it/s]Epoch: 2: Step: 2201/28124, loss=0.876411, lr=0.000014
2299it [06:43,  5.50it/s]Train batch 2300
Avg. loss per last 100 batches: 1.501113
2300it [06:44,  5.49it/s]Epoch: 2: Step: 2301/28124, loss=1.710073, lr=0.000014
2399it [07:01,  5.73it/s]Train batch 2400
Avg. loss per last 100 batches: 1.569947
2400it [07:01,  5.72it/s]Epoch: 2: Step: 2401/28124, loss=1.168653, lr=0.000014
2499it [07:18,  5.73it/s]Train batch 2500
Avg. loss per last 100 batches: 1.607044
2500it [07:19,  5.73it/s]Epoch: 2: Step: 2501/28124, loss=1.271213, lr=0.000014
2599it [07:36,  5.71it/s]Train batch 2600
Avg. loss per last 100 batches: 1.591498
2600it [07:36,  5.71it/s]Epoch: 2: Step: 2601/28124, loss=1.196166, lr=0.000014
2699it [07:53,  5.73it/s]Train batch 2700
Avg. loss per last 100 batches: 1.551359
2700it [07:54,  5.73it/s]Epoch: 2: Step: 2701/28124, loss=2.101584, lr=0.000014
2799it [08:11,  5.74it/s]Train batch 2800
Avg. loss per last 100 batches: 1.572964
2800it [08:11,  5.75it/s]Epoch: 2: Step: 2801/28124, loss=1.403918, lr=0.000014
2899it [08:29,  5.76it/s]Train batch 2900
Avg. loss per last 100 batches: 1.596196
2900it [08:29,  5.75it/s]Epoch: 2: Step: 2901/28124, loss=1.620797, lr=0.000014
2999it [08:46,  5.73it/s]Train batch 3000
Avg. loss per last 100 batches: 1.509687
3000it [08:46,  5.73it/s]Epoch: 2: Step: 3001/28124, loss=1.500301, lr=0.000014
3099it [09:04,  5.75it/s]Train batch 3100
Avg. loss per last 100 batches: 1.618613
3100it [09:04,  5.68it/s]Epoch: 2: Step: 3101/28124, loss=1.652357, lr=0.000014
3199it [09:21,  5.73it/s]Train batch 3200
Avg. loss per last 100 batches: 1.570113
3200it [09:21,  5.64it/s]Epoch: 2: Step: 3201/28124, loss=1.734385, lr=0.000014
3299it [09:38,  5.76it/s]Train batch 3300
Avg. loss per last 100 batches: 1.579576
3300it [09:39,  5.75it/s]Epoch: 2: Step: 3301/28124, loss=1.886592, lr=0.000014
3399it [09:56,  5.73it/s]Train batch 3400
Avg. loss per last 100 batches: 1.595036
3400it [09:56,  5.75it/s]Epoch: 2: Step: 3401/28124, loss=1.939981, lr=0.000014
3499it [10:13,  5.74it/s]Train batch 3500
Avg. loss per last 100 batches: 1.601280
3500it [10:14,  5.71it/s]Epoch: 2: Step: 3501/28124, loss=1.562749, lr=0.000014
3599it [10:31,  5.74it/s]Train batch 3600
Avg. loss per last 100 batches: 1.535933
3600it [10:31,  5.74it/s]Epoch: 2: Step: 3601/28124, loss=1.933712, lr=0.000014
3699it [10:49,  5.73it/s]Train batch 3700
Avg. loss per last 100 batches: 1.562879
3700it [10:49,  5.71it/s]Epoch: 2: Step: 3701/28124, loss=1.609962, lr=0.000014
3799it [11:06,  5.76it/s]Train batch 3800
Avg. loss per last 100 batches: 1.585016
3800it [11:06,  5.76it/s]Epoch: 2: Step: 3801/28124, loss=1.649303, lr=0.000014
3899it [11:24,  5.66it/s]Train batch 3900
Avg. loss per last 100 batches: 1.564720
3900it [11:24,  5.66it/s]Epoch: 2: Step: 3901/28124, loss=1.993791, lr=0.000014
3999it [11:41,  5.69it/s]Train batch 4000
Avg. loss per last 100 batches: 1.556745
4000it [11:41,  5.66it/s]Epoch: 2: Step: 4001/28124, loss=2.161685, lr=0.000014
4099it [11:59,  5.72it/s]Train batch 4100
Avg. loss per last 100 batches: 1.615922
4100it [11:59,  5.71it/s]Epoch: 2: Step: 4101/28124, loss=1.932588, lr=0.000014
4199it [12:16,  5.73it/s]Train batch 4200
Avg. loss per last 100 batches: 1.600576
4200it [12:16,  5.74it/s]Epoch: 2: Step: 4201/28124, loss=1.414175, lr=0.000014
4299it [12:34,  5.58it/s]Train batch 4300
Avg. loss per last 100 batches: 1.561757
4300it [12:34,  5.49it/s]Epoch: 2: Step: 4301/28124, loss=1.505632, lr=0.000014
4399it [12:51,  5.70it/s]Train batch 4400
Avg. loss per last 100 batches: 1.580516
4400it [12:52,  5.69it/s]Epoch: 2: Step: 4401/28124, loss=1.103670, lr=0.000014
4499it [13:09,  5.72it/s]Train batch 4500
Avg. loss per last 100 batches: 1.556309
4500it [13:09,  5.72it/s]Epoch: 2: Step: 4501/28124, loss=1.148405, lr=0.000014
4599it [13:27,  5.73it/s]Train batch 4600
Avg. loss per last 100 batches: 1.564223
4600it [13:27,  5.74it/s]Epoch: 2: Step: 4601/28124, loss=1.682035, lr=0.000014
4699it [13:44,  5.73it/s]Train batch 4700
Avg. loss per last 100 batches: 1.600828
4700it [13:44,  5.74it/s]Epoch: 2: Step: 4701/28124, loss=1.868067, lr=0.000014
4799it [14:02,  5.76it/s]Train batch 4800
Avg. loss per last 100 batches: 1.567472
4800it [14:02,  5.77it/s]Epoch: 2: Step: 4801/28124, loss=1.754141, lr=0.000014
4899it [14:19,  5.75it/s]Train batch 4900
Avg. loss per last 100 batches: 1.589016
4900it [14:19,  5.76it/s]Epoch: 2: Step: 4901/28124, loss=1.609102, lr=0.000014
4999it [14:37,  5.73it/s]Train batch 5000
Avg. loss per last 100 batches: 1.602579
5000it [14:37,  5.72it/s]Epoch: 2: Step: 5001/28124, loss=1.325246, lr=0.000014
5099it [14:54,  5.63it/s]Train batch 5100
Avg. loss per last 100 batches: 1.535295
5100it [14:54,  5.66it/s]Epoch: 2: Step: 5101/28124, loss=1.211378, lr=0.000014
5199it [15:12,  5.43it/s]Train batch 5200
Avg. loss per last 100 batches: 1.568368
5200it [15:12,  5.52it/s]Epoch: 2: Step: 5201/28124, loss=1.376203, lr=0.000014
5299it [15:29,  5.76it/s]Train batch 5300
Avg. loss per last 100 batches: 1.543964
5300it [15:29,  5.73it/s]Epoch: 2: Step: 5301/28124, loss=1.313978, lr=0.000014
5399it [15:47,  5.74it/s]Train batch 5400
Avg. loss per last 100 batches: 1.526699
5400it [15:47,  5.74it/s]Epoch: 2: Step: 5401/28124, loss=1.284149, lr=0.000014
5499it [16:04,  5.51it/s]Train batch 5500
Avg. loss per last 100 batches: 1.607188
5500it [16:04,  5.58it/s]Epoch: 2: Step: 5501/28124, loss=1.796046, lr=0.000014
5599it [16:22,  5.74it/s]Train batch 5600
Avg. loss per last 100 batches: 1.567391
5600it [16:22,  5.75it/s]Epoch: 2: Step: 5601/28124, loss=1.416216, lr=0.000014
5624it [16:26,  5.75it/s]Validation: Epoch: 2 Step: 5625/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.333098 sec., loss=1.212447 
Eval step: 199 , used_time=8.606479 sec., loss=1.087211 
Eval step: 299 , used_time=12.911374 sec., loss=0.953846 
Eval step: 399 , used_time=17.371831 sec., loss=1.259396 
Eval step: 499 , used_time=21.650620 sec., loss=1.509800 
Eval step: 599 , used_time=25.984707 sec., loss=1.572011 
Eval step: 699 , used_time=30.266839 sec., loss=1.705749 
Eval step: 799 , used_time=34.572957 sec., loss=1.636676 
Eval step: 899 , used_time=38.848339 sec., loss=1.140375 
Eval step: 999 , used_time=43.155093 sec., loss=1.154386 
Eval step: 1099 , used_time=47.615613 sec., loss=1.062273 
Eval step: 1199 , used_time=51.893590 sec., loss=1.341626 
Eval step: 1299 , used_time=56.197235 sec., loss=0.901857 
Eval step: 1399 , used_time=60.469998 sec., loss=0.663783 
Eval step: 1499 , used_time=64.769775 sec., loss=0.888979 
Eval step: 1599 , used_time=69.033491 sec., loss=1.051445 
Eval step: 1699 , used_time=73.335659 sec., loss=1.116580 
Eval step: 1799 , used_time=77.605386 sec., loss=0.784500 
Eval step: 1899 , used_time=82.058513 sec., loss=0.819305 
Eval step: 1999 , used_time=86.383479 sec., loss=2.008040 
Eval step: 2099 , used_time=90.653608 sec., loss=0.840306 
Eval step: 2199 , used_time=94.954149 sec., loss=0.979467 
Eval step: 2299 , used_time=99.223363 sec., loss=0.535843 
Eval step: 2399 , used_time=103.538255 sec., loss=1.328096 
Eval step: 2499 , used_time=107.822972 sec., loss=1.087472 
Eval step: 2599 , used_time=112.274588 sec., loss=1.250342 
Eval step: 2699 , used_time=116.578020 sec., loss=1.544210 
Eval step: 2799 , used_time=120.849563 sec., loss=1.074665 
Eval step: 2899 , used_time=125.145217 sec., loss=1.017852 
Eval step: 2999 , used_time=129.422560 sec., loss=0.901470 
Eval step: 3099 , used_time=133.736392 sec., loss=1.117038 
NLL Validation: loss = 1.176554. correct prediction ratio  66823/100032 ~  0.668016
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:04,  5.74it/s]Train batch 5700
Avg. loss per last 100 batches: 1.549141
5700it [19:04,  5.72it/s]Epoch: 2: Step: 5701/28124, loss=1.889868, lr=0.000014
5799it [19:21,  5.75it/s]Train batch 5800
Avg. loss per last 100 batches: 1.655561
5800it [19:22,  5.75it/s]Epoch: 2: Step: 5801/28124, loss=1.866485, lr=0.000014
5899it [19:39,  5.75it/s]Train batch 5900
Avg. loss per last 100 batches: 1.526223
5900it [19:39,  5.73it/s]Epoch: 2: Step: 5901/28124, loss=1.426962, lr=0.000014
5999it [19:56,  5.56it/s]Train batch 6000
Avg. loss per last 100 batches: 1.607786
6000it [19:57,  5.50it/s]Epoch: 2: Step: 6001/28124, loss=1.629740, lr=0.000014
6099it [20:14,  5.73it/s]Train batch 6100
Avg. loss per last 100 batches: 1.593695
6100it [20:14,  5.73it/s]Epoch: 2: Step: 6101/28124, loss=1.426727, lr=0.000014
6199it [20:31,  5.75it/s]Train batch 6200
Avg. loss per last 100 batches: 1.591853
6200it [20:32,  5.74it/s]Epoch: 2: Step: 6201/28124, loss=1.991111, lr=0.000014
6299it [20:49,  5.76it/s]Train batch 6300
Avg. loss per last 100 batches: 1.598553
6300it [20:49,  5.76it/s]Epoch: 2: Step: 6301/28124, loss=1.850915, lr=0.000014
6399it [21:07,  5.74it/s]Train batch 6400
Avg. loss per last 100 batches: 1.560065
6400it [21:07,  5.74it/s]Epoch: 2: Step: 6401/28124, loss=1.981708, lr=0.000014
6499it [21:24,  5.56it/s]Train batch 6500
Avg. loss per last 100 batches: 1.584787
6500it [21:24,  5.62it/s]Epoch: 2: Step: 6501/28124, loss=1.440170, lr=0.000014
6599it [21:42,  5.72it/s]Train batch 6600
Avg. loss per last 100 batches: 1.527650
6600it [21:42,  5.72it/s]Epoch: 2: Step: 6601/28124, loss=1.875203, lr=0.000014
6699it [21:59,  5.76it/s]Train batch 6700
Avg. loss per last 100 batches: 1.582298
6700it [21:59,  5.73it/s]Epoch: 2: Step: 6701/28124, loss=1.501948, lr=0.000014
6799it [22:17,  5.74it/s]Train batch 6800
Avg. loss per last 100 batches: 1.583470
6800it [22:17,  5.73it/s]Epoch: 2: Step: 6801/28124, loss=2.363002, lr=0.000014
6899it [22:34,  5.73it/s]Train batch 6900
Avg. loss per last 100 batches: 1.534447
6900it [22:34,  5.74it/s]Epoch: 2: Step: 6901/28124, loss=1.725542, lr=0.000014
6999it [22:51,  5.76it/s]Train batch 7000
Avg. loss per last 100 batches: 1.532992
7000it [22:52,  5.74it/s]Epoch: 2: Step: 7001/28124, loss=2.348754, lr=0.000014
7099it [23:09,  5.64it/s]Train batch 7100
Avg. loss per last 100 batches: 1.519532
7100it [23:09,  5.66it/s]Epoch: 2: Step: 7101/28124, loss=1.696866, lr=0.000014
7199it [23:26,  5.71it/s]Train batch 7200
Avg. loss per last 100 batches: 1.501030
7200it [23:27,  5.73it/s]Epoch: 2: Step: 7201/28124, loss=1.239997, lr=0.000014
7299it [23:44,  5.50it/s]Train batch 7300
Avg. loss per last 100 batches: 1.531379
7300it [23:44,  5.57it/s]Epoch: 2: Step: 7301/28124, loss=1.730949, lr=0.000014
7399it [24:01,  5.73it/s]Train batch 7400
Avg. loss per last 100 batches: 1.548377
7400it [24:02,  5.73it/s]Epoch: 2: Step: 7401/28124, loss=1.227538, lr=0.000014
7499it [24:19,  5.71it/s]Train batch 7500
Avg. loss per last 100 batches: 1.541361
7500it [24:19,  5.72it/s]Epoch: 2: Step: 7501/28124, loss=1.470860, lr=0.000014
7599it [24:36,  5.75it/s]Train batch 7600
Avg. loss per last 100 batches: 1.522283
7600it [24:37,  5.74it/s]Epoch: 2: Step: 7601/28124, loss=1.616695, lr=0.000014
7699it [24:54,  5.48it/s]Train batch 7700
Avg. loss per last 100 batches: 1.509337
7700it [24:54,  5.56it/s]Epoch: 2: Step: 7701/28124, loss=1.298661, lr=0.000014
7799it [25:11,  5.72it/s]Train batch 7800
Avg. loss per last 100 batches: 1.584102
7800it [25:12,  5.74it/s]Epoch: 2: Step: 7801/28124, loss=1.532724, lr=0.000014
7899it [25:29,  5.75it/s]Train batch 7900
Avg. loss per last 100 batches: 1.548452
7900it [25:29,  5.74it/s]Epoch: 2: Step: 7901/28124, loss=1.288248, lr=0.000014
7999it [25:47,  5.45it/s]Train batch 8000
Avg. loss per last 100 batches: 1.544124
8000it [25:47,  5.39it/s]Epoch: 2: Step: 8001/28124, loss=0.930671, lr=0.000014
8099it [26:04,  5.51it/s]Train batch 8100
Avg. loss per last 100 batches: 1.602302
8100it [26:04,  5.59it/s]Epoch: 2: Step: 8101/28124, loss=1.816520, lr=0.000014
8199it [26:22,  5.76it/s]Train batch 8200
Avg. loss per last 100 batches: 1.502280
8200it [26:22,  5.75it/s]Epoch: 2: Step: 8201/28124, loss=1.558006, lr=0.000014
8299it [26:39,  5.76it/s]Train batch 8300
Avg. loss per last 100 batches: 1.569622
8300it [26:39,  5.76it/s]Epoch: 2: Step: 8301/28124, loss=1.846806, lr=0.000014
8399it [26:57,  5.75it/s]Train batch 8400
Avg. loss per last 100 batches: 1.594614
8400it [26:57,  5.77it/s]Epoch: 2: Step: 8401/28124, loss=2.010220, lr=0.000014
8499it [27:14,  5.49it/s]Train batch 8500
Avg. loss per last 100 batches: 1.514885
8500it [27:14,  5.55it/s]Epoch: 2: Step: 8501/28124, loss=1.464365, lr=0.000014
8599it [27:31,  5.76it/s]Train batch 8600
Avg. loss per last 100 batches: 1.552828
8600it [27:32,  5.76it/s]Epoch: 2: Step: 8601/28124, loss=1.423089, lr=0.000013
8699it [27:49,  5.75it/s]Train batch 8700
Avg. loss per last 100 batches: 1.566941
8700it [27:49,  5.75it/s]Epoch: 2: Step: 8701/28124, loss=2.306094, lr=0.000013
8799it [28:06,  5.75it/s]Train batch 8800
Avg. loss per last 100 batches: 1.585243
8800it [28:07,  5.75it/s]Epoch: 2: Step: 8801/28124, loss=1.163962, lr=0.000013
8899it [28:24,  5.69it/s]Train batch 8900
Avg. loss per last 100 batches: 1.563873
8900it [28:24,  5.71it/s]Epoch: 2: Step: 8901/28124, loss=1.765817, lr=0.000013
8999it [28:41,  5.76it/s]Train batch 9000
Avg. loss per last 100 batches: 1.581130
9000it [28:42,  5.77it/s]Epoch: 2: Step: 9001/28124, loss=2.589625, lr=0.000013
9099it [28:59,  5.73it/s]Train batch 9100
Avg. loss per last 100 batches: 1.585573
9100it [28:59,  5.73it/s]Epoch: 2: Step: 9101/28124, loss=1.611666, lr=0.000013
9199it [29:16,  5.74it/s]Train batch 9200
Avg. loss per last 100 batches: 1.590515
9200it [29:17,  5.74it/s]Epoch: 2: Step: 9201/28124, loss=1.868197, lr=0.000013
9299it [29:34,  5.66it/s]Train batch 9300
Avg. loss per last 100 batches: 1.569627
9300it [29:34,  5.69it/s]Epoch: 2: Step: 9301/28124, loss=1.586978, lr=0.000013
9399it [29:51,  5.77it/s]Train batch 9400
Avg. loss per last 100 batches: 1.537142
9400it [29:51,  5.75it/s]Epoch: 2: Step: 9401/28124, loss=2.521477, lr=0.000013
9499it [30:09,  5.76it/s]Train batch 9500
Avg. loss per last 100 batches: 1.548090
9500it [30:09,  5.73it/s]Epoch: 2: Step: 9501/28124, loss=1.010322, lr=0.000013
9599it [30:26,  5.73it/s]Train batch 9600
Avg. loss per last 100 batches: 1.549595
9600it [30:26,  5.74it/s]Epoch: 2: Step: 9601/28124, loss=1.174810, lr=0.000013
9699it [30:44,  5.70it/s]Train batch 9700
Avg. loss per last 100 batches: 1.597796
9700it [30:44,  5.49it/s]Epoch: 2: Step: 9701/28124, loss=1.571762, lr=0.000013
9799it [31:01,  5.73it/s]Train batch 9800
Avg. loss per last 100 batches: 1.460361
9800it [31:01,  5.71it/s]Epoch: 2: Step: 9801/28124, loss=1.790116, lr=0.000013
9899it [31:19,  5.77it/s]Train batch 9900
Avg. loss per last 100 batches: 1.559204
9900it [31:19,  5.76it/s]Epoch: 2: Step: 9901/28124, loss=1.884066, lr=0.000013
9999it [31:36,  5.45it/s]Train batch 10000
Avg. loss per last 100 batches: 1.559953
10000it [31:36,  5.53it/s]Epoch: 2: Step: 10001/28124, loss=1.580248, lr=0.000013
10099it [31:54,  5.51it/s]Train batch 10100
Avg. loss per last 100 batches: 1.550615
10100it [31:54,  5.53it/s]Epoch: 2: Step: 10101/28124, loss=1.054384, lr=0.000013
10199it [32:11,  5.72it/s]Train batch 10200
Avg. loss per last 100 batches: 1.541854
10200it [32:11,  5.74it/s]Epoch: 2: Step: 10201/28124, loss=0.847330, lr=0.000013
10299it [32:29,  5.77it/s]Train batch 10300
Avg. loss per last 100 batches: 1.553062
10300it [32:29,  5.73it/s]Epoch: 2: Step: 10301/28124, loss=1.608826, lr=0.000013
10399it [32:46,  5.76it/s]Train batch 10400
Avg. loss per last 100 batches: 1.511367
10400it [32:46,  5.77it/s]Epoch: 2: Step: 10401/28124, loss=1.633719, lr=0.000013
10499it [33:04,  5.77it/s]Train batch 10500
Avg. loss per last 100 batches: 1.542738
10500it [33:04,  5.75it/s]Epoch: 2: Step: 10501/28124, loss=1.877791, lr=0.000013
10599it [33:21,  5.74it/s]Train batch 10600
Avg. loss per last 100 batches: 1.592719
10600it [33:21,  5.75it/s]Epoch: 2: Step: 10601/28124, loss=1.516511, lr=0.000013
10699it [33:39,  5.76it/s]Train batch 10700
Avg. loss per last 100 batches: 1.526768
10700it [33:39,  5.74it/s]Epoch: 2: Step: 10701/28124, loss=1.227118, lr=0.000013
10799it [33:56,  5.75it/s]Train batch 10800
Avg. loss per last 100 batches: 1.497093
10800it [33:56,  5.75it/s]Epoch: 2: Step: 10801/28124, loss=1.188198, lr=0.000013
10899it [34:14,  5.61it/s]Train batch 10900
Avg. loss per last 100 batches: 1.507381
10900it [34:14,  5.53it/s]Epoch: 2: Step: 10901/28124, loss=1.791412, lr=0.000013
10999it [34:31,  5.76it/s]Train batch 11000
Avg. loss per last 100 batches: 1.570077
11000it [34:31,  5.77it/s]Epoch: 2: Step: 11001/28124, loss=2.036672, lr=0.000013
11099it [34:49,  5.74it/s]Train batch 11100
Avg. loss per last 100 batches: 1.546133
11100it [34:49,  5.72it/s]Epoch: 2: Step: 11101/28124, loss=1.219998, lr=0.000013
11199it [35:06,  5.73it/s]Train batch 11200
Avg. loss per last 100 batches: 1.539707
11200it [35:06,  5.75it/s]Epoch: 2: Step: 11201/28124, loss=1.677759, lr=0.000013
11249it [35:15,  5.73it/s]Validation: Epoch: 2 Step: 11250/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.484950 sec., loss=1.133075 
Eval step: 199 , used_time=8.775187 sec., loss=1.277055 
Eval step: 299 , used_time=13.048585 sec., loss=1.027375 
Eval step: 399 , used_time=17.318462 sec., loss=1.188232 
Eval step: 499 , used_time=21.617301 sec., loss=1.259335 
Eval step: 599 , used_time=25.896155 sec., loss=1.351246 
Eval step: 699 , used_time=30.214906 sec., loss=1.507211 
Eval step: 799 , used_time=34.683351 sec., loss=1.381989 
Eval step: 899 , used_time=39.005519 sec., loss=1.158783 
Eval step: 999 , used_time=43.283284 sec., loss=1.241142 
Eval step: 1099 , used_time=47.554065 sec., loss=1.009396 
Eval step: 1199 , used_time=51.852256 sec., loss=1.236246 
Eval step: 1299 , used_time=56.134178 sec., loss=0.987566 
Eval step: 1399 , used_time=60.443743 sec., loss=0.741783 
Eval step: 1499 , used_time=64.736245 sec., loss=0.747276 
Eval step: 1599 , used_time=69.236974 sec., loss=1.199891 
Eval step: 1699 , used_time=73.513483 sec., loss=1.054788 
Eval step: 1799 , used_time=77.791228 sec., loss=0.909324 
Eval step: 1899 , used_time=82.084794 sec., loss=0.817581 
Eval step: 1999 , used_time=86.357954 sec., loss=1.770817 
Eval step: 2099 , used_time=90.659915 sec., loss=0.842773 
Eval step: 2199 , used_time=94.953424 sec., loss=1.037114 
Eval step: 2299 , used_time=99.461413 sec., loss=0.499297 
Eval step: 2399 , used_time=103.732103 sec., loss=1.486466 
Eval step: 2499 , used_time=108.023010 sec., loss=0.969194 
Eval step: 2599 , used_time=112.345519 sec., loss=1.218962 
Eval step: 2699 , used_time=116.635173 sec., loss=1.643082 
Eval step: 2799 , used_time=120.939416 sec., loss=1.215165 
Eval step: 2899 , used_time=125.229144 sec., loss=0.848115 
Eval step: 2999 , used_time=129.699017 sec., loss=0.852848 
Eval step: 3099 , used_time=134.026053 sec., loss=1.204128 
NLL Validation: loss = 1.152617. correct prediction ratio  67661/100032 ~  0.676394
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [37:44,  5.73it/s]Train batch 11300
Avg. loss per last 100 batches: 1.525952
11300it [37:44,  5.72it/s]Epoch: 2: Step: 11301/28124, loss=1.549267, lr=0.000013
11399it [38:02,  5.76it/s]Train batch 11400
Avg. loss per last 100 batches: 1.532702
11400it [38:02,  5.76it/s]Epoch: 2: Step: 11401/28124, loss=1.400231, lr=0.000013
11499it [38:19,  5.73it/s]Train batch 11500
Avg. loss per last 100 batches: 1.534355
11500it [38:19,  5.74it/s]Epoch: 2: Step: 11501/28124, loss=1.594382, lr=0.000013
11599it [38:37,  5.74it/s]Train batch 11600
Avg. loss per last 100 batches: 1.586488
11600it [38:37,  5.75it/s]Epoch: 2: Step: 11601/28124, loss=1.556525, lr=0.000013
11699it [38:54,  5.63it/s]Train batch 11700
Avg. loss per last 100 batches: 1.532861
11700it [38:54,  5.64it/s]Epoch: 2: Step: 11701/28124, loss=1.261801, lr=0.000013
11799it [39:12,  5.75it/s]Train batch 11800
Avg. loss per last 100 batches: 1.530680
11800it [39:12,  5.75it/s]Epoch: 2: Step: 11801/28124, loss=2.063539, lr=0.000013
11899it [39:29,  5.76it/s]Train batch 11900
Avg. loss per last 100 batches: 1.585311
11900it [39:29,  5.76it/s]Epoch: 2: Step: 11901/28124, loss=1.098101, lr=0.000013
11999it [39:47,  5.76it/s]Train batch 12000
Avg. loss per last 100 batches: 1.552951
12000it [39:47,  5.75it/s]Epoch: 2: Step: 12001/28124, loss=1.832860, lr=0.000013
12099it [40:04,  5.33it/s]Train batch 12100
Avg. loss per last 100 batches: 1.563785
12100it [40:04,  5.34it/s]Epoch: 2: Step: 12101/28124, loss=1.574936, lr=0.000013
12199it [40:22,  5.74it/s]Train batch 12200
Avg. loss per last 100 batches: 1.524168
12200it [40:22,  5.74it/s]Epoch: 2: Step: 12201/28124, loss=1.882645, lr=0.000013
12299it [40:39,  5.77it/s]Train batch 12300
Avg. loss per last 100 batches: 1.577642
12300it [40:39,  5.77it/s]Epoch: 2: Step: 12301/28124, loss=1.409906, lr=0.000013
12399it [40:57,  5.76it/s]Train batch 12400
Avg. loss per last 100 batches: 1.586903
12400it [40:57,  5.75it/s]Epoch: 2: Step: 12401/28124, loss=2.240369, lr=0.000013
12499it [41:14,  5.62it/s]Train batch 12500
Avg. loss per last 100 batches: 1.580001
12500it [41:14,  5.67it/s]Epoch: 2: Step: 12501/28124, loss=1.405334, lr=0.000013
12599it [41:31,  5.75it/s]Train batch 12600
Avg. loss per last 100 batches: 1.499597
12600it [41:32,  5.74it/s]Epoch: 2: Step: 12601/28124, loss=1.358077, lr=0.000013
12699it [41:49,  5.76it/s]Train batch 12700
Avg. loss per last 100 batches: 1.537398
12700it [41:49,  5.75it/s]Epoch: 2: Step: 12701/28124, loss=1.457445, lr=0.000013
12799it [42:06,  5.76it/s]Train batch 12800
Avg. loss per last 100 batches: 1.470419
12800it [42:07,  5.75it/s]Epoch: 2: Step: 12801/28124, loss=1.456033, lr=0.000013
12899it [42:24,  5.73it/s]Train batch 12900
Avg. loss per last 100 batches: 1.559524
12900it [42:24,  5.74it/s]Epoch: 2: Step: 12901/28124, loss=2.506692, lr=0.000013
12999it [42:41,  5.75it/s]Train batch 13000
Avg. loss per last 100 batches: 1.562978
13000it [42:42,  5.67it/s]Epoch: 2: Step: 13001/28124, loss=1.371695, lr=0.000013
13099it [42:59,  5.74it/s]Train batch 13100
Avg. loss per last 100 batches: 1.465291
13100it [42:59,  5.74it/s]Epoch: 2: Step: 13101/28124, loss=1.218982, lr=0.000013
13199it [43:16,  5.73it/s]Train batch 13200
Avg. loss per last 100 batches: 1.529487
13200it [43:17,  5.75it/s]Epoch: 2: Step: 13201/28124, loss=1.141224, lr=0.000013
13299it [43:34,  5.55it/s]Train batch 13300
Avg. loss per last 100 batches: 1.533526
13300it [43:34,  5.45it/s]Epoch: 2: Step: 13301/28124, loss=1.085919, lr=0.000013
13399it [43:51,  5.75it/s]Train batch 13400
Avg. loss per last 100 batches: 1.489433
13400it [43:52,  5.76it/s]Epoch: 2: Step: 13401/28124, loss=0.919269, lr=0.000013
13499it [44:09,  5.76it/s]Train batch 13500
Avg. loss per last 100 batches: 1.538940
13500it [44:09,  5.75it/s]Epoch: 2: Step: 13501/28124, loss=0.903153, lr=0.000013
13599it [44:26,  5.73it/s]Train batch 13600
Avg. loss per last 100 batches: 1.527589
13600it [44:27,  5.71it/s]Epoch: 2: Step: 13601/28124, loss=1.144611, lr=0.000013
13699it [44:44,  5.71it/s]Train batch 13700
Avg. loss per last 100 batches: 1.524734
13700it [44:44,  5.51it/s]Epoch: 2: Step: 13701/28124, loss=1.547414, lr=0.000013
13799it [45:01,  5.72it/s]Train batch 13800
Avg. loss per last 100 batches: 1.557030
13800it [45:02,  5.73it/s]Epoch: 2: Step: 13801/28124, loss=1.750632, lr=0.000013
13899it [45:19,  5.76it/s]Train batch 13900
Avg. loss per last 100 batches: 1.594231
13900it [45:19,  5.75it/s]Epoch: 2: Step: 13901/28124, loss=1.165661, lr=0.000013
13999it [45:36,  5.77it/s]Train batch 14000
Avg. loss per last 100 batches: 1.527763
14000it [45:36,  5.75it/s]Epoch: 2: Step: 14001/28124, loss=1.008735, lr=0.000013
14099it [45:54,  5.52it/s]Train batch 14100
Avg. loss per last 100 batches: 1.526807
14100it [45:54,  5.32it/s]Epoch: 2: Step: 14101/28124, loss=1.172922, lr=0.000013
14199it [46:11,  5.74it/s]Train batch 14200
Avg. loss per last 100 batches: 1.594085
14200it [46:11,  5.73it/s]Epoch: 2: Step: 14201/28124, loss=1.702068, lr=0.000013
14299it [46:29,  5.72it/s]Train batch 14300
Avg. loss per last 100 batches: 1.510311
14300it [46:29,  5.73it/s]Epoch: 2: Step: 14301/28124, loss=1.498415, lr=0.000013
14399it [46:46,  5.75it/s]Train batch 14400
Avg. loss per last 100 batches: 1.521311
14400it [46:46,  5.75it/s]Epoch: 2: Step: 14401/28124, loss=2.015003, lr=0.000013
14499it [47:04,  5.75it/s]Train batch 14500
Avg. loss per last 100 batches: 1.549659
14500it [47:04,  5.66it/s]Epoch: 2: Step: 14501/28124, loss=1.279822, lr=0.000013
14599it [47:21,  5.76it/s]Train batch 14600
Avg. loss per last 100 batches: 1.483162
14600it [47:21,  5.72it/s]Epoch: 2: Step: 14601/28124, loss=1.795114, lr=0.000013
14699it [47:39,  5.75it/s]Train batch 14700
Avg. loss per last 100 batches: 1.488036
14700it [47:39,  5.75it/s]Epoch: 2: Step: 14701/28124, loss=1.224834, lr=0.000013
14799it [47:56,  5.76it/s]Train batch 14800
Avg. loss per last 100 batches: 1.494821
14800it [47:56,  5.76it/s]Epoch: 2: Step: 14801/28124, loss=1.341617, lr=0.000013
14899it [48:14,  5.76it/s]Train batch 14900
Avg. loss per last 100 batches: 1.465217
14900it [48:14,  5.55it/s]Epoch: 2: Step: 14901/28124, loss=0.844024, lr=0.000013
14999it [48:31,  5.49it/s]Train batch 15000
Avg. loss per last 100 batches: 1.560967
15000it [48:31,  5.46it/s]Epoch: 2: Step: 15001/28124, loss=1.500458, lr=0.000013
15099it [48:49,  5.75it/s]Train batch 15100
Avg. loss per last 100 batches: 1.517403
15100it [48:49,  5.75it/s]Epoch: 2: Step: 15101/28124, loss=1.126922, lr=0.000013
15199it [49:06,  5.73it/s]Train batch 15200
Avg. loss per last 100 batches: 1.510725
15200it [49:06,  5.75it/s]Epoch: 2: Step: 15201/28124, loss=1.585799, lr=0.000013
15299it [49:24,  5.77it/s]Train batch 15300
Avg. loss per last 100 batches: 1.509349
15300it [49:24,  5.71it/s]Epoch: 2: Step: 15301/28124, loss=1.563776, lr=0.000013
15399it [49:41,  5.76it/s]Train batch 15400
Avg. loss per last 100 batches: 1.536850
15400it [49:41,  5.75it/s]Epoch: 2: Step: 15401/28124, loss=1.741931, lr=0.000013
15499it [49:59,  5.76it/s]Train batch 15500
Avg. loss per last 100 batches: 1.538803
15500it [49:59,  5.76it/s]Epoch: 2: Step: 15501/28124, loss=1.267247, lr=0.000013
15599it [50:16,  5.74it/s]Train batch 15600
Avg. loss per last 100 batches: 1.473912
15600it [50:16,  5.74it/s]Epoch: 2: Step: 15601/28124, loss=1.681954, lr=0.000013
15699it [50:34,  5.74it/s]Train batch 15700
Avg. loss per last 100 batches: 1.537125
15700it [50:34,  5.74it/s]Epoch: 2: Step: 15701/28124, loss=1.210568, lr=0.000013
15799it [50:51,  5.76it/s]Train batch 15800
Avg. loss per last 100 batches: 1.543207
15800it [50:51,  5.77it/s]Epoch: 2: Step: 15801/28124, loss=1.528752, lr=0.000013
15899it [51:09,  5.78it/s]Train batch 15900
Avg. loss per last 100 batches: 1.539046
15900it [51:09,  5.77it/s]Epoch: 2: Step: 15901/28124, loss=1.289710, lr=0.000013
15999it [51:26,  5.74it/s]Train batch 16000
Avg. loss per last 100 batches: 1.513043
16000it [51:26,  5.75it/s]Epoch: 2: Step: 16001/28124, loss=1.478679, lr=0.000013
16099it [51:44,  5.71it/s]Train batch 16100
Avg. loss per last 100 batches: 1.497342
16100it [51:44,  5.57it/s]Epoch: 2: Step: 16101/28124, loss=1.348140, lr=0.000013
16199it [52:01,  5.74it/s]Train batch 16200
Avg. loss per last 100 batches: 1.532770
16200it [52:01,  5.73it/s]Epoch: 2: Step: 16201/28124, loss=1.774041, lr=0.000013
16299it [52:19,  5.74it/s]Train batch 16300
Avg. loss per last 100 batches: 1.492575
16300it [52:19,  5.73it/s]Epoch: 2: Step: 16301/28124, loss=2.205645, lr=0.000013
16399it [52:36,  5.73it/s]Train batch 16400
Avg. loss per last 100 batches: 1.535112
16400it [52:36,  5.73it/s]Epoch: 2: Step: 16401/28124, loss=1.517051, lr=0.000013
16499it [52:54,  5.72it/s]Train batch 16500
Avg. loss per last 100 batches: 1.520113
16500it [52:54,  5.67it/s]Epoch: 2: Step: 16501/28124, loss=1.350418, lr=0.000013
16599it [53:11,  5.72it/s]Train batch 16600
Avg. loss per last 100 batches: 1.514543
16600it [53:11,  5.72it/s]Epoch: 2: Step: 16601/28124, loss=2.115508, lr=0.000013
16699it [53:29,  5.75it/s]Train batch 16700
Avg. loss per last 100 batches: 1.549538
16700it [53:29,  5.76it/s]Epoch: 2: Step: 16701/28124, loss=1.217194, lr=0.000013
16799it [53:46,  5.72it/s]Train batch 16800
Avg. loss per last 100 batches: 1.522556
16800it [53:46,  5.73it/s]Epoch: 2: Step: 16801/28124, loss=1.238907, lr=0.000013
16874it [53:59,  5.76it/s]Validation: Epoch: 2 Step: 16875/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.296308 sec., loss=1.108204 
Eval step: 199 , used_time=8.553971 sec., loss=1.023358 
Eval step: 299 , used_time=12.885940 sec., loss=0.833800 
Eval step: 399 , used_time=17.346133 sec., loss=1.482986 
Eval step: 499 , used_time=21.649387 sec., loss=1.368701 
Eval step: 599 , used_time=25.913817 sec., loss=1.474148 
Eval step: 699 , used_time=30.220559 sec., loss=1.454239 
Eval step: 799 , used_time=34.504744 sec., loss=1.336782 
Eval step: 899 , used_time=38.772300 sec., loss=0.967100 
Eval step: 999 , used_time=43.084232 sec., loss=1.182254 
Eval step: 1099 , used_time=47.358030 sec., loss=0.954215 
Eval step: 1199 , used_time=51.829245 sec., loss=1.144849 
Eval step: 1299 , used_time=56.093686 sec., loss=0.909084 
Eval step: 1399 , used_time=60.391725 sec., loss=0.729440 
Eval step: 1499 , used_time=64.681555 sec., loss=0.682072 
Eval step: 1599 , used_time=68.941755 sec., loss=1.276920 
Eval step: 1699 , used_time=73.246761 sec., loss=1.072705 
Eval step: 1799 , used_time=77.533332 sec., loss=0.900521 
Eval step: 1899 , used_time=82.062873 sec., loss=0.661003 
Eval step: 1999 , used_time=86.354636 sec., loss=1.551062 
Eval step: 2099 , used_time=90.683330 sec., loss=0.859254 
Eval step: 2199 , used_time=94.998768 sec., loss=0.979525 
Eval step: 2299 , used_time=99.307510 sec., loss=0.492304 
Eval step: 2399 , used_time=103.588593 sec., loss=1.470046 
Eval step: 2499 , used_time=107.874030 sec., loss=0.929899 
Eval step: 2599 , used_time=112.398523 sec., loss=1.327705 
Eval step: 2699 , used_time=116.681208 sec., loss=1.544316 
Eval step: 2799 , used_time=121.009089 sec., loss=1.296153 
Eval step: 2899 , used_time=125.335724 sec., loss=0.961409 
Eval step: 2999 , used_time=129.654371 sec., loss=0.781260 
Eval step: 3099 , used_time=133.969254 sec., loss=1.080435 
NLL Validation: loss = 1.114221. correct prediction ratio  68696/100032 ~  0.686740
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
16899it [56:29,  4.99it/s]Train batch 16900
Avg. loss per last 100 batches: 1.419244
16900it [56:29,  5.17it/s]Epoch: 2: Step: 16901/28124, loss=1.234082, lr=0.000013
16999it [56:46,  5.69it/s]Train batch 17000
Avg. loss per last 100 batches: 1.530293
17000it [56:47,  5.70it/s]Epoch: 2: Step: 17001/28124, loss=2.042343, lr=0.000013
17099it [57:04,  5.72it/s]Train batch 17100
Avg. loss per last 100 batches: 1.586179
17100it [57:04,  5.72it/s]Epoch: 2: Step: 17101/28124, loss=1.962659, lr=0.000013
17199it [57:22,  5.75it/s]Train batch 17200
Avg. loss per last 100 batches: 1.525019
17200it [57:22,  5.73it/s]Epoch: 2: Step: 17201/28124, loss=2.035391, lr=0.000013
17299it [57:39,  5.68it/s]Train batch 17300
Avg. loss per last 100 batches: 1.479988
17300it [57:39,  5.69it/s]Epoch: 2: Step: 17301/28124, loss=1.857846, lr=0.000013
17399it [57:57,  5.71it/s]Train batch 17400
Avg. loss per last 100 batches: 1.513139
17400it [57:57,  5.73it/s]Epoch: 2: Step: 17401/28124, loss=1.895812, lr=0.000013
17499it [58:14,  5.72it/s]Train batch 17500
Avg. loss per last 100 batches: 1.560833
17500it [58:14,  5.71it/s]Epoch: 2: Step: 17501/28124, loss=1.669244, lr=0.000013
17599it [58:32,  5.74it/s]Train batch 17600
Avg. loss per last 100 batches: 1.505196
17600it [58:32,  5.75it/s]Epoch: 2: Step: 17601/28124, loss=1.495504, lr=0.000013
17699it [58:49,  5.75it/s]Train batch 17700
Avg. loss per last 100 batches: 1.572653
17700it [58:49,  5.76it/s]Epoch: 2: Step: 17701/28124, loss=1.051797, lr=0.000013
17799it [59:07,  5.46it/s]Train batch 17800
Avg. loss per last 100 batches: 1.548802
17800it [59:07,  5.44it/s]Epoch: 2: Step: 17801/28124, loss=1.189196, lr=0.000013
17899it [59:24,  5.61it/s]Train batch 17900
Avg. loss per last 100 batches: 1.511876
17900it [59:25,  5.65it/s]Epoch: 2: Step: 17901/28124, loss=1.602901, lr=0.000013
17999it [59:42,  5.70it/s]Train batch 18000
Avg. loss per last 100 batches: 1.516547
18000it [59:42,  5.71it/s]Epoch: 2: Step: 18001/28124, loss=1.841521, lr=0.000013
18099it [59:59,  5.72it/s]Train batch 18100
Avg. loss per last 100 batches: 1.469904
18100it [1:00:00,  5.73it/s]Epoch: 2: Step: 18101/28124, loss=1.360802, lr=0.000013
18199it [1:00:17,  5.75it/s]Train batch 18200
Avg. loss per last 100 batches: 1.529906
18200it [1:00:17,  5.75it/s]Epoch: 2: Step: 18201/28124, loss=1.243557, lr=0.000013
18299it [1:00:35,  5.66it/s]Train batch 18300
Avg. loss per last 100 batches: 1.499614
18300it [1:00:35,  5.67it/s]Epoch: 2: Step: 18301/28124, loss=1.351716, lr=0.000013
18399it [1:00:52,  5.72it/s]Train batch 18400
Avg. loss per last 100 batches: 1.466007
18400it [1:00:52,  5.72it/s]Epoch: 2: Step: 18401/28124, loss=1.698910, lr=0.000012
18499it [1:01:10,  5.74it/s]Train batch 18500
Avg. loss per last 100 batches: 1.485594
18500it [1:01:10,  5.73it/s]Epoch: 2: Step: 18501/28124, loss=1.162425, lr=0.000012
18599it [1:01:27,  5.73it/s]Train batch 18600
Avg. loss per last 100 batches: 1.504900
18600it [1:01:27,  5.72it/s]Epoch: 2: Step: 18601/28124, loss=1.486224, lr=0.000012
18699it [1:01:45,  5.72it/s]Train batch 18700
Avg. loss per last 100 batches: 1.488516
18700it [1:01:45,  5.58it/s]Epoch: 2: Step: 18701/28124, loss=1.488214, lr=0.000012
18799it [1:02:02,  5.73it/s]Train batch 18800
Avg. loss per last 100 batches: 1.552046
18800it [1:02:03,  5.72it/s]Epoch: 2: Step: 18801/28124, loss=0.938936, lr=0.000012
18899it [1:02:20,  5.73it/s]Train batch 18900
Avg. loss per last 100 batches: 1.432416
18900it [1:02:20,  5.73it/s]Epoch: 2: Step: 18901/28124, loss=1.941010, lr=0.000012
18999it [1:02:37,  5.73it/s]Train batch 19000
Avg. loss per last 100 batches: 1.515441
19000it [1:02:38,  5.70it/s]Epoch: 2: Step: 19001/28124, loss=1.019225, lr=0.000012
19099it [1:02:55,  5.72it/s]Train batch 19100
Avg. loss per last 100 batches: 1.497092
19100it [1:02:55,  5.70it/s]Epoch: 2: Step: 19101/28124, loss=1.348617, lr=0.000012
19199it [1:03:12,  5.67it/s]Train batch 19200
Avg. loss per last 100 batches: 1.559100
19200it [1:03:13,  5.68it/s]Epoch: 2: Step: 19201/28124, loss=1.375977, lr=0.000012
19299it [1:03:30,  5.74it/s]Train batch 19300
Avg. loss per last 100 batches: 1.488723
19300it [1:03:30,  5.73it/s]Epoch: 2: Step: 19301/28124, loss=1.653310, lr=0.000012
19399it [1:03:48,  5.73it/s]Train batch 19400
Avg. loss per last 100 batches: 1.519878
19400it [1:03:48,  5.74it/s]Epoch: 2: Step: 19401/28124, loss=1.926540, lr=0.000012
19499it [1:04:05,  5.73it/s]Train batch 19500
Avg. loss per last 100 batches: 1.519751
19500it [1:04:05,  5.73it/s]Epoch: 2: Step: 19501/28124, loss=1.828813, lr=0.000012
19599it [1:04:23,  5.75it/s]Train batch 19600
Avg. loss per last 100 batches: 1.474441
19600it [1:04:23,  5.72it/s]Epoch: 2: Step: 19601/28124, loss=1.356354, lr=0.000012
19699it [1:04:40,  5.73it/s]Train batch 19700
Avg. loss per last 100 batches: 1.495242
19700it [1:04:40,  5.74it/s]Epoch: 2: Step: 19701/28124, loss=1.345090, lr=0.000012
19799it [1:04:58,  5.69it/s]Train batch 19800
Avg. loss per last 100 batches: 1.511012
19800it [1:04:58,  5.69it/s]Epoch: 2: Step: 19801/28124, loss=1.316756, lr=0.000012
19899it [1:05:15,  5.70it/s]Train batch 19900
Avg. loss per last 100 batches: 1.480842
19900it [1:05:15,  5.69it/s]Epoch: 2: Step: 19901/28124, loss=1.213833, lr=0.000012
19999it [1:05:33,  5.73it/s]Train batch 20000
Avg. loss per last 100 batches: 1.527451
20000it [1:05:33,  5.74it/s]Epoch: 2: Step: 20001/28124, loss=1.896874, lr=0.000012
20099it [1:05:50,  5.73it/s]Train batch 20100
Avg. loss per last 100 batches: 1.459836
20100it [1:05:51,  5.73it/s]Epoch: 2: Step: 20101/28124, loss=1.256930, lr=0.000012
20199it [1:06:08,  5.74it/s]Train batch 20200
Avg. loss per last 100 batches: 1.514668
20200it [1:06:08,  5.72it/s]Epoch: 2: Step: 20201/28124, loss=2.476801, lr=0.000012
20299it [1:06:26,  5.71it/s]Train batch 20300
Avg. loss per last 100 batches: 1.518155
20300it [1:06:26,  5.70it/s]Epoch: 2: Step: 20301/28124, loss=0.870785, lr=0.000012
20399it [1:06:43,  5.68it/s]Train batch 20400
Avg. loss per last 100 batches: 1.476210
20400it [1:06:43,  5.67it/s]Epoch: 2: Step: 20401/28124, loss=1.146372, lr=0.000012
20499it [1:07:01,  5.69it/s]Train batch 20500
Avg. loss per last 100 batches: 1.507720
20500it [1:07:01,  5.68it/s]Epoch: 2: Step: 20501/28124, loss=2.059189, lr=0.000012
20599it [1:07:18,  5.71it/s]Train batch 20600
Avg. loss per last 100 batches: 1.517334
20600it [1:07:19,  5.71it/s]Epoch: 2: Step: 20601/28124, loss=1.492695, lr=0.000012
20699it [1:07:36,  5.58it/s]Train batch 20700
Avg. loss per last 100 batches: 1.478830
20700it [1:07:36,  5.61it/s]Epoch: 2: Step: 20701/28124, loss=1.693366, lr=0.000012
20799it [1:07:54,  5.69it/s]Train batch 20800
Avg. loss per last 100 batches: 1.494320
20800it [1:07:54,  5.60it/s]Epoch: 2: Step: 20801/28124, loss=1.745803, lr=0.000012
20899it [1:08:11,  5.72it/s]Train batch 20900
Avg. loss per last 100 batches: 1.530868
20900it [1:08:11,  5.72it/s]Epoch: 2: Step: 20901/28124, loss=1.343129, lr=0.000012
20999it [1:08:29,  5.72it/s]Train batch 21000
Avg. loss per last 100 batches: 1.514915
21000it [1:08:29,  5.72it/s]Epoch: 2: Step: 21001/28124, loss=1.682141, lr=0.000012
21099it [1:08:46,  5.71it/s]Train batch 21100
Avg. loss per last 100 batches: 1.511607
21100it [1:08:47,  5.71it/s]Epoch: 2: Step: 21101/28124, loss=1.785093, lr=0.000012
21199it [1:09:04,  5.70it/s]Train batch 21200
Avg. loss per last 100 batches: 1.557432
21200it [1:09:04,  5.71it/s]Epoch: 2: Step: 21201/28124, loss=0.777102, lr=0.000012
21299it [1:09:22,  5.71it/s]Train batch 21300
Avg. loss per last 100 batches: 1.506583
21300it [1:09:22,  5.71it/s]Epoch: 2: Step: 21301/28124, loss=1.911884, lr=0.000012
21399it [1:09:39,  5.72it/s]Train batch 21400
Avg. loss per last 100 batches: 1.489087
21400it [1:09:39,  5.68it/s]Epoch: 2: Step: 21401/28124, loss=1.575208, lr=0.000012
21499it [1:09:57,  5.72it/s]Train batch 21500
Avg. loss per last 100 batches: 1.522924
21500it [1:09:57,  5.73it/s]Epoch: 2: Step: 21501/28124, loss=1.877681, lr=0.000012
21599it [1:10:14,  5.48it/s]Train batch 21600
Avg. loss per last 100 batches: 1.507025
21600it [1:10:15,  5.55it/s]Epoch: 2: Step: 21601/28124, loss=1.493578, lr=0.000012
21699it [1:10:32,  5.73it/s]Train batch 21700
Avg. loss per last 100 batches: 1.503775
21700it [1:10:32,  5.71it/s]Epoch: 2: Step: 21701/28124, loss=1.801445, lr=0.000012
21799it [1:10:50,  5.72it/s]Train batch 21800
Avg. loss per last 100 batches: 1.514760
21800it [1:10:50,  5.71it/s]Epoch: 2: Step: 21801/28124, loss=1.942258, lr=0.000012
21899it [1:11:07,  5.73it/s]Train batch 21900
Avg. loss per last 100 batches: 1.534440
21900it [1:11:07,  5.73it/s]Epoch: 2: Step: 21901/28124, loss=1.420278, lr=0.000012
21999it [1:11:25,  5.68it/s]Train batch 22000
Avg. loss per last 100 batches: 1.447096
22000it [1:11:25,  5.66it/s]Epoch: 2: Step: 22001/28124, loss=2.185648, lr=0.000012
22099it [1:11:42,  5.74it/s]Train batch 22100
Avg. loss per last 100 batches: 1.501526
22100it [1:11:42,  5.75it/s]Epoch: 2: Step: 22101/28124, loss=1.351406, lr=0.000012
22199it [1:12:00,  5.75it/s]Train batch 22200
Avg. loss per last 100 batches: 1.511068
22200it [1:12:00,  5.73it/s]Epoch: 2: Step: 22201/28124, loss=1.699876, lr=0.000012
22299it [1:12:17,  5.74it/s]Train batch 22300
Avg. loss per last 100 batches: 1.493553
22300it [1:12:17,  5.74it/s]Epoch: 2: Step: 22301/28124, loss=1.601536, lr=0.000012
22399it [1:12:35,  5.74it/s]Train batch 22400
Avg. loss per last 100 batches: 1.499115
22400it [1:12:35,  5.74it/s]Epoch: 2: Step: 22401/28124, loss=1.817460, lr=0.000012
22499it [1:12:52,  5.43it/s]Train batch 22500
Avg. loss per last 100 batches: 1.530120
Validation: Epoch: 2 Step: 22500/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.350807 sec., loss=1.146096 
Eval step: 199 , used_time=8.628231 sec., loss=0.959847 
Eval step: 299 , used_time=12.947583 sec., loss=0.861076 
Eval step: 399 , used_time=17.230418 sec., loss=1.328294 
Eval step: 499 , used_time=21.540439 sec., loss=1.300874 
Eval step: 599 , used_time=25.831927 sec., loss=1.501939 
Eval step: 699 , used_time=30.143997 sec., loss=1.535757 
Eval step: 799 , used_time=34.659204 sec., loss=1.201685 
Eval step: 899 , used_time=38.943412 sec., loss=0.914518 
Eval step: 999 , used_time=43.259239 sec., loss=1.160124 
Eval step: 1099 , used_time=47.543950 sec., loss=1.049696 
Eval step: 1199 , used_time=51.845676 sec., loss=1.305209 
Eval step: 1299 , used_time=56.129706 sec., loss=0.935124 
Eval step: 1399 , used_time=60.430019 sec., loss=0.672684 
Eval step: 1499 , used_time=64.964659 sec., loss=0.662124 
Eval step: 1599 , used_time=69.242208 sec., loss=1.081901 
Eval step: 1699 , used_time=73.559630 sec., loss=0.951874 
Eval step: 1799 , used_time=77.834809 sec., loss=0.745962 
Eval step: 1899 , used_time=82.147541 sec., loss=0.779447 
Eval step: 1999 , used_time=86.469537 sec., loss=1.493083 
Eval step: 2099 , used_time=90.752846 sec., loss=0.798565 
Eval step: 2199 , used_time=95.278216 sec., loss=0.857423 
Eval step: 2299 , used_time=99.560515 sec., loss=0.499476 
Eval step: 2399 , used_time=103.873997 sec., loss=1.542481 
Eval step: 2499 , used_time=108.152375 sec., loss=0.949210 
Eval step: 2599 , used_time=112.483464 sec., loss=1.305349 
Eval step: 2699 , used_time=116.779016 sec., loss=1.234758 
Eval step: 2799 , used_time=121.119659 sec., loss=1.229509 
Eval step: 2899 , used_time=125.427493 sec., loss=0.998890 
Eval step: 2999 , used_time=129.891147 sec., loss=0.785171 
Eval step: 3099 , used_time=134.207482 sec., loss=1.146683 
NLL Validation: loss = 1.079098. correct prediction ratio  69338/100032 ~  0.693158
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
22500it [1:15:13, 42.40s/it]Epoch: 2: Step: 22501/28124, loss=1.288747, lr=0.000012
22599it [1:15:31,  5.46it/s]Train batch 22600
Avg. loss per last 100 batches: 1.485959
22600it [1:15:31,  5.39it/s]Epoch: 2: Step: 22601/28124, loss=1.054050, lr=0.000012
22699it [1:15:48,  5.72it/s]Train batch 22700
Avg. loss per last 100 batches: 1.442732
22700it [1:15:48,  5.72it/s]Epoch: 2: Step: 22701/28124, loss=0.948499, lr=0.000012
22799it [1:16:06,  5.74it/s]Train batch 22800
Avg. loss per last 100 batches: 1.492245
22800it [1:16:06,  5.72it/s]Epoch: 2: Step: 22801/28124, loss=1.291457, lr=0.000012
22899it [1:16:23,  5.73it/s]Train batch 22900
Avg. loss per last 100 batches: 1.499119
22900it [1:16:23,  5.71it/s]Epoch: 2: Step: 22901/28124, loss=1.346691, lr=0.000012
22999it [1:16:41,  5.75it/s]Train batch 23000
Avg. loss per last 100 batches: 1.514350
23000it [1:16:41,  5.74it/s]Epoch: 2: Step: 23001/28124, loss=1.550812, lr=0.000012
23099it [1:16:58,  5.75it/s]Train batch 23100
Avg. loss per last 100 batches: 1.459054
23100it [1:16:58,  5.75it/s]Epoch: 2: Step: 23101/28124, loss=1.546956, lr=0.000012
23199it [1:17:16,  5.73it/s]Train batch 23200
Avg. loss per last 100 batches: 1.437051
23200it [1:17:16,  5.74it/s]Epoch: 2: Step: 23201/28124, loss=2.264768, lr=0.000012
23299it [1:17:33,  5.70it/s]Train batch 23300
Avg. loss per last 100 batches: 1.483669
23300it [1:17:33,  5.69it/s]Epoch: 2: Step: 23301/28124, loss=1.917597, lr=0.000012
23399it [1:17:51,  5.71it/s]Train batch 23400
Avg. loss per last 100 batches: 1.452407
23400it [1:17:51,  5.72it/s]Epoch: 2: Step: 23401/28124, loss=1.180432, lr=0.000012
23499it [1:18:08,  5.75it/s]Train batch 23500
Avg. loss per last 100 batches: 1.485641
23500it [1:18:09,  5.75it/s]Epoch: 2: Step: 23501/28124, loss=1.651601, lr=0.000012
23599it [1:18:26,  5.75it/s]Train batch 23600
Avg. loss per last 100 batches: 1.523772
23600it [1:18:26,  5.74it/s]Epoch: 2: Step: 23601/28124, loss=0.930892, lr=0.000012
23699it [1:18:43,  5.73it/s]Train batch 23700
Avg. loss per last 100 batches: 1.488491
23700it [1:18:44,  5.71it/s]Epoch: 2: Step: 23701/28124, loss=1.480266, lr=0.000012
23799it [1:19:01,  5.75it/s]Train batch 23800
Avg. loss per last 100 batches: 1.467282
23800it [1:19:01,  5.73it/s]Epoch: 2: Step: 23801/28124, loss=1.094474, lr=0.000012
23899it [1:19:18,  5.69it/s]Train batch 23900
Avg. loss per last 100 batches: 1.447621
23900it [1:19:19,  5.70it/s]Epoch: 2: Step: 23901/28124, loss=1.730353, lr=0.000012
23999it [1:19:36,  5.73it/s]Train batch 24000
Avg. loss per last 100 batches: 1.517627
24000it [1:19:36,  5.73it/s]Epoch: 2: Step: 24001/28124, loss=1.999497, lr=0.000012
24099it [1:19:53,  5.75it/s]Train batch 24100
Avg. loss per last 100 batches: 1.504118
24100it [1:19:54,  5.73it/s]Epoch: 2: Step: 24101/28124, loss=1.139886, lr=0.000012
24199it [1:20:11,  5.75it/s]Train batch 24200
Avg. loss per last 100 batches: 1.500787
24200it [1:20:11,  5.72it/s]Epoch: 2: Step: 24201/28124, loss=1.569991, lr=0.000012
24299it [1:20:29,  5.75it/s]Train batch 24300
Avg. loss per last 100 batches: 1.491181
24300it [1:20:29,  5.73it/s]Epoch: 2: Step: 24301/28124, loss=1.571600, lr=0.000012
24399it [1:20:46,  5.74it/s]Train batch 24400
Avg. loss per last 100 batches: 1.446285
24400it [1:20:46,  5.74it/s]Epoch: 2: Step: 24401/28124, loss=1.769665, lr=0.000012
24499it [1:21:04,  5.67it/s]Train batch 24500
Avg. loss per last 100 batches: 1.523537
24500it [1:21:04,  5.69it/s]Epoch: 2: Step: 24501/28124, loss=1.366658, lr=0.000012
24599it [1:21:21,  5.56it/s]Train batch 24600
Avg. loss per last 100 batches: 1.457908
24600it [1:21:21,  5.61it/s]Epoch: 2: Step: 24601/28124, loss=1.896576, lr=0.000012
24699it [1:21:39,  5.72it/s]Train batch 24700
Avg. loss per last 100 batches: 1.478970
24700it [1:21:39,  5.72it/s]Epoch: 2: Step: 24701/28124, loss=1.210272, lr=0.000012
24799it [1:21:56,  5.72it/s]Train batch 24800
Avg. loss per last 100 batches: 1.429329
24800it [1:21:56,  5.70it/s]Epoch: 2: Step: 24801/28124, loss=1.243459, lr=0.000012
24899it [1:22:14,  5.57it/s]Train batch 24900
Avg. loss per last 100 batches: 1.452303
24900it [1:22:14,  5.59it/s]Epoch: 2: Step: 24901/28124, loss=1.382824, lr=0.000012
24999it [1:22:32,  5.70it/s]Train batch 25000
Avg. loss per last 100 batches: 1.500706
25000it [1:22:32,  5.70it/s]Epoch: 2: Step: 25001/28124, loss=2.038506, lr=0.000012
25099it [1:22:49,  5.72it/s]Train batch 25100
Avg. loss per last 100 batches: 1.454647
25100it [1:22:49,  5.70it/s]Epoch: 2: Step: 25101/28124, loss=1.464546, lr=0.000012
25199it [1:23:07,  5.71it/s]Train batch 25200
Avg. loss per last 100 batches: 1.474401
25200it [1:23:07,  5.70it/s]Epoch: 2: Step: 25201/28124, loss=1.420639, lr=0.000012
25299it [1:23:24,  5.68it/s]Train batch 25300
Avg. loss per last 100 batches: 1.533434
25300it [1:23:24,  5.68it/s]Epoch: 2: Step: 25301/28124, loss=1.449353, lr=0.000012
25399it [1:23:42,  5.72it/s]Train batch 25400
Avg. loss per last 100 batches: 1.463702
25400it [1:23:42,  5.73it/s]Epoch: 2: Step: 25401/28124, loss=1.285189, lr=0.000012
25499it [1:23:59,  5.43it/s]Train batch 25500
Avg. loss per last 100 batches: 1.517810
25500it [1:24:00,  5.51it/s]Epoch: 2: Step: 25501/28124, loss=1.789276, lr=0.000012
25599it [1:24:17,  5.73it/s]Train batch 25600
Avg. loss per last 100 batches: 1.474087
25600it [1:24:17,  5.74it/s]Epoch: 2: Step: 25601/28124, loss=1.240882, lr=0.000012
25699it [1:24:34,  5.70it/s]Train batch 25700
Avg. loss per last 100 batches: 1.534302
25700it [1:24:35,  5.72it/s]Epoch: 2: Step: 25701/28124, loss=1.737247, lr=0.000012
25799it [1:24:52,  5.74it/s]Train batch 25800
Avg. loss per last 100 batches: 1.490770
25800it [1:24:52,  5.74it/s]Epoch: 2: Step: 25801/28124, loss=1.427260, lr=0.000012
25899it [1:25:09,  5.69it/s]Train batch 25900
Avg. loss per last 100 batches: 1.519604
25900it [1:25:10,  5.68it/s]Epoch: 2: Step: 25901/28124, loss=1.505776, lr=0.000012
25999it [1:25:27,  5.72it/s]Train batch 26000
Avg. loss per last 100 batches: 1.423877
26000it [1:25:27,  5.73it/s]Epoch: 2: Step: 26001/28124, loss=1.099384, lr=0.000012
26099it [1:25:45,  5.65it/s]Train batch 26100
Avg. loss per last 100 batches: 1.522849
26100it [1:25:45,  5.68it/s]Epoch: 2: Step: 26101/28124, loss=1.407476, lr=0.000012
26199it [1:26:02,  5.76it/s]Train batch 26200
Avg. loss per last 100 batches: 1.484875
26200it [1:26:02,  5.74it/s]Epoch: 2: Step: 26201/28124, loss=1.508111, lr=0.000012
26299it [1:26:20,  5.75it/s]Train batch 26300
Avg. loss per last 100 batches: 1.426939
26300it [1:26:20,  5.74it/s]Epoch: 2: Step: 26301/28124, loss=1.279278, lr=0.000012
26399it [1:26:37,  5.61it/s]Train batch 26400
Avg. loss per last 100 batches: 1.415621
26400it [1:26:37,  5.53it/s]Epoch: 2: Step: 26401/28124, loss=1.282290, lr=0.000012
26499it [1:26:55,  5.66it/s]Train batch 26500
Avg. loss per last 100 batches: 1.589780
26500it [1:26:55,  5.69it/s]Epoch: 2: Step: 26501/28124, loss=1.201588, lr=0.000012
26599it [1:27:12,  5.74it/s]Train batch 26600
Avg. loss per last 100 batches: 1.515230
26600it [1:27:12,  5.70it/s]Epoch: 2: Step: 26601/28124, loss=1.516557, lr=0.000012
26699it [1:27:30,  5.74it/s]Train batch 26700
Avg. loss per last 100 batches: 1.497252
26700it [1:27:30,  5.72it/s]Epoch: 2: Step: 26701/28124, loss=1.668896, lr=0.000012
26799it [1:27:47,  5.73it/s]Train batch 26800
Avg. loss per last 100 batches: 1.471998
26800it [1:27:47,  5.74it/s]Epoch: 2: Step: 26801/28124, loss=1.432914, lr=0.000012
26899it [1:28:05,  5.66it/s]Train batch 26900
Avg. loss per last 100 batches: 1.475748
26900it [1:28:05,  5.69it/s]Epoch: 2: Step: 26901/28124, loss=1.348413, lr=0.000012
26999it [1:28:22,  5.76it/s]Train batch 27000
Avg. loss per last 100 batches: 1.451691
27000it [1:28:22,  5.74it/s]Epoch: 2: Step: 27001/28124, loss=1.332401, lr=0.000012
27099it [1:28:40,  5.73it/s]Train batch 27100
Avg. loss per last 100 batches: 1.472607
27100it [1:28:40,  5.73it/s]Epoch: 2: Step: 27101/28124, loss=1.736730, lr=0.000012
27199it [1:28:57,  5.74it/s]Train batch 27200
Avg. loss per last 100 batches: 1.446859
27200it [1:28:57,  5.72it/s]Epoch: 2: Step: 27201/28124, loss=1.434841, lr=0.000012
27299it [1:29:15,  5.71it/s]Train batch 27300
Avg. loss per last 100 batches: 1.405722
27300it [1:29:15,  5.71it/s]Epoch: 2: Step: 27301/28124, loss=1.800307, lr=0.000012
27399it [1:29:32,  5.73it/s]Train batch 27400
Avg. loss per last 100 batches: 1.520579
27400it [1:29:33,  5.73it/s]Epoch: 2: Step: 27401/28124, loss=1.364153, lr=0.000012
27499it [1:29:50,  5.71it/s]Train batch 27500
Avg. loss per last 100 batches: 1.453646
27500it [1:29:50,  5.71it/s]Epoch: 2: Step: 27501/28124, loss=1.868569, lr=0.000012
27599it [1:30:07,  5.74it/s]Train batch 27600
Avg. loss per last 100 batches: 1.499385
27600it [1:30:08,  5.73it/s]Epoch: 2: Step: 27601/28124, loss=1.625161, lr=0.000012
27699it [1:30:25,  5.72it/s]Train batch 27700
Avg. loss per last 100 batches: 1.525025
27700it [1:30:25,  5.70it/s]Epoch: 2: Step: 27701/28124, loss=1.944091, lr=0.000012
27799it [1:30:42,  5.74it/s]Train batch 27800
Avg. loss per last 100 batches: 1.469325
27800it [1:30:43,  5.74it/s]Epoch: 2: Step: 27801/28124, loss=1.413247, lr=0.000012
27899it [1:31:00,  5.72it/s]Train batch 27900
Avg. loss per last 100 batches: 1.471573
27900it [1:31:00,  5.72it/s]Epoch: 2: Step: 27901/28124, loss=1.401681, lr=0.000012
27999it [1:31:18,  5.73it/s]Train batch 28000
Avg. loss per last 100 batches: 1.448580
28000it [1:31:18,  5.73it/s]Epoch: 2: Step: 28001/28124, loss=1.735698, lr=0.000012
28099it [1:31:35,  5.68it/s]Train batch 28100
Avg. loss per last 100 batches: 1.448385
28100it [1:31:35,  5.70it/s]Epoch: 2: Step: 28101/28124, loss=1.242972, lr=0.000012
28124it [1:31:40,  5.11it/s]
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.362400 sec., loss=1.029658 
Eval step: 199 , used_time=8.684395 sec., loss=1.252783 
Eval step: 299 , used_time=12.985708 sec., loss=0.843497 
Eval step: 399 , used_time=17.540984 sec., loss=1.465103 
Eval step: 499 , used_time=21.845322 sec., loss=1.276386 
Eval step: 599 , used_time=26.193364 sec., loss=1.696958 
Eval step: 699 , used_time=30.502567 sec., loss=1.592003 
Eval step: 799 , used_time=34.839676 sec., loss=1.173145 
Eval step: 899 , used_time=39.169013 sec., loss=0.997067 
Eval step: 999 , used_time=43.523602 sec., loss=1.171800 
Eval step: 1099 , used_time=48.088158 sec., loss=1.031222 
Eval step: 1199 , used_time=52.442120 sec., loss=1.199533 
Eval step: 1299 , used_time=56.787593 sec., loss=0.943645 
Eval step: 1399 , used_time=61.129195 sec., loss=0.586000 
Eval step: 1499 , used_time=65.514462 sec., loss=0.696859 
Eval step: 1599 , used_time=69.862805 sec., loss=1.165762 
Eval step: 1699 , used_time=74.208869 sec., loss=0.920817 
Eval step: 1799 , used_time=78.659614 sec., loss=0.845891 
Eval step: 1899 , used_time=83.018520 sec., loss=0.705712 
Eval step: 1999 , used_time=87.345578 sec., loss=1.553892 
Eval step: 2099 , used_time=91.681383 sec., loss=0.675099 
Eval step: 2199 , used_time=96.047156 sec., loss=1.026531 
Eval step: 2299 , used_time=100.376137 sec., loss=0.391486 
Eval step: 2399 , used_time=104.770890 sec., loss=1.382366 
Eval step: 2499 , used_time=109.090057 sec., loss=0.977934 
Eval step: 2599 , used_time=113.609174 sec., loss=1.056325 
Eval step: 2699 , used_time=117.954245 sec., loss=1.313444 
Eval step: 2799 , used_time=122.275634 sec., loss=1.271536 
Eval step: 2899 , used_time=126.674354 sec., loss=0.888509 
Eval step: 2999 , used_time=130.984415 sec., loss=0.806511 
Eval step: 3099 , used_time=135.346742 sec., loss=1.070790 
NLL Validation: loss = 1.060738. correct prediction ratio  70046/100032 ~  0.700236
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=1.529499
epoch total correct predictions=526324
***** Epoch 3 *****
0it [00:00, ?it/s]Epoch: 3: Step: 1/28124, loss=1.241439, lr=0.000012
99it [00:18,  5.72it/s]Train batch 100
Avg. loss per last 100 batches: 1.247273
100it [00:19,  5.70it/s]Epoch: 3: Step: 101/28124, loss=1.174800, lr=0.000011
199it [00:36,  5.71it/s]Train batch 200
Avg. loss per last 100 batches: 1.274770
200it [00:36,  5.72it/s]Epoch: 3: Step: 201/28124, loss=0.893584, lr=0.000011
299it [00:54,  5.69it/s]Train batch 300
Avg. loss per last 100 batches: 1.252899
300it [00:54,  5.69it/s]Epoch: 3: Step: 301/28124, loss=1.215187, lr=0.000011
399it [01:11,  5.69it/s]Train batch 400
Avg. loss per last 100 batches: 1.261215
400it [01:11,  5.70it/s]Epoch: 3: Step: 401/28124, loss=1.109816, lr=0.000011
499it [01:29,  5.69it/s]Train batch 500
Avg. loss per last 100 batches: 1.274119
500it [01:29,  5.68it/s]Epoch: 3: Step: 501/28124, loss=1.486594, lr=0.000011
599it [01:47,  5.69it/s]Train batch 600
Avg. loss per last 100 batches: 1.318447
600it [01:47,  5.68it/s]Epoch: 3: Step: 601/28124, loss=1.105927, lr=0.000011
699it [02:04,  5.69it/s]Train batch 700
Avg. loss per last 100 batches: 1.284931
700it [02:04,  5.69it/s]Epoch: 3: Step: 701/28124, loss=1.218314, lr=0.000011
799it [02:22,  5.69it/s]Train batch 800
Avg. loss per last 100 batches: 1.273545
800it [02:22,  5.63it/s]Epoch: 3: Step: 801/28124, loss=1.585452, lr=0.000011
899it [02:40,  5.38it/s]Train batch 900
Avg. loss per last 100 batches: 1.232602
900it [02:40,  5.36it/s]Epoch: 3: Step: 901/28124, loss=1.389481, lr=0.000011
999it [02:57,  5.70it/s]Train batch 1000
Avg. loss per last 100 batches: 1.311140
1000it [02:57,  5.72it/s]Epoch: 3: Step: 1001/28124, loss=1.100306, lr=0.000011
1099it [03:15,  5.72it/s]Train batch 1100
Avg. loss per last 100 batches: 1.259387
1100it [03:15,  5.73it/s]Epoch: 3: Step: 1101/28124, loss=1.231869, lr=0.000011
1199it [03:32,  5.60it/s]Train batch 1200
Avg. loss per last 100 batches: 1.288797
1200it [03:33,  5.63it/s]Epoch: 3: Step: 1201/28124, loss=1.028008, lr=0.000011
1299it [03:50,  5.67it/s]Train batch 1300
Avg. loss per last 100 batches: 1.259124
1300it [03:50,  5.67it/s]Epoch: 3: Step: 1301/28124, loss=1.065467, lr=0.000011
1399it [04:07,  5.73it/s]Train batch 1400
Avg. loss per last 100 batches: 1.254185
1400it [04:08,  5.72it/s]Epoch: 3: Step: 1401/28124, loss=1.123031, lr=0.000011
1499it [04:25,  5.68it/s]Train batch 1500
Avg. loss per last 100 batches: 1.326778
1500it [04:25,  5.69it/s]Epoch: 3: Step: 1501/28124, loss=1.093426, lr=0.000011
1599it [04:43,  5.66it/s]Train batch 1600
Avg. loss per last 100 batches: 1.307493
1600it [04:43,  5.66it/s]Epoch: 3: Step: 1601/28124, loss=1.293537, lr=0.000011
1699it [05:00,  5.72it/s]Train batch 1700
Avg. loss per last 100 batches: 1.336200
1700it [05:00,  5.73it/s]Epoch: 3: Step: 1701/28124, loss=0.994322, lr=0.000011
1799it [05:18,  5.37it/s]Train batch 1800
Avg. loss per last 100 batches: 1.281541
1800it [05:18,  5.35it/s]Epoch: 3: Step: 1801/28124, loss=1.091003, lr=0.000011
1899it [05:35,  5.71it/s]Train batch 1900
Avg. loss per last 100 batches: 1.342183
1900it [05:35,  5.70it/s]Epoch: 3: Step: 1901/28124, loss=1.081703, lr=0.000011
1999it [05:53,  5.70it/s]Train batch 2000
Avg. loss per last 100 batches: 1.296619
2000it [05:53,  5.70it/s]Epoch: 3: Step: 2001/28124, loss=1.168581, lr=0.000011
2099it [06:10,  5.74it/s]Train batch 2100
Avg. loss per last 100 batches: 1.325601
2100it [06:11,  5.75it/s]Epoch: 3: Step: 2101/28124, loss=1.280835, lr=0.000011
2199it [06:28,  5.72it/s]Train batch 2200
Avg. loss per last 100 batches: 1.314622
2200it [06:28,  5.71it/s]Epoch: 3: Step: 2201/28124, loss=1.661164, lr=0.000011
2299it [06:46,  5.74it/s]Train batch 2300
Avg. loss per last 100 batches: 1.340441
2300it [06:46,  5.74it/s]Epoch: 3: Step: 2301/28124, loss=1.317658, lr=0.000011
2399it [07:03,  5.67it/s]Train batch 2400
Avg. loss per last 100 batches: 1.325687
2400it [07:03,  5.66it/s]Epoch: 3: Step: 2401/28124, loss=1.373710, lr=0.000011
2499it [07:21,  5.68it/s]Train batch 2500
Avg. loss per last 100 batches: 1.243787
2500it [07:21,  5.69it/s]Epoch: 3: Step: 2501/28124, loss=1.761029, lr=0.000011
2599it [07:38,  5.73it/s]Train batch 2600
Avg. loss per last 100 batches: 1.248058
2600it [07:39,  5.73it/s]Epoch: 3: Step: 2601/28124, loss=1.228041, lr=0.000011
2699it [07:56,  5.57it/s]Train batch 2700
Avg. loss per last 100 batches: 1.337709
2700it [07:56,  5.36it/s]Epoch: 3: Step: 2701/28124, loss=1.071188, lr=0.000011
2799it [08:14,  5.73it/s]Train batch 2800
Avg. loss per last 100 batches: 1.289056
2800it [08:14,  5.74it/s]Epoch: 3: Step: 2801/28124, loss=1.397535, lr=0.000011
2899it [08:31,  5.75it/s]Train batch 2900
Avg. loss per last 100 batches: 1.239604
2900it [08:31,  5.73it/s]Epoch: 3: Step: 2901/28124, loss=0.926250, lr=0.000011
2999it [08:49,  5.73it/s]Train batch 3000
Avg. loss per last 100 batches: 1.307073
3000it [08:49,  5.74it/s]Epoch: 3: Step: 3001/28124, loss=0.884366, lr=0.000011
3099it [09:06,  5.73it/s]Train batch 3100
Avg. loss per last 100 batches: 1.310343
3100it [09:06,  5.73it/s]Epoch: 3: Step: 3101/28124, loss=1.852794, lr=0.000011
3199it [09:24,  5.74it/s]Train batch 3200
Avg. loss per last 100 batches: 1.284647
3200it [09:24,  5.71it/s]Epoch: 3: Step: 3201/28124, loss=1.603675, lr=0.000011
3299it [09:41,  5.73it/s]Train batch 3300
Avg. loss per last 100 batches: 1.271453
3300it [09:42,  5.73it/s]Epoch: 3: Step: 3301/28124, loss=1.360408, lr=0.000011
3399it [09:59,  5.74it/s]Train batch 3400
Avg. loss per last 100 batches: 1.353055
3400it [09:59,  5.72it/s]Epoch: 3: Step: 3401/28124, loss=1.212551, lr=0.000011
3499it [10:16,  5.71it/s]Train batch 3500
Avg. loss per last 100 batches: 1.310907
3500it [10:17,  5.72it/s]Epoch: 3: Step: 3501/28124, loss=0.975071, lr=0.000011
3599it [10:34,  5.73it/s]Train batch 3600
Avg. loss per last 100 batches: 1.263867
3600it [10:34,  5.73it/s]Epoch: 3: Step: 3601/28124, loss=1.638428, lr=0.000011
3699it [10:52,  5.73it/s]Train batch 3700
Avg. loss per last 100 batches: 1.322698
3700it [10:52,  5.72it/s]Epoch: 3: Step: 3701/28124, loss=1.298504, lr=0.000011
3799it [11:09,  5.67it/s]Train batch 3800
Avg. loss per last 100 batches: 1.329743
3800it [11:09,  5.69it/s]Epoch: 3: Step: 3801/28124, loss=1.711559, lr=0.000011
3899it [11:27,  5.74it/s]Train batch 3900
Avg. loss per last 100 batches: 1.266845
3900it [11:27,  5.68it/s]Epoch: 3: Step: 3901/28124, loss=1.414187, lr=0.000011
3999it [11:44,  5.73it/s]Train batch 4000
Avg. loss per last 100 batches: 1.303817
4000it [11:44,  5.72it/s]Epoch: 3: Step: 4001/28124, loss=1.136166, lr=0.000011
4099it [12:02,  5.73it/s]Train batch 4100
Avg. loss per last 100 batches: 1.345325
4100it [12:02,  5.74it/s]Epoch: 3: Step: 4101/28124, loss=1.716413, lr=0.000011
4199it [12:19,  5.75it/s]Train batch 4200
Avg. loss per last 100 batches: 1.294372
4200it [12:19,  5.75it/s]Epoch: 3: Step: 4201/28124, loss=1.334954, lr=0.000011
4299it [12:37,  5.73it/s]Train batch 4300
Avg. loss per last 100 batches: 1.319747
4300it [12:37,  5.73it/s]Epoch: 3: Step: 4301/28124, loss=1.672844, lr=0.000011
4399it [12:54,  5.69it/s]Train batch 4400
Avg. loss per last 100 batches: 1.312640
4400it [12:55,  5.69it/s]Epoch: 3: Step: 4401/28124, loss=1.236215, lr=0.000011
4499it [13:12,  5.71it/s]Train batch 4500
Avg. loss per last 100 batches: 1.273881
4500it [13:12,  5.72it/s]Epoch: 3: Step: 4501/28124, loss=1.051984, lr=0.000011
4599it [13:29,  5.74it/s]Train batch 4600
Avg. loss per last 100 batches: 1.288861
4600it [13:30,  5.73it/s]Epoch: 3: Step: 4601/28124, loss=1.238466, lr=0.000011
4699it [13:47,  5.52it/s]Train batch 4700
Avg. loss per last 100 batches: 1.293149
4700it [13:47,  5.59it/s]Epoch: 3: Step: 4701/28124, loss=1.342513, lr=0.000011
4799it [14:04,  5.75it/s]Train batch 4800
Avg. loss per last 100 batches: 1.278404
4800it [14:05,  5.72it/s]Epoch: 3: Step: 4801/28124, loss=1.418285, lr=0.000011
4899it [14:22,  5.69it/s]Train batch 4900
Avg. loss per last 100 batches: 1.293616
4900it [14:22,  5.70it/s]Epoch: 3: Step: 4901/28124, loss=1.196479, lr=0.000011
4999it [14:40,  5.72it/s]Train batch 5000
Avg. loss per last 100 batches: 1.323327
5000it [14:40,  5.72it/s]Epoch: 3: Step: 5001/28124, loss=1.623217, lr=0.000011
5099it [14:57,  5.74it/s]Train batch 5100
Avg. loss per last 100 batches: 1.306594
5100it [14:57,  5.73it/s]Epoch: 3: Step: 5101/28124, loss=1.862129, lr=0.000011
5199it [15:15,  5.71it/s]Train batch 5200
Avg. loss per last 100 batches: 1.294106
5200it [15:15,  5.72it/s]Epoch: 3: Step: 5201/28124, loss=1.303168, lr=0.000011
5299it [15:32,  5.43it/s]Train batch 5300
Avg. loss per last 100 batches: 1.306709
5300it [15:33,  5.49it/s]Epoch: 3: Step: 5301/28124, loss=1.357207, lr=0.000011
5399it [15:50,  5.72it/s]Train batch 5400
Avg. loss per last 100 batches: 1.331069
5400it [15:50,  5.72it/s]Epoch: 3: Step: 5401/28124, loss=0.753237, lr=0.000011
5499it [16:08,  5.70it/s]Train batch 5500
Avg. loss per last 100 batches: 1.279138
5500it [16:08,  5.70it/s]Epoch: 3: Step: 5501/28124, loss=1.555592, lr=0.000011
5599it [16:25,  5.36it/s]Train batch 5600
Avg. loss per last 100 batches: 1.307068
5600it [16:25,  5.40it/s]Epoch: 3: Step: 5601/28124, loss=0.985287, lr=0.000011
5624it [16:30,  5.69it/s]Validation: Epoch: 3 Step: 5625/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.311472 sec., loss=1.014597 
Eval step: 199 , used_time=8.636407 sec., loss=1.360887 
Eval step: 299 , used_time=12.944753 sec., loss=0.867425 
Eval step: 399 , used_time=17.276215 sec., loss=1.408825 
Eval step: 499 , used_time=21.758026 sec., loss=1.343457 
Eval step: 599 , used_time=26.092976 sec., loss=1.483974 
Eval step: 699 , used_time=30.426842 sec., loss=1.505238 
Eval step: 799 , used_time=34.720870 sec., loss=1.306983 
Eval step: 899 , used_time=39.041079 sec., loss=0.950915 
Eval step: 999 , used_time=43.336915 sec., loss=1.081551 
Eval step: 1099 , used_time=47.657940 sec., loss=0.921581 
Eval step: 1199 , used_time=51.951708 sec., loss=1.324780 
Eval step: 1299 , used_time=56.444767 sec., loss=0.785307 
Eval step: 1399 , used_time=60.783777 sec., loss=0.591537 
Eval step: 1499 , used_time=65.096585 sec., loss=0.607133 
Eval step: 1599 , used_time=69.418380 sec., loss=0.947757 
Eval step: 1699 , used_time=73.695526 sec., loss=0.875197 
Eval step: 1799 , used_time=78.008658 sec., loss=0.765564 
Eval step: 1899 , used_time=82.292603 sec., loss=0.645307 
Eval step: 1999 , used_time=86.768922 sec., loss=1.684952 
Eval step: 2099 , used_time=91.124290 sec., loss=0.771438 
Eval step: 2199 , used_time=95.420710 sec., loss=0.982042 
Eval step: 2299 , used_time=99.733755 sec., loss=0.468578 
Eval step: 2399 , used_time=104.039173 sec., loss=1.347594 
Eval step: 2499 , used_time=108.365369 sec., loss=1.105956 
Eval step: 2599 , used_time=112.666798 sec., loss=1.105169 
Eval step: 2699 , used_time=117.204962 sec., loss=1.274969 
Eval step: 2799 , used_time=121.512103 sec., loss=1.187711 
Eval step: 2899 , used_time=125.806017 sec., loss=0.975404 
Eval step: 2999 , used_time=130.107666 sec., loss=0.783827 
Eval step: 3099 , used_time=134.386665 sec., loss=0.978787 
NLL Validation: loss = 1.066983. correct prediction ratio  70550/100032 ~  0.705274
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:09,  5.74it/s]Train batch 5700
Avg. loss per last 100 batches: 1.311838
5700it [19:09,  5.73it/s]Epoch: 3: Step: 5701/28124, loss=1.495042, lr=0.000011
5799it [19:26,  5.75it/s]Train batch 5800
Avg. loss per last 100 batches: 1.382152
5800it [19:26,  5.73it/s]Epoch: 3: Step: 5801/28124, loss=1.244440, lr=0.000011
5899it [19:44,  5.71it/s]Train batch 5900
Avg. loss per last 100 batches: 1.305273
5900it [19:44,  5.71it/s]Epoch: 3: Step: 5901/28124, loss=1.418879, lr=0.000011
5999it [20:01,  5.73it/s]Train batch 6000
Avg. loss per last 100 batches: 1.301355
6000it [20:01,  5.74it/s]Epoch: 3: Step: 6001/28124, loss=1.394959, lr=0.000011
6099it [20:19,  5.73it/s]Train batch 6100
Avg. loss per last 100 batches: 1.298372
6100it [20:19,  5.72it/s]Epoch: 3: Step: 6101/28124, loss=1.237779, lr=0.000011
6199it [20:36,  5.66it/s]Train batch 6200
Avg. loss per last 100 batches: 1.338736
6200it [20:37,  5.66it/s]Epoch: 3: Step: 6201/28124, loss=1.129262, lr=0.000011
6299it [20:54,  5.72it/s]Train batch 6300
Avg. loss per last 100 batches: 1.307082
6300it [20:54,  5.73it/s]Epoch: 3: Step: 6301/28124, loss=1.333488, lr=0.000011
6399it [21:12,  5.59it/s]Train batch 6400
Avg. loss per last 100 batches: 1.353639
6400it [21:12,  5.63it/s]Epoch: 3: Step: 6401/28124, loss=1.184986, lr=0.000011
6499it [21:29,  5.74it/s]Train batch 6500
Avg. loss per last 100 batches: 1.351263
6500it [21:29,  5.73it/s]Epoch: 3: Step: 6501/28124, loss=1.146226, lr=0.000011
6599it [21:47,  5.74it/s]Train batch 6600
Avg. loss per last 100 batches: 1.321650
6600it [21:47,  5.72it/s]Epoch: 3: Step: 6601/28124, loss=1.729567, lr=0.000011
6699it [22:04,  5.73it/s]Train batch 6700
Avg. loss per last 100 batches: 1.300288
6700it [22:04,  5.73it/s]Epoch: 3: Step: 6701/28124, loss=1.445023, lr=0.000011
6799it [22:22,  5.71it/s]Train batch 6800
Avg. loss per last 100 batches: 1.273422
6800it [22:22,  5.68it/s]Epoch: 3: Step: 6801/28124, loss=1.151152, lr=0.000011
6899it [22:39,  5.73it/s]Train batch 6900
Avg. loss per last 100 batches: 1.288446
6900it [22:39,  5.74it/s]Epoch: 3: Step: 6901/28124, loss=1.534041, lr=0.000011
6999it [22:57,  5.71it/s]Train batch 7000
Avg. loss per last 100 batches: 1.330400
7000it [22:57,  5.70it/s]Epoch: 3: Step: 7001/28124, loss=1.420831, lr=0.000011
7099it [23:14,  5.73it/s]Train batch 7100
Avg. loss per last 100 batches: 1.300520
7100it [23:15,  5.73it/s]Epoch: 3: Step: 7101/28124, loss=1.032415, lr=0.000011
7199it [23:32,  5.65it/s]Train batch 7200
Avg. loss per last 100 batches: 1.327780
7200it [23:32,  5.67it/s]Epoch: 3: Step: 7201/28124, loss=0.890157, lr=0.000011
7299it [23:50,  5.39it/s]Train batch 7300
Avg. loss per last 100 batches: 1.297041
7300it [23:50,  5.42it/s]Epoch: 3: Step: 7301/28124, loss=1.253302, lr=0.000011
7399it [24:07,  5.75it/s]Train batch 7400
Avg. loss per last 100 batches: 1.321835
7400it [24:07,  5.73it/s]Epoch: 3: Step: 7401/28124, loss=1.015736, lr=0.000011
7499it [24:25,  5.73it/s]Train batch 7500
Avg. loss per last 100 batches: 1.284102
7500it [24:25,  5.74it/s]Epoch: 3: Step: 7501/28124, loss=1.332233, lr=0.000011
7599it [24:42,  5.38it/s]Train batch 7600
Avg. loss per last 100 batches: 1.342518
7600it [24:42,  5.45it/s]Epoch: 3: Step: 7601/28124, loss=1.447853, lr=0.000011
7699it [25:00,  5.72it/s]Train batch 7700
Avg. loss per last 100 batches: 1.296454
7700it [25:00,  5.72it/s]Epoch: 3: Step: 7701/28124, loss=1.476638, lr=0.000011
7799it [25:17,  5.74it/s]Train batch 7800
Avg. loss per last 100 batches: 1.306812
7800it [25:17,  5.72it/s]Epoch: 3: Step: 7801/28124, loss=1.922536, lr=0.000011
7899it [25:35,  5.73it/s]Train batch 7900
Avg. loss per last 100 batches: 1.296423
7900it [25:35,  5.73it/s]Epoch: 3: Step: 7901/28124, loss=1.102532, lr=0.000011
7999it [25:52,  5.64it/s]Train batch 8000
Avg. loss per last 100 batches: 1.329210
8000it [25:53,  5.68it/s]Epoch: 3: Step: 8001/28124, loss=1.329226, lr=0.000011
8099it [26:10,  5.74it/s]Train batch 8100
Avg. loss per last 100 batches: 1.326214
8100it [26:10,  5.74it/s]Epoch: 3: Step: 8101/28124, loss=1.290093, lr=0.000011
8199it [26:27,  5.51it/s]Train batch 8200
Avg. loss per last 100 batches: 1.296507
8200it [26:28,  5.42it/s]Epoch: 3: Step: 8201/28124, loss=1.637776, lr=0.000011
8299it [26:45,  5.70it/s]Train batch 8300
Avg. loss per last 100 batches: 1.304813
8300it [26:45,  5.72it/s]Epoch: 3: Step: 8301/28124, loss=0.944216, lr=0.000011
8399it [27:03,  5.73it/s]Train batch 8400
Avg. loss per last 100 batches: 1.276220
8400it [27:03,  5.73it/s]Epoch: 3: Step: 8401/28124, loss=0.652557, lr=0.000011
8499it [27:20,  5.70it/s]Train batch 8500
Avg. loss per last 100 batches: 1.303381
8500it [27:20,  5.71it/s]Epoch: 3: Step: 8501/28124, loss=1.190588, lr=0.000011
8599it [27:38,  5.72it/s]Train batch 8600
Avg. loss per last 100 batches: 1.297475
8600it [27:38,  5.73it/s]Epoch: 3: Step: 8601/28124, loss=1.179051, lr=0.000011
8699it [27:55,  5.71it/s]Train batch 8700
Avg. loss per last 100 batches: 1.282187
8700it [27:55,  5.71it/s]Epoch: 3: Step: 8701/28124, loss=1.414053, lr=0.000011
8799it [28:13,  5.73it/s]Train batch 8800
Avg. loss per last 100 batches: 1.334779
8800it [28:13,  5.70it/s]Epoch: 3: Step: 8801/28124, loss=1.202139, lr=0.000011
8899it [28:30,  5.71it/s]Train batch 8900
Avg. loss per last 100 batches: 1.265954
8900it [28:30,  5.72it/s]Epoch: 3: Step: 8901/28124, loss=1.154751, lr=0.000011
8999it [28:48,  5.71it/s]Train batch 9000
Avg. loss per last 100 batches: 1.288750
9000it [28:48,  5.72it/s]Epoch: 3: Step: 9001/28124, loss=1.228418, lr=0.000011
9099it [29:06,  5.71it/s]Train batch 9100
Avg. loss per last 100 batches: 1.292827
9100it [29:06,  5.65it/s]Epoch: 3: Step: 9101/28124, loss=1.303001, lr=0.000011
9199it [29:23,  5.67it/s]Train batch 9200
Avg. loss per last 100 batches: 1.273811
9200it [29:23,  5.68it/s]Epoch: 3: Step: 9201/28124, loss=1.039882, lr=0.000011
9299it [29:41,  5.71it/s]Train batch 9300
Avg. loss per last 100 batches: 1.318069
9300it [29:41,  5.72it/s]Epoch: 3: Step: 9301/28124, loss=1.411476, lr=0.000011
9399it [29:58,  5.74it/s]Train batch 9400
Avg. loss per last 100 batches: 1.311947
9400it [29:59,  5.73it/s]Epoch: 3: Step: 9401/28124, loss=1.519147, lr=0.000011
9499it [30:16,  5.64it/s]Train batch 9500
Avg. loss per last 100 batches: 1.266796
9500it [30:16,  5.64it/s]Epoch: 3: Step: 9501/28124, loss=1.259733, lr=0.000011
9599it [30:34,  5.70it/s]Train batch 9600
Avg. loss per last 100 batches: 1.316440
9600it [30:34,  5.71it/s]Epoch: 3: Step: 9601/28124, loss=0.656195, lr=0.000011
9699it [30:51,  5.72it/s]Train batch 9700
Avg. loss per last 100 batches: 1.355563
9700it [30:51,  5.73it/s]Epoch: 3: Step: 9701/28124, loss=1.050911, lr=0.000011
9799it [31:09,  5.73it/s]Train batch 9800
Avg. loss per last 100 batches: 1.263146
9800it [31:09,  5.72it/s]Epoch: 3: Step: 9801/28124, loss=1.450552, lr=0.000010
9899it [31:26,  5.73it/s]Train batch 9900
Avg. loss per last 100 batches: 1.265557
9900it [31:26,  5.73it/s]Epoch: 3: Step: 9901/28124, loss=0.873854, lr=0.000010
9999it [31:44,  5.71it/s]Train batch 10000
Avg. loss per last 100 batches: 1.288413
10000it [31:44,  5.71it/s]Epoch: 3: Step: 10001/28124, loss=1.519076, lr=0.000010
10099it [32:01,  5.74it/s]Train batch 10100
Avg. loss per last 100 batches: 1.311696
10100it [32:01,  5.75it/s]Epoch: 3: Step: 10101/28124, loss=1.676278, lr=0.000010
10199it [32:19,  5.73it/s]Train batch 10200
Avg. loss per last 100 batches: 1.293855
10200it [32:19,  5.73it/s]Epoch: 3: Step: 10201/28124, loss=0.873087, lr=0.000010
10299it [32:36,  5.75it/s]Train batch 10300
Avg. loss per last 100 batches: 1.255605
10300it [32:37,  5.75it/s]Epoch: 3: Step: 10301/28124, loss=1.017467, lr=0.000010
10399it [32:54,  5.75it/s]Train batch 10400
Avg. loss per last 100 batches: 1.250136
10400it [32:54,  5.74it/s]Epoch: 3: Step: 10401/28124, loss=1.087707, lr=0.000010
10499it [33:11,  5.75it/s]Train batch 10500
Avg. loss per last 100 batches: 1.333397
10500it [33:12,  5.73it/s]Epoch: 3: Step: 10501/28124, loss=1.642726, lr=0.000010
10599it [33:29,  5.73it/s]Train batch 10600
Avg. loss per last 100 batches: 1.304254
10600it [33:29,  5.73it/s]Epoch: 3: Step: 10601/28124, loss=1.418418, lr=0.000010
10699it [33:47,  5.71it/s]Train batch 10700
Avg. loss per last 100 batches: 1.286314
10700it [33:47,  5.70it/s]Epoch: 3: Step: 10701/28124, loss=0.771415, lr=0.000010
10799it [34:04,  5.66it/s]Train batch 10800
Avg. loss per last 100 batches: 1.232500
10800it [34:04,  5.69it/s]Epoch: 3: Step: 10801/28124, loss=1.545744, lr=0.000010
10899it [34:22,  5.70it/s]Train batch 10900
Avg. loss per last 100 batches: 1.275753
10900it [34:22,  5.69it/s]Epoch: 3: Step: 10901/28124, loss=1.510538, lr=0.000010
10999it [34:39,  5.67it/s]Train batch 11000
Avg. loss per last 100 batches: 1.355544
11000it [34:40,  5.69it/s]Epoch: 3: Step: 11001/28124, loss=1.256547, lr=0.000010
11099it [34:57,  5.55it/s]Train batch 11100
Avg. loss per last 100 batches: 1.257376
11100it [34:57,  5.58it/s]Epoch: 3: Step: 11101/28124, loss=1.914545, lr=0.000010
11199it [35:15,  5.71it/s]Train batch 11200
Avg. loss per last 100 batches: 1.317969
11200it [35:15,  5.71it/s]Epoch: 3: Step: 11201/28124, loss=0.971911, lr=0.000010
11249it [35:23,  5.69it/s]Validation: Epoch: 3 Step: 11250/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.509535 sec., loss=0.949428 
Eval step: 199 , used_time=8.842396 sec., loss=0.930613 
Eval step: 299 , used_time=13.147958 sec., loss=0.835113 
Eval step: 399 , used_time=17.457178 sec., loss=1.369455 
Eval step: 499 , used_time=21.786928 sec., loss=1.246306 
Eval step: 599 , used_time=26.058630 sec., loss=1.649160 
Eval step: 699 , used_time=30.387295 sec., loss=1.519722 
Eval step: 799 , used_time=34.710176 sec., loss=1.297128 
Eval step: 899 , used_time=39.221040 sec., loss=1.139709 
Eval step: 999 , used_time=43.520528 sec., loss=1.178124 
Eval step: 1099 , used_time=47.820333 sec., loss=1.044146 
Eval step: 1199 , used_time=52.124412 sec., loss=1.350681 
Eval step: 1299 , used_time=56.406776 sec., loss=0.850017 
Eval step: 1399 , used_time=60.754625 sec., loss=0.577808 
Eval step: 1499 , used_time=65.052363 sec., loss=0.675731 
Eval step: 1599 , used_time=69.568255 sec., loss=0.985115 
Eval step: 1699 , used_time=73.851798 sec., loss=0.817448 
Eval step: 1799 , used_time=78.168097 sec., loss=0.851859 
Eval step: 1899 , used_time=82.439440 sec., loss=0.596338 
Eval step: 1999 , used_time=86.709523 sec., loss=1.548117 
Eval step: 2099 , used_time=91.044472 sec., loss=0.608947 
Eval step: 2199 , used_time=95.319934 sec., loss=0.933079 
Eval step: 2299 , used_time=99.821800 sec., loss=0.449084 
Eval step: 2399 , used_time=104.089432 sec., loss=1.259026 
Eval step: 2499 , used_time=108.391747 sec., loss=0.952702 
Eval step: 2599 , used_time=112.673152 sec., loss=1.143083 
Eval step: 2699 , used_time=116.956506 sec., loss=1.147827 
Eval step: 2799 , used_time=121.279688 sec., loss=1.244522 
Eval step: 2899 , used_time=125.561909 sec., loss=0.791880 
Eval step: 2999 , used_time=129.882136 sec., loss=0.887063 
Eval step: 3099 , used_time=134.323467 sec., loss=0.944836 
NLL Validation: loss = 1.042202. correct prediction ratio  71224/100032 ~  0.712012
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [37:53,  5.71it/s]Train batch 11300
Avg. loss per last 100 batches: 1.250721
11300it [37:53,  5.71it/s]Epoch: 3: Step: 11301/28124, loss=1.393850, lr=0.000010
11399it [38:11,  5.75it/s]Train batch 11400
Avg. loss per last 100 batches: 1.329950
11400it [38:11,  5.74it/s]Epoch: 3: Step: 11401/28124, loss=1.782815, lr=0.000010
11499it [38:28,  5.72it/s]Train batch 11500
Avg. loss per last 100 batches: 1.292607
11500it [38:28,  5.72it/s]Epoch: 3: Step: 11501/28124, loss=1.306593, lr=0.000010
11599it [38:46,  5.74it/s]Train batch 11600
Avg. loss per last 100 batches: 1.272114
11600it [38:46,  5.72it/s]Epoch: 3: Step: 11601/28124, loss=1.099857, lr=0.000010
11699it [39:03,  5.71it/s]Train batch 11700
Avg. loss per last 100 batches: 1.304674
11700it [39:03,  5.71it/s]Epoch: 3: Step: 11701/28124, loss=1.072126, lr=0.000010
11799it [39:21,  5.72it/s]Train batch 11800
Avg. loss per last 100 batches: 1.228005
11800it [39:21,  5.73it/s]Epoch: 3: Step: 11801/28124, loss=1.239833, lr=0.000010
11899it [39:38,  5.77it/s]Train batch 11900
Avg. loss per last 100 batches: 1.300896
11900it [39:38,  5.75it/s]Epoch: 3: Step: 11901/28124, loss=1.701073, lr=0.000010
11999it [39:56,  5.73it/s]Train batch 12000
Avg. loss per last 100 batches: 1.275233
12000it [39:56,  5.72it/s]Epoch: 3: Step: 12001/28124, loss=1.649404, lr=0.000010
12099it [40:13,  5.35it/s]Train batch 12100
Avg. loss per last 100 batches: 1.308763
12100it [40:14,  5.37it/s]Epoch: 3: Step: 12101/28124, loss=1.300178, lr=0.000010
12199it [40:31,  5.73it/s]Train batch 12200
Avg. loss per last 100 batches: 1.306567
12200it [40:31,  5.74it/s]Epoch: 3: Step: 12201/28124, loss=1.340007, lr=0.000010
12299it [40:48,  5.73it/s]Train batch 12300
Avg. loss per last 100 batches: 1.294757
12300it [40:49,  5.72it/s]Epoch: 3: Step: 12301/28124, loss=0.882052, lr=0.000010
12399it [41:06,  5.74it/s]Train batch 12400
Avg. loss per last 100 batches: 1.291511
12400it [41:06,  5.73it/s]Epoch: 3: Step: 12401/28124, loss=1.179953, lr=0.000010
12499it [41:23,  5.73it/s]Train batch 12500
Avg. loss per last 100 batches: 1.287818
12500it [41:24,  5.71it/s]Epoch: 3: Step: 12501/28124, loss=1.364996, lr=0.000010
12599it [41:41,  5.71it/s]Train batch 12600
Avg. loss per last 100 batches: 1.395398
12600it [41:41,  5.73it/s]Epoch: 3: Step: 12601/28124, loss=0.837654, lr=0.000010
12699it [41:59,  5.75it/s]Train batch 12700
Avg. loss per last 100 batches: 1.283240
12700it [41:59,  5.73it/s]Epoch: 3: Step: 12701/28124, loss=1.035815, lr=0.000010
12799it [42:16,  5.74it/s]Train batch 12800
Avg. loss per last 100 batches: 1.287480
12800it [42:16,  5.72it/s]Epoch: 3: Step: 12801/28124, loss=0.903709, lr=0.000010
12899it [42:34,  5.73it/s]Train batch 12900
Avg. loss per last 100 batches: 1.307375
12900it [42:34,  5.72it/s]Epoch: 3: Step: 12901/28124, loss=0.838279, lr=0.000010
12999it [42:51,  5.73it/s]Train batch 13000
Avg. loss per last 100 batches: 1.282988
13000it [42:51,  5.64it/s]Epoch: 3: Step: 13001/28124, loss=1.451542, lr=0.000010
13099it [43:09,  5.71it/s]Train batch 13100
Avg. loss per last 100 batches: 1.288977
13100it [43:09,  5.71it/s]Epoch: 3: Step: 13101/28124, loss=1.534838, lr=0.000010
13199it [43:26,  5.71it/s]Train batch 13200
Avg. loss per last 100 batches: 1.315064
13200it [43:27,  5.71it/s]Epoch: 3: Step: 13201/28124, loss=1.322541, lr=0.000010
13299it [43:44,  5.73it/s]Train batch 13300
Avg. loss per last 100 batches: 1.290220
13300it [43:44,  5.73it/s]Epoch: 3: Step: 13301/28124, loss=0.928476, lr=0.000010
13399it [44:01,  5.71it/s]Train batch 13400
Avg. loss per last 100 batches: 1.294564
13400it [44:02,  5.71it/s]Epoch: 3: Step: 13401/28124, loss=1.111424, lr=0.000010
13499it [44:19,  5.73it/s]Train batch 13500
Avg. loss per last 100 batches: 1.220762
13500it [44:19,  5.72it/s]Epoch: 3: Step: 13501/28124, loss=0.715070, lr=0.000010
13599it [44:37,  5.74it/s]Train batch 13600
Avg. loss per last 100 batches: 1.302808
13600it [44:37,  5.74it/s]Epoch: 3: Step: 13601/28124, loss=1.210096, lr=0.000010
13699it [44:54,  5.72it/s]Train batch 13700
Avg. loss per last 100 batches: 1.264396
13700it [44:54,  5.73it/s]Epoch: 3: Step: 13701/28124, loss=1.232946, lr=0.000010
13799it [45:12,  5.74it/s]Train batch 13800
Avg. loss per last 100 batches: 1.309260
13800it [45:12,  5.72it/s]Epoch: 3: Step: 13801/28124, loss=1.061110, lr=0.000010
13899it [45:29,  5.72it/s]Train batch 13900
Avg. loss per last 100 batches: 1.276496
13900it [45:29,  5.72it/s]Epoch: 3: Step: 13901/28124, loss=1.190058, lr=0.000010
13999it [45:47,  5.73it/s]Train batch 14000
Avg. loss per last 100 batches: 1.262491
14000it [45:47,  5.72it/s]Epoch: 3: Step: 14001/28124, loss=0.947936, lr=0.000010
14099it [46:04,  5.69it/s]Train batch 14100
Avg. loss per last 100 batches: 1.332450
14100it [46:05,  5.67it/s]Epoch: 3: Step: 14101/28124, loss=1.307040, lr=0.000010
14199it [46:22,  5.59it/s]Train batch 14200
Avg. loss per last 100 batches: 1.271969
14200it [46:22,  5.43it/s]Epoch: 3: Step: 14201/28124, loss=1.768739, lr=0.000010
14299it [46:40,  5.71it/s]Train batch 14300
Avg. loss per last 100 batches: 1.310629
14300it [46:40,  5.72it/s]Epoch: 3: Step: 14301/28124, loss=1.635024, lr=0.000010
14399it [46:57,  5.74it/s]Train batch 14400
Avg. loss per last 100 batches: 1.320180
14400it [46:57,  5.75it/s]Epoch: 3: Step: 14401/28124, loss=1.443483, lr=0.000010
14499it [47:15,  5.74it/s]Train batch 14500
Avg. loss per last 100 batches: 1.258068
14500it [47:15,  5.73it/s]Epoch: 3: Step: 14501/28124, loss=1.589168, lr=0.000010
14599it [47:32,  5.55it/s]Train batch 14600
Avg. loss per last 100 batches: 1.294314
14600it [47:33,  5.58it/s]Epoch: 3: Step: 14601/28124, loss=1.381835, lr=0.000010
14699it [47:50,  5.73it/s]Train batch 14700
Avg. loss per last 100 batches: 1.277121
14700it [47:50,  5.69it/s]Epoch: 3: Step: 14701/28124, loss=1.369430, lr=0.000010
14799it [48:07,  5.72it/s]Train batch 14800
Avg. loss per last 100 batches: 1.301668
14800it [48:08,  5.72it/s]Epoch: 3: Step: 14801/28124, loss=1.029162, lr=0.000010
14899it [48:25,  5.72it/s]Train batch 14900
Avg. loss per last 100 batches: 1.259312
14900it [48:25,  5.72it/s]Epoch: 3: Step: 14901/28124, loss=1.416944, lr=0.000010
14999it [48:43,  5.54it/s]Train batch 15000
Avg. loss per last 100 batches: 1.331440
15000it [48:43,  5.59it/s]Epoch: 3: Step: 15001/28124, loss=1.412923, lr=0.000010
15099it [49:00,  5.74it/s]Train batch 15100
Avg. loss per last 100 batches: 1.336571
15100it [49:00,  5.73it/s]Epoch: 3: Step: 15101/28124, loss=1.731651, lr=0.000010
15199it [49:18,  5.73it/s]Train batch 15200
Avg. loss per last 100 batches: 1.299008
15200it [49:18,  5.71it/s]Epoch: 3: Step: 15201/28124, loss=0.789785, lr=0.000010
15299it [49:35,  5.73it/s]Train batch 15300
Avg. loss per last 100 batches: 1.271834
15300it [49:36,  5.73it/s]Epoch: 3: Step: 15301/28124, loss=0.826465, lr=0.000010
15399it [49:53,  5.69it/s]Train batch 15400
Avg. loss per last 100 batches: 1.305168
15400it [49:53,  5.69it/s]Epoch: 3: Step: 15401/28124, loss=1.240831, lr=0.000010
15499it [50:10,  5.75it/s]Train batch 15500
Avg. loss per last 100 batches: 1.301395
15500it [50:11,  5.74it/s]Epoch: 3: Step: 15501/28124, loss=1.341021, lr=0.000010
15599it [50:28,  5.72it/s]Train batch 15600
Avg. loss per last 100 batches: 1.243126
15600it [50:28,  5.72it/s]Epoch: 3: Step: 15601/28124, loss=1.361018, lr=0.000010
15699it [50:46,  5.74it/s]Train batch 15700
Avg. loss per last 100 batches: 1.310843
15700it [50:46,  5.71it/s]Epoch: 3: Step: 15701/28124, loss=1.183185, lr=0.000010
15799it [51:03,  5.70it/s]Train batch 15800
Avg. loss per last 100 batches: 1.280352
15800it [51:03,  5.69it/s]Epoch: 3: Step: 15801/28124, loss=1.513128, lr=0.000010
15899it [51:21,  5.38it/s]Train batch 15900
Avg. loss per last 100 batches: 1.298680
15900it [51:21,  5.42it/s]Epoch: 3: Step: 15901/28124, loss=1.212141, lr=0.000010
15999it [51:38,  5.73it/s]Train batch 16000
Avg. loss per last 100 batches: 1.267668
16000it [51:39,  5.73it/s]Epoch: 3: Step: 16001/28124, loss=1.068455, lr=0.000010
16099it [51:56,  5.73it/s]Train batch 16100
Avg. loss per last 100 batches: 1.219457
16100it [51:56,  5.71it/s]Epoch: 3: Step: 16101/28124, loss=1.692684, lr=0.000010
16199it [52:14,  5.68it/s]Train batch 16200
Avg. loss per last 100 batches: 1.313971
16200it [52:14,  5.68it/s]Epoch: 3: Step: 16201/28124, loss=1.148249, lr=0.000010
16299it [52:31,  5.75it/s]Train batch 16300
Avg. loss per last 100 batches: 1.301356
16300it [52:31,  5.75it/s]Epoch: 3: Step: 16301/28124, loss=1.761195, lr=0.000010
16399it [52:49,  5.72it/s]Train batch 16400
Avg. loss per last 100 batches: 1.280547
16400it [52:49,  5.72it/s]Epoch: 3: Step: 16401/28124, loss=1.100764, lr=0.000010
16499it [53:06,  5.71it/s]Train batch 16500
Avg. loss per last 100 batches: 1.215079
16500it [53:06,  5.70it/s]Epoch: 3: Step: 16501/28124, loss=1.693740, lr=0.000010
16599it [53:24,  5.74it/s]Train batch 16600
Avg. loss per last 100 batches: 1.292954
16600it [53:24,  5.71it/s]Epoch: 3: Step: 16601/28124, loss=1.182225, lr=0.000010
16699it [53:41,  5.74it/s]Train batch 16700
Avg. loss per last 100 batches: 1.360578
16700it [53:41,  5.72it/s]Epoch: 3: Step: 16701/28124, loss=1.617894, lr=0.000010
16799it [53:59,  5.42it/s]Train batch 16800
Avg. loss per last 100 batches: 1.307424
16800it [53:59,  5.41it/s]Epoch: 3: Step: 16801/28124, loss=1.147145, lr=0.000010
16874it [54:12,  5.74it/s]Validation: Epoch: 3 Step: 16875/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.306176 sec., loss=0.882394 
Eval step: 199 , used_time=8.611672 sec., loss=0.858458 
Eval step: 299 , used_time=12.881332 sec., loss=0.691010 
Eval step: 399 , used_time=17.377417 sec., loss=1.416790 
Eval step: 499 , used_time=21.656731 sec., loss=1.335958 
Eval step: 599 , used_time=25.959026 sec., loss=1.555811 
Eval step: 699 , used_time=30.250599 sec., loss=1.557590 
Eval step: 799 , used_time=34.529979 sec., loss=1.351208 
Eval step: 899 , used_time=38.855641 sec., loss=1.045104 
Eval step: 999 , used_time=43.135846 sec., loss=1.182760 
Eval step: 1099 , used_time=47.630958 sec., loss=0.979200 
Eval step: 1199 , used_time=51.908811 sec., loss=1.095965 
Eval step: 1299 , used_time=56.216516 sec., loss=0.707981 
Eval step: 1399 , used_time=60.532477 sec., loss=0.652972 
Eval step: 1499 , used_time=64.805238 sec., loss=0.623192 
Eval step: 1599 , used_time=69.108912 sec., loss=1.140534 
Eval step: 1699 , used_time=73.369546 sec., loss=0.928298 
Eval step: 1799 , used_time=77.827969 sec., loss=0.764274 
Eval step: 1899 , used_time=82.119030 sec., loss=0.623605 
Eval step: 1999 , used_time=86.413721 sec., loss=1.579165 
Eval step: 2099 , used_time=90.714992 sec., loss=0.633575 
Eval step: 2199 , used_time=95.023016 sec., loss=0.908460 
Eval step: 2299 , used_time=99.292417 sec., loss=0.451620 
Eval step: 2399 , used_time=103.566280 sec., loss=1.284582 
Eval step: 2499 , used_time=107.874536 sec., loss=0.902225 
Eval step: 2599 , used_time=112.348230 sec., loss=1.158096 
Eval step: 2699 , used_time=116.657808 sec., loss=1.140766 
Eval step: 2799 , used_time=120.966778 sec., loss=1.262312 
Eval step: 2899 , used_time=125.267701 sec., loss=0.770676 
Eval step: 2999 , used_time=129.540902 sec., loss=0.817178 
Eval step: 3099 , used_time=133.808459 sec., loss=0.948239 
NLL Validation: loss = 1.017970. correct prediction ratio  71572/100032 ~  0.715491
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
16899it [56:41,  5.42it/s]Train batch 16900
Avg. loss per last 100 batches: 1.278705
16900it [56:41,  5.50it/s]Epoch: 3: Step: 16901/28124, loss=1.507459, lr=0.000010
16999it [56:59,  5.75it/s]Train batch 17000
Avg. loss per last 100 batches: 1.315149
17000it [56:59,  5.71it/s]Epoch: 3: Step: 17001/28124, loss=1.049663, lr=0.000010
17099it [57:16,  5.69it/s]Train batch 17100
Avg. loss per last 100 batches: 1.286721
17100it [57:16,  5.68it/s]Epoch: 3: Step: 17101/28124, loss=1.396433, lr=0.000010
17199it [57:34,  5.74it/s]Train batch 17200
Avg. loss per last 100 batches: 1.232408
17200it [57:34,  5.74it/s]Epoch: 3: Step: 17201/28124, loss=1.254971, lr=0.000010
17299it [57:51,  5.74it/s]Train batch 17300
Avg. loss per last 100 batches: 1.245318
17300it [57:51,  5.74it/s]Epoch: 3: Step: 17301/28124, loss=1.086854, lr=0.000010
17399it [58:09,  5.74it/s]Train batch 17400
Avg. loss per last 100 batches: 1.306235
17400it [58:09,  5.74it/s]Epoch: 3: Step: 17401/28124, loss=1.573806, lr=0.000010
17499it [58:26,  5.72it/s]Train batch 17500
Avg. loss per last 100 batches: 1.289929
17500it [58:26,  5.73it/s]Epoch: 3: Step: 17501/28124, loss=1.434376, lr=0.000010
17599it [58:44,  5.74it/s]Train batch 17600
Avg. loss per last 100 batches: 1.324703
17600it [58:44,  5.75it/s]Epoch: 3: Step: 17601/28124, loss=1.298912, lr=0.000010
17699it [59:01,  5.70it/s]Train batch 17700
Avg. loss per last 100 batches: 1.295847
17700it [59:01,  5.71it/s]Epoch: 3: Step: 17701/28124, loss=1.468154, lr=0.000010
17799it [59:19,  5.68it/s]Train batch 17800
Avg. loss per last 100 batches: 1.289936
17800it [59:19,  5.69it/s]Epoch: 3: Step: 17801/28124, loss=1.142766, lr=0.000010
17899it [59:36,  5.75it/s]Train batch 17900
Avg. loss per last 100 batches: 1.283836
17900it [59:37,  5.70it/s]Epoch: 3: Step: 17901/28124, loss=1.138963, lr=0.000010
17999it [59:54,  5.72it/s]Train batch 18000
Avg. loss per last 100 batches: 1.284181
18000it [59:54,  5.72it/s]Epoch: 3: Step: 18001/28124, loss=0.990389, lr=0.000010
18099it [1:00:11,  5.74it/s]Train batch 18100
Avg. loss per last 100 batches: 1.231481
18100it [1:00:12,  5.75it/s]Epoch: 3: Step: 18101/28124, loss=1.643934, lr=0.000010
18199it [1:00:29,  5.73it/s]Train batch 18200
Avg. loss per last 100 batches: 1.249439
18200it [1:00:29,  5.74it/s]Epoch: 3: Step: 18201/28124, loss=1.077418, lr=0.000010
18299it [1:00:46,  5.73it/s]Train batch 18300
Avg. loss per last 100 batches: 1.270086
18300it [1:00:47,  5.74it/s]Epoch: 3: Step: 18301/28124, loss=0.883252, lr=0.000010
18399it [1:01:04,  5.74it/s]Train batch 18400
Avg. loss per last 100 batches: 1.243649
18400it [1:01:04,  5.73it/s]Epoch: 3: Step: 18401/28124, loss=1.152890, lr=0.000010
18499it [1:01:21,  5.76it/s]Train batch 18500
Avg. loss per last 100 batches: 1.272466
18500it [1:01:22,  5.75it/s]Epoch: 3: Step: 18501/28124, loss=1.478583, lr=0.000010
18599it [1:01:39,  5.76it/s]Train batch 18600
Avg. loss per last 100 batches: 1.304941
18600it [1:01:39,  5.74it/s]Epoch: 3: Step: 18601/28124, loss=1.341202, lr=0.000010
18699it [1:01:57,  5.44it/s]Train batch 18700
Avg. loss per last 100 batches: 1.277473
18700it [1:01:57,  5.52it/s]Epoch: 3: Step: 18701/28124, loss=1.096238, lr=0.000010
18799it [1:02:14,  5.75it/s]Train batch 18800
Avg. loss per last 100 batches: 1.261283
18800it [1:02:14,  5.75it/s]Epoch: 3: Step: 18801/28124, loss=1.081740, lr=0.000010
18899it [1:02:32,  5.74it/s]Train batch 18900
Avg. loss per last 100 batches: 1.252777
18900it [1:02:32,  5.73it/s]Epoch: 3: Step: 18901/28124, loss=1.355830, lr=0.000010
18999it [1:02:49,  5.75it/s]Train batch 19000
Avg. loss per last 100 batches: 1.292071
19000it [1:02:49,  5.75it/s]Epoch: 3: Step: 19001/28124, loss=1.625700, lr=0.000010
19099it [1:03:07,  5.74it/s]Train batch 19100
Avg. loss per last 100 batches: 1.297601
19100it [1:03:07,  5.73it/s]Epoch: 3: Step: 19101/28124, loss=1.216074, lr=0.000010
19199it [1:03:24,  5.68it/s]Train batch 19200
Avg. loss per last 100 batches: 1.258985
19200it [1:03:24,  5.69it/s]Epoch: 3: Step: 19201/28124, loss=0.834999, lr=0.000010
19299it [1:03:42,  5.77it/s]Train batch 19300
Avg. loss per last 100 batches: 1.222143
19300it [1:03:42,  5.75it/s]Epoch: 3: Step: 19301/28124, loss=1.523825, lr=0.000010
19399it [1:03:59,  5.72it/s]Train batch 19400
Avg. loss per last 100 batches: 1.236209
19400it [1:03:59,  5.72it/s]Epoch: 3: Step: 19401/28124, loss=1.401455, lr=0.000010
19499it [1:04:17,  5.71it/s]Train batch 19500
Avg. loss per last 100 batches: 1.251060
19500it [1:04:17,  5.71it/s]Epoch: 3: Step: 19501/28124, loss=1.494927, lr=0.000010
19599it [1:04:34,  5.51it/s]Train batch 19600
Avg. loss per last 100 batches: 1.249048
19600it [1:04:34,  5.45it/s]Epoch: 3: Step: 19601/28124, loss=0.802913, lr=0.000009
19699it [1:04:52,  5.69it/s]Train batch 19700
Avg. loss per last 100 batches: 1.291474
19700it [1:04:52,  5.48it/s]Epoch: 3: Step: 19701/28124, loss=1.225558, lr=0.000009
19799it [1:05:09,  5.72it/s]Train batch 19800
Avg. loss per last 100 batches: 1.350287
19800it [1:05:09,  5.73it/s]Epoch: 3: Step: 19801/28124, loss=1.175495, lr=0.000009
19899it [1:05:27,  5.71it/s]Train batch 19900
Avg. loss per last 100 batches: 1.308940
19900it [1:05:27,  5.71it/s]Epoch: 3: Step: 19901/28124, loss=1.918303, lr=0.000009
19999it [1:05:44,  5.73it/s]Train batch 20000
Avg. loss per last 100 batches: 1.318523
20000it [1:05:44,  5.73it/s]Epoch: 3: Step: 20001/28124, loss=1.421446, lr=0.000009
20099it [1:06:02,  5.74it/s]Train batch 20100
Avg. loss per last 100 batches: 1.308355
20100it [1:06:02,  5.70it/s]Epoch: 3: Step: 20101/28124, loss=1.334827, lr=0.000009
20199it [1:06:19,  5.75it/s]Train batch 20200
Avg. loss per last 100 batches: 1.278779
20200it [1:06:20,  5.73it/s]Epoch: 3: Step: 20201/28124, loss=1.328429, lr=0.000009
20299it [1:06:37,  5.75it/s]Train batch 20300
Avg. loss per last 100 batches: 1.287618
20300it [1:06:37,  5.75it/s]Epoch: 3: Step: 20301/28124, loss=1.298952, lr=0.000009
20399it [1:06:54,  5.71it/s]Train batch 20400
Avg. loss per last 100 batches: 1.265659
20400it [1:06:55,  5.70it/s]Epoch: 3: Step: 20401/28124, loss=1.185023, lr=0.000009
20499it [1:07:12,  5.73it/s]Train batch 20500
Avg. loss per last 100 batches: 1.267401
20500it [1:07:12,  5.74it/s]Epoch: 3: Step: 20501/28124, loss=1.090741, lr=0.000009
20599it [1:07:29,  5.74it/s]Train batch 20600
Avg. loss per last 100 batches: 1.338528
20600it [1:07:30,  5.74it/s]Epoch: 3: Step: 20601/28124, loss=1.067702, lr=0.000009
20699it [1:07:47,  5.71it/s]Train batch 20700
Avg. loss per last 100 batches: 1.280407
20700it [1:07:47,  5.70it/s]Epoch: 3: Step: 20701/28124, loss=0.789959, lr=0.000009
20799it [1:08:04,  5.73it/s]Train batch 20800
Avg. loss per last 100 batches: 1.287795
20800it [1:08:05,  5.72it/s]Epoch: 3: Step: 20801/28124, loss=1.700489, lr=0.000009
20899it [1:08:22,  5.50it/s]Train batch 20900
Avg. loss per last 100 batches: 1.288978
20900it [1:08:22,  5.56it/s]Epoch: 3: Step: 20901/28124, loss=1.276171, lr=0.000009
20999it [1:08:39,  5.74it/s]Train batch 21000
Avg. loss per last 100 batches: 1.282119
21000it [1:08:40,  5.75it/s]Epoch: 3: Step: 21001/28124, loss=1.043929, lr=0.000009
21099it [1:08:57,  5.75it/s]Train batch 21100
Avg. loss per last 100 batches: 1.255285
21100it [1:08:57,  5.76it/s]Epoch: 3: Step: 21101/28124, loss=1.144581, lr=0.000009
21199it [1:09:15,  5.74it/s]Train batch 21200
Avg. loss per last 100 batches: 1.302637
21200it [1:09:15,  5.72it/s]Epoch: 3: Step: 21201/28124, loss=1.184631, lr=0.000009
21299it [1:09:32,  5.49it/s]Train batch 21300
Avg. loss per last 100 batches: 1.267363
21300it [1:09:32,  5.54it/s]Epoch: 3: Step: 21301/28124, loss=0.958983, lr=0.000009
21399it [1:09:50,  5.74it/s]Train batch 21400
Avg. loss per last 100 batches: 1.271834
21400it [1:09:50,  5.76it/s]Epoch: 3: Step: 21401/28124, loss=0.932482, lr=0.000009
21499it [1:10:07,  5.75it/s]Train batch 21500
Avg. loss per last 100 batches: 1.291414
21500it [1:10:07,  5.76it/s]Epoch: 3: Step: 21501/28124, loss=0.731496, lr=0.000009
21599it [1:10:25,  5.54it/s]Train batch 21600
Avg. loss per last 100 batches: 1.268887
21600it [1:10:25,  5.61it/s]Epoch: 3: Step: 21601/28124, loss=1.091490, lr=0.000009
21699it [1:10:42,  5.58it/s]Train batch 21700
Avg. loss per last 100 batches: 1.233597
21700it [1:10:43,  5.61it/s]Epoch: 3: Step: 21701/28124, loss=1.722690, lr=0.000009
21799it [1:11:00,  5.74it/s]Train batch 21800
Avg. loss per last 100 batches: 1.271178
21800it [1:11:00,  5.73it/s]Epoch: 3: Step: 21801/28124, loss=1.869878, lr=0.000009
21899it [1:11:17,  5.75it/s]Train batch 21900
Avg. loss per last 100 batches: 1.322475
21900it [1:11:18,  5.76it/s]Epoch: 3: Step: 21901/28124, loss=1.566039, lr=0.000009
21999it [1:11:35,  5.73it/s]Train batch 22000
Avg. loss per last 100 batches: 1.277980
22000it [1:11:35,  5.72it/s]Epoch: 3: Step: 22001/28124, loss=1.012203, lr=0.000009
22099it [1:11:53,  5.62it/s]Train batch 22100
Avg. loss per last 100 batches: 1.241244
22100it [1:11:53,  5.65it/s]Epoch: 3: Step: 22101/28124, loss=0.747799, lr=0.000009
22199it [1:12:10,  5.72it/s]Train batch 22200
Avg. loss per last 100 batches: 1.275698
22200it [1:12:10,  5.72it/s]Epoch: 3: Step: 22201/28124, loss=1.343056, lr=0.000009
22299it [1:12:28,  5.70it/s]Train batch 22300
Avg. loss per last 100 batches: 1.274468
22300it [1:12:28,  5.70it/s]Epoch: 3: Step: 22301/28124, loss=1.954195, lr=0.000009
22399it [1:12:46,  5.69it/s]Train batch 22400
Avg. loss per last 100 batches: 1.305179
22400it [1:12:46,  5.70it/s]Epoch: 3: Step: 22401/28124, loss=1.018136, lr=0.000009
22499it [1:13:03,  5.36it/s]Train batch 22500
Avg. loss per last 100 batches: 1.267304
Validation: Epoch: 3 Step: 22500/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.383274 sec., loss=0.839322 
Eval step: 199 , used_time=8.734818 sec., loss=0.992936 
Eval step: 299 , used_time=13.063296 sec., loss=0.774131 
Eval step: 399 , used_time=17.394335 sec., loss=1.363200 
Eval step: 499 , used_time=21.754308 sec., loss=1.244638 
Eval step: 599 , used_time=26.056389 sec., loss=1.524424 
Eval step: 699 , used_time=30.528691 sec., loss=1.588900 
Eval step: 799 , used_time=34.936418 sec., loss=1.302652 
Eval step: 899 , used_time=39.293491 sec., loss=0.953313 
Eval step: 999 , used_time=43.616125 sec., loss=1.160798 
Eval step: 1099 , used_time=47.950544 sec., loss=0.963413 
Eval step: 1199 , used_time=52.286915 sec., loss=1.124976 
Eval step: 1299 , used_time=56.588691 sec., loss=0.730465 
Eval step: 1399 , used_time=60.936924 sec., loss=0.594990 
Eval step: 1499 , used_time=65.510686 sec., loss=0.465051 
Eval step: 1599 , used_time=69.848038 sec., loss=1.124118 
Eval step: 1699 , used_time=74.158695 sec., loss=0.786570 
Eval step: 1799 , used_time=78.514311 sec., loss=0.808505 
Eval step: 1899 , used_time=82.833484 sec., loss=0.559966 
Eval step: 1999 , used_time=87.121312 sec., loss=1.553198 
Eval step: 2099 , used_time=91.449562 sec., loss=0.613482 
Eval step: 2199 , used_time=95.998281 sec., loss=0.824027 
Eval step: 2299 , used_time=100.322768 sec., loss=0.355045 
Eval step: 2399 , used_time=104.608802 sec., loss=1.194028 
Eval step: 2499 , used_time=108.943414 sec., loss=0.955418 
Eval step: 2599 , used_time=113.254070 sec., loss=1.055341 
Eval step: 2699 , used_time=117.561872 sec., loss=1.126895 
Eval step: 2799 , used_time=121.904982 sec., loss=1.224895 
Eval step: 2899 , used_time=126.422915 sec., loss=0.814622 
Eval step: 2999 , used_time=130.760001 sec., loss=0.767440 
Eval step: 3099 , used_time=135.089907 sec., loss=1.017509 
NLL Validation: loss = 0.998451. correct prediction ratio  72190/100032 ~  0.721669
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
22500it [1:15:25, 42.57s/it]Epoch: 3: Step: 22501/28124, loss=1.483308, lr=0.000009
22599it [1:15:42,  5.36it/s]Train batch 22600
Avg. loss per last 100 batches: 1.244736
22600it [1:15:42,  5.46it/s]Epoch: 3: Step: 22601/28124, loss=1.384468, lr=0.000009
22699it [1:16:00,  5.72it/s]Train batch 22700
Avg. loss per last 100 batches: 1.317150
22700it [1:16:00,  5.73it/s]Epoch: 3: Step: 22701/28124, loss=0.803751, lr=0.000009
22799it [1:16:17,  5.71it/s]Train batch 22800
Avg. loss per last 100 batches: 1.274811
22800it [1:16:18,  5.72it/s]Epoch: 3: Step: 22801/28124, loss=1.240500, lr=0.000009
22899it [1:16:35,  5.72it/s]Train batch 22900
Avg. loss per last 100 batches: 1.266497
22900it [1:16:35,  5.72it/s]Epoch: 3: Step: 22901/28124, loss=0.854821, lr=0.000009
22999it [1:16:53,  5.66it/s]Train batch 23000
Avg. loss per last 100 batches: 1.252105
23000it [1:16:53,  5.67it/s]Epoch: 3: Step: 23001/28124, loss=1.242671, lr=0.000009
23099it [1:17:10,  5.71it/s]Train batch 23100
Avg. loss per last 100 batches: 1.284878
23100it [1:17:10,  5.71it/s]Epoch: 3: Step: 23101/28124, loss=0.764026, lr=0.000009
23199it [1:17:28,  5.71it/s]Train batch 23200
Avg. loss per last 100 batches: 1.309006
23200it [1:17:28,  5.70it/s]Epoch: 3: Step: 23201/28124, loss=1.588771, lr=0.000009
23299it [1:17:45,  5.72it/s]Train batch 23300
Avg. loss per last 100 batches: 1.269639
23300it [1:17:45,  5.72it/s]Epoch: 3: Step: 23301/28124, loss=1.334011, lr=0.000009
23399it [1:18:03,  5.63it/s]Train batch 23400
Avg. loss per last 100 batches: 1.247517
23400it [1:18:03,  5.67it/s]Epoch: 3: Step: 23401/28124, loss=1.119804, lr=0.000009
23499it [1:18:21,  5.35it/s]Train batch 23500
Avg. loss per last 100 batches: 1.254094
23500it [1:18:21,  5.37it/s]Epoch: 3: Step: 23501/28124, loss=0.960170, lr=0.000009
23599it [1:18:38,  5.73it/s]Train batch 23600
Avg. loss per last 100 batches: 1.243011
23600it [1:18:38,  5.72it/s]Epoch: 3: Step: 23601/28124, loss=1.117945, lr=0.000009
23699it [1:18:56,  5.73it/s]Train batch 23700
Avg. loss per last 100 batches: 1.281697
23700it [1:18:56,  5.71it/s]Epoch: 3: Step: 23701/28124, loss=1.198298, lr=0.000009
23799it [1:19:13,  5.70it/s]Train batch 23800
Avg. loss per last 100 batches: 1.315989
23800it [1:19:13,  5.71it/s]Epoch: 3: Step: 23801/28124, loss=1.406304, lr=0.000009
23899it [1:19:31,  5.70it/s]Train batch 23900
Avg. loss per last 100 batches: 1.306146
23900it [1:19:31,  5.71it/s]Epoch: 3: Step: 23901/28124, loss=1.301636, lr=0.000009
23999it [1:19:48,  5.71it/s]Train batch 24000
Avg. loss per last 100 batches: 1.241767
24000it [1:19:49,  5.72it/s]Epoch: 3: Step: 24001/28124, loss=1.032047, lr=0.000009
24099it [1:20:06,  5.71it/s]Train batch 24100
Avg. loss per last 100 batches: 1.252450
24100it [1:20:06,  5.71it/s]Epoch: 3: Step: 24101/28124, loss=1.212995, lr=0.000009
24199it [1:20:24,  5.68it/s]Train batch 24200
Avg. loss per last 100 batches: 1.309551
24200it [1:20:24,  5.68it/s]Epoch: 3: Step: 24201/28124, loss=1.045398, lr=0.000009
24299it [1:20:41,  5.70it/s]Train batch 24300
Avg. loss per last 100 batches: 1.283305
24300it [1:20:41,  5.71it/s]Epoch: 3: Step: 24301/28124, loss=1.802268, lr=0.000009
24399it [1:20:59,  5.41it/s]Train batch 24400
Avg. loss per last 100 batches: 1.285002
24400it [1:20:59,  5.42it/s]Epoch: 3: Step: 24401/28124, loss=1.544315, lr=0.000009
24499it [1:21:16,  5.72it/s]Train batch 24500
Avg. loss per last 100 batches: 1.158333
24500it [1:21:17,  5.72it/s]Epoch: 3: Step: 24501/28124, loss=1.787046, lr=0.000009
24599it [1:21:34,  5.73it/s]Train batch 24600
Avg. loss per last 100 batches: 1.256864
24600it [1:21:34,  5.73it/s]Epoch: 3: Step: 24601/28124, loss=0.853735, lr=0.000009
24699it [1:21:52,  5.71it/s]Train batch 24700
Avg. loss per last 100 batches: 1.300733
24700it [1:21:52,  5.67it/s]Epoch: 3: Step: 24701/28124, loss=0.920154, lr=0.000009
24799it [1:22:09,  5.71it/s]Train batch 24800
Avg. loss per last 100 batches: 1.257719
24800it [1:22:09,  5.72it/s]Epoch: 3: Step: 24801/28124, loss=1.736851, lr=0.000009
24899it [1:22:27,  5.74it/s]Train batch 24900
Avg. loss per last 100 batches: 1.290072
24900it [1:22:27,  5.74it/s]Epoch: 3: Step: 24901/28124, loss=1.194499, lr=0.000009
24999it [1:22:44,  5.72it/s]Train batch 25000
Avg. loss per last 100 batches: 1.283876
25000it [1:22:45,  5.71it/s]Epoch: 3: Step: 25001/28124, loss=1.380598, lr=0.000009
25099it [1:23:02,  5.67it/s]Train batch 25100
Avg. loss per last 100 batches: 1.288575
25100it [1:23:02,  5.47it/s]Epoch: 3: Step: 25101/28124, loss=1.347492, lr=0.000009
25199it [1:23:20,  5.71it/s]Train batch 25200
Avg. loss per last 100 batches: 1.274509
25200it [1:23:20,  5.71it/s]Epoch: 3: Step: 25201/28124, loss=0.840669, lr=0.000009
25299it [1:23:37,  5.58it/s]Train batch 25300
Avg. loss per last 100 batches: 1.251503
25300it [1:23:37,  5.52it/s]Epoch: 3: Step: 25301/28124, loss=0.989526, lr=0.000009
25399it [1:23:55,  5.72it/s]Train batch 25400
Avg. loss per last 100 batches: 1.267130
25400it [1:23:55,  5.70it/s]Epoch: 3: Step: 25401/28124, loss=0.893110, lr=0.000009
25499it [1:24:12,  5.71it/s]Train batch 25500
Avg. loss per last 100 batches: 1.266492
25500it [1:24:13,  5.71it/s]Epoch: 3: Step: 25501/28124, loss=0.957887, lr=0.000009
25599it [1:24:30,  5.69it/s]Train batch 25600
Avg. loss per last 100 batches: 1.262366
25600it [1:24:30,  5.70it/s]Epoch: 3: Step: 25601/28124, loss=1.571546, lr=0.000009
25699it [1:24:48,  5.72it/s]Train batch 25700
Avg. loss per last 100 batches: 1.273372
25700it [1:24:48,  5.71it/s]Epoch: 3: Step: 25701/28124, loss=1.163001, lr=0.000009
25799it [1:25:05,  5.70it/s]Train batch 25800
Avg. loss per last 100 batches: 1.258991
25800it [1:25:05,  5.70it/s]Epoch: 3: Step: 25801/28124, loss=1.694655, lr=0.000009
25899it [1:25:23,  5.69it/s]Train batch 25900
Avg. loss per last 100 batches: 1.262994
25900it [1:25:23,  5.68it/s]Epoch: 3: Step: 25901/28124, loss=0.790816, lr=0.000009
25999it [1:25:40,  5.72it/s]Train batch 26000
Avg. loss per last 100 batches: 1.242418
26000it [1:25:41,  5.70it/s]Epoch: 3: Step: 26001/28124, loss=1.497092, lr=0.000009
26099it [1:25:58,  5.71it/s]Train batch 26100
Avg. loss per last 100 batches: 1.220237
26100it [1:25:58,  5.70it/s]Epoch: 3: Step: 26101/28124, loss=1.456396, lr=0.000009
26199it [1:26:16,  5.45it/s]Train batch 26200
Avg. loss per last 100 batches: 1.253545
26200it [1:26:16,  5.42it/s]Epoch: 3: Step: 26201/28124, loss=1.143516, lr=0.000009
26299it [1:26:33,  5.65it/s]Train batch 26300
Avg. loss per last 100 batches: 1.254812
26300it [1:26:34,  5.67it/s]Epoch: 3: Step: 26301/28124, loss=1.132402, lr=0.000009
26399it [1:26:51,  5.71it/s]Train batch 26400
Avg. loss per last 100 batches: 1.180519
26400it [1:26:51,  5.72it/s]Epoch: 3: Step: 26401/28124, loss=1.393699, lr=0.000009
26499it [1:27:09,  5.71it/s]Train batch 26500
Avg. loss per last 100 batches: 1.285052
26500it [1:27:09,  5.71it/s]Epoch: 3: Step: 26501/28124, loss=0.897617, lr=0.000009
26599it [1:27:26,  5.75it/s]Train batch 26600
Avg. loss per last 100 batches: 1.263157
26600it [1:27:26,  5.72it/s]Epoch: 3: Step: 26601/28124, loss=1.372016, lr=0.000009
26699it [1:27:44,  5.73it/s]Train batch 26700
Avg. loss per last 100 batches: 1.242184
26700it [1:27:44,  5.74it/s]Epoch: 3: Step: 26701/28124, loss=1.537528, lr=0.000009
26799it [1:28:01,  5.75it/s]Train batch 26800
Avg. loss per last 100 batches: 1.237910
26800it [1:28:02,  5.74it/s]Epoch: 3: Step: 26801/28124, loss=1.209062, lr=0.000009
26899it [1:28:19,  5.73it/s]Train batch 26900
Avg. loss per last 100 batches: 1.215703
26900it [1:28:19,  5.74it/s]Epoch: 3: Step: 26901/28124, loss=2.379534, lr=0.000009
26999it [1:28:36,  5.76it/s]Train batch 27000
Avg. loss per last 100 batches: 1.261486
27000it [1:28:37,  5.73it/s]Epoch: 3: Step: 27001/28124, loss=0.723279, lr=0.000009
27099it [1:28:54,  5.72it/s]Train batch 27100
Avg. loss per last 100 batches: 1.232630
27100it [1:28:54,  5.73it/s]Epoch: 3: Step: 27101/28124, loss=1.205723, lr=0.000009
27199it [1:29:11,  5.74it/s]Train batch 27200
Avg. loss per last 100 batches: 1.224212
27200it [1:29:12,  5.73it/s]Epoch: 3: Step: 27201/28124, loss=0.813151, lr=0.000009
27299it [1:29:29,  5.70it/s]Train batch 27300
Avg. loss per last 100 batches: 1.270392
27300it [1:29:29,  5.71it/s]Epoch: 3: Step: 27301/28124, loss=1.006986, lr=0.000009
27399it [1:29:47,  5.75it/s]Train batch 27400
Avg. loss per last 100 batches: 1.279534
27400it [1:29:47,  5.74it/s]Epoch: 3: Step: 27401/28124, loss=1.598738, lr=0.000009
27499it [1:30:04,  5.74it/s]Train batch 27500
Avg. loss per last 100 batches: 1.274836
27500it [1:30:04,  5.71it/s]Epoch: 3: Step: 27501/28124, loss=1.867924, lr=0.000009
27599it [1:30:22,  5.71it/s]Train batch 27600
Avg. loss per last 100 batches: 1.237772
27600it [1:30:22,  5.70it/s]Epoch: 3: Step: 27601/28124, loss=0.670755, lr=0.000009
27699it [1:30:39,  5.75it/s]Train batch 27700
Avg. loss per last 100 batches: 1.274865
27700it [1:30:39,  5.74it/s]Epoch: 3: Step: 27701/28124, loss=0.973036, lr=0.000009
27799it [1:30:57,  5.71it/s]Train batch 27800
Avg. loss per last 100 batches: 1.277138
27800it [1:30:57,  5.71it/s]Epoch: 3: Step: 27801/28124, loss=1.417607, lr=0.000009
27899it [1:31:14,  5.72it/s]Train batch 27900
Avg. loss per last 100 batches: 1.314473
27900it [1:31:15,  5.69it/s]Epoch: 3: Step: 27901/28124, loss=0.903841, lr=0.000009
27999it [1:31:32,  5.72it/s]Train batch 28000
Avg. loss per last 100 batches: 1.281460
28000it [1:31:32,  5.58it/s]Epoch: 3: Step: 28001/28124, loss=0.856311, lr=0.000009
28099it [1:31:49,  5.75it/s]Train batch 28100
Avg. loss per last 100 batches: 1.206827
28100it [1:31:50,  5.73it/s]Epoch: 3: Step: 28101/28124, loss=1.448979, lr=0.000009
28124it [1:31:54,  5.10it/s]
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.349747 sec., loss=0.839689 
Eval step: 199 , used_time=8.656762 sec., loss=1.096853 
Eval step: 299 , used_time=13.140699 sec., loss=0.706694 
Eval step: 399 , used_time=17.433361 sec., loss=1.380102 
Eval step: 499 , used_time=21.743836 sec., loss=1.286066 
Eval step: 599 , used_time=26.019997 sec., loss=1.454494 
Eval step: 699 , used_time=30.340592 sec., loss=1.620303 
Eval step: 799 , used_time=34.653570 sec., loss=1.177563 
Eval step: 899 , used_time=38.975241 sec., loss=1.046591 
Eval step: 999 , used_time=43.411874 sec., loss=1.135809 
Eval step: 1099 , used_time=47.779526 sec., loss=0.853894 
Eval step: 1199 , used_time=52.116067 sec., loss=1.002736 
Eval step: 1299 , used_time=56.402729 sec., loss=0.743854 
Eval step: 1399 , used_time=60.717364 sec., loss=0.557986 
Eval step: 1499 , used_time=65.042139 sec., loss=0.605348 
Eval step: 1599 , used_time=69.359633 sec., loss=1.038137 
Eval step: 1699 , used_time=73.643924 sec., loss=0.701977 
Eval step: 1799 , used_time=78.175431 sec., loss=0.691167 
Eval step: 1899 , used_time=82.457675 sec., loss=0.569889 
Eval step: 1999 , used_time=86.751254 sec., loss=1.360766 
Eval step: 2099 , used_time=91.056576 sec., loss=0.677519 
Eval step: 2199 , used_time=95.373492 sec., loss=0.898096 
Eval step: 2299 , used_time=99.686728 sec., loss=0.271039 
Eval step: 2399 , used_time=103.966973 sec., loss=1.127745 
Eval step: 2499 , used_time=108.469417 sec., loss=0.959879 
Eval step: 2599 , used_time=112.758486 sec., loss=1.200504 
Eval step: 2699 , used_time=117.052891 sec., loss=1.055122 
Eval step: 2799 , used_time=121.394710 sec., loss=1.253882 
Eval step: 2899 , used_time=125.690635 sec., loss=0.829185 
Eval step: 2999 , used_time=130.022280 sec., loss=0.865194 
Eval step: 3099 , used_time=134.306648 sec., loss=1.031806 
NLL Validation: loss = 0.988558. correct prediction ratio  72538/100032 ~  0.725148
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=1.286031
epoch total correct predictions=579969
***** Epoch 4 *****
0it [00:00, ?it/s]Epoch: 4: Step: 1/28124, loss=1.323239, lr=0.000009
99it [00:18,  5.70it/s]Train batch 100
Avg. loss per last 100 batches: 1.102683
100it [00:18,  5.71it/s]Epoch: 4: Step: 101/28124, loss=1.482628, lr=0.000009
199it [00:35,  5.71it/s]Train batch 200
Avg. loss per last 100 batches: 1.123645
200it [00:36,  5.69it/s]Epoch: 4: Step: 201/28124, loss=1.120592, lr=0.000009
299it [00:53,  5.73it/s]Train batch 300
Avg. loss per last 100 batches: 1.107513
300it [00:53,  5.71it/s]Epoch: 4: Step: 301/28124, loss=1.193633, lr=0.000009
399it [01:11,  5.62it/s]Train batch 400
Avg. loss per last 100 batches: 1.124422
400it [01:11,  5.65it/s]Epoch: 4: Step: 401/28124, loss=1.545882, lr=0.000009
499it [01:28,  5.63it/s]Train batch 500
Avg. loss per last 100 batches: 1.118691
500it [01:28,  5.66it/s]Epoch: 4: Step: 501/28124, loss=0.902183, lr=0.000009
599it [01:46,  5.73it/s]Train batch 600
Avg. loss per last 100 batches: 1.166342
600it [01:46,  5.72it/s]Epoch: 4: Step: 601/28124, loss=0.836494, lr=0.000009
699it [02:03,  5.74it/s]Train batch 700
Avg. loss per last 100 batches: 1.120734
700it [02:03,  5.73it/s]Epoch: 4: Step: 701/28124, loss=0.848350, lr=0.000009
799it [02:21,  5.71it/s]Train batch 800
Avg. loss per last 100 batches: 1.082918
800it [02:21,  5.72it/s]Epoch: 4: Step: 801/28124, loss=0.780095, lr=0.000009
899it [02:38,  5.71it/s]Train batch 900
Avg. loss per last 100 batches: 1.103713
900it [02:39,  5.69it/s]Epoch: 4: Step: 901/28124, loss=1.128969, lr=0.000009
999it [02:56,  5.74it/s]Train batch 1000
Avg. loss per last 100 batches: 1.097352
1000it [02:56,  5.74it/s]Epoch: 4: Step: 1001/28124, loss=1.136569, lr=0.000009
1099it [03:13,  5.74it/s]Train batch 1100
Avg. loss per last 100 batches: 1.111879
1100it [03:14,  5.72it/s]Epoch: 4: Step: 1101/28124, loss=1.100846, lr=0.000009
1199it [03:31,  5.66it/s]Train batch 1200
Avg. loss per last 100 batches: 1.125864
1200it [03:31,  5.66it/s]Epoch: 4: Step: 1201/28124, loss=1.493016, lr=0.000009
1299it [03:49,  5.71it/s]Train batch 1300
Avg. loss per last 100 batches: 1.078815
1300it [03:49,  5.69it/s]Epoch: 4: Step: 1301/28124, loss=0.894593, lr=0.000008
1399it [04:06,  5.35it/s]Train batch 1400
Avg. loss per last 100 batches: 1.065164
1400it [04:06,  5.45it/s]Epoch: 4: Step: 1401/28124, loss=1.168841, lr=0.000008
1499it [04:24,  5.71it/s]Train batch 1500
Avg. loss per last 100 batches: 1.132198
1500it [04:24,  5.71it/s]Epoch: 4: Step: 1501/28124, loss=1.538550, lr=0.000008
1599it [04:42,  5.69it/s]Train batch 1600
Avg. loss per last 100 batches: 1.064645
1600it [04:42,  5.70it/s]Epoch: 4: Step: 1601/28124, loss=1.056961, lr=0.000008
1699it [04:59,  5.68it/s]Train batch 1700
Avg. loss per last 100 batches: 1.112633
1700it [04:59,  5.70it/s]Epoch: 4: Step: 1701/28124, loss=0.854001, lr=0.000008
1799it [05:17,  5.71it/s]Train batch 1800
Avg. loss per last 100 batches: 1.078073
1800it [05:17,  5.71it/s]Epoch: 4: Step: 1801/28124, loss=1.452498, lr=0.000008
1899it [05:34,  5.72it/s]Train batch 1900
Avg. loss per last 100 batches: 1.118861
1900it [05:35,  5.71it/s]Epoch: 4: Step: 1901/28124, loss=0.762783, lr=0.000008
1999it [05:52,  5.72it/s]Train batch 2000
Avg. loss per last 100 batches: 1.109295
2000it [05:52,  5.72it/s]Epoch: 4: Step: 2001/28124, loss=1.601904, lr=0.000008
2099it [06:09,  5.73it/s]Train batch 2100
Avg. loss per last 100 batches: 1.060828
2100it [06:10,  5.71it/s]Epoch: 4: Step: 2101/28124, loss=0.753183, lr=0.000008
2199it [06:27,  5.73it/s]Train batch 2200
Avg. loss per last 100 batches: 1.141111
2200it [06:27,  5.71it/s]Epoch: 4: Step: 2201/28124, loss=1.301078, lr=0.000008
2299it [06:45,  5.38it/s]Train batch 2300
Avg. loss per last 100 batches: 1.095786
2300it [06:45,  5.38it/s]Epoch: 4: Step: 2301/28124, loss=1.793860, lr=0.000008
2399it [07:02,  5.73it/s]Train batch 2400
Avg. loss per last 100 batches: 1.108991
2400it [07:02,  5.70it/s]Epoch: 4: Step: 2401/28124, loss=1.238740, lr=0.000008
2499it [07:20,  5.72it/s]Train batch 2500
Avg. loss per last 100 batches: 1.091928
2500it [07:20,  5.73it/s]Epoch: 4: Step: 2501/28124, loss=1.163659, lr=0.000008
2599it [07:37,  5.71it/s]Train batch 2600
Avg. loss per last 100 batches: 1.139352
2600it [07:37,  5.72it/s]Epoch: 4: Step: 2601/28124, loss=1.777255, lr=0.000008
2699it [07:55,  5.68it/s]Train batch 2700
Avg. loss per last 100 batches: 1.118765
2700it [07:55,  5.70it/s]Epoch: 4: Step: 2701/28124, loss=1.401827, lr=0.000008
2799it [08:12,  5.72it/s]Train batch 2800
Avg. loss per last 100 batches: 1.144124
2800it [08:13,  5.72it/s]Epoch: 4: Step: 2801/28124, loss=1.041484, lr=0.000008
2899it [08:30,  5.55it/s]Train batch 2900
Avg. loss per last 100 batches: 1.086475
2900it [08:30,  5.60it/s]Epoch: 4: Step: 2901/28124, loss=0.996845, lr=0.000008
2999it [08:48,  5.72it/s]Train batch 3000
Avg. loss per last 100 batches: 1.121859
3000it [08:48,  5.72it/s]Epoch: 4: Step: 3001/28124, loss=0.881766, lr=0.000008
3099it [09:05,  5.72it/s]Train batch 3100
Avg. loss per last 100 batches: 1.139424
3100it [09:05,  5.72it/s]Epoch: 4: Step: 3101/28124, loss=0.781956, lr=0.000008
3199it [09:23,  5.43it/s]Train batch 3200
Avg. loss per last 100 batches: 1.091286
3200it [09:23,  5.39it/s]Epoch: 4: Step: 3201/28124, loss=0.984216, lr=0.000008
3299it [09:40,  5.71it/s]Train batch 3300
Avg. loss per last 100 batches: 1.058667
3300it [09:40,  5.71it/s]Epoch: 4: Step: 3301/28124, loss=1.625442, lr=0.000008
3399it [09:58,  5.71it/s]Train batch 3400
Avg. loss per last 100 batches: 1.152812
3400it [09:58,  5.72it/s]Epoch: 4: Step: 3401/28124, loss=1.297579, lr=0.000008
3499it [10:15,  5.68it/s]Train batch 3500
Avg. loss per last 100 batches: 1.113234
3500it [10:16,  5.66it/s]Epoch: 4: Step: 3501/28124, loss=1.327630, lr=0.000008
3599it [10:33,  5.73it/s]Train batch 3600
Avg. loss per last 100 batches: 1.155564
3600it [10:33,  5.73it/s]Epoch: 4: Step: 3601/28124, loss=1.172313, lr=0.000008
3699it [10:51,  5.57it/s]Train batch 3700
Avg. loss per last 100 batches: 1.087207
3700it [10:51,  5.60it/s]Epoch: 4: Step: 3701/28124, loss=0.582902, lr=0.000008
3799it [11:08,  5.71it/s]Train batch 3800
Avg. loss per last 100 batches: 1.184291
3800it [11:08,  5.72it/s]Epoch: 4: Step: 3801/28124, loss=1.163066, lr=0.000008
3899it [11:26,  5.74it/s]Train batch 3900
Avg. loss per last 100 batches: 1.130658
3900it [11:26,  5.75it/s]Epoch: 4: Step: 3901/28124, loss=1.168989, lr=0.000008
3999it [11:43,  5.68it/s]Train batch 4000
Avg. loss per last 100 batches: 1.146282
4000it [11:43,  5.69it/s]Epoch: 4: Step: 4001/28124, loss=1.335960, lr=0.000008
4099it [12:01,  5.72it/s]Train batch 4100
Avg. loss per last 100 batches: 1.069986
4100it [12:01,  5.73it/s]Epoch: 4: Step: 4101/28124, loss=0.890050, lr=0.000008
4199it [12:18,  5.71it/s]Train batch 4200
Avg. loss per last 100 batches: 1.082632
4200it [12:19,  5.69it/s]Epoch: 4: Step: 4201/28124, loss=1.326562, lr=0.000008
4299it [12:36,  5.72it/s]Train batch 4300
Avg. loss per last 100 batches: 1.109878
4300it [12:36,  5.72it/s]Epoch: 4: Step: 4301/28124, loss=0.943730, lr=0.000008
4399it [12:54,  5.73it/s]Train batch 4400
Avg. loss per last 100 batches: 1.133922
4400it [12:54,  5.71it/s]Epoch: 4: Step: 4401/28124, loss=1.388991, lr=0.000008
4499it [13:11,  5.69it/s]Train batch 4500
Avg. loss per last 100 batches: 1.148025
4500it [13:11,  5.68it/s]Epoch: 4: Step: 4501/28124, loss=1.193476, lr=0.000008
4599it [13:29,  5.73it/s]Train batch 4600
Avg. loss per last 100 batches: 1.105333
4600it [13:29,  5.73it/s]Epoch: 4: Step: 4601/28124, loss=1.626224, lr=0.000008
4699it [13:46,  5.72it/s]Train batch 4700
Avg. loss per last 100 batches: 1.099289
4700it [13:47,  5.72it/s]Epoch: 4: Step: 4701/28124, loss=1.359765, lr=0.000008
4799it [14:04,  5.70it/s]Train batch 4800
Avg. loss per last 100 batches: 1.052596
4800it [14:04,  5.71it/s]Epoch: 4: Step: 4801/28124, loss=0.944060, lr=0.000008
4899it [14:22,  5.69it/s]Train batch 4900
Avg. loss per last 100 batches: 1.139219
4900it [14:22,  5.70it/s]Epoch: 4: Step: 4901/28124, loss=1.305280, lr=0.000008
4999it [14:39,  5.72it/s]Train batch 5000
Avg. loss per last 100 batches: 1.141849
5000it [14:39,  5.71it/s]Epoch: 4: Step: 5001/28124, loss=0.788339, lr=0.000008
5099it [14:57,  5.72it/s]Train batch 5100
Avg. loss per last 100 batches: 1.089181
5100it [14:57,  5.72it/s]Epoch: 4: Step: 5101/28124, loss=1.150726, lr=0.000008
5199it [15:14,  5.70it/s]Train batch 5200
Avg. loss per last 100 batches: 1.087653
5200it [15:14,  5.71it/s]Epoch: 4: Step: 5201/28124, loss=1.533952, lr=0.000008
5299it [15:32,  5.73it/s]Train batch 5300
Avg. loss per last 100 batches: 1.090807
5300it [15:32,  5.69it/s]Epoch: 4: Step: 5301/28124, loss=0.980994, lr=0.000008
5399it [15:49,  5.72it/s]Train batch 5400
Avg. loss per last 100 batches: 1.100946
5400it [15:50,  5.70it/s]Epoch: 4: Step: 5401/28124, loss=0.784898, lr=0.000008
5499it [16:07,  5.71it/s]Train batch 5500
Avg. loss per last 100 batches: 1.122298
5500it [16:07,  5.66it/s]Epoch: 4: Step: 5501/28124, loss=0.882890, lr=0.000008
5599it [16:25,  5.72it/s]Train batch 5600
Avg. loss per last 100 batches: 1.106446
5600it [16:25,  5.72it/s]Epoch: 4: Step: 5601/28124, loss=0.860878, lr=0.000008
5624it [16:29,  5.74it/s]Validation: Epoch: 4 Step: 5625/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.344625 sec., loss=0.900042 
Eval step: 199 , used_time=8.705390 sec., loss=1.148596 
Eval step: 299 , used_time=13.153672 sec., loss=0.666550 
Eval step: 399 , used_time=17.591199 sec., loss=1.416130 
Eval step: 499 , used_time=21.919190 sec., loss=1.223697 
Eval step: 599 , used_time=26.293594 sec., loss=1.619368 
Eval step: 699 , used_time=30.654725 sec., loss=1.612814 
Eval step: 799 , used_time=35.012039 sec., loss=1.110620 
Eval step: 899 , used_time=39.360106 sec., loss=1.104055 
Eval step: 999 , used_time=43.684284 sec., loss=1.144879 
Eval step: 1099 , used_time=48.246129 sec., loss=0.897617 
Eval step: 1199 , used_time=52.616660 sec., loss=1.153835 
Eval step: 1299 , used_time=56.979697 sec., loss=0.749693 
Eval step: 1399 , used_time=61.303881 sec., loss=0.538339 
Eval step: 1499 , used_time=65.655060 sec., loss=0.589131 
Eval step: 1599 , used_time=69.978684 sec., loss=1.018489 
Eval step: 1699 , used_time=74.287384 sec., loss=0.766078 
Eval step: 1799 , used_time=78.789793 sec., loss=0.768711 
Eval step: 1899 , used_time=83.123215 sec., loss=0.670601 
Eval step: 1999 , used_time=87.447663 sec., loss=1.287761 
Eval step: 2099 , used_time=91.765628 sec., loss=0.632394 
Eval step: 2199 , used_time=96.119911 sec., loss=0.899696 
Eval step: 2299 , used_time=100.452832 sec., loss=0.352543 
Eval step: 2399 , used_time=104.741901 sec., loss=1.109638 
Eval step: 2499 , used_time=109.278551 sec., loss=0.876304 
Eval step: 2599 , used_time=113.601463 sec., loss=1.289007 
Eval step: 2699 , used_time=117.959206 sec., loss=1.007319 
Eval step: 2799 , used_time=122.272417 sec., loss=1.109775 
Eval step: 2899 , used_time=126.626300 sec., loss=0.878692 
Eval step: 2999 , used_time=130.928608 sec., loss=0.817799 
Eval step: 3099 , used_time=135.235423 sec., loss=1.051965 
NLL Validation: loss = 0.993260. correct prediction ratio  72915/100032 ~  0.728917
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:14,  5.75it/s]Train batch 5700
Avg. loss per last 100 batches: 1.121123
5700it [19:14,  5.73it/s]Epoch: 4: Step: 5701/28124, loss=0.947324, lr=0.000008
5799it [19:32,  5.71it/s]Train batch 5800
Avg. loss per last 100 batches: 1.139535
5800it [19:32,  5.73it/s]Epoch: 4: Step: 5801/28124, loss=0.937714, lr=0.000008
5899it [19:49,  5.71it/s]Train batch 5900
Avg. loss per last 100 batches: 1.111735
5900it [19:49,  5.72it/s]Epoch: 4: Step: 5901/28124, loss=1.555017, lr=0.000008
5999it [20:07,  5.69it/s]Train batch 6000
Avg. loss per last 100 batches: 1.097111
6000it [20:07,  5.71it/s]Epoch: 4: Step: 6001/28124, loss=1.680117, lr=0.000008
6099it [20:24,  5.76it/s]Train batch 6100
Avg. loss per last 100 batches: 1.130846
6100it [20:24,  5.74it/s]Epoch: 4: Step: 6101/28124, loss=0.865266, lr=0.000008
6199it [20:42,  5.74it/s]Train batch 6200
Avg. loss per last 100 batches: 1.141988
6200it [20:42,  5.75it/s]Epoch: 4: Step: 6201/28124, loss=1.061771, lr=0.000008
6299it [20:59,  5.73it/s]Train batch 6300
Avg. loss per last 100 batches: 1.121682
6300it [20:59,  5.74it/s]Epoch: 4: Step: 6301/28124, loss=1.259583, lr=0.000008
6399it [21:17,  5.75it/s]Train batch 6400
Avg. loss per last 100 batches: 1.131991
6400it [21:17,  5.75it/s]Epoch: 4: Step: 6401/28124, loss=1.143412, lr=0.000008
6499it [21:34,  5.41it/s]Train batch 6500
Avg. loss per last 100 batches: 1.100428
6500it [21:35,  5.38it/s]Epoch: 4: Step: 6501/28124, loss=1.402532, lr=0.000008
6599it [21:52,  5.72it/s]Train batch 6600
Avg. loss per last 100 batches: 1.106444
6600it [21:52,  5.73it/s]Epoch: 4: Step: 6601/28124, loss=1.176421, lr=0.000008
6699it [22:10,  5.74it/s]Train batch 6700
Avg. loss per last 100 batches: 1.155367
6700it [22:10,  5.74it/s]Epoch: 4: Step: 6701/28124, loss=1.257669, lr=0.000008
6799it [22:27,  5.69it/s]Train batch 6800
Avg. loss per last 100 batches: 1.128239
6800it [22:27,  5.70it/s]Epoch: 4: Step: 6801/28124, loss=1.204863, lr=0.000008
6899it [22:45,  5.74it/s]Train batch 6900
Avg. loss per last 100 batches: 1.159070
6900it [22:45,  5.74it/s]Epoch: 4: Step: 6901/28124, loss=1.457546, lr=0.000008
6999it [23:02,  5.72it/s]Train batch 7000
Avg. loss per last 100 batches: 1.121750
7000it [23:02,  5.73it/s]Epoch: 4: Step: 7001/28124, loss=0.854891, lr=0.000008
7099it [23:20,  5.75it/s]Train batch 7100
Avg. loss per last 100 batches: 1.100334
7100it [23:20,  5.72it/s]Epoch: 4: Step: 7101/28124, loss=1.225896, lr=0.000008
7199it [23:37,  5.73it/s]Train batch 7200
Avg. loss per last 100 batches: 1.090649
7200it [23:37,  5.74it/s]Epoch: 4: Step: 7201/28124, loss=1.328247, lr=0.000008
7299it [23:55,  5.73it/s]Train batch 7300
Avg. loss per last 100 batches: 1.114221
7300it [23:55,  5.73it/s]Epoch: 4: Step: 7301/28124, loss=1.166925, lr=0.000008
7399it [24:12,  5.40it/s]Train batch 7400
Avg. loss per last 100 batches: 1.121640
7400it [24:13,  5.37it/s]Epoch: 4: Step: 7401/28124, loss=1.100796, lr=0.000008
7499it [24:30,  5.71it/s]Train batch 7500
Avg. loss per last 100 batches: 1.131925
7500it [24:30,  5.46it/s]Epoch: 4: Step: 7501/28124, loss=1.570208, lr=0.000008
7599it [24:47,  5.73it/s]Train batch 7600
Avg. loss per last 100 batches: 1.084095
7600it [24:48,  5.72it/s]Epoch: 4: Step: 7601/28124, loss=1.400429, lr=0.000008
7699it [25:05,  5.72it/s]Train batch 7700
Avg. loss per last 100 batches: 1.124996
7700it [25:05,  5.73it/s]Epoch: 4: Step: 7701/28124, loss=1.296870, lr=0.000008
7799it [25:23,  5.74it/s]Train batch 7800
Avg. loss per last 100 batches: 1.129153
7800it [25:23,  5.73it/s]Epoch: 4: Step: 7801/28124, loss=0.938774, lr=0.000008
7899it [25:40,  5.69it/s]Train batch 7900
Avg. loss per last 100 batches: 1.170038
7900it [25:40,  5.64it/s]Epoch: 4: Step: 7901/28124, loss=1.244326, lr=0.000008
7999it [25:58,  5.73it/s]Train batch 8000
Avg. loss per last 100 batches: 1.113568
8000it [25:58,  5.74it/s]Epoch: 4: Step: 8001/28124, loss=0.605387, lr=0.000008
8099it [26:15,  5.73it/s]Train batch 8100
Avg. loss per last 100 batches: 1.141966
8100it [26:15,  5.74it/s]Epoch: 4: Step: 8101/28124, loss=1.245117, lr=0.000008
8199it [26:33,  5.75it/s]Train batch 8200
Avg. loss per last 100 batches: 1.130972
8200it [26:33,  5.73it/s]Epoch: 4: Step: 8201/28124, loss=0.758375, lr=0.000008
8299it [26:50,  5.66it/s]Train batch 8300
Avg. loss per last 100 batches: 1.105814
8300it [26:50,  5.48it/s]Epoch: 4: Step: 8301/28124, loss=1.059624, lr=0.000008
8399it [27:08,  5.75it/s]Train batch 8400
Avg. loss per last 100 batches: 1.132986
8400it [27:08,  5.72it/s]Epoch: 4: Step: 8401/28124, loss=1.342504, lr=0.000008
8499it [27:25,  5.69it/s]Train batch 8500
Avg. loss per last 100 batches: 1.055861
8500it [27:25,  5.69it/s]Epoch: 4: Step: 8501/28124, loss=1.459258, lr=0.000008
8599it [27:43,  5.73it/s]Train batch 8600
Avg. loss per last 100 batches: 1.085674
8600it [27:43,  5.74it/s]Epoch: 4: Step: 8601/28124, loss=0.886479, lr=0.000008
8699it [28:00,  5.74it/s]Train batch 8700
Avg. loss per last 100 batches: 1.056994
8700it [28:01,  5.72it/s]Epoch: 4: Step: 8701/28124, loss=1.560707, lr=0.000008
8799it [28:18,  5.72it/s]Train batch 8800
Avg. loss per last 100 batches: 1.100080
8800it [28:18,  5.73it/s]Epoch: 4: Step: 8801/28124, loss=1.870764, lr=0.000008
8899it [28:35,  5.74it/s]Train batch 8900
Avg. loss per last 100 batches: 1.150755
8900it [28:36,  5.72it/s]Epoch: 4: Step: 8901/28124, loss=1.440967, lr=0.000008
8999it [28:53,  5.70it/s]Train batch 9000
Avg. loss per last 100 batches: 1.145744
9000it [28:53,  5.71it/s]Epoch: 4: Step: 9001/28124, loss=1.149262, lr=0.000008
9099it [29:11,  5.72it/s]Train batch 9100
Avg. loss per last 100 batches: 1.105491
9100it [29:11,  5.71it/s]Epoch: 4: Step: 9101/28124, loss=1.702683, lr=0.000008
9199it [29:28,  5.70it/s]Train batch 9200
Avg. loss per last 100 batches: 1.140547
9200it [29:28,  5.71it/s]Epoch: 4: Step: 9201/28124, loss=0.963742, lr=0.000008
9299it [29:46,  5.71it/s]Train batch 9300
Avg. loss per last 100 batches: 1.123743
9300it [29:46,  5.69it/s]Epoch: 4: Step: 9301/28124, loss=0.933314, lr=0.000008
9399it [30:03,  5.64it/s]Train batch 9400
Avg. loss per last 100 batches: 1.142710
9400it [30:04,  5.67it/s]Epoch: 4: Step: 9401/28124, loss=0.937654, lr=0.000008
9499it [30:21,  5.66it/s]Train batch 9500
Avg. loss per last 100 batches: 1.100120
9500it [30:21,  5.65it/s]Epoch: 4: Step: 9501/28124, loss=1.233649, lr=0.000008
9599it [30:39,  5.67it/s]Train batch 9600
Avg. loss per last 100 batches: 1.152978
9600it [30:39,  5.69it/s]Epoch: 4: Step: 9601/28124, loss=1.379615, lr=0.000008
9699it [30:56,  5.72it/s]Train batch 9700
Avg. loss per last 100 batches: 1.141316
9700it [30:56,  5.70it/s]Epoch: 4: Step: 9701/28124, loss=1.450444, lr=0.000008
9799it [31:14,  5.71it/s]Train batch 9800
Avg. loss per last 100 batches: 1.100141
9800it [31:14,  5.72it/s]Epoch: 4: Step: 9801/28124, loss=1.523103, lr=0.000008
9899it [31:31,  5.69it/s]Train batch 9900
Avg. loss per last 100 batches: 1.152370
9900it [31:32,  5.72it/s]Epoch: 4: Step: 9901/28124, loss=1.561010, lr=0.000008
9999it [31:49,  5.72it/s]Train batch 10000
Avg. loss per last 100 batches: 1.097455
10000it [31:49,  5.73it/s]Epoch: 4: Step: 10001/28124, loss=0.807503, lr=0.000008
10099it [32:06,  5.74it/s]Train batch 10100
Avg. loss per last 100 batches: 1.125251
10100it [32:07,  5.74it/s]Epoch: 4: Step: 10101/28124, loss=1.156381, lr=0.000008
10199it [32:24,  5.74it/s]Train batch 10200
Avg. loss per last 100 batches: 1.129603
10200it [32:24,  5.74it/s]Epoch: 4: Step: 10201/28124, loss=1.515586, lr=0.000008
10299it [32:42,  5.44it/s]Train batch 10300
Avg. loss per last 100 batches: 1.117431
10300it [32:42,  5.51it/s]Epoch: 4: Step: 10301/28124, loss=0.975448, lr=0.000008
10399it [32:59,  5.73it/s]Train batch 10400
Avg. loss per last 100 batches: 1.066222
10400it [32:59,  5.71it/s]Epoch: 4: Step: 10401/28124, loss=0.690114, lr=0.000008
10499it [33:17,  5.70it/s]Train batch 10500
Avg. loss per last 100 batches: 1.110887
10500it [33:17,  5.71it/s]Epoch: 4: Step: 10501/28124, loss=0.842824, lr=0.000008
10599it [33:34,  5.73it/s]Train batch 10600
Avg. loss per last 100 batches: 1.081648
10600it [33:34,  5.72it/s]Epoch: 4: Step: 10601/28124, loss=1.454190, lr=0.000008
10699it [33:52,  5.75it/s]Train batch 10700
Avg. loss per last 100 batches: 1.109326
10700it [33:52,  5.75it/s]Epoch: 4: Step: 10701/28124, loss=1.686601, lr=0.000008
10799it [34:09,  5.73it/s]Train batch 10800
Avg. loss per last 100 batches: 1.113832
10800it [34:09,  5.72it/s]Epoch: 4: Step: 10801/28124, loss=1.031784, lr=0.000008
10899it [34:27,  5.72it/s]Train batch 10900
Avg. loss per last 100 batches: 1.116912
10900it [34:27,  5.72it/s]Epoch: 4: Step: 10901/28124, loss=0.924954, lr=0.000008
10999it [34:44,  5.73it/s]Train batch 11000
Avg. loss per last 100 batches: 1.091899
11000it [34:45,  5.74it/s]Epoch: 4: Step: 11001/28124, loss=1.294727, lr=0.000008
11099it [35:02,  5.74it/s]Train batch 11100
Avg. loss per last 100 batches: 1.107180
11100it [35:02,  5.74it/s]Epoch: 4: Step: 11101/28124, loss=0.887879, lr=0.000007
11199it [35:20,  5.33it/s]Train batch 11200
Avg. loss per last 100 batches: 1.140963
11200it [35:20,  5.37it/s]Epoch: 4: Step: 11201/28124, loss=1.544045, lr=0.000007
11249it [35:28,  5.73it/s]Validation: Epoch: 4 Step: 11250/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.337268 sec., loss=0.778042 
Eval step: 199 , used_time=8.615382 sec., loss=1.175278 
Eval step: 299 , used_time=12.945972 sec., loss=0.716508 
Eval step: 399 , used_time=17.251873 sec., loss=1.360421 
Eval step: 499 , used_time=21.553452 sec., loss=1.149416 
Eval step: 599 , used_time=26.051906 sec., loss=1.456835 
Eval step: 699 , used_time=30.348853 sec., loss=1.491190 
Eval step: 799 , used_time=34.658068 sec., loss=1.106096 
Eval step: 899 , used_time=38.932650 sec., loss=1.096135 
Eval step: 999 , used_time=43.264450 sec., loss=1.087496 
Eval step: 1099 , used_time=47.568371 sec., loss=0.819120 
Eval step: 1199 , used_time=51.877457 sec., loss=1.049566 
Eval step: 1299 , used_time=56.351075 sec., loss=0.758753 
Eval step: 1399 , used_time=60.641748 sec., loss=0.515093 
Eval step: 1499 , used_time=64.965077 sec., loss=0.606245 
Eval step: 1599 , used_time=69.241013 sec., loss=1.021238 
Eval step: 1699 , used_time=73.550292 sec., loss=0.702713 
Eval step: 1799 , used_time=77.870225 sec., loss=0.665204 
Eval step: 1899 , used_time=82.178974 sec., loss=0.671397 
Eval step: 1999 , used_time=86.642189 sec., loss=1.541042 
Eval step: 2099 , used_time=90.922863 sec., loss=0.655943 
Eval step: 2199 , used_time=95.218893 sec., loss=0.952237 
Eval step: 2299 , used_time=99.511149 sec., loss=0.334342 
Eval step: 2399 , used_time=103.836217 sec., loss=1.237424 
Eval step: 2499 , used_time=108.144995 sec., loss=0.871218 
Eval step: 2599 , used_time=112.473890 sec., loss=1.250961 
Eval step: 2699 , used_time=116.748762 sec., loss=0.978148 
Eval step: 2799 , used_time=121.235313 sec., loss=1.173340 
Eval step: 2899 , used_time=125.534856 sec., loss=0.691112 
Eval step: 2999 , used_time=129.818820 sec., loss=0.833724 
Eval step: 3099 , used_time=134.131140 sec., loss=0.993069 
NLL Validation: loss = 0.978571. correct prediction ratio  73118/100032 ~  0.730946
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [37:58,  5.72it/s]Train batch 11300
Avg. loss per last 100 batches: 1.157758
11300it [37:58,  5.63it/s]Epoch: 4: Step: 11301/28124, loss=0.689905, lr=0.000007
11399it [38:15,  5.72it/s]Train batch 11400
Avg. loss per last 100 batches: 1.133455
11400it [38:15,  5.73it/s]Epoch: 4: Step: 11401/28124, loss=0.851225, lr=0.000007
11499it [38:33,  5.70it/s]Train batch 11500
Avg. loss per last 100 batches: 1.073283
11500it [38:33,  5.70it/s]Epoch: 4: Step: 11501/28124, loss=1.339503, lr=0.000007
11599it [38:50,  5.69it/s]Train batch 11600
Avg. loss per last 100 batches: 1.124057
11600it [38:51,  5.70it/s]Epoch: 4: Step: 11601/28124, loss=1.276566, lr=0.000007
11699it [39:08,  5.71it/s]Train batch 11700
Avg. loss per last 100 batches: 1.140066
11700it [39:08,  5.72it/s]Epoch: 4: Step: 11701/28124, loss=0.750350, lr=0.000007
11799it [39:25,  5.73it/s]Train batch 11800
Avg. loss per last 100 batches: 1.156740
11800it [39:26,  5.74it/s]Epoch: 4: Step: 11801/28124, loss=1.297915, lr=0.000007
11899it [39:43,  5.74it/s]Train batch 11900
Avg. loss per last 100 batches: 1.131560
11900it [39:43,  5.75it/s]Epoch: 4: Step: 11901/28124, loss=0.703955, lr=0.000007
11999it [40:01,  5.64it/s]Train batch 12000
Avg. loss per last 100 batches: 1.117432
12000it [40:01,  5.66it/s]Epoch: 4: Step: 12001/28124, loss=1.556349, lr=0.000007
12099it [40:18,  5.69it/s]Train batch 12100
Avg. loss per last 100 batches: 1.118543
12100it [40:18,  5.67it/s]Epoch: 4: Step: 12101/28124, loss=1.083418, lr=0.000007
12199it [40:36,  5.69it/s]Train batch 12200
Avg. loss per last 100 batches: 1.100339
12200it [40:36,  5.68it/s]Epoch: 4: Step: 12201/28124, loss=0.906052, lr=0.000007
12299it [40:53,  5.72it/s]Train batch 12300
Avg. loss per last 100 batches: 1.151395
12300it [40:53,  5.71it/s]Epoch: 4: Step: 12301/28124, loss=1.303440, lr=0.000007
12399it [41:11,  5.55it/s]Train batch 12400
Avg. loss per last 100 batches: 1.156179
12400it [41:11,  5.58it/s]Epoch: 4: Step: 12401/28124, loss=1.139523, lr=0.000007
12499it [41:29,  5.74it/s]Train batch 12500
Avg. loss per last 100 batches: 1.142434
12500it [41:29,  5.73it/s]Epoch: 4: Step: 12501/28124, loss=1.120022, lr=0.000007
12599it [41:46,  5.72it/s]Train batch 12600
Avg. loss per last 100 batches: 1.119238
12600it [41:46,  5.72it/s]Epoch: 4: Step: 12601/28124, loss=0.965743, lr=0.000007
12699it [42:04,  5.73it/s]Train batch 12700
Avg. loss per last 100 batches: 1.160901
12700it [42:04,  5.72it/s]Epoch: 4: Step: 12701/28124, loss=1.400045, lr=0.000007
12799it [42:21,  5.67it/s]Train batch 12800
Avg. loss per last 100 batches: 1.084259
12800it [42:21,  5.67it/s]Epoch: 4: Step: 12801/28124, loss=1.052859, lr=0.000007
12899it [42:39,  5.72it/s]Train batch 12900
Avg. loss per last 100 batches: 1.062986
12900it [42:39,  5.73it/s]Epoch: 4: Step: 12901/28124, loss=0.878212, lr=0.000007
12999it [42:56,  5.71it/s]Train batch 13000
Avg. loss per last 100 batches: 1.101087
13000it [42:57,  5.70it/s]Epoch: 4: Step: 13001/28124, loss=1.275023, lr=0.000007
13099it [43:14,  5.75it/s]Train batch 13100
Avg. loss per last 100 batches: 1.134351
13100it [43:14,  5.72it/s]Epoch: 4: Step: 13101/28124, loss=1.046854, lr=0.000007
13199it [43:32,  5.67it/s]Train batch 13200
Avg. loss per last 100 batches: 1.104174
13200it [43:32,  5.68it/s]Epoch: 4: Step: 13201/28124, loss=1.069329, lr=0.000007
13299it [43:49,  5.65it/s]Train batch 13300
Avg. loss per last 100 batches: 1.145774
13300it [43:49,  5.67it/s]Epoch: 4: Step: 13301/28124, loss=1.262179, lr=0.000007
13399it [44:07,  5.70it/s]Train batch 13400
Avg. loss per last 100 batches: 1.109130
13400it [44:07,  5.70it/s]Epoch: 4: Step: 13401/28124, loss=1.050248, lr=0.000007
13499it [44:25,  5.70it/s]Train batch 13500
Avg. loss per last 100 batches: 1.118055
13500it [44:25,  5.70it/s]Epoch: 4: Step: 13501/28124, loss=1.306103, lr=0.000007
13599it [44:42,  5.71it/s]Train batch 13600
Avg. loss per last 100 batches: 1.073275
13600it [44:42,  5.69it/s]Epoch: 4: Step: 13601/28124, loss=1.542494, lr=0.000007
13699it [45:00,  5.72it/s]Train batch 13700
Avg. loss per last 100 batches: 1.138954
13700it [45:00,  5.72it/s]Epoch: 4: Step: 13701/28124, loss=1.089988, lr=0.000007
13799it [45:17,  5.72it/s]Train batch 13800
Avg. loss per last 100 batches: 1.098192
13800it [45:18,  5.73it/s]Epoch: 4: Step: 13801/28124, loss=1.378849, lr=0.000007
13899it [45:35,  5.73it/s]Train batch 13900
Avg. loss per last 100 batches: 1.152156
13900it [45:35,  5.71it/s]Epoch: 4: Step: 13901/28124, loss=1.340347, lr=0.000007
13999it [45:53,  5.73it/s]Train batch 14000
Avg. loss per last 100 batches: 1.160711
14000it [45:53,  5.71it/s]Epoch: 4: Step: 14001/28124, loss=0.758756, lr=0.000007
14099it [46:10,  5.68it/s]Train batch 14100
Avg. loss per last 100 batches: 1.159069
14100it [46:10,  5.65it/s]Epoch: 4: Step: 14101/28124, loss=1.261219, lr=0.000007
14199it [46:28,  5.66it/s]Train batch 14200
Avg. loss per last 100 batches: 1.126306
14200it [46:28,  5.68it/s]Epoch: 4: Step: 14201/28124, loss=1.482266, lr=0.000007
14299it [46:45,  5.72it/s]Train batch 14300
Avg. loss per last 100 batches: 1.099018
14300it [46:45,  5.71it/s]Epoch: 4: Step: 14301/28124, loss=1.069739, lr=0.000007
14399it [47:03,  5.74it/s]Train batch 14400
Avg. loss per last 100 batches: 1.063024
14400it [47:03,  5.73it/s]Epoch: 4: Step: 14401/28124, loss=1.203207, lr=0.000007
14499it [47:20,  5.57it/s]Train batch 14500
Avg. loss per last 100 batches: 1.063662
14500it [47:21,  5.61it/s]Epoch: 4: Step: 14501/28124, loss=1.133419, lr=0.000007
14599it [47:38,  5.73it/s]Train batch 14600
Avg. loss per last 100 batches: 1.110499
14600it [47:38,  5.73it/s]Epoch: 4: Step: 14601/28124, loss=1.266843, lr=0.000007
14699it [47:55,  5.75it/s]Train batch 14700
Avg. loss per last 100 batches: 1.142230
14700it [47:56,  5.76it/s]Epoch: 4: Step: 14701/28124, loss=0.653831, lr=0.000007
14799it [48:13,  5.74it/s]Train batch 14800
Avg. loss per last 100 batches: 1.135111
14800it [48:13,  5.73it/s]Epoch: 4: Step: 14801/28124, loss=0.686189, lr=0.000007
14899it [48:31,  5.60it/s]Train batch 14900
Avg. loss per last 100 batches: 1.190331
14900it [48:31,  5.63it/s]Epoch: 4: Step: 14901/28124, loss=1.355765, lr=0.000007
14999it [48:48,  5.73it/s]Train batch 15000
Avg. loss per last 100 batches: 1.043107
15000it [48:48,  5.72it/s]Epoch: 4: Step: 15001/28124, loss=1.332124, lr=0.000007
15099it [49:06,  5.41it/s]Train batch 15100
Avg. loss per last 100 batches: 1.130828
15100it [49:06,  5.40it/s]Epoch: 4: Step: 15101/28124, loss=1.210100, lr=0.000007
15199it [49:23,  5.72it/s]Train batch 15200
Avg. loss per last 100 batches: 1.118071
15200it [49:23,  5.72it/s]Epoch: 4: Step: 15201/28124, loss=0.891218, lr=0.000007
15299it [49:41,  5.63it/s]Train batch 15300
Avg. loss per last 100 batches: 1.129955
15300it [49:41,  5.65it/s]Epoch: 4: Step: 15301/28124, loss=0.866960, lr=0.000007
15399it [49:58,  5.74it/s]Train batch 15400
Avg. loss per last 100 batches: 1.082844
15400it [49:59,  5.72it/s]Epoch: 4: Step: 15401/28124, loss=1.197856, lr=0.000007
15499it [50:16,  5.73it/s]Train batch 15500
Avg. loss per last 100 batches: 1.106974
15500it [50:16,  5.72it/s]Epoch: 4: Step: 15501/28124, loss=0.937667, lr=0.000007
15599it [50:34,  5.72it/s]Train batch 15600
Avg. loss per last 100 batches: 1.112388
15600it [50:34,  5.73it/s]Epoch: 4: Step: 15601/28124, loss=1.549015, lr=0.000007
15699it [50:51,  5.73it/s]Train batch 15700
Avg. loss per last 100 batches: 1.162348
15700it [50:51,  5.74it/s]Epoch: 4: Step: 15701/28124, loss=1.217207, lr=0.000007
15799it [51:09,  5.74it/s]Train batch 15800
Avg. loss per last 100 batches: 1.071320
15800it [51:09,  5.71it/s]Epoch: 4: Step: 15801/28124, loss=1.177109, lr=0.000007
15899it [51:26,  5.72it/s]Train batch 15900
Avg. loss per last 100 batches: 1.141491
15900it [51:26,  5.71it/s]Epoch: 4: Step: 15901/28124, loss=0.900877, lr=0.000007
15999it [51:44,  5.34it/s]Train batch 16000
Avg. loss per last 100 batches: 1.145702
16000it [51:44,  5.28it/s]Epoch: 4: Step: 16001/28124, loss=0.934565, lr=0.000007
16099it [52:01,  5.71it/s]Train batch 16100
Avg. loss per last 100 batches: 1.134600
16100it [52:01,  5.72it/s]Epoch: 4: Step: 16101/28124, loss=1.141455, lr=0.000007
16199it [52:19,  5.69it/s]Train batch 16200
Avg. loss per last 100 batches: 1.076793
16200it [52:19,  5.71it/s]Epoch: 4: Step: 16201/28124, loss=0.811773, lr=0.000007
16299it [52:36,  5.74it/s]Train batch 16300
Avg. loss per last 100 batches: 1.118259
16300it [52:37,  5.72it/s]Epoch: 4: Step: 16301/28124, loss=1.114525, lr=0.000007
16399it [52:54,  5.72it/s]Train batch 16400
Avg. loss per last 100 batches: 1.121003
16400it [52:54,  5.72it/s]Epoch: 4: Step: 16401/28124, loss=0.658733, lr=0.000007
16499it [53:12,  5.67it/s]Train batch 16500
Avg. loss per last 100 batches: 1.123895
16500it [53:12,  5.69it/s]Epoch: 4: Step: 16501/28124, loss=1.010481, lr=0.000007
16599it [53:29,  5.73it/s]Train batch 16600
Avg. loss per last 100 batches: 1.090624
16600it [53:29,  5.73it/s]Epoch: 4: Step: 16601/28124, loss=0.974797, lr=0.000007
16699it [53:47,  5.74it/s]Train batch 16700
Avg. loss per last 100 batches: 1.101025
16700it [53:47,  5.73it/s]Epoch: 4: Step: 16701/28124, loss=1.295958, lr=0.000007
16799it [54:04,  5.71it/s]Train batch 16800
Avg. loss per last 100 batches: 1.109925
16800it [54:04,  5.72it/s]Epoch: 4: Step: 16801/28124, loss=1.095144, lr=0.000007
16874it [54:17,  5.73it/s]Validation: Epoch: 4 Step: 16875/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.391339 sec., loss=0.945046 
Eval step: 199 , used_time=8.799396 sec., loss=1.136495 
Eval step: 299 , used_time=13.113061 sec., loss=0.686178 
Eval step: 399 , used_time=17.430003 sec., loss=1.369025 
Eval step: 499 , used_time=21.714200 sec., loss=1.235251 
Eval step: 599 , used_time=26.053784 sec., loss=1.545383 
Eval step: 699 , used_time=30.354138 sec., loss=1.620209 
Eval step: 799 , used_time=34.670063 sec., loss=1.132210 
Eval step: 899 , used_time=39.126475 sec., loss=1.167216 
Eval step: 999 , used_time=43.445654 sec., loss=1.130508 
Eval step: 1099 , used_time=47.755442 sec., loss=0.862930 
Eval step: 1199 , used_time=52.043072 sec., loss=1.053845 
Eval step: 1299 , used_time=56.359463 sec., loss=0.826513 
Eval step: 1399 , used_time=60.663831 sec., loss=0.451916 
Eval step: 1499 , used_time=64.984706 sec., loss=0.804064 
Eval step: 1599 , used_time=69.453610 sec., loss=1.005981 
Eval step: 1699 , used_time=73.777713 sec., loss=0.756184 
Eval step: 1799 , used_time=78.082835 sec., loss=0.730173 
Eval step: 1899 , used_time=82.404183 sec., loss=0.678203 
Eval step: 1999 , used_time=86.683492 sec., loss=1.417768 
Eval step: 2099 , used_time=90.968808 sec., loss=0.754041 
Eval step: 2199 , used_time=95.286407 sec., loss=0.880228 
Eval step: 2299 , used_time=99.644858 sec., loss=0.255472 
Eval step: 2399 , used_time=104.083661 sec., loss=1.136718 
Eval step: 2499 , used_time=108.380093 sec., loss=0.893535 
Eval step: 2599 , used_time=112.694619 sec., loss=1.362720 
Eval step: 2699 , used_time=116.976435 sec., loss=1.079468 
Eval step: 2799 , used_time=121.240896 sec., loss=1.164370 
Eval step: 2899 , used_time=125.534885 sec., loss=0.775250 
Eval step: 2999 , used_time=129.799862 sec., loss=0.990213 
Eval step: 3099 , used_time=134.339859 sec., loss=0.938515 
NLL Validation: loss = 0.965183. correct prediction ratio  73410/100032 ~  0.733865
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
16899it [56:43,  5.45it/s]Train batch 16900
Avg. loss per last 100 batches: 1.114019
16900it [56:43,  5.52it/s]Epoch: 4: Step: 16901/28124, loss=1.147178, lr=0.000007
16999it [57:00,  5.74it/s]Train batch 17000
Avg. loss per last 100 batches: 1.090850
17000it [57:00,  5.71it/s]Epoch: 4: Step: 17001/28124, loss=0.896828, lr=0.000007
17099it [57:18,  5.75it/s]Train batch 17100
Avg. loss per last 100 batches: 1.101540
17100it [57:18,  5.76it/s]Epoch: 4: Step: 17101/28124, loss=0.817149, lr=0.000007
17199it [57:35,  5.73it/s]Train batch 17200
Avg. loss per last 100 batches: 1.101739
17200it [57:35,  5.75it/s]Epoch: 4: Step: 17201/28124, loss=0.893604, lr=0.000007
17299it [57:53,  5.75it/s]Train batch 17300
Avg. loss per last 100 batches: 1.121168
17300it [57:53,  5.74it/s]Epoch: 4: Step: 17301/28124, loss=1.137212, lr=0.000007
17399it [58:10,  5.38it/s]Train batch 17400
Avg. loss per last 100 batches: 1.113745
17400it [58:11,  5.47it/s]Epoch: 4: Step: 17401/28124, loss=1.277837, lr=0.000007
17499it [58:28,  5.70it/s]Train batch 17500
Avg. loss per last 100 batches: 1.105688
17500it [58:28,  5.71it/s]Epoch: 4: Step: 17501/28124, loss=1.253997, lr=0.000007
17599it [58:45,  5.74it/s]Train batch 17600
Avg. loss per last 100 batches: 1.126894
17600it [58:46,  5.74it/s]Epoch: 4: Step: 17601/28124, loss=0.975268, lr=0.000007
17699it [59:03,  5.73it/s]Train batch 17700
Avg. loss per last 100 batches: 1.074670
17700it [59:03,  5.74it/s]Epoch: 4: Step: 17701/28124, loss=1.003357, lr=0.000007
17799it [59:20,  5.62it/s]Train batch 17800
Avg. loss per last 100 batches: 1.104161
17800it [59:21,  5.67it/s]Epoch: 4: Step: 17801/28124, loss=0.530387, lr=0.000007
17899it [59:38,  5.75it/s]Train batch 17900
Avg. loss per last 100 batches: 1.097615
17900it [59:38,  5.75it/s]Epoch: 4: Step: 17901/28124, loss=0.659508, lr=0.000007
17999it [59:55,  5.75it/s]Train batch 18000
Avg. loss per last 100 batches: 1.100350
18000it [59:56,  5.76it/s]Epoch: 4: Step: 18001/28124, loss=0.990867, lr=0.000007
18099it [1:00:13,  5.52it/s]Train batch 18100
Avg. loss per last 100 batches: 1.064655
18100it [1:00:13,  5.58it/s]Epoch: 4: Step: 18101/28124, loss=1.001075, lr=0.000007
18199it [1:00:30,  5.53it/s]Train batch 18200
Avg. loss per last 100 batches: 1.110838
18200it [1:00:31,  5.57it/s]Epoch: 4: Step: 18201/28124, loss=0.811295, lr=0.000007
18299it [1:00:48,  5.73it/s]Train batch 18300
Avg. loss per last 100 batches: 1.113692
18300it [1:00:48,  5.73it/s]Epoch: 4: Step: 18301/28124, loss=0.893437, lr=0.000007
18399it [1:01:05,  5.73it/s]Train batch 18400
Avg. loss per last 100 batches: 1.090662
18400it [1:01:06,  5.73it/s]Epoch: 4: Step: 18401/28124, loss=0.886468, lr=0.000007
18499it [1:01:23,  5.74it/s]Train batch 18500
Avg. loss per last 100 batches: 1.096851
18500it [1:01:23,  5.70it/s]Epoch: 4: Step: 18501/28124, loss=1.661439, lr=0.000007
18599it [1:01:41,  5.51it/s]Train batch 18600
Avg. loss per last 100 batches: 1.107165
18600it [1:01:41,  5.57it/s]Epoch: 4: Step: 18601/28124, loss=0.822873, lr=0.000007
18699it [1:01:58,  5.74it/s]Train batch 18700
Avg. loss per last 100 batches: 1.133437
18700it [1:01:58,  5.74it/s]Epoch: 4: Step: 18701/28124, loss=1.224681, lr=0.000007
18799it [1:02:16,  5.75it/s]Train batch 18800
Avg. loss per last 100 batches: 1.084386
18800it [1:02:16,  5.73it/s]Epoch: 4: Step: 18801/28124, loss=0.974330, lr=0.000007
18899it [1:02:33,  5.73it/s]Train batch 18900
Avg. loss per last 100 batches: 1.135734
18900it [1:02:33,  5.72it/s]Epoch: 4: Step: 18901/28124, loss=1.182238, lr=0.000007
18999it [1:02:51,  5.26it/s]Train batch 19000
Avg. loss per last 100 batches: 1.114572
19000it [1:02:51,  5.24it/s]Epoch: 4: Step: 19001/28124, loss=1.394425, lr=0.000007
19099it [1:03:08,  5.74it/s]Train batch 19100
Avg. loss per last 100 batches: 1.119453
19100it [1:03:08,  5.75it/s]Epoch: 4: Step: 19101/28124, loss=1.300986, lr=0.000007
19199it [1:03:26,  5.74it/s]Train batch 19200
Avg. loss per last 100 batches: 1.095990
19200it [1:03:26,  5.75it/s]Epoch: 4: Step: 19201/28124, loss=0.919230, lr=0.000007
19299it [1:03:43,  5.73it/s]Train batch 19300
Avg. loss per last 100 batches: 1.053906
19300it [1:03:43,  5.74it/s]Epoch: 4: Step: 19301/28124, loss=1.075503, lr=0.000007
19399it [1:04:01,  5.73it/s]Train batch 19400
Avg. loss per last 100 batches: 1.026895
19400it [1:04:01,  5.74it/s]Epoch: 4: Step: 19401/28124, loss=0.985129, lr=0.000007
19499it [1:04:18,  5.73it/s]Train batch 19500
Avg. loss per last 100 batches: 1.108756
19500it [1:04:18,  5.74it/s]Epoch: 4: Step: 19501/28124, loss=0.850620, lr=0.000007
19599it [1:04:36,  5.73it/s]Train batch 19600
Avg. loss per last 100 batches: 1.109800
19600it [1:04:36,  5.74it/s]Epoch: 4: Step: 19601/28124, loss=1.023992, lr=0.000007
19699it [1:04:53,  5.72it/s]Train batch 19700
Avg. loss per last 100 batches: 1.100574
19700it [1:04:53,  5.72it/s]Epoch: 4: Step: 19701/28124, loss=0.880057, lr=0.000007
19799it [1:05:11,  5.63it/s]Train batch 19800
Avg. loss per last 100 batches: 1.078893
19800it [1:05:11,  5.66it/s]Epoch: 4: Step: 19801/28124, loss=1.306174, lr=0.000007
19899it [1:05:28,  5.73it/s]Train batch 19900
Avg. loss per last 100 batches: 1.077802
19900it [1:05:29,  5.72it/s]Epoch: 4: Step: 19901/28124, loss=0.719489, lr=0.000007
19999it [1:05:46,  5.69it/s]Train batch 20000
Avg. loss per last 100 batches: 1.133337
20000it [1:05:46,  5.70it/s]Epoch: 4: Step: 20001/28124, loss=1.037274, lr=0.000007
20099it [1:06:04,  5.69it/s]Train batch 20100
Avg. loss per last 100 batches: 1.075979
20100it [1:06:04,  5.70it/s]Epoch: 4: Step: 20101/28124, loss=0.641781, lr=0.000007
20199it [1:06:21,  5.69it/s]Train batch 20200
Avg. loss per last 100 batches: 1.094577
20200it [1:06:22,  5.70it/s]Epoch: 4: Step: 20201/28124, loss=1.119993, lr=0.000007
20299it [1:06:39,  5.68it/s]Train batch 20300
Avg. loss per last 100 batches: 1.090190
20300it [1:06:39,  5.69it/s]Epoch: 4: Step: 20301/28124, loss=1.631696, lr=0.000007
20399it [1:06:57,  5.73it/s]Train batch 20400
Avg. loss per last 100 batches: 1.129484
20400it [1:06:57,  5.70it/s]Epoch: 4: Step: 20401/28124, loss=1.361431, lr=0.000007
20499it [1:07:14,  5.70it/s]Train batch 20500
Avg. loss per last 100 batches: 1.043831
20500it [1:07:14,  5.71it/s]Epoch: 4: Step: 20501/28124, loss=1.408539, lr=0.000007
20599it [1:07:32,  5.71it/s]Train batch 20600
Avg. loss per last 100 batches: 1.088099
20600it [1:07:32,  5.72it/s]Epoch: 4: Step: 20601/28124, loss=1.143145, lr=0.000007
20699it [1:07:49,  5.66it/s]Train batch 20700
Avg. loss per last 100 batches: 1.104940
20700it [1:07:50,  5.67it/s]Epoch: 4: Step: 20701/28124, loss=0.768507, lr=0.000007
20799it [1:08:07,  5.69it/s]Train batch 20800
Avg. loss per last 100 batches: 1.123772
20800it [1:08:07,  5.70it/s]Epoch: 4: Step: 20801/28124, loss=1.102683, lr=0.000006
20899it [1:08:25,  5.75it/s]Train batch 20900
Avg. loss per last 100 batches: 1.139178
20900it [1:08:25,  5.75it/s]Epoch: 4: Step: 20901/28124, loss=0.742331, lr=0.000006
20999it [1:08:42,  5.68it/s]Train batch 21000
Avg. loss per last 100 batches: 1.090494
21000it [1:08:42,  5.70it/s]Epoch: 4: Step: 21001/28124, loss=1.104204, lr=0.000006
21099it [1:09:00,  5.77it/s]Train batch 21100
Avg. loss per last 100 batches: 1.100849
21100it [1:09:00,  5.76it/s]Epoch: 4: Step: 21101/28124, loss=1.045884, lr=0.000006
21199it [1:09:17,  5.75it/s]Train batch 21200
Avg. loss per last 100 batches: 1.081834
21200it [1:09:17,  5.72it/s]Epoch: 4: Step: 21201/28124, loss=1.200489, lr=0.000006
21299it [1:09:35,  5.71it/s]Train batch 21300
Avg. loss per last 100 batches: 1.140964
21300it [1:09:35,  5.71it/s]Epoch: 4: Step: 21301/28124, loss=1.154578, lr=0.000006
21399it [1:09:52,  5.74it/s]Train batch 21400
Avg. loss per last 100 batches: 1.083153
21400it [1:09:52,  5.73it/s]Epoch: 4: Step: 21401/28124, loss=0.872119, lr=0.000006
21499it [1:10:10,  5.74it/s]Train batch 21500
Avg. loss per last 100 batches: 1.059503
21500it [1:10:10,  5.72it/s]Epoch: 4: Step: 21501/28124, loss=0.991180, lr=0.000006
21599it [1:10:27,  5.74it/s]Train batch 21600
Avg. loss per last 100 batches: 1.127880
21600it [1:10:28,  5.75it/s]Epoch: 4: Step: 21601/28124, loss=1.014484, lr=0.000006
21699it [1:10:45,  5.72it/s]Train batch 21700
Avg. loss per last 100 batches: 1.145248
21700it [1:10:45,  5.72it/s]Epoch: 4: Step: 21701/28124, loss=1.052940, lr=0.000006
21799it [1:11:02,  5.73it/s]Train batch 21800
Avg. loss per last 100 batches: 1.093017
21800it [1:11:03,  5.72it/s]Epoch: 4: Step: 21801/28124, loss=1.181623, lr=0.000006
21899it [1:11:20,  5.61it/s]Train batch 21900
Avg. loss per last 100 batches: 1.089878
21900it [1:11:20,  5.63it/s]Epoch: 4: Step: 21901/28124, loss=1.162349, lr=0.000006
21999it [1:11:38,  5.74it/s]Train batch 22000
Avg. loss per last 100 batches: 1.129973
22000it [1:11:38,  5.74it/s]Epoch: 4: Step: 22001/28124, loss=0.844369, lr=0.000006
22099it [1:11:55,  5.73it/s]Train batch 22100
Avg. loss per last 100 batches: 1.114467
22100it [1:11:55,  5.74it/s]Epoch: 4: Step: 22101/28124, loss=1.258178, lr=0.000006
22199it [1:12:13,  5.71it/s]Train batch 22200
Avg. loss per last 100 batches: 1.077436
22200it [1:12:13,  5.71it/s]Epoch: 4: Step: 22201/28124, loss=1.146433, lr=0.000006
22299it [1:12:30,  5.39it/s]Train batch 22300
Avg. loss per last 100 batches: 1.078212
22300it [1:12:31,  5.47it/s]Epoch: 4: Step: 22301/28124, loss=1.559769, lr=0.000006
22399it [1:12:48,  5.75it/s]Train batch 22400
Avg. loss per last 100 batches: 1.134514
22400it [1:12:48,  5.72it/s]Epoch: 4: Step: 22401/28124, loss=1.433882, lr=0.000006
22499it [1:13:05,  5.71it/s]Train batch 22500
Avg. loss per last 100 batches: 1.114072
Validation: Epoch: 4 Step: 22500/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.316185 sec., loss=0.953357 
Eval step: 199 , used_time=8.603491 sec., loss=1.111487 
Eval step: 299 , used_time=12.941954 sec., loss=0.624169 
Eval step: 399 , used_time=17.428239 sec., loss=1.281288 
Eval step: 499 , used_time=21.745985 sec., loss=1.280629 
Eval step: 599 , used_time=26.038233 sec., loss=1.585263 
Eval step: 699 , used_time=30.348821 sec., loss=1.559781 
Eval step: 799 , used_time=34.623646 sec., loss=1.064204 
Eval step: 899 , used_time=38.901749 sec., loss=1.260992 
Eval step: 999 , used_time=43.219584 sec., loss=1.203948 
Eval step: 1099 , used_time=47.693682 sec., loss=0.795029 
Eval step: 1199 , used_time=52.006507 sec., loss=1.018159 
Eval step: 1299 , used_time=56.284467 sec., loss=0.742323 
Eval step: 1399 , used_time=60.591201 sec., loss=0.423594 
Eval step: 1499 , used_time=64.868918 sec., loss=0.579758 
Eval step: 1599 , used_time=69.141652 sec., loss=0.928442 
Eval step: 1699 , used_time=73.455709 sec., loss=0.796507 
Eval step: 1799 , used_time=77.753128 sec., loss=0.847857 
Eval step: 1899 , used_time=82.270031 sec., loss=0.727422 
Eval step: 1999 , used_time=86.542638 sec., loss=1.309802 
Eval step: 2099 , used_time=90.854331 sec., loss=0.751564 
Eval step: 2199 , used_time=95.130666 sec., loss=0.880961 
Eval step: 2299 , used_time=99.418180 sec., loss=0.327015 
Eval step: 2399 , used_time=103.716716 sec., loss=1.067296 
Eval step: 2499 , used_time=108.004561 sec., loss=0.860008 
Eval step: 2599 , used_time=112.515281 sec., loss=1.228731 
Eval step: 2699 , used_time=116.786225 sec., loss=0.969036 
Eval step: 2799 , used_time=121.085246 sec., loss=1.024609 
Eval step: 2899 , used_time=125.364516 sec., loss=0.746544 
Eval step: 2999 , used_time=129.661938 sec., loss=0.832151 
Eval step: 3099 , used_time=133.933286 sec., loss=0.918038 
NLL Validation: loss = 0.954102. correct prediction ratio  73789/100032 ~  0.737654
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
22500it [1:15:31, 43.64s/it]Epoch: 4: Step: 22501/28124, loss=0.987878, lr=0.000006
22599it [1:15:48,  5.74it/s]Train batch 22600
Avg. loss per last 100 batches: 1.103318
22600it [1:15:48,  5.74it/s]Epoch: 4: Step: 22601/28124, loss=0.873400, lr=0.000006
22699it [1:16:06,  5.41it/s]Train batch 22700
Avg. loss per last 100 batches: 1.161344
22700it [1:16:06,  5.40it/s]Epoch: 4: Step: 22701/28124, loss=1.017955, lr=0.000006
22799it [1:16:23,  5.73it/s]Train batch 22800
Avg. loss per last 100 batches: 1.100484
22800it [1:16:23,  5.74it/s]Epoch: 4: Step: 22801/28124, loss=1.100038, lr=0.000006
22899it [1:16:41,  5.72it/s]Train batch 22900
Avg. loss per last 100 batches: 1.101793
22900it [1:16:41,  5.74it/s]Epoch: 4: Step: 22901/28124, loss=1.049068, lr=0.000006
22999it [1:16:58,  5.72it/s]Train batch 23000
Avg. loss per last 100 batches: 1.162609
23000it [1:16:58,  5.74it/s]Epoch: 4: Step: 23001/28124, loss=0.868077, lr=0.000006
23099it [1:17:16,  5.72it/s]Train batch 23100
Avg. loss per last 100 batches: 1.078356
23100it [1:17:16,  5.73it/s]Epoch: 4: Step: 23101/28124, loss=0.939216, lr=0.000006
23199it [1:17:33,  5.72it/s]Train batch 23200
Avg. loss per last 100 batches: 1.094898
23200it [1:17:33,  5.73it/s]Epoch: 4: Step: 23201/28124, loss=0.970197, lr=0.000006
23299it [1:17:51,  5.62it/s]Train batch 23300
Avg. loss per last 100 batches: 1.112249
23300it [1:17:51,  5.64it/s]Epoch: 4: Step: 23301/28124, loss=0.920226, lr=0.000006
23399it [1:18:08,  5.70it/s]Train batch 23400
Avg. loss per last 100 batches: 1.108786
23400it [1:18:09,  5.69it/s]Epoch: 4: Step: 23401/28124, loss=1.063365, lr=0.000006
23499it [1:18:26,  5.72it/s]Train batch 23500
Avg. loss per last 100 batches: 1.072034
23500it [1:18:26,  5.70it/s]Epoch: 4: Step: 23501/28124, loss=1.596999, lr=0.000006
23599it [1:18:44,  5.40it/s]Train batch 23600
Avg. loss per last 100 batches: 1.055398
23600it [1:18:44,  5.37it/s]Epoch: 4: Step: 23601/28124, loss=0.937422, lr=0.000006
23699it [1:19:01,  5.64it/s]Train batch 23700
Avg. loss per last 100 batches: 1.119170
23700it [1:19:01,  5.66it/s]Epoch: 4: Step: 23701/28124, loss=1.659622, lr=0.000006
23799it [1:19:19,  5.75it/s]Train batch 23800
Avg. loss per last 100 batches: 1.096466
23800it [1:19:19,  5.74it/s]Epoch: 4: Step: 23801/28124, loss=1.076768, lr=0.000006
23899it [1:19:36,  5.71it/s]Train batch 23900
Avg. loss per last 100 batches: 1.106130
23900it [1:19:37,  5.68it/s]Epoch: 4: Step: 23901/28124, loss=0.857735, lr=0.000006
23999it [1:19:54,  5.71it/s]Train batch 24000
Avg. loss per last 100 batches: 1.112358
24000it [1:19:54,  5.71it/s]Epoch: 4: Step: 24001/28124, loss=1.312492, lr=0.000006
24099it [1:20:12,  5.73it/s]Train batch 24100
Avg. loss per last 100 batches: 1.087129
24100it [1:20:12,  5.70it/s]Epoch: 4: Step: 24101/28124, loss=0.975136, lr=0.000006
24199it [1:20:29,  5.75it/s]Train batch 24200
Avg. loss per last 100 batches: 1.103644
24200it [1:20:29,  5.72it/s]Epoch: 4: Step: 24201/28124, loss=0.632266, lr=0.000006
24299it [1:20:47,  5.72it/s]Train batch 24300
Avg. loss per last 100 batches: 1.137486
24300it [1:20:47,  5.73it/s]Epoch: 4: Step: 24301/28124, loss=1.241553, lr=0.000006
24399it [1:21:04,  5.74it/s]Train batch 24400
Avg. loss per last 100 batches: 1.115968
24400it [1:21:04,  5.72it/s]Epoch: 4: Step: 24401/28124, loss=1.254735, lr=0.000006
24499it [1:21:22,  5.64it/s]Train batch 24500
Avg. loss per last 100 batches: 1.109390
24500it [1:21:22,  5.53it/s]Epoch: 4: Step: 24501/28124, loss=1.158641, lr=0.000006
24599it [1:21:39,  5.71it/s]Train batch 24600
Avg. loss per last 100 batches: 1.098166
24600it [1:21:39,  5.72it/s]Epoch: 4: Step: 24601/28124, loss=1.351955, lr=0.000006
24699it [1:21:57,  5.74it/s]Train batch 24700
Avg. loss per last 100 batches: 1.141984
24700it [1:21:57,  5.73it/s]Epoch: 4: Step: 24701/28124, loss=1.024316, lr=0.000006
24799it [1:22:14,  5.67it/s]Train batch 24800
Avg. loss per last 100 batches: 1.129739
24800it [1:22:15,  5.67it/s]Epoch: 4: Step: 24801/28124, loss=0.917187, lr=0.000006
24899it [1:22:32,  5.74it/s]Train batch 24900
Avg. loss per last 100 batches: 1.092411
24900it [1:22:32,  5.74it/s]Epoch: 4: Step: 24901/28124, loss=1.025051, lr=0.000006
24999it [1:22:49,  5.74it/s]Train batch 25000
Avg. loss per last 100 batches: 1.125197
25000it [1:22:50,  5.75it/s]Epoch: 4: Step: 25001/28124, loss=1.060520, lr=0.000006
25099it [1:23:07,  5.72it/s]Train batch 25100
Avg. loss per last 100 batches: 1.090190
25100it [1:23:07,  5.73it/s]Epoch: 4: Step: 25101/28124, loss=0.693521, lr=0.000006
25199it [1:23:25,  5.73it/s]Train batch 25200
Avg. loss per last 100 batches: 1.094555
25200it [1:23:25,  5.71it/s]Epoch: 4: Step: 25201/28124, loss=1.215204, lr=0.000006
25299it [1:23:42,  5.73it/s]Train batch 25300
Avg. loss per last 100 batches: 1.125338
25300it [1:23:42,  5.72it/s]Epoch: 4: Step: 25301/28124, loss=0.996180, lr=0.000006
25399it [1:24:00,  5.75it/s]Train batch 25400
Avg. loss per last 100 batches: 1.056865
25400it [1:24:00,  5.75it/s]Epoch: 4: Step: 25401/28124, loss=0.833353, lr=0.000006
25499it [1:24:17,  5.73it/s]Train batch 25500
Avg. loss per last 100 batches: 1.122266
25500it [1:24:17,  5.73it/s]Epoch: 4: Step: 25501/28124, loss=0.847430, lr=0.000006
25599it [1:24:35,  5.66it/s]Train batch 25600
Avg. loss per last 100 batches: 1.087270
25600it [1:24:35,  5.64it/s]Epoch: 4: Step: 25601/28124, loss=1.210107, lr=0.000006
25699it [1:24:52,  5.72it/s]Train batch 25700
Avg. loss per last 100 batches: 1.106337
25700it [1:24:53,  5.72it/s]Epoch: 4: Step: 25701/28124, loss=1.356745, lr=0.000006
25799it [1:25:10,  5.72it/s]Train batch 25800
Avg. loss per last 100 batches: 1.116027
25800it [1:25:10,  5.65it/s]Epoch: 4: Step: 25801/28124, loss=0.811276, lr=0.000006
25899it [1:25:27,  5.73it/s]Train batch 25900
Avg. loss per last 100 batches: 1.062243
25900it [1:25:28,  5.73it/s]Epoch: 4: Step: 25901/28124, loss=1.485232, lr=0.000006
25999it [1:25:45,  5.71it/s]Train batch 26000
Avg. loss per last 100 batches: 1.118982
26000it [1:25:45,  5.69it/s]Epoch: 4: Step: 26001/28124, loss=1.622716, lr=0.000006
26099it [1:26:03,  5.72it/s]Train batch 26100
Avg. loss per last 100 batches: 1.098406
26100it [1:26:03,  5.71it/s]Epoch: 4: Step: 26101/28124, loss=1.090415, lr=0.000006
26199it [1:26:20,  5.73it/s]Train batch 26200
Avg. loss per last 100 batches: 1.105945
26200it [1:26:20,  5.70it/s]Epoch: 4: Step: 26201/28124, loss=1.644197, lr=0.000006
26299it [1:26:38,  5.69it/s]Train batch 26300
Avg. loss per last 100 batches: 1.061216
26300it [1:26:38,  5.69it/s]Epoch: 4: Step: 26301/28124, loss=1.140474, lr=0.000006
26399it [1:26:55,  5.72it/s]Train batch 26400
Avg. loss per last 100 batches: 1.129138
26400it [1:26:55,  5.73it/s]Epoch: 4: Step: 26401/28124, loss=0.907459, lr=0.000006
26499it [1:27:13,  5.59it/s]Train batch 26500
Avg. loss per last 100 batches: 1.068712
26500it [1:27:13,  5.64it/s]Epoch: 4: Step: 26501/28124, loss=0.715055, lr=0.000006
26599it [1:27:30,  5.62it/s]Train batch 26600
Avg. loss per last 100 batches: 1.101451
26600it [1:27:31,  5.64it/s]Epoch: 4: Step: 26601/28124, loss=1.224398, lr=0.000006
26699it [1:27:48,  5.73it/s]Train batch 26700
Avg. loss per last 100 batches: 1.115944
26700it [1:27:48,  5.74it/s]Epoch: 4: Step: 26701/28124, loss=1.386587, lr=0.000006
26799it [1:28:05,  5.76it/s]Train batch 26800
Avg. loss per last 100 batches: 1.073332
26800it [1:28:06,  5.75it/s]Epoch: 4: Step: 26801/28124, loss=1.251029, lr=0.000006
26899it [1:28:23,  5.73it/s]Train batch 26900
Avg. loss per last 100 batches: 1.116985
26900it [1:28:23,  5.71it/s]Epoch: 4: Step: 26901/28124, loss=1.645153, lr=0.000006
26999it [1:28:41,  5.64it/s]Train batch 27000
Avg. loss per last 100 batches: 1.095921
27000it [1:28:41,  5.65it/s]Epoch: 4: Step: 27001/28124, loss=0.797398, lr=0.000006
27099it [1:28:58,  5.73it/s]Train batch 27100
Avg. loss per last 100 batches: 1.142000
27100it [1:28:58,  5.73it/s]Epoch: 4: Step: 27101/28124, loss=0.992503, lr=0.000006
27199it [1:29:16,  5.75it/s]Train batch 27200
Avg. loss per last 100 batches: 1.084840
27200it [1:29:16,  5.75it/s]Epoch: 4: Step: 27201/28124, loss=0.777080, lr=0.000006
27299it [1:29:33,  5.70it/s]Train batch 27300
Avg. loss per last 100 batches: 1.105112
27300it [1:29:33,  5.71it/s]Epoch: 4: Step: 27301/28124, loss=1.127846, lr=0.000006
27399it [1:29:51,  5.36it/s]Train batch 27400
Avg. loss per last 100 batches: 1.104539
27400it [1:29:51,  5.35it/s]Epoch: 4: Step: 27401/28124, loss=1.607690, lr=0.000006
27499it [1:30:08,  5.70it/s]Train batch 27500
Avg. loss per last 100 batches: 1.111468
27500it [1:30:09,  5.69it/s]Epoch: 4: Step: 27501/28124, loss=0.912040, lr=0.000006
27599it [1:30:26,  5.71it/s]Train batch 27600
Avg. loss per last 100 batches: 1.145127
27600it [1:30:26,  5.71it/s]Epoch: 4: Step: 27601/28124, loss=0.834923, lr=0.000006
27699it [1:30:44,  5.67it/s]Train batch 27700
Avg. loss per last 100 batches: 1.079369
27700it [1:30:44,  5.67it/s]Epoch: 4: Step: 27701/28124, loss=1.093056, lr=0.000006
27799it [1:31:01,  5.66it/s]Train batch 27800
Avg. loss per last 100 batches: 1.097696
27800it [1:31:02,  5.67it/s]Epoch: 4: Step: 27801/28124, loss=1.219245, lr=0.000006
27899it [1:31:19,  5.71it/s]Train batch 27900
Avg. loss per last 100 batches: 1.115366
27900it [1:31:19,  5.73it/s]Epoch: 4: Step: 27901/28124, loss=1.437474, lr=0.000006
27999it [1:31:37,  5.72it/s]Train batch 28000
Avg. loss per last 100 batches: 1.150934
28000it [1:31:37,  5.71it/s]Epoch: 4: Step: 28001/28124, loss=1.157711, lr=0.000006
28099it [1:31:54,  5.70it/s]Train batch 28100
Avg. loss per last 100 batches: 1.060190
28100it [1:31:54,  5.69it/s]Epoch: 4: Step: 28101/28124, loss=1.566300, lr=0.000006
28124it [1:31:59,  5.10it/s]
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.355160 sec., loss=0.884700 
Eval step: 199 , used_time=8.686483 sec., loss=1.207845 
Eval step: 299 , used_time=13.039027 sec., loss=0.615180 
Eval step: 399 , used_time=17.372131 sec., loss=1.249660 
Eval step: 499 , used_time=21.702209 sec., loss=1.224598 
Eval step: 599 , used_time=25.995536 sec., loss=1.569463 
Eval step: 699 , used_time=30.437286 sec., loss=1.394409 
Eval step: 799 , used_time=34.801432 sec., loss=1.064251 
Eval step: 899 , used_time=39.082285 sec., loss=1.135884 
Eval step: 999 , used_time=43.397563 sec., loss=1.215507 
Eval step: 1099 , used_time=47.727313 sec., loss=0.766944 
Eval step: 1199 , used_time=52.043096 sec., loss=1.001258 
Eval step: 1299 , used_time=56.328269 sec., loss=0.714563 
Eval step: 1399 , used_time=60.618984 sec., loss=0.488814 
Eval step: 1499 , used_time=65.106439 sec., loss=0.622511 
Eval step: 1599 , used_time=69.381608 sec., loss=0.985755 
Eval step: 1699 , used_time=73.686290 sec., loss=0.813162 
Eval step: 1799 , used_time=78.026413 sec., loss=0.727223 
Eval step: 1899 , used_time=82.346502 sec., loss=0.571641 
Eval step: 1999 , used_time=86.626564 sec., loss=1.376227 
Eval step: 2099 , used_time=90.934904 sec., loss=0.721991 
Eval step: 2199 , used_time=95.436566 sec., loss=0.862686 
Eval step: 2299 , used_time=99.717690 sec., loss=0.288092 
Eval step: 2399 , used_time=104.027188 sec., loss=1.154058 
Eval step: 2499 , used_time=108.323740 sec., loss=0.896657 
Eval step: 2599 , used_time=112.644125 sec., loss=1.255957 
Eval step: 2699 , used_time=116.939058 sec., loss=0.906372 
Eval step: 2799 , used_time=121.259772 sec., loss=1.029363 
Eval step: 2899 , used_time=125.692828 sec., loss=0.760139 
Eval step: 2999 , used_time=130.030474 sec., loss=0.822458 
Eval step: 3099 , used_time=134.366880 sec., loss=0.839197 
NLL Validation: loss = 0.939182. correct prediction ratio  74118/100032 ~  0.740943
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=1.110764
epoch total correct predictions=619154
***** Epoch 5 *****
0it [00:00, ?it/s]Epoch: 5: Step: 1/28124, loss=0.852766, lr=0.000006
99it [00:18,  5.68it/s]Train batch 100
Avg. loss per last 100 batches: 0.985563
100it [00:18,  5.70it/s]Epoch: 5: Step: 101/28124, loss=1.134830, lr=0.000006
199it [00:36,  5.69it/s]Train batch 200
Avg. loss per last 100 batches: 1.019833
200it [00:36,  5.71it/s]Epoch: 5: Step: 201/28124, loss=1.218065, lr=0.000006
299it [00:53,  5.73it/s]Train batch 300
Avg. loss per last 100 batches: 0.984892
300it [00:53,  5.71it/s]Epoch: 5: Step: 301/28124, loss=0.765331, lr=0.000006
399it [01:11,  5.66it/s]Train batch 400
Avg. loss per last 100 batches: 0.990379
400it [01:11,  5.67it/s]Epoch: 5: Step: 401/28124, loss=1.472055, lr=0.000006
499it [01:28,  5.70it/s]Train batch 500
Avg. loss per last 100 batches: 1.031565
500it [01:29,  5.69it/s]Epoch: 5: Step: 501/28124, loss=0.861510, lr=0.000006
599it [01:46,  5.73it/s]Train batch 600
Avg. loss per last 100 batches: 0.945268
600it [01:46,  5.71it/s]Epoch: 5: Step: 601/28124, loss=0.778407, lr=0.000006
699it [02:04,  5.72it/s]Train batch 700
Avg. loss per last 100 batches: 0.974798
700it [02:04,  5.73it/s]Epoch: 5: Step: 701/28124, loss=1.416839, lr=0.000006
799it [02:21,  5.69it/s]Train batch 800
Avg. loss per last 100 batches: 0.998129
800it [02:21,  5.68it/s]Epoch: 5: Step: 801/28124, loss=1.250147, lr=0.000006
899it [02:39,  5.71it/s]Train batch 900
Avg. loss per last 100 batches: 0.998893
900it [02:39,  5.70it/s]Epoch: 5: Step: 901/28124, loss=0.609431, lr=0.000006
999it [02:57,  5.65it/s]Train batch 1000
Avg. loss per last 100 batches: 0.968565
1000it [02:57,  5.66it/s]Epoch: 5: Step: 1001/28124, loss=0.890407, lr=0.000006
1099it [03:14,  5.72it/s]Train batch 1100
Avg. loss per last 100 batches: 0.985945
1100it [03:14,  5.71it/s]Epoch: 5: Step: 1101/28124, loss=1.094435, lr=0.000006
1199it [03:32,  5.69it/s]Train batch 1200
Avg. loss per last 100 batches: 0.955998
1200it [03:32,  5.70it/s]Epoch: 5: Step: 1201/28124, loss=0.483202, lr=0.000006
1299it [03:49,  5.73it/s]Train batch 1300
Avg. loss per last 100 batches: 0.927605
1300it [03:50,  5.71it/s]Epoch: 5: Step: 1301/28124, loss=0.650858, lr=0.000006
1399it [04:07,  5.70it/s]Train batch 1400
Avg. loss per last 100 batches: 0.994112
1400it [04:07,  5.71it/s]Epoch: 5: Step: 1401/28124, loss=0.846799, lr=0.000006
1499it [04:25,  5.71it/s]Train batch 1500
Avg. loss per last 100 batches: 0.998234
1500it [04:25,  5.71it/s]Epoch: 5: Step: 1501/28124, loss=0.978802, lr=0.000006
1599it [04:42,  5.70it/s]Train batch 1600
Avg. loss per last 100 batches: 1.017849
1600it [04:42,  5.68it/s]Epoch: 5: Step: 1601/28124, loss=0.797992, lr=0.000006
1699it [05:00,  5.70it/s]Train batch 1700
Avg. loss per last 100 batches: 0.976973
1700it [05:00,  5.69it/s]Epoch: 5: Step: 1701/28124, loss=0.906597, lr=0.000006
1799it [05:18,  5.68it/s]Train batch 1800
Avg. loss per last 100 batches: 0.964097
1800it [05:18,  5.68it/s]Epoch: 5: Step: 1801/28124, loss=1.027971, lr=0.000006
1899it [05:35,  5.62it/s]Train batch 1900
Avg. loss per last 100 batches: 0.981946
1900it [05:35,  5.64it/s]Epoch: 5: Step: 1901/28124, loss=0.863356, lr=0.000006
1999it [05:53,  5.69it/s]Train batch 2000
Avg. loss per last 100 batches: 0.950972
2000it [05:53,  5.70it/s]Epoch: 5: Step: 2001/28124, loss=0.921189, lr=0.000006
2099it [06:11,  5.51it/s]Train batch 2100
Avg. loss per last 100 batches: 0.967714
2100it [06:11,  5.55it/s]Epoch: 5: Step: 2101/28124, loss=1.176568, lr=0.000006
2199it [06:28,  5.71it/s]Train batch 2200
Avg. loss per last 100 batches: 0.989767
2200it [06:28,  5.71it/s]Epoch: 5: Step: 2201/28124, loss=0.821346, lr=0.000006
2299it [06:46,  5.70it/s]Train batch 2300
Avg. loss per last 100 batches: 0.967308
2300it [06:46,  5.70it/s]Epoch: 5: Step: 2301/28124, loss=0.688529, lr=0.000006
2399it [07:03,  5.69it/s]Train batch 2400
Avg. loss per last 100 batches: 0.974714
2400it [07:03,  5.66it/s]Epoch: 5: Step: 2401/28124, loss=1.650474, lr=0.000006
2499it [07:21,  5.72it/s]Train batch 2500
Avg. loss per last 100 batches: 0.964679
2500it [07:21,  5.71it/s]Epoch: 5: Step: 2501/28124, loss=0.585358, lr=0.000005
2599it [07:38,  5.69it/s]Train batch 2600
Avg. loss per last 100 batches: 0.991460
2600it [07:39,  5.69it/s]Epoch: 5: Step: 2601/28124, loss=0.938862, lr=0.000005
2699it [07:56,  5.70it/s]Train batch 2700
Avg. loss per last 100 batches: 1.008335
2700it [07:56,  5.71it/s]Epoch: 5: Step: 2701/28124, loss=0.618793, lr=0.000005
2799it [08:14,  5.60it/s]Train batch 2800
Avg. loss per last 100 batches: 0.995433
2800it [08:14,  5.64it/s]Epoch: 5: Step: 2801/28124, loss=0.874364, lr=0.000005
2899it [08:31,  5.70it/s]Train batch 2900
Avg. loss per last 100 batches: 0.997865
2900it [08:32,  5.70it/s]Epoch: 5: Step: 2901/28124, loss=0.749029, lr=0.000005
2999it [08:49,  5.66it/s]Train batch 3000
Avg. loss per last 100 batches: 0.980651
3000it [08:49,  5.68it/s]Epoch: 5: Step: 3001/28124, loss=0.927117, lr=0.000005
3099it [09:07,  5.67it/s]Train batch 3100
Avg. loss per last 100 batches: 0.972329
3100it [09:07,  5.67it/s]Epoch: 5: Step: 3101/28124, loss=0.712465, lr=0.000005
3199it [09:24,  5.68it/s]Train batch 3200
Avg. loss per last 100 batches: 0.969975
3200it [09:25,  5.68it/s]Epoch: 5: Step: 3201/28124, loss=1.243204, lr=0.000005
3299it [09:42,  5.70it/s]Train batch 3300
Avg. loss per last 100 batches: 0.988944
3300it [09:42,  5.70it/s]Epoch: 5: Step: 3301/28124, loss=1.031288, lr=0.000005
3399it [10:00,  5.71it/s]Train batch 3400
Avg. loss per last 100 batches: 0.988474
3400it [10:00,  5.68it/s]Epoch: 5: Step: 3401/28124, loss=1.608172, lr=0.000005
3499it [10:17,  5.70it/s]Train batch 3500
Avg. loss per last 100 batches: 0.942903
3500it [10:17,  5.70it/s]Epoch: 5: Step: 3501/28124, loss=0.898210, lr=0.000005
3599it [10:35,  5.71it/s]Train batch 3600
Avg. loss per last 100 batches: 1.012962
3600it [10:35,  5.70it/s]Epoch: 5: Step: 3601/28124, loss=0.790707, lr=0.000005
3699it [10:53,  5.58it/s]Train batch 3700
Avg. loss per last 100 batches: 1.002957
3700it [10:53,  5.62it/s]Epoch: 5: Step: 3701/28124, loss=1.391154, lr=0.000005
3799it [11:10,  5.54it/s]Train batch 3800
Avg. loss per last 100 batches: 0.994855
3800it [11:10,  5.52it/s]Epoch: 5: Step: 3801/28124, loss=0.623766, lr=0.000005
3899it [11:28,  5.71it/s]Train batch 3900
Avg. loss per last 100 batches: 0.986581
3900it [11:28,  5.70it/s]Epoch: 5: Step: 3901/28124, loss=0.984381, lr=0.000005
3999it [11:45,  5.72it/s]Train batch 4000
Avg. loss per last 100 batches: 0.969197
4000it [11:46,  5.73it/s]Epoch: 5: Step: 4001/28124, loss=1.056840, lr=0.000005
4099it [12:03,  5.74it/s]Train batch 4100
Avg. loss per last 100 batches: 0.997910
4100it [12:03,  5.74it/s]Epoch: 5: Step: 4101/28124, loss=0.890912, lr=0.000005
4199it [12:21,  5.56it/s]Train batch 4200
Avg. loss per last 100 batches: 1.007044
4200it [12:21,  5.62it/s]Epoch: 5: Step: 4201/28124, loss=1.188084, lr=0.000005
4299it [12:38,  5.71it/s]Train batch 4300
Avg. loss per last 100 batches: 0.964001
4300it [12:38,  5.71it/s]Epoch: 5: Step: 4301/28124, loss=0.942364, lr=0.000005
4399it [12:56,  5.73it/s]Train batch 4400
Avg. loss per last 100 batches: 1.032188
4400it [12:56,  5.72it/s]Epoch: 5: Step: 4401/28124, loss=0.878007, lr=0.000005
4499it [13:13,  5.73it/s]Train batch 4500
Avg. loss per last 100 batches: 0.968009
4500it [13:14,  5.72it/s]Epoch: 5: Step: 4501/28124, loss=1.310419, lr=0.000005
4599it [13:31,  5.46it/s]Train batch 4600
Avg. loss per last 100 batches: 1.001267
4600it [13:31,  5.53it/s]Epoch: 5: Step: 4601/28124, loss=1.502982, lr=0.000005
4699it [13:48,  5.73it/s]Train batch 4700
Avg. loss per last 100 batches: 1.019195
4700it [13:49,  5.73it/s]Epoch: 5: Step: 4701/28124, loss=0.880214, lr=0.000005
4799it [14:06,  5.72it/s]Train batch 4800
Avg. loss per last 100 batches: 0.991754
4800it [14:06,  5.72it/s]Epoch: 5: Step: 4801/28124, loss=0.985460, lr=0.000005
4899it [14:24,  5.73it/s]Train batch 4900
Avg. loss per last 100 batches: 1.002420
4900it [14:24,  5.72it/s]Epoch: 5: Step: 4901/28124, loss=0.732759, lr=0.000005
4999it [14:41,  5.68it/s]Train batch 5000
Avg. loss per last 100 batches: 0.973335
5000it [14:41,  5.68it/s]Epoch: 5: Step: 5001/28124, loss=1.175932, lr=0.000005
5099it [14:59,  5.73it/s]Train batch 5100
Avg. loss per last 100 batches: 0.968975
5100it [14:59,  5.73it/s]Epoch: 5: Step: 5101/28124, loss=0.999059, lr=0.000005
5199it [15:16,  5.73it/s]Train batch 5200
Avg. loss per last 100 batches: 0.965664
5200it [15:17,  5.71it/s]Epoch: 5: Step: 5201/28124, loss=0.848602, lr=0.000005
5299it [15:34,  5.71it/s]Train batch 5300
Avg. loss per last 100 batches: 0.971595
5300it [15:34,  5.72it/s]Epoch: 5: Step: 5301/28124, loss=1.265609, lr=0.000005
5399it [15:52,  5.72it/s]Train batch 5400
Avg. loss per last 100 batches: 0.964650
5400it [15:52,  5.69it/s]Epoch: 5: Step: 5401/28124, loss=0.897730, lr=0.000005
5499it [16:09,  5.41it/s]Train batch 5500
Avg. loss per last 100 batches: 0.977651
5500it [16:09,  5.40it/s]Epoch: 5: Step: 5501/28124, loss=0.680096, lr=0.000005
5599it [16:27,  5.73it/s]Train batch 5600
Avg. loss per last 100 batches: 0.998372
5600it [16:27,  5.72it/s]Epoch: 5: Step: 5601/28124, loss=1.131687, lr=0.000005
5624it [16:31,  5.71it/s]Validation: Epoch: 5 Step: 5625/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.524232 sec., loss=0.836993 
Eval step: 199 , used_time=8.858115 sec., loss=1.215810 
Eval step: 299 , used_time=13.136802 sec., loss=0.673515 
Eval step: 399 , used_time=17.458986 sec., loss=1.396702 
Eval step: 499 , used_time=21.777767 sec., loss=1.235145 
Eval step: 599 , used_time=26.104166 sec., loss=1.492709 
Eval step: 699 , used_time=30.406610 sec., loss=1.450917 
Eval step: 799 , used_time=34.735130 sec., loss=1.239772 
Eval step: 899 , used_time=39.259276 sec., loss=1.202801 
Eval step: 999 , used_time=43.562137 sec., loss=1.197323 
Eval step: 1099 , used_time=47.877396 sec., loss=0.789624 
Eval step: 1199 , used_time=52.165713 sec., loss=1.030553 
Eval step: 1299 , used_time=56.486583 sec., loss=0.681799 
Eval step: 1399 , used_time=60.777617 sec., loss=0.457519 
Eval step: 1499 , used_time=65.085558 sec., loss=0.630472 
Eval step: 1599 , used_time=69.586543 sec., loss=0.995268 
Eval step: 1699 , used_time=73.904441 sec., loss=0.855460 
Eval step: 1799 , used_time=78.184228 sec., loss=0.883691 
Eval step: 1899 , used_time=82.470616 sec., loss=0.662743 
Eval step: 1999 , used_time=86.781710 sec., loss=1.369820 
Eval step: 2099 , used_time=91.067490 sec., loss=0.684592 
Eval step: 2199 , used_time=95.399150 sec., loss=0.797744 
Eval step: 2299 , used_time=99.854203 sec., loss=0.329918 
Eval step: 2399 , used_time=104.218832 sec., loss=1.218298 
Eval step: 2499 , used_time=108.523652 sec., loss=0.857709 
Eval step: 2599 , used_time=112.811479 sec., loss=1.257631 
Eval step: 2699 , used_time=117.147131 sec., loss=0.954443 
Eval step: 2799 , used_time=121.430685 sec., loss=1.069715 
Eval step: 2899 , used_time=125.743495 sec., loss=0.805592 
Eval step: 2999 , used_time=130.047812 sec., loss=0.803720 
Eval step: 3099 , used_time=134.550117 sec., loss=0.943680 
NLL Validation: loss = 0.952440. correct prediction ratio  74204/100032 ~  0.741803
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:10,  5.72it/s]Train batch 5700
Avg. loss per last 100 batches: 0.960916
5700it [19:10,  5.69it/s]Epoch: 5: Step: 5701/28124, loss=2.067123, lr=0.000005
5799it [19:27,  5.73it/s]Train batch 5800
Avg. loss per last 100 batches: 1.006850
5800it [19:28,  5.72it/s]Epoch: 5: Step: 5801/28124, loss=0.684779, lr=0.000005
5899it [19:45,  5.68it/s]Train batch 5900
Avg. loss per last 100 batches: 0.961056
5900it [19:45,  5.68it/s]Epoch: 5: Step: 5901/28124, loss=1.310128, lr=0.000005
5999it [20:03,  5.70it/s]Train batch 6000
Avg. loss per last 100 batches: 1.023267
6000it [20:03,  5.72it/s]Epoch: 5: Step: 6001/28124, loss=0.712963, lr=0.000005
6099it [20:20,  5.58it/s]Train batch 6100
Avg. loss per last 100 batches: 0.984407
6100it [20:20,  5.58it/s]Epoch: 5: Step: 6101/28124, loss=0.679902, lr=0.000005
6199it [20:38,  5.70it/s]Train batch 6200
Avg. loss per last 100 batches: 0.947392
6200it [20:38,  5.71it/s]Epoch: 5: Step: 6201/28124, loss=1.195601, lr=0.000005
6299it [20:55,  5.55it/s]Train batch 6300
Avg. loss per last 100 batches: 1.030961
6300it [20:56,  5.59it/s]Epoch: 5: Step: 6301/28124, loss=0.947742, lr=0.000005
6399it [21:13,  5.73it/s]Train batch 6400
Avg. loss per last 100 batches: 1.009351
6400it [21:13,  5.74it/s]Epoch: 5: Step: 6401/28124, loss=0.613889, lr=0.000005
6499it [21:31,  5.73it/s]Train batch 6500
Avg. loss per last 100 batches: 0.990321
6500it [21:31,  5.73it/s]Epoch: 5: Step: 6501/28124, loss=1.163145, lr=0.000005
6599it [21:48,  5.65it/s]Train batch 6600
Avg. loss per last 100 batches: 1.012690
6600it [21:48,  5.64it/s]Epoch: 5: Step: 6601/28124, loss=1.044831, lr=0.000005
6699it [22:06,  5.69it/s]Train batch 6700
Avg. loss per last 100 batches: 0.997337
6700it [22:06,  5.71it/s]Epoch: 5: Step: 6701/28124, loss=1.050672, lr=0.000005
6799it [22:23,  5.69it/s]Train batch 6800
Avg. loss per last 100 batches: 0.945003
6800it [22:24,  5.68it/s]Epoch: 5: Step: 6801/28124, loss=0.948742, lr=0.000005
6899it [22:41,  5.65it/s]Train batch 6900
Avg. loss per last 100 batches: 1.012557
6900it [22:41,  5.67it/s]Epoch: 5: Step: 6901/28124, loss=1.209701, lr=0.000005
6999it [22:59,  5.69it/s]Train batch 7000
Avg. loss per last 100 batches: 1.011599
7000it [22:59,  5.66it/s]Epoch: 5: Step: 7001/28124, loss=0.949112, lr=0.000005
7099it [23:16,  5.70it/s]Train batch 7100
Avg. loss per last 100 batches: 0.956611
7100it [23:17,  5.69it/s]Epoch: 5: Step: 7101/28124, loss=1.011694, lr=0.000005
7199it [23:34,  5.46it/s]Train batch 7200
Avg. loss per last 100 batches: 0.990306
7200it [23:34,  5.54it/s]Epoch: 5: Step: 7201/28124, loss=0.866526, lr=0.000005
7299it [23:52,  5.69it/s]Train batch 7300
Avg. loss per last 100 batches: 1.002984
7300it [23:52,  5.70it/s]Epoch: 5: Step: 7301/28124, loss=1.393702, lr=0.000005
7399it [24:09,  5.71it/s]Train batch 7400
Avg. loss per last 100 batches: 1.009335
7400it [24:09,  5.69it/s]Epoch: 5: Step: 7401/28124, loss=1.194343, lr=0.000005
7499it [24:27,  5.71it/s]Train batch 7500
Avg. loss per last 100 batches: 1.006198
7500it [24:27,  5.71it/s]Epoch: 5: Step: 7501/28124, loss=0.766625, lr=0.000005
7599it [24:44,  5.72it/s]Train batch 7600
Avg. loss per last 100 batches: 0.980493
7600it [24:45,  5.71it/s]Epoch: 5: Step: 7601/28124, loss=0.819016, lr=0.000005
7699it [25:02,  5.72it/s]Train batch 7700
Avg. loss per last 100 batches: 0.972797
7700it [25:02,  5.70it/s]Epoch: 5: Step: 7701/28124, loss=1.263601, lr=0.000005
7799it [25:20,  5.72it/s]Train batch 7800
Avg. loss per last 100 batches: 0.940462
7800it [25:20,  5.71it/s]Epoch: 5: Step: 7801/28124, loss=1.550863, lr=0.000005
7899it [25:37,  5.71it/s]Train batch 7900
Avg. loss per last 100 batches: 0.981287
7900it [25:37,  5.71it/s]Epoch: 5: Step: 7901/28124, loss=1.124356, lr=0.000005
7999it [25:55,  5.67it/s]Train batch 8000
Avg. loss per last 100 batches: 1.016119
8000it [25:55,  5.67it/s]Epoch: 5: Step: 8001/28124, loss=1.319986, lr=0.000005
8099it [26:13,  5.35it/s]Train batch 8100
Avg. loss per last 100 batches: 0.946736
8100it [26:13,  5.44it/s]Epoch: 5: Step: 8101/28124, loss=0.809045, lr=0.000005
8199it [26:30,  5.70it/s]Train batch 8200
Avg. loss per last 100 batches: 0.963772
8200it [26:30,  5.68it/s]Epoch: 5: Step: 8201/28124, loss=0.906424, lr=0.000005
8299it [26:48,  5.72it/s]Train batch 8300
Avg. loss per last 100 batches: 1.034434
8300it [26:48,  5.70it/s]Epoch: 5: Step: 8301/28124, loss=0.774658, lr=0.000005
8399it [27:05,  5.73it/s]Train batch 8400
Avg. loss per last 100 batches: 1.006299
8400it [27:05,  5.71it/s]Epoch: 5: Step: 8401/28124, loss=0.778522, lr=0.000005
8499it [27:23,  5.74it/s]Train batch 8500
Avg. loss per last 100 batches: 1.003129
8500it [27:23,  5.72it/s]Epoch: 5: Step: 8501/28124, loss=0.645040, lr=0.000005
8599it [27:40,  5.44it/s]Train batch 8600
Avg. loss per last 100 batches: 1.011854
8600it [27:41,  5.51it/s]Epoch: 5: Step: 8601/28124, loss=1.161731, lr=0.000005
8699it [27:58,  5.73it/s]Train batch 8700
Avg. loss per last 100 batches: 0.960819
8700it [27:58,  5.71it/s]Epoch: 5: Step: 8701/28124, loss=1.409128, lr=0.000005
8799it [28:15,  5.73it/s]Train batch 8800
Avg. loss per last 100 batches: 0.953455
8800it [28:16,  5.73it/s]Epoch: 5: Step: 8801/28124, loss=1.447763, lr=0.000005
8899it [28:33,  5.70it/s]Train batch 8900
Avg. loss per last 100 batches: 0.998898
8900it [28:33,  5.71it/s]Epoch: 5: Step: 8901/28124, loss=1.248858, lr=0.000005
8999it [28:51,  5.29it/s]Train batch 9000
Avg. loss per last 100 batches: 0.967640
9000it [28:51,  5.28it/s]Epoch: 5: Step: 9001/28124, loss=1.430412, lr=0.000005
9099it [29:08,  5.71it/s]Train batch 9100
Avg. loss per last 100 batches: 0.996344
9100it [29:08,  5.70it/s]Epoch: 5: Step: 9101/28124, loss=0.831209, lr=0.000005
9199it [29:26,  5.73it/s]Train batch 9200
Avg. loss per last 100 batches: 0.948278
9200it [29:26,  5.73it/s]Epoch: 5: Step: 9201/28124, loss=0.778930, lr=0.000005
9299it [29:43,  5.72it/s]Train batch 9300
Avg. loss per last 100 batches: 0.986143
9300it [29:44,  5.71it/s]Epoch: 5: Step: 9301/28124, loss=1.048654, lr=0.000005
9399it [30:01,  5.72it/s]Train batch 9400
Avg. loss per last 100 batches: 1.002328
9400it [30:01,  5.73it/s]Epoch: 5: Step: 9401/28124, loss=0.746630, lr=0.000005
9499it [30:18,  5.73it/s]Train batch 9500
Avg. loss per last 100 batches: 1.001214
9500it [30:19,  5.71it/s]Epoch: 5: Step: 9501/28124, loss=1.243045, lr=0.000005
9599it [30:36,  5.72it/s]Train batch 9600
Avg. loss per last 100 batches: 0.988857
9600it [30:36,  5.70it/s]Epoch: 5: Step: 9601/28124, loss=1.284105, lr=0.000005
9699it [30:54,  5.72it/s]Train batch 9700
Avg. loss per last 100 batches: 0.976814
9700it [30:54,  5.70it/s]Epoch: 5: Step: 9701/28124, loss=0.854161, lr=0.000005
9799it [31:11,  5.67it/s]Train batch 9800
Avg. loss per last 100 batches: 0.976641
9800it [31:11,  5.69it/s]Epoch: 5: Step: 9801/28124, loss=0.660219, lr=0.000005
9899it [31:29,  5.30it/s]Train batch 9900
Avg. loss per last 100 batches: 0.925951
9900it [31:29,  5.31it/s]Epoch: 5: Step: 9901/28124, loss=1.094609, lr=0.000005
9999it [31:46,  5.73it/s]Train batch 10000
Avg. loss per last 100 batches: 0.972884
10000it [31:47,  5.72it/s]Epoch: 5: Step: 10001/28124, loss=1.201183, lr=0.000005
10099it [32:04,  5.73it/s]Train batch 10100
Avg. loss per last 100 batches: 1.007032
10100it [32:04,  5.72it/s]Epoch: 5: Step: 10101/28124, loss=1.115370, lr=0.000005
10199it [32:21,  5.72it/s]Train batch 10200
Avg. loss per last 100 batches: 0.967620
10200it [32:22,  5.73it/s]Epoch: 5: Step: 10201/28124, loss=0.990266, lr=0.000005
10299it [32:39,  5.73it/s]Train batch 10300
Avg. loss per last 100 batches: 0.972906
10300it [32:39,  5.73it/s]Epoch: 5: Step: 10301/28124, loss=1.125330, lr=0.000005
10399it [32:57,  5.74it/s]Train batch 10400
Avg. loss per last 100 batches: 0.989195
10400it [32:57,  5.73it/s]Epoch: 5: Step: 10401/28124, loss=0.828127, lr=0.000005
10499it [33:14,  5.74it/s]Train batch 10500
Avg. loss per last 100 batches: 1.061244
10500it [33:14,  5.75it/s]Epoch: 5: Step: 10501/28124, loss=0.955093, lr=0.000005
10599it [33:32,  5.73it/s]Train batch 10600
Avg. loss per last 100 batches: 0.951101
10600it [33:32,  5.71it/s]Epoch: 5: Step: 10601/28124, loss=0.978735, lr=0.000005
10699it [33:49,  5.72it/s]Train batch 10700
Avg. loss per last 100 batches: 0.963464
10700it [33:49,  5.69it/s]Epoch: 5: Step: 10701/28124, loss=1.138167, lr=0.000005
10799it [34:07,  5.75it/s]Train batch 10800
Avg. loss per last 100 batches: 1.021493
10800it [34:07,  5.74it/s]Epoch: 5: Step: 10801/28124, loss=0.985015, lr=0.000005
10899it [34:24,  5.74it/s]Train batch 10900
Avg. loss per last 100 batches: 0.976221
10900it [34:25,  5.72it/s]Epoch: 5: Step: 10901/28124, loss=0.772093, lr=0.000005
10999it [34:42,  5.67it/s]Train batch 11000
Avg. loss per last 100 batches: 0.931270
11000it [34:42,  5.69it/s]Epoch: 5: Step: 11001/28124, loss=1.555096, lr=0.000005
11099it [35:00,  5.70it/s]Train batch 11100
Avg. loss per last 100 batches: 0.974873
11100it [35:00,  5.71it/s]Epoch: 5: Step: 11101/28124, loss=0.765859, lr=0.000005
11199it [35:17,  5.69it/s]Train batch 11200
Avg. loss per last 100 batches: 1.014531
11200it [35:17,  5.66it/s]Epoch: 5: Step: 11201/28124, loss=0.778385, lr=0.000005
11249it [35:26,  5.70it/s]Validation: Epoch: 5 Step: 11250/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.350810 sec., loss=0.859024 
Eval step: 199 , used_time=8.694155 sec., loss=1.177021 
Eval step: 299 , used_time=13.012064 sec., loss=0.497629 
Eval step: 399 , used_time=17.567410 sec., loss=1.411546 
Eval step: 499 , used_time=21.887920 sec., loss=1.199474 
Eval step: 599 , used_time=26.242840 sec., loss=1.490282 
Eval step: 699 , used_time=30.592750 sec., loss=1.499548 
Eval step: 799 , used_time=34.938702 sec., loss=1.133564 
Eval step: 899 , used_time=39.274482 sec., loss=1.096018 
Eval step: 999 , used_time=43.608938 sec., loss=1.098684 
Eval step: 1099 , used_time=47.991244 sec., loss=0.807072 
Eval step: 1199 , used_time=52.476157 sec., loss=1.021167 
Eval step: 1299 , used_time=56.823899 sec., loss=0.764545 
Eval step: 1399 , used_time=61.143204 sec., loss=0.468431 
Eval step: 1499 , used_time=65.494068 sec., loss=0.631082 
Eval step: 1599 , used_time=69.840898 sec., loss=1.022660 
Eval step: 1699 , used_time=74.181937 sec., loss=0.737682 
Eval step: 1799 , used_time=78.496543 sec., loss=0.861893 
Eval step: 1899 , used_time=83.000946 sec., loss=0.642528 
Eval step: 1999 , used_time=87.307113 sec., loss=1.277096 
Eval step: 2099 , used_time=91.589941 sec., loss=0.750316 
Eval step: 2199 , used_time=95.922438 sec., loss=0.848823 
Eval step: 2299 , used_time=100.257500 sec., loss=0.313231 
Eval step: 2399 , used_time=104.609843 sec., loss=1.141908 
Eval step: 2499 , used_time=108.925587 sec., loss=0.859712 
Eval step: 2599 , used_time=113.454927 sec., loss=1.203759 
Eval step: 2699 , used_time=117.813252 sec., loss=0.958011 
Eval step: 2799 , used_time=122.094584 sec., loss=0.949543 
Eval step: 2899 , used_time=126.423878 sec., loss=0.765734 
Eval step: 2999 , used_time=130.749179 sec., loss=0.832069 
Eval step: 3099 , used_time=135.070579 sec., loss=0.922307 
NLL Validation: loss = 0.942815. correct prediction ratio  74524/100032 ~  0.745002
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [37:56,  5.71it/s]Train batch 11300
Avg. loss per last 100 batches: 0.960506
11300it [37:56,  5.71it/s]Epoch: 5: Step: 11301/28124, loss=0.966401, lr=0.000005
11399it [38:14,  5.75it/s]Train batch 11400
Avg. loss per last 100 batches: 1.045454
11400it [38:14,  5.73it/s]Epoch: 5: Step: 11401/28124, loss=1.102878, lr=0.000005
11499it [38:31,  5.73it/s]Train batch 11500
Avg. loss per last 100 batches: 0.991846
11500it [38:31,  5.71it/s]Epoch: 5: Step: 11501/28124, loss=1.026179, lr=0.000005
11599it [38:49,  5.73it/s]Train batch 11600
Avg. loss per last 100 batches: 1.017574
11600it [38:49,  5.73it/s]Epoch: 5: Step: 11601/28124, loss=0.990560, lr=0.000005
11699it [39:06,  5.73it/s]Train batch 11700
Avg. loss per last 100 batches: 0.959025
11700it [39:07,  5.74it/s]Epoch: 5: Step: 11701/28124, loss=0.932110, lr=0.000005
11799it [39:24,  5.72it/s]Train batch 11800
Avg. loss per last 100 batches: 1.013014
11800it [39:24,  5.71it/s]Epoch: 5: Step: 11801/28124, loss=0.878434, lr=0.000005
11899it [39:42,  5.70it/s]Train batch 11900
Avg. loss per last 100 batches: 0.989776
11900it [39:42,  5.71it/s]Epoch: 5: Step: 11901/28124, loss=0.748814, lr=0.000005
11999it [39:59,  5.63it/s]Train batch 12000
Avg. loss per last 100 batches: 0.978142
12000it [39:59,  5.65it/s]Epoch: 5: Step: 12001/28124, loss=0.790880, lr=0.000005
12099it [40:17,  5.72it/s]Train batch 12100
Avg. loss per last 100 batches: 0.959169
12100it [40:17,  5.73it/s]Epoch: 5: Step: 12101/28124, loss=1.457235, lr=0.000005
12199it [40:34,  5.74it/s]Train batch 12200
Avg. loss per last 100 batches: 1.003214
12200it [40:34,  5.75it/s]Epoch: 5: Step: 12201/28124, loss=0.932472, lr=0.000005
12299it [40:52,  5.70it/s]Train batch 12300
Avg. loss per last 100 batches: 0.955397
12300it [40:52,  5.68it/s]Epoch: 5: Step: 12301/28124, loss=1.138383, lr=0.000004
12399it [41:09,  5.67it/s]Train batch 12400
Avg. loss per last 100 batches: 1.031431
12400it [41:09,  5.65it/s]Epoch: 5: Step: 12401/28124, loss=1.025478, lr=0.000004
12499it [41:27,  5.73it/s]Train batch 12500
Avg. loss per last 100 batches: 0.988490
12500it [41:27,  5.74it/s]Epoch: 5: Step: 12501/28124, loss=0.673454, lr=0.000004
12599it [41:44,  5.74it/s]Train batch 12600
Avg. loss per last 100 batches: 0.982701
12600it [41:45,  5.72it/s]Epoch: 5: Step: 12601/28124, loss=1.496097, lr=0.000004
12699it [42:02,  5.71it/s]Train batch 12700
Avg. loss per last 100 batches: 1.008704
12700it [42:02,  5.70it/s]Epoch: 5: Step: 12701/28124, loss=1.385954, lr=0.000004
12799it [42:20,  5.73it/s]Train batch 12800
Avg. loss per last 100 batches: 1.021939
12800it [42:20,  5.72it/s]Epoch: 5: Step: 12801/28124, loss=0.876282, lr=0.000004
12899it [42:37,  5.53it/s]Train batch 12900
Avg. loss per last 100 batches: 0.981902
12900it [42:37,  5.59it/s]Epoch: 5: Step: 12901/28124, loss=0.982387, lr=0.000004
12999it [42:55,  5.74it/s]Train batch 13000
Avg. loss per last 100 batches: 0.980891
13000it [42:55,  5.71it/s]Epoch: 5: Step: 13001/28124, loss=0.911982, lr=0.000004
13699it [44:58,  5.73it/s]Train batch 13700
Avg. loss per last 100 batches: 1.020799
13700it [44:58,  5.72it/s]Epoch: 5: Step: 13701/28124, loss=1.685014, lr=0.000004
13799it [45:15,  5.46it/s]Train batch 13800
Avg. loss per last 100 batches: 1.000200
13800it [45:15,  5.45it/s]Epoch: 5: Step: 13801/28124, loss=0.705770, lr=0.000004
13899it [45:33,  5.73it/s]Train batch 13900
Avg. loss per last 100 batches: 0.946698
13900it [45:33,  5.73it/s]Epoch: 5: Step: 13901/28124, loss=0.843827, lr=0.000004
13999it [45:50,  5.71it/s]Train batch 14000
Avg. loss per last 100 batches: 0.986800
14000it [45:51,  5.72it/s]Epoch: 5: Step: 14001/28124, loss=0.611944, lr=0.000004
14099it [46:08,  5.75it/s]Train batch 14100
Avg. loss per last 100 batches: 0.944235
14100it [46:08,  5.75it/s]Epoch: 5: Step: 14101/28124, loss=1.408459, lr=0.000004
14199it [46:25,  5.72it/s]Train batch 14200
Avg. loss per last 100 batches: 0.976206
14200it [46:26,  5.71it/s]Epoch: 5: Step: 14201/28124, loss=0.770042, lr=0.000004
14299it [46:43,  5.72it/s]Train batch 14300
Avg. loss per last 100 batches: 1.000303
14300it [46:43,  5.71it/s]Epoch: 5: Step: 14301/28124, loss=0.987228, lr=0.000004
14399it [47:01,  5.72it/s]Train batch 14400
Avg. loss per last 100 batches: 0.942586
14400it [47:01,  5.73it/s]Epoch: 5: Step: 14401/28124, loss=0.970929, lr=0.000004
14499it [47:18,  5.72it/s]Train batch 14500
Avg. loss per last 100 batches: 0.969243
14500it [47:18,  5.70it/s]Epoch: 5: Step: 14501/28124, loss=0.842209, lr=0.000004
14599it [47:36,  5.72it/s]Train batch 14600
Avg. loss per last 100 batches: 0.964443
14600it [47:36,  5.72it/s]Epoch: 5: Step: 14601/28124, loss=1.165323, lr=0.000004
14699it [47:53,  5.45it/s]Train batch 14700
Avg. loss per last 100 batches: 0.978915
14700it [47:53,  5.40it/s]Epoch: 5: Step: 14701/28124, loss=0.857546, lr=0.000004
14799it [48:11,  5.65it/s]Train batch 14800
Avg. loss per last 100 batches: 0.946543
14800it [48:11,  5.69it/s]Epoch: 5: Step: 14801/28124, loss=0.655723, lr=0.000004
14899it [48:28,  5.74it/s]Train batch 14900
Avg. loss per last 100 batches: 0.977494
14900it [48:28,  5.74it/s]Epoch: 5: Step: 14901/28124, loss=1.108391, lr=0.000004
14999it [48:46,  5.73it/s]Train batch 15000
Avg. loss per last 100 batches: 0.934109
15000it [48:46,  5.73it/s]Epoch: 5: Step: 15001/28124, loss=1.088966, lr=0.000004
15099it [49:03,  5.75it/s]Train batch 15100
Avg. loss per last 100 batches: 0.992371
15100it [49:03,  5.73it/s]Epoch: 5: Step: 15101/28124, loss=1.300007, lr=0.000004
15199it [49:21,  5.64it/s]Train batch 15200
Avg. loss per last 100 batches: 0.957357
15200it [49:21,  5.66it/s]Epoch: 5: Step: 15201/28124, loss=1.377243, lr=0.000004
15299it [49:38,  5.74it/s]Train batch 15300
Avg. loss per last 100 batches: 1.044800
15300it [49:38,  5.75it/s]Epoch: 5: Step: 15301/28124, loss=0.668488, lr=0.000004
15399it [49:56,  5.74it/s]Train batch 15400
Avg. loss per last 100 batches: 1.039975
15400it [49:56,  5.75it/s]Epoch: 5: Step: 15401/28124, loss=0.772613, lr=0.000004
15499it [50:13,  5.76it/s]Train batch 15500
Avg. loss per last 100 batches: 0.990605
15500it [50:13,  5.75it/s]Epoch: 5: Step: 15501/28124, loss=0.556905, lr=0.000004
15599it [50:31,  5.62it/s]Train batch 15600
Avg. loss per last 100 batches: 1.003176
15600it [50:31,  5.65it/s]Epoch: 5: Step: 15601/28124, loss=0.900439, lr=0.000004
15699it [50:48,  5.72it/s]Train batch 15700
Avg. loss per last 100 batches: 0.967324
15700it [50:48,  5.73it/s]Epoch: 5: Step: 15701/28124, loss=0.779102, lr=0.000004
15799it [51:06,  5.69it/s]Train batch 15800
Avg. loss per last 100 batches: 1.000484
15800it [51:06,  5.71it/s]Epoch: 5: Step: 15801/28124, loss=0.808275, lr=0.000004
15899it [51:23,  5.72it/s]Train batch 15900
Avg. loss per last 100 batches: 1.015365
15900it [51:23,  5.74it/s]Epoch: 5: Step: 15901/28124, loss=0.775994, lr=0.000004
15999it [51:41,  5.67it/s]Train batch 16000
Avg. loss per last 100 batches: 0.971439
16000it [51:41,  5.68it/s]Epoch: 5: Step: 16001/28124, loss=0.886005, lr=0.000004
16099it [51:58,  5.74it/s]Train batch 16100
Avg. loss per last 100 batches: 0.973952
16100it [51:58,  5.69it/s]Epoch: 5: Step: 16101/28124, loss=0.904747, lr=0.000004
16199it [52:16,  5.77it/s]Train batch 16200
Avg. loss per last 100 batches: 0.988337
16200it [52:16,  5.77it/s]Epoch: 5: Step: 16201/28124, loss=1.118901, lr=0.000004
16299it [52:33,  5.75it/s]Train batch 16300
Avg. loss per last 100 batches: 0.990529
16300it [52:33,  5.75it/s]Epoch: 5: Step: 16301/28124, loss=0.966394, lr=0.000004
16399it [52:51,  5.69it/s]Train batch 16400
Avg. loss per last 100 batches: 0.992890
16400it [52:51,  5.70it/s]Epoch: 5: Step: 16401/28124, loss=1.131011, lr=0.000004
16499it [53:08,  5.74it/s]Train batch 16500
Avg. loss per last 100 batches: 0.986011
16500it [53:08,  5.74it/s]Epoch: 5: Step: 16501/28124, loss=0.910205, lr=0.000004
16599it [53:26,  5.75it/s]Train batch 16600
Avg. loss per last 100 batches: 0.974211
16600it [53:26,  5.75it/s]Epoch: 5: Step: 16601/28124, loss=0.930775, lr=0.000004
16699it [53:44,  5.45it/s]Train batch 16700
Avg. loss per last 100 batches: 1.019485
16700it [53:44,  5.54it/s]Epoch: 5: Step: 16701/28124, loss=1.159507, lr=0.000004
16786it [53:59,  5.75it/s]Eval step: 1199 , used_time=51.626613 sec., loss=0.958601 
Eval step: 1299 , used_time=55.928866 sec., loss=0.754006 
Eval step: 1399 , used_time=60.199739 sec., loss=0.478023 
Eval step: 1499 , used_time=64.656544 sec., loss=0.567842 
Eval step: 1599 , used_time=68.963651 sec., loss=1.072542 
Eval step: 1699 , used_time=73.264118 sec., loss=0.641306 
Eval step: 1799 , used_time=77.563955 sec., loss=0.878176 
Eval step: 1899 , used_time=81.824839 sec., loss=0.687293 
Eval step: 1999 , used_time=86.128621 sec., loss=1.339013 
Eval step: 2099 , used_time=90.392359 sec., loss=0.709593 
Eval step: 2199 , used_time=94.739435 sec., loss=0.850554 
Eval step: 2299 , used_time=99.157228 sec., loss=0.299017 
Eval step: 2399 , used_time=103.489801 sec., loss=1.189314 
Eval step: 2499 , used_time=107.799399 sec., loss=0.868864 
Eval step: 2599 , used_time=112.074171 sec., loss=1.260864 
Eval step: 2699 , used_time=116.388908 sec., loss=0.948642 
Eval step: 2799 , used_time=120.651587 sec., loss=1.036393 
Eval step: 2899 , used_time=124.925394 sec., loss=0.754801 
Eval step: 2999 , used_time=129.399171 sec., loss=0.858423 
Eval step: 3099 , used_time=133.691084 sec., loss=0.862865 
NLL Validation: loss = 0.934810. correct prediction ratio  74629/100032 ~  0.746051
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
16899it [56:39,  5.40it/s]Train batch 16900
Avg. loss per last 100 batches: 0.971817
16900it [56:39,  5.47it/s]Epoch: 5: Step: 16901/28124, loss=0.548767, lr=0.000004
16999it [56:57,  5.73it/s]Train batch 17000
Avg. loss per last 100 batches: 0.992637
17000it [56:57,  5.69it/s]Epoch: 5: Step: 17001/28124, loss=1.224811, lr=0.000004
17099it [57:14,  5.77it/s]Train batch 17100
Avg. loss per last 100 batches: 1.007931
17100it [57:14,  5.74it/s]Epoch: 5: Step: 17101/28124, loss=0.674406, lr=0.000004
17199it [57:32,  5.75it/s]Train batch 17200
Avg. loss per last 100 batches: 0.970800
17200it [57:32,  5.73it/s]Epoch: 5: Step: 17201/28124, loss=0.928075, lr=0.000004
17299it [57:49,  5.74it/s]Train batch 17300
Avg. loss per last 100 batches: 0.971302
17300it [57:49,  5.73it/s]Epoch: 5: Step: 17301/28124, loss=1.065406, lr=0.000004
17399it [58:07,  5.72it/s]Train batch 17400
Avg. loss per last 100 batches: 0.958617
17400it [58:07,  5.74it/s]Epoch: 5: Step: 17401/28124, loss=0.679857, lr=0.000004
17499it [58:24,  5.74it/s]Train batch 17500
Avg. loss per last 100 batches: 0.956175
17500it [58:24,  5.73it/s]Epoch: 5: Step: 17501/28124, loss=1.106839, lr=0.000004
17599it [58:42,  5.74it/s]Train batch 17600
Avg. loss per last 100 batches: 0.965192
17600it [58:42,  5.75it/s]Epoch: 5: Step: 17601/28124, loss=1.098248, lr=0.000004
17699it [58:59,  5.68it/s]Train batch 17700
Avg. loss per last 100 batches: 0.975844
17700it [58:59,  5.67it/s]Epoch: 5: Step: 17701/28124, loss=1.172544, lr=0.000004
17799it [59:17,  5.75it/s]Train batch 17800
Avg. loss per last 100 batches: 1.039124
17800it [59:17,  5.73it/s]Epoch: 5: Step: 17801/28124, loss=0.848174, lr=0.000004
17899it [59:34,  5.74it/s]Train batch 17900
Avg. loss per last 100 batches: 1.005221
17900it [59:34,  5.74it/s]Epoch: 5: Step: 17901/28124, loss=0.491572, lr=0.000004
17999it [59:52,  5.76it/s]Train batch 18000
Avg. loss per last 100 batches: 0.981110
18000it [59:52,  5.74it/s]Epoch: 5: Step: 18001/28124, loss=1.200456, lr=0.000004
18099it [1:00:09,  5.75it/s]Train batch 18100
Avg. loss per last 100 batches: 1.034538
18100it [1:00:09,  5.75it/s]Epoch: 5: Step: 18101/28124, loss=1.103735, lr=0.000004
18199it [1:00:27,  5.76it/s]Train batch 18200
Avg. loss per last 100 batches: 0.972790
18200it [1:00:27,  5.75it/s]Epoch: 5: Step: 18201/28124, loss=0.836196, lr=0.000004
18299it [1:00:44,  5.76it/s]Train batch 18300
Avg. loss per last 100 batches: 0.926908
18300it [1:00:44,  5.77it/s]Epoch: 5: Step: 18301/28124, loss=1.128018, lr=0.000004
18399it [1:01:02,  5.71it/s]Train batch 18400
Avg. loss per last 100 batches: 0.985166
18400it [1:01:02,  5.72it/s]Epoch: 5: Step: 18401/28124, loss=0.793241, lr=0.000004
18499it [1:01:19,  5.72it/s]Train batch 18500
Avg. loss per last 100 batches: 0.940088
18500it [1:01:19,  5.73it/s]Epoch: 5: Step: 18501/28124, loss=1.233938, lr=0.000004
18599it [1:01:37,  5.72it/s]Train batch 18600
Avg. loss per last 100 batches: 1.006815
18600it [1:01:37,  5.73it/s]Epoch: 5: Step: 18601/28124, loss=0.453771, lr=0.000004
18699it [1:01:54,  5.76it/s]Train batch 18700
Avg. loss per last 100 batches: 0.943407
18700it [1:01:55,  5.75it/s]Epoch: 5: Step: 18701/28124, loss=1.130326, lr=0.000004
18799it [1:02:12,  5.52it/s]Train batch 18800
Avg. loss per last 100 batches: 0.952590
18800it [1:02:12,  5.59it/s]Epoch: 5: Step: 18801/28124, loss=1.202761, lr=0.000004
18899it [1:02:29,  5.75it/s]Train batch 18900
Avg. loss per last 100 batches: 1.029814
18900it [1:02:30,  5.73it/s]Epoch: 5: Step: 18901/28124, loss=0.868227, lr=0.000004
18999it [1:02:47,  5.73it/s]Train batch 19000
Avg. loss per last 100 batches: 0.966474
19000it [1:02:47,  5.71it/s]Epoch: 5: Step: 19001/28124, loss=0.656004, lr=0.000004
19099it [1:03:04,  5.68it/s]Train batch 19100
Avg. loss per last 100 batches: 1.016978
19100it [1:03:05,  5.67it/s]Epoch: 5: Step: 19101/28124, loss=0.813883, lr=0.000004
19199it [1:03:22,  5.74it/s]Train batch 19200
Avg. loss per last 100 batches: 0.986423
19200it [1:03:22,  5.73it/s]Epoch: 5: Step: 19201/28124, loss=1.045931, lr=0.000004
19299it [1:03:39,  5.73it/s]Train batch 19300
Avg. loss per last 100 batches: 0.990284
19300it [1:03:40,  5.73it/s]Epoch: 5: Step: 19301/28124, loss=0.854749, lr=0.000004
19399it [1:03:57,  5.72it/s]Train batch 19400
Avg. loss per last 100 batches: 0.968093
19400it [1:03:57,  5.71it/s]Epoch: 5: Step: 19401/28124, loss=1.010274, lr=0.000004
19499it [1:04:15,  5.76it/s]Train batch 19500
Avg. loss per last 100 batches: 0.987718
19500it [1:04:15,  5.75it/s]Epoch: 5: Step: 19501/28124, loss=0.663234, lr=0.000004
19599it [1:04:32,  5.74it/s]Train batch 19600
Avg. loss per last 100 batches: 1.011155
19600it [1:04:32,  5.75it/s]Epoch: 5: Step: 19601/28124, loss=1.232966, lr=0.000004
19699it [1:04:50,  5.39it/s]Train batch 19700
Avg. loss per last 100 batches: 0.957936
19700it [1:04:50,  5.38it/s]Epoch: 5: Step: 19701/28124, loss=1.063587, lr=0.000004
19799it [1:05:07,  5.73it/s]Train batch 19800
Avg. loss per last 100 batches: 1.029487
19800it [1:05:07,  5.72it/s]Epoch: 5: Step: 19801/28124, loss=0.805487, lr=0.000004
19899it [1:05:25,  5.71it/s]Train batch 19900
Avg. loss per last 100 batches: 0.968351
19900it [1:05:25,  5.71it/s]Epoch: 5: Step: 19901/28124, loss=0.886639, lr=0.000004
19999it [1:05:42,  5.73it/s]Train batch 20000
Avg. loss per last 100 batches: 0.959689
20000it [1:05:42,  5.74it/s]Epoch: 5: Step: 20001/28124, loss=0.573081, lr=0.000004
20099it [1:06:00,  5.76it/s]Train batch 20100
Avg. loss per last 100 batches: 0.937080
20100it [1:06:00,  5.75it/s]Epoch: 5: Step: 20101/28124, loss=0.750118, lr=0.000004
20199it [1:06:17,  5.73it/s]Train batch 20200
Avg. loss per last 100 batches: 0.986781
20200it [1:06:17,  5.74it/s]Epoch: 5: Step: 20201/28124, loss=0.754394, lr=0.000004
20299it [1:06:35,  5.72it/s]Train batch 20300
Avg. loss per last 100 batches: 0.986111
20300it [1:06:35,  5.72it/s]Epoch: 5: Step: 20301/28124, loss=0.733775, lr=0.000004
20399it [1:06:52,  5.72it/s]Train batch 20400
Avg. loss per last 100 batches: 0.949500
20400it [1:06:52,  5.74it/s]Epoch: 5: Step: 20401/28124, loss=1.006381, lr=0.000004
20499it [1:07:10,  5.74it/s]Train batch 20500
Avg. loss per last 100 batches: 1.016918
20500it [1:07:10,  5.74it/s]Epoch: 5: Step: 20501/28124, loss=0.869320, lr=0.000004
20599it [1:07:27,  5.76it/s]Train batch 20600
Avg. loss per last 100 batches: 0.984031
20600it [1:07:27,  5.76it/s]Epoch: 5: Step: 20601/28124, loss=0.702835, lr=0.000004
20699it [1:07:45,  5.76it/s]Train batch 20700
Avg. loss per last 100 batches: 1.025139
20700it [1:07:45,  5.76it/s]Epoch: 5: Step: 20701/28124, loss=1.358484, lr=0.000004
20799it [1:08:02,  5.74it/s]Train batch 20800
Avg. loss per last 100 batches: 0.949027
20800it [1:08:03,  5.75it/s]Epoch: 5: Step: 20801/28124, loss=1.137436, lr=0.000004
20899it [1:08:20,  5.74it/s]Train batch 20900
Avg. loss per last 100 batches: 1.013663
20900it [1:08:20,  5.71it/s]Epoch: 5: Step: 20901/28124, loss=0.718902, lr=0.000004
20999it [1:08:37,  5.78it/s]Train batch 21000
Avg. loss per last 100 batches: 1.018420
21000it [1:08:38,  5.77it/s]Epoch: 5: Step: 21001/28124, loss=0.670643, lr=0.000004
21099it [1:08:55,  5.75it/s]Train batch 21100
Avg. loss per last 100 batches: 0.970108
21100it [1:08:55,  5.72it/s]Epoch: 5: Step: 21101/28124, loss=0.909390, lr=0.000004
21199it [1:09:12,  5.74it/s]Train batch 21200
Avg. loss per last 100 batches: 0.996417
21200it [1:09:13,  5.72it/s]Epoch: 5: Step: 21201/28124, loss=0.810852, lr=0.000004
21299it [1:09:30,  5.73it/s]Train batch 21300
Avg. loss per last 100 batches: 0.941911
21300it [1:09:30,  5.66it/s]Epoch: 5: Step: 21301/28124, loss=0.609371, lr=0.000004
21399it [1:09:47,  5.77it/s]Train batch 21400
Avg. loss per last 100 batches: 0.991754
21400it [1:09:48,  5.75it/s]Epoch: 5: Step: 21401/28124, loss=1.221716, lr=0.000004
21499it [1:10:05,  5.75it/s]Train batch 21500
Avg. loss per last 100 batches: 0.964583
21500it [1:10:05,  5.75it/s]Epoch: 5: Step: 21501/28124, loss=0.875247, lr=0.000004
21599it [1:10:22,  5.75it/s]Train batch 21600
Avg. loss per last 100 batches: 1.005524
21600it [1:10:23,  5.74it/s]Epoch: 5: Step: 21601/28124, loss=0.975081, lr=0.000004
21699it [1:10:40,  5.55it/s]Train batch 21700
Avg. loss per last 100 batches: 0.953552
21700it [1:10:40,  5.54it/s]Epoch: 5: Step: 21701/28124, loss=1.103758, lr=0.000004
21799it [1:10:58,  5.71it/s]Train batch 21800
Avg. loss per last 100 batches: 0.990256
21800it [1:10:58,  5.73it/s]Epoch: 5: Step: 21801/28124, loss=0.864307, lr=0.000004
21899it [1:11:15,  5.76it/s]Train batch 21900
Avg. loss per last 100 batches: 0.977806
21900it [1:11:15,  5.76it/s]Epoch: 5: Step: 21901/28124, loss=1.277135, lr=0.000004
21999it [1:11:33,  5.75it/s]Train batch 22000
Avg. loss per last 100 batches: 0.996186
22000it [1:11:33,  5.74it/s]Epoch: 5: Step: 22001/28124, loss=0.943481, lr=0.000004
22099it [1:11:50,  5.62it/s]Train batch 22100
Avg. loss per last 100 batches: 1.032378
22100it [1:11:50,  5.54it/s]Epoch: 5: Step: 22101/28124, loss=1.330292, lr=0.000003
22199it [1:12:08,  5.75it/s]Train batch 22200
Avg. loss per last 100 batches: 0.991501
22200it [1:12:08,  5.75it/s]Epoch: 5: Step: 22201/28124, loss=0.773689, lr=0.000003
22299it [1:12:25,  5.77it/s]Train batch 22300
Avg. loss per last 100 batches: 0.997835
22300it [1:12:25,  5.76it/s]Epoch: 5: Step: 22301/28124, loss=1.319403, lr=0.000003
22399it [1:12:43,  5.73it/s]Train batch 22400
Avg. loss per last 100 batches: 1.005303
22400it [1:12:43,  5.74it/s]Epoch: 5: Step: 22401/28124, loss=1.588183, lr=0.000003
22499it [1:13:00,  5.58it/s]Train batch 22500
Avg. loss per last 100 batches: 0.997125
Validation: Epoch: 5 Step: 22500/28124
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.289877 sec., loss=0.729745 
Eval step: 199 , used_time=8.602019 sec., loss=1.107141 
Eval step: 299 , used_time=13.070015 sec., loss=0.474289 
Eval step: 399 , used_time=17.362217 sec., loss=1.303069 
Eval step: 499 , used_time=21.623999 sec., loss=1.231591 
Eval step: 599 , used_time=25.914688 sec., loss=1.467637 
Eval step: 699 , used_time=30.200698 sec., loss=1.453064 
Eval step: 799 , used_time=34.471093 sec., loss=1.210450 
Eval step: 899 , used_time=38.760941 sec., loss=1.139072 
Eval step: 999 , used_time=43.043725 sec., loss=1.138656 
Eval step: 1099 , used_time=47.534045 sec., loss=0.827727 
Eval step: 1199 , used_time=51.793319 sec., loss=0.995754 
Eval step: 1299 , used_time=56.074728 sec., loss=0.808076 
Eval step: 1399 , used_time=60.360097 sec., loss=0.455513 
Eval step: 1499 , used_time=64.658060 sec., loss=0.541411 
Eval step: 1599 , used_time=68.979326 sec., loss=0.982961 
Eval step: 1699 , used_time=73.312316 sec., loss=0.648805 
Eval step: 1799 , used_time=77.798606 sec., loss=0.743454 
Eval step: 1899 , used_time=82.064699 sec., loss=0.652698 
Eval step: 1999 , used_time=86.357760 sec., loss=1.325184 
Eval step: 2099 , used_time=90.624196 sec., loss=0.675923 
Eval step: 2199 , used_time=94.917290 sec., loss=0.820103 
Eval step: 2299 , used_time=99.187340 sec., loss=0.333742 
Eval step: 2399 , used_time=103.468363 sec., loss=1.155956 
Eval step: 2499 , used_time=107.924692 sec., loss=0.818179 
Eval step: 2599 , used_time=112.217891 sec., loss=1.184559 
Eval step: 2699 , used_time=116.512356 sec., loss=0.868794 
Eval step: 2799 , used_time=120.791232 sec., loss=1.014825 
Eval step: 2899 , used_time=125.092263 sec., loss=0.696647 
Eval step: 2999 , used_time=129.359253 sec., loss=0.851975 
Eval step: 3099 , used_time=133.655921 sec., loss=0.817356 
NLL Validation: loss = 0.923823. correct prediction ratio  74848/100032 ~  0.748241
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
22500it [1:15:25, 43.67s/it]Epoch: 5: Step: 22501/28124, loss=0.799546, lr=0.000003
22599it [1:15:43,  5.72it/s]Train batch 22600
Avg. loss per last 100 batches: 1.000453
22600it [1:15:43,  5.73it/s]Epoch: 5: Step: 22601/28124, loss=0.720667, lr=0.000003
22699it [1:16:00,  5.53it/s]Train batch 22700
Avg. loss per last 100 batches: 0.941877
22700it [1:16:01,  5.59it/s]Epoch: 5: Step: 22701/28124, loss=0.936947, lr=0.000003
22799it [1:16:18,  5.74it/s]Train batch 22800
Avg. loss per last 100 batches: 0.951916
22800it [1:16:18,  5.72it/s]Epoch: 5: Step: 22801/28124, loss=1.103210, lr=0.000003
22899it [1:16:35,  5.74it/s]Train batch 22900
Avg. loss per last 100 batches: 0.962019
22900it [1:16:36,  5.73it/s]Epoch: 5: Step: 22901/28124, loss=1.119805, lr=0.000003
22999it [1:16:53,  5.74it/s]Train batch 23000
Avg. loss per last 100 batches: 0.950374
23000it [1:16:53,  5.75it/s]Epoch: 5: Step: 23001/28124, loss=0.704071, lr=0.000003
23099it [1:17:10,  5.63it/s]Train batch 23100
Avg. loss per last 100 batches: 0.967990
23100it [1:17:11,  5.65it/s]Epoch: 5: Step: 23101/28124, loss=1.363766, lr=0.000003
23199it [1:17:28,  5.74it/s]Train batch 23200
Avg. loss per last 100 batches: 0.978812
23200it [1:17:28,  5.74it/s]Epoch: 5: Step: 23201/28124, loss=1.133157, lr=0.000003
23299it [1:17:45,  5.74it/s]Train batch 23300
Avg. loss per last 100 batches: 0.920379
23300it [1:17:46,  5.75it/s]Epoch: 5: Step: 23301/28124, loss=0.905538, lr=0.000003
23399it [1:18:03,  5.50it/s]Train batch 23400
Avg. loss per last 100 batches: 0.997375
23400it [1:18:03,  5.42it/s]Epoch: 5: Step: 23401/28124, loss=0.967832, lr=0.000003
23499it [1:18:21,  5.60it/s]Train batch 23500
Avg. loss per last 100 batches: 0.972594
23500it [1:18:21,  5.61it/s]Epoch: 5: Step: 23501/28124, loss=1.102724, lr=0.000003
23599it [1:18:38,  5.68it/s]Train batch 23600
Avg. loss per last 100 batches: 0.946422
23600it [1:18:38,  5.68it/s]Epoch: 5: Step: 23601/28124, loss=1.028357, lr=0.000003
23699it [1:18:56,  5.71it/s]Train batch 23700
Avg. loss per last 100 batches: 0.979966
23700it [1:18:56,  5.69it/s]Epoch: 5: Step: 23701/28124, loss=1.228555, lr=0.000003
23799it [1:19:13,  5.76it/s]Train batch 23800
Avg. loss per last 100 batches: 1.019191
23800it [1:19:13,  5.76it/s]Epoch: 5: Step: 23801/28124, loss=0.947460, lr=0.000003
23899it [1:19:31,  5.63it/s]Train batch 23900
Avg. loss per last 100 batches: 0.998025
23900it [1:19:31,  5.64it/s]Epoch: 5: Step: 23901/28124, loss=0.808741, lr=0.000003
23999it [1:19:49,  5.73it/s]Train batch 24000
Avg. loss per last 100 batches: 0.950947
24000it [1:19:49,  5.71it/s]Epoch: 5: Step: 24001/28124, loss=0.929321, lr=0.000003
24099it [1:20:06,  5.73it/s]Train batch 24100
Avg. loss per last 100 batches: 0.971825
24100it [1:20:06,  5.73it/s]Epoch: 5: Step: 24101/28124, loss=1.418177, lr=0.000003
24199it [1:20:24,  5.75it/s]Train batch 24200
Avg. loss per last 100 batches: 0.943105
24200it [1:20:24,  5.73it/s]Epoch: 5: Step: 24201/28124, loss=0.542984, lr=0.000003
24299it [1:20:41,  5.70it/s]Train batch 24300
Avg. loss per last 100 batches: 0.941281
24300it [1:20:41,  5.71it/s]Epoch: 5: Step: 24301/28124, loss=0.827929, lr=0.000003
24399it [1:20:59,  5.76it/s]Train batch 24400
Avg. loss per last 100 batches: 0.938664
24400it [1:20:59,  5.75it/s]Epoch: 5: Step: 24401/28124, loss=0.804067, lr=0.000003
24499it [1:21:16,  5.71it/s]Train batch 24500
Avg. loss per last 100 batches: 0.916881
24500it [1:21:17,  5.73it/s]Epoch: 5: Step: 24501/28124, loss=0.657204, lr=0.000003
24599it [1:21:34,  5.69it/s]Train batch 24600
Avg. loss per last 100 batches: 0.920677
24600it [1:21:34,  5.71it/s]Epoch: 5: Step: 24601/28124, loss=0.941870, lr=0.000003
24699it [1:21:51,  5.74it/s]Train batch 24700
Avg. loss per last 100 batches: 0.992514
24700it [1:21:52,  5.75it/s]Epoch: 5: Step: 24701/28124, loss=0.745129, lr=0.000003
24799it [1:22:09,  5.74it/s]Train batch 24800
Avg. loss per last 100 batches: 0.965912
24800it [1:22:09,  5.72it/s]Epoch: 5: Step: 24801/28124, loss=1.112160, lr=0.000003
24899it [1:22:26,  5.72it/s]Train batch 24900
Avg. loss per last 100 batches: 0.954019
24900it [1:22:27,  5.74it/s]Epoch: 5: Step: 24901/28124, loss=0.701609, lr=0.000003
24999it [1:22:44,  5.76it/s]Train batch 25000
Avg. loss per last 100 batches: 0.920424
25000it [1:22:44,  5.76it/s]Epoch: 5: Step: 25001/28124, loss=1.720702, lr=0.000003
25099it [1:23:02,  5.71it/s]Train batch 25100
Avg. loss per last 100 batches: 1.015237
25100it [1:23:02,  5.71it/s]Epoch: 5: Step: 25101/28124, loss=0.951788, lr=0.000003
25199it [1:23:19,  5.72it/s]Train batch 25200
Avg. loss per last 100 batches: 0.947403
25200it [1:23:19,  5.73it/s]Epoch: 5: Step: 25201/28124, loss=0.685722, lr=0.000003
25299it [1:23:37,  5.75it/s]Train batch 25300
Avg. loss per last 100 batches: 0.958717
25300it [1:23:37,  5.75it/s]Epoch: 5: Step: 25301/28124, loss=0.733489, lr=0.000003
25399it [1:23:54,  5.65it/s]Train batch 25400
Avg. loss per last 100 batches: 0.947854
25400it [1:23:54,  5.69it/s]Epoch: 5: Step: 25401/28124, loss=1.300058, lr=0.000003
25499it [1:24:12,  5.73it/s]Train batch 25500
Avg. loss per last 100 batches: 0.997287
25500it [1:24:12,  5.74it/s]Epoch: 5: Step: 25501/28124, loss=1.004543, lr=0.000003
25599it [1:24:29,  5.74it/s]Train batch 25600
Avg. loss per last 100 batches: 0.929327
25600it [1:24:29,  5.73it/s]Epoch: 5: Step: 25601/28124, loss=0.897771, lr=0.000003
25699it [1:24:47,  5.75it/s]Train batch 25700
Avg. loss per last 100 batches: 0.975669
25700it [1:24:47,  5.74it/s]Epoch: 5: Step: 25701/28124, loss=0.700081, lr=0.000003
25799it [1:25:04,  5.74it/s]Train batch 25800
Avg. loss per last 100 batches: 0.957693
25800it [1:25:04,  5.74it/s]Epoch: 5: Step: 25801/28124, loss=1.004078, lr=0.000003
25899it [1:25:22,  5.72it/s]Train batch 25900
Avg. loss per last 100 batches: 0.979627
25900it [1:25:22,  5.72it/s]Epoch: 5: Step: 25901/28124, loss=0.933888, lr=0.000003
25999it [1:25:39,  5.72it/s]Train batch 26000
Avg. loss per last 100 batches: 0.984820
26000it [1:25:39,  5.73it/s]Epoch: 5: Step: 26001/28124, loss=0.870609, lr=0.000003
26099it [1:25:57,  5.75it/s]Train batch 26100
Avg. loss per last 100 batches: 1.008505
26100it [1:25:57,  5.75it/s]Epoch: 5: Step: 26101/28124, loss=0.686859, lr=0.000003
26199it [1:26:14,  5.74it/s]Train batch 26200
Avg. loss per last 100 batches: 0.976170
26200it [1:26:15,  5.75it/s]Epoch: 5: Step: 26201/28124, loss=0.924022, lr=0.000003
26299it [1:26:32,  5.41it/s]Train batch 26300
Avg. loss per last 100 batches: 0.975842
26300it [1:26:32,  5.41it/s]Epoch: 5: Step: 26301/28124, loss=1.209637, lr=0.000003
26399it [1:26:49,  5.73it/s]Train batch 26400
Avg. loss per last 100 batches: 1.035985
26400it [1:26:50,  5.73it/s]Epoch: 5: Step: 26401/28124, loss=0.653856, lr=0.000003
26499it [1:27:07,  5.75it/s]Train batch 26500
Avg. loss per last 100 batches: 1.012385
26500it [1:27:07,  5.74it/s]Epoch: 5: Step: 26501/28124, loss=0.844767, lr=0.000003
26599it [1:27:25,  5.74it/s]Train batch 26600
Avg. loss per last 100 batches: 0.990134
26600it [1:27:25,  5.75it/s]Epoch: 5: Step: 26601/28124, loss=0.752803, lr=0.000003
26699it [1:27:42,  5.74it/s]Train batch 26700
Avg. loss per last 100 batches: 0.956338
26700it [1:27:42,  5.72it/s]Epoch: 5: Step: 26701/28124, loss=0.720414, lr=0.000003
26799it [1:28:00,  5.71it/s]Train batch 26800
Avg. loss per last 100 batches: 0.941356
26800it [1:28:00,  5.67it/s]Epoch: 5: Step: 26801/28124, loss=0.727545, lr=0.000003
26899it [1:28:17,  5.75it/s]Train batch 26900
Avg. loss per last 100 batches: 1.000134
26900it [1:28:17,  5.74it/s]Epoch: 5: Step: 26901/28124, loss=0.904524, lr=0.000003
26999it [1:28:35,  5.74it/s]Train batch 27000
Avg. loss per last 100 batches: 0.962018
27000it [1:28:35,  5.73it/s]Epoch: 5: Step: 27001/28124, loss=0.953309, lr=0.000003
27099it [1:28:52,  5.71it/s]Train batch 27100
Avg. loss per last 100 batches: 0.975136
27100it [1:28:52,  5.71it/s]Epoch: 5: Step: 27101/28124, loss=0.808284, lr=0.000003
27199it [1:29:10,  5.59it/s]Train batch 27200
Avg. loss per last 100 batches: 0.965523
27200it [1:29:10,  5.42it/s]Epoch: 5: Step: 27201/28124, loss=0.875857, lr=0.000003
27299it [1:29:27,  5.73it/s]Train batch 27300
Avg. loss per last 100 batches: 0.951535
27300it [1:29:27,  5.74it/s]Epoch: 5: Step: 27301/28124, loss=1.204270, lr=0.000003
27399it [1:29:45,  5.73it/s]Train batch 27400
Avg. loss per last 100 batches: 0.970495
27400it [1:29:45,  5.72it/s]Epoch: 5: Step: 27401/28124, loss=1.125591, lr=0.000003
27499it [1:30:02,  5.72it/s]Train batch 27500
Avg. loss per last 100 batches: 0.984701
27500it [1:30:02,  5.73it/s]Epoch: 5: Step: 27501/28124, loss=0.788716, lr=0.000003
27599it [1:30:20,  5.73it/s]Train batch 27600
Avg. loss per last 100 batches: 0.977654
27600it [1:30:20,  5.74it/s]Epoch: 5: Step: 27601/28124, loss=1.143581, lr=0.000003
27699it [1:30:37,  5.73it/s]Train batch 27700
Avg. loss per last 100 batches: 0.963692
27700it [1:30:38,  5.74it/s]Epoch: 5: Step: 27701/28124, loss=0.828848, lr=0.000003
27799it [1:30:55,  5.73it/s]Train batch 27800
Avg. loss per last 100 batches: 1.003709
27800it [1:30:55,  5.74it/s]Epoch: 5: Step: 27801/28124, loss=1.141899, lr=0.000003
27899it [1:31:12,  5.70it/s]Train batch 27900
Avg. loss per last 100 batches: 0.903399
27900it [1:31:13,  5.71it/s]Epoch: 5: Step: 27901/28124, loss=0.656016, lr=0.000003
27999it [1:31:30,  5.70it/s]Train batch 28000
Avg. loss per last 100 batches: 1.010745
28000it [1:31:30,  5.64it/s]Epoch: 5: Step: 28001/28124, loss=0.672022, lr=0.000003
28099it [1:31:47,  5.72it/s]Train batch 28100
Avg. loss per last 100 batches: 0.961616
28100it [1:31:48,  5.72it/s]Epoch: 5: Step: 28101/28124, loss=0.935855, lr=0.000003
28124it [1:31:52,  5.10it/s]
NLL validation ...
Reading file /kaggle/working/cleaned_valid_1.json
Aggregated data size: 100028
Total cleaned data size: 100028
Eval step: 99 , used_time=4.274541 sec., loss=0.765744 
Eval step: 199 , used_time=8.562773 sec., loss=1.188823 
Eval step: 299 , used_time=12.844936 sec., loss=0.561744 
Eval step: 399 , used_time=17.108230 sec., loss=1.264965 
Eval step: 499 , used_time=21.415140 sec., loss=1.149896 
Eval step: 599 , used_time=25.695188 sec., loss=1.505092 
Eval step: 699 , used_time=30.199056 sec., loss=1.511640 
Eval step: 799 , used_time=34.472535 sec., loss=1.252431 
Eval step: 899 , used_time=38.771521 sec., loss=1.136442 
Eval step: 999 , used_time=43.030811 sec., loss=1.104135 
Eval step: 1099 , used_time=47.303415 sec., loss=0.846124 
Eval step: 1199 , used_time=51.600620 sec., loss=0.978893 
Eval step: 1299 , used_time=55.869862 sec., loss=0.775505 
Eval step: 1399 , used_time=60.290790 sec., loss=0.443161 
Eval step: 1499 , used_time=64.620304 sec., loss=0.628803 
Eval step: 1599 , used_time=68.899616 sec., loss=0.961506 
Eval step: 1699 , used_time=73.162661 sec., loss=0.664517 
Eval step: 1799 , used_time=77.460329 sec., loss=0.731290 
Eval step: 1899 , used_time=81.749929 sec., loss=0.626314 
Eval step: 1999 , used_time=86.011471 sec., loss=1.347931 
Eval step: 2099 , used_time=90.304299 sec., loss=0.671805 
Eval step: 2199 , used_time=94.768521 sec., loss=0.832142 
Eval step: 2299 , used_time=99.061498 sec., loss=0.325655 
Eval step: 2399 , used_time=103.327689 sec., loss=1.162769 
Eval step: 2499 , used_time=107.621686 sec., loss=0.923063 
Eval step: 2599 , used_time=111.912259 sec., loss=1.164237 
Eval step: 2699 , used_time=116.193836 sec., loss=0.833359 
Eval step: 2799 , used_time=120.492473 sec., loss=1.002915 
Eval step: 2899 , used_time=124.934544 sec., loss=0.704700 
Eval step: 2999 , used_time=129.228388 sec., loss=0.885232 
Eval step: 3099 , used_time=133.493692 sec., loss=0.764740 
NLL Validation: loss = 0.918183. correct prediction ratio  75108/100032 ~  0.750840
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=0.981834
epoch total correct predictions=648243