***** Training *****
***** Epoch 0 *****
0it [00:00, ?it/s]Epoch: 0: Step: 1/14003, loss=13.094327, lr=0.000000
99it [00:19,  5.88it/s]Train batch 100
Avg. loss per last 100 batches: 11.490402
100it [00:19,  5.83it/s]Epoch: 0: Step: 101/14003, loss=7.204224, lr=0.000002
199it [00:36,  5.82it/s]Train batch 200
Avg. loss per last 100 batches: 4.955420
200it [00:36,  5.83it/s]Epoch: 0: Step: 201/14003, loss=3.662887, lr=0.000003
299it [00:53,  5.86it/s]Train batch 300
Avg. loss per last 100 batches: 3.586406
300it [00:53,  5.84it/s]Epoch: 0: Step: 301/14003, loss=2.986175, lr=0.000005
399it [01:11,  5.88it/s]Train batch 400
Avg. loss per last 100 batches: 3.014354
400it [01:11,  5.86it/s]Epoch: 0: Step: 401/14003, loss=2.674053, lr=0.000006
499it [01:28,  5.87it/s]Train batch 500
Avg. loss per last 100 batches: 2.855912
500it [01:28,  5.85it/s]Epoch: 0: Step: 501/14003, loss=3.106879, lr=0.000008
599it [01:45,  5.87it/s]Train batch 600
Avg. loss per last 100 batches: 2.794836
600it [01:45,  5.87it/s]Epoch: 0: Step: 601/14003, loss=2.709266, lr=0.000010
699it [02:02,  5.81it/s]Train batch 700
Avg. loss per last 100 batches: 2.690085
700it [02:02,  5.83it/s]Epoch: 0: Step: 701/14003, loss=2.897742, lr=0.000011
799it [02:19,  5.86it/s]Train batch 800
Avg. loss per last 100 batches: 2.678805
800it [02:20,  5.86it/s]Epoch: 0: Step: 801/14003, loss=1.852796, lr=0.000013
899it [02:36,  5.88it/s]Train batch 900
Avg. loss per last 100 batches: 2.587394
900it [02:37,  5.73it/s]Epoch: 0: Step: 901/14003, loss=2.208641, lr=0.000015
999it [02:54,  5.86it/s]Train batch 1000
Avg. loss per last 100 batches: 2.600569
1000it [02:54,  5.87it/s]Epoch: 0: Step: 1001/14003, loss=2.618236, lr=0.000016
1099it [03:11,  5.63it/s]Train batch 1100
Avg. loss per last 100 batches: 2.493186
1100it [03:11,  5.46it/s]Epoch: 0: Step: 1101/14003, loss=2.722247, lr=0.000018
1199it [03:28,  5.87it/s]Train batch 1200
Avg. loss per last 100 batches: 2.514291
1200it [03:28,  5.86it/s]Epoch: 0: Step: 1201/14003, loss=2.244781, lr=0.000019
1299it [03:46,  5.85it/s]Train batch 1300
Avg. loss per last 100 batches: 2.450372
1300it [03:46,  5.85it/s]Epoch: 0: Step: 1301/14003, loss=2.347578, lr=0.000020
1399it [04:03,  5.83it/s]Train batch 1400
Avg. loss per last 100 batches: 2.427585
1400it [04:03,  5.83it/s]Epoch: 0: Step: 1401/14003, loss=2.410288, lr=0.000020
1499it [04:20,  5.84it/s]Train batch 1500
Avg. loss per last 100 batches: 2.389293
1500it [04:20,  5.83it/s]Epoch: 0: Step: 1501/14003, loss=2.158746, lr=0.000020
1599it [04:37,  5.87it/s]Train batch 1600
Avg. loss per last 100 batches: 2.425961
1600it [04:37,  5.87it/s]Epoch: 0: Step: 1601/14003, loss=1.692033, lr=0.000020
1699it [04:54,  5.85it/s]Train batch 1700
Avg. loss per last 100 batches: 2.398626
1700it [04:55,  5.84it/s]Epoch: 0: Step: 1701/14003, loss=2.449168, lr=0.000020
1799it [05:12,  5.84it/s]Train batch 1800
Avg. loss per last 100 batches: 2.332140
1800it [05:12,  5.85it/s]Epoch: 0: Step: 1801/14003, loss=2.240297, lr=0.000020
1899it [05:29,  5.88it/s]Train batch 1900
Avg. loss per last 100 batches: 2.303710
1900it [05:29,  5.85it/s]Epoch: 0: Step: 1901/14003, loss=2.381697, lr=0.000020
1999it [05:46,  5.85it/s]Train batch 2000
Avg. loss per last 100 batches: 2.321690
2000it [05:46,  5.80it/s]Epoch: 0: Step: 2001/14003, loss=2.102723, lr=0.000020
2099it [06:03,  5.83it/s]Train batch 2100
Avg. loss per last 100 batches: 2.328753
2100it [06:03,  5.84it/s]Epoch: 0: Step: 2101/14003, loss=2.540599, lr=0.000020
2199it [06:21,  5.78it/s]Train batch 2200
Avg. loss per last 100 batches: 2.262043
2200it [06:21,  5.78it/s]Epoch: 0: Step: 2201/14003, loss=2.348662, lr=0.000020
2299it [06:38,  5.89it/s]Train batch 2300
Avg. loss per last 100 batches: 2.280239
2300it [06:38,  5.88it/s]Epoch: 0: Step: 2301/14003, loss=2.239137, lr=0.000020
2399it [06:55,  5.87it/s]Train batch 2400
Avg. loss per last 100 batches: 2.188446
2400it [06:55,  5.86it/s]Epoch: 0: Step: 2401/14003, loss=2.626150, lr=0.000020
2499it [07:12,  5.79it/s]Train batch 2500
Avg. loss per last 100 batches: 2.250184
2500it [07:12,  5.82it/s]Epoch: 0: Step: 2501/14003, loss=2.678968, lr=0.000020
2599it [07:30,  5.89it/s]Train batch 2600
Avg. loss per last 100 batches: 2.211046
2600it [07:30,  5.89it/s]Epoch: 0: Step: 2601/14003, loss=1.896131, lr=0.000020
2699it [07:47,  5.86it/s]Train batch 2700
Avg. loss per last 100 batches: 2.210051
2700it [07:48,  5.86it/s]Epoch: 0: Step: 2701/14003, loss=1.850876, lr=0.000020
2799it [08:05,  5.86it/s]Train batch 2800
Avg. loss per last 100 batches: 2.171450
2800it [08:05,  5.83it/s]Epoch: 0: Step: 2801/14003, loss=2.579456, lr=0.000020
Validation: Epoch: 0 Step: 2801/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.793523 sec., loss=1.478604 
Eval step: 199 , used_time=9.577321 sec., loss=1.779989 
Eval step: 299 , used_time=14.375329 sec., loss=2.106096 
Eval step: 399 , used_time=19.142411 sec., loss=1.388088 
Eval step: 499 , used_time=24.127540 sec., loss=1.158806 
Eval step: 599 , used_time=28.918751 sec., loss=2.143342 
Eval step: 699 , used_time=33.688170 sec., loss=1.579881 
Eval step: 799 , used_time=38.480360 sec., loss=1.591459 
Eval step: 899 , used_time=43.241444 sec., loss=1.560799 
Eval step: 999 , used_time=48.061732 sec., loss=1.981475 
Eval step: 1099 , used_time=53.034312 sec., loss=1.674824 
Eval step: 1199 , used_time=57.809922 sec., loss=1.439446 
Eval step: 1299 , used_time=62.646314 sec., loss=1.934001 
Eval step: 1399 , used_time=67.481501 sec., loss=1.198390 
Eval step: 1499 , used_time=72.217481 sec., loss=1.476029 
Eval step: 1599 , used_time=77.036213 sec., loss=1.228265 
NLL Validation: loss = 1.545186. correct prediction ratio  29717/52032 ~  0.571129
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
2899it [09:43,  5.87it/s]Train batch 2900
Avg. loss per last 100 batches: 2.164287
2900it [09:44,  5.85it/s]Epoch: 0: Step: 2901/14003, loss=2.010211, lr=0.000020
2999it [10:01,  5.34it/s]Train batch 3000
Avg. loss per last 100 batches: 2.178878
3000it [10:01,  5.36it/s]Epoch: 0: Step: 3001/14003, loss=1.990474, lr=0.000020
3099it [10:18,  5.87it/s]Train batch 3100
Avg. loss per last 100 batches: 2.237162
3100it [10:18,  5.84it/s]Epoch: 0: Step: 3101/14003, loss=1.956429, lr=0.000020
3199it [10:35,  5.87it/s]Train batch 3200
Avg. loss per last 100 batches: 2.150148
3200it [10:35,  5.89it/s]Epoch: 0: Step: 3201/14003, loss=2.199286, lr=0.000020
3299it [10:52,  5.82it/s]Train batch 3300
Avg. loss per last 100 batches: 2.187096
3300it [10:52,  5.84it/s]Epoch: 0: Step: 3301/14003, loss=1.948471, lr=0.000020
3399it [11:10,  5.82it/s]Train batch 3400
Avg. loss per last 100 batches: 2.109294
3400it [11:10,  5.82it/s]Epoch: 0: Step: 3401/14003, loss=2.506697, lr=0.000020
3499it [11:27,  5.85it/s]Train batch 3500
Avg. loss per last 100 batches: 2.181531
3500it [11:27,  5.84it/s]Epoch: 0: Step: 3501/14003, loss=1.733524, lr=0.000020
3599it [11:44,  5.85it/s]Train batch 3600
Avg. loss per last 100 batches: 2.095767
3600it [11:44,  5.82it/s]Epoch: 0: Step: 3601/14003, loss=2.037358, lr=0.000020
3699it [12:01,  5.82it/s]Train batch 3700
Avg. loss per last 100 batches: 2.100576
3700it [12:01,  5.82it/s]Epoch: 0: Step: 3701/14003, loss=2.521050, lr=0.000019
3799it [12:19,  5.88it/s]Train batch 3800
Avg. loss per last 100 batches: 2.139924
3800it [12:19,  5.86it/s]Epoch: 0: Step: 3801/14003, loss=2.047529, lr=0.000019
3899it [12:36,  5.85it/s]Train batch 3900
Avg. loss per last 100 batches: 2.095524
3900it [12:36,  5.86it/s]Epoch: 0: Step: 3901/14003, loss=1.853812, lr=0.000019
3999it [12:53,  5.83it/s]Train batch 4000
Avg. loss per last 100 batches: 2.116016
4000it [12:53,  5.83it/s]Epoch: 0: Step: 4001/14003, loss=2.089165, lr=0.000019
4099it [13:12,  5.77it/s]Train batch 4100
Avg. loss per last 100 batches: 2.068717
4100it [13:12,  5.78it/s]Epoch: 0: Step: 4101/14003, loss=2.224509, lr=0.000019
4199it [13:29,  5.89it/s]Train batch 4200
Avg. loss per last 100 batches: 2.052312
4200it [13:29,  5.89it/s]Epoch: 0: Step: 4201/14003, loss=1.579027, lr=0.000019
4299it [13:47,  5.87it/s]Train batch 4300
Avg. loss per last 100 batches: 2.065397
4300it [13:47,  5.86it/s]Epoch: 0: Step: 4301/14003, loss=1.858736, lr=0.000019
4399it [14:04,  5.85it/s]Train batch 4400
Avg. loss per last 100 batches: 2.085313
4400it [14:04,  5.80it/s]Epoch: 0: Step: 4401/14003, loss=1.988194, lr=0.000019
4499it [14:21,  5.87it/s]Train batch 4500
Avg. loss per last 100 batches: 2.037730
4500it [14:21,  5.63it/s]Epoch: 0: Step: 4501/14003, loss=1.792432, lr=0.000019
4599it [14:38,  5.86it/s]Train batch 4600
Avg. loss per last 100 batches: 2.051950
4600it [14:38,  5.86it/s]Epoch: 0: Step: 4601/14003, loss=1.604835, lr=0.000019
4699it [14:55,  5.87it/s]Train batch 4700
Avg. loss per last 100 batches: 1.999484
4700it [14:56,  5.87it/s]Epoch: 0: Step: 4701/14003, loss=1.362747, lr=0.000019
4799it [15:13,  5.85it/s]Train batch 4800
Avg. loss per last 100 batches: 1.981932
4800it [15:13,  5.86it/s]Epoch: 0: Step: 4801/14003, loss=1.763423, lr=0.000019
4899it [15:30,  5.86it/s]Train batch 4900
Avg. loss per last 100 batches: 1.960028
4900it [15:30,  5.88it/s]Epoch: 0: Step: 4901/14003, loss=1.670448, lr=0.000019
4999it [15:47,  5.55it/s]Train batch 5000
Avg. loss per last 100 batches: 2.016529
5000it [15:47,  5.44it/s]Epoch: 0: Step: 5001/14003, loss=2.179797, lr=0.000019
5099it [16:05,  5.87it/s]Train batch 5100
Avg. loss per last 100 batches: 2.015317
5100it [16:05,  5.83it/s]Epoch: 0: Step: 5101/14003, loss=1.693070, lr=0.000019
5199it [16:22,  5.73it/s]Train batch 5200
Avg. loss per last 100 batches: 1.957954
5200it [16:22,  5.74it/s]Epoch: 0: Step: 5201/14003, loss=2.162436, lr=0.000019
5299it [16:39,  5.85it/s]Train batch 5300
Avg. loss per last 100 batches: 1.989579
5300it [16:39,  5.86it/s]Epoch: 0: Step: 5301/14003, loss=1.752859, lr=0.000019
5399it [16:56,  5.87it/s]Train batch 5400
Avg. loss per last 100 batches: 1.961236
5400it [16:56,  5.88it/s]Epoch: 0: Step: 5401/14003, loss=2.340252, lr=0.000019
5499it [17:13,  5.86it/s]Train batch 5500
Avg. loss per last 100 batches: 1.946830
5500it [17:14,  5.86it/s]Epoch: 0: Step: 5501/14003, loss=1.943247, lr=0.000019
5599it [17:31,  5.81it/s]Train batch 5600
Avg. loss per last 100 batches: 1.976151
5600it [17:31,  5.74it/s]Epoch: 0: Step: 5601/14003, loss=2.054457, lr=0.000019
5601it [17:31,  5.64it/s]Validation: Epoch: 0 Step: 5602/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.774619 sec., loss=1.364314 
Eval step: 199 , used_time=9.524942 sec., loss=1.725095 
Eval step: 299 , used_time=14.293115 sec., loss=1.607620 
Eval step: 399 , used_time=19.036961 sec., loss=1.359300 
Eval step: 499 , used_time=24.034655 sec., loss=1.207495 
Eval step: 599 , used_time=28.769900 sec., loss=1.799931 
Eval step: 699 , used_time=33.614790 sec., loss=1.375101 
Eval step: 799 , used_time=38.415388 sec., loss=1.424672 
Eval step: 899 , used_time=43.214760 sec., loss=1.605191 
Eval step: 999 , used_time=47.953653 sec., loss=1.765553 
Eval step: 1099 , used_time=52.726854 sec., loss=1.533403 
Eval step: 1199 , used_time=57.690037 sec., loss=1.276004 
Eval step: 1299 , used_time=62.482772 sec., loss=1.766273 
Eval step: 1399 , used_time=67.247912 sec., loss=1.116684 
Eval step: 1499 , used_time=72.003318 sec., loss=1.119326 
Eval step: 1599 , used_time=76.748297 sec., loss=1.053137 
NLL Validation: loss = 1.352342. correct prediction ratio  32345/52032 ~  0.621637
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:10,  5.83it/s]Train batch 5700
Avg. loss per last 100 batches: 1.982932
5700it [19:10,  5.82it/s]Epoch: 0: Step: 5701/14003, loss=1.935960, lr=0.000019
5799it [19:27,  5.85it/s]Train batch 5800
Avg. loss per last 100 batches: 1.925504
5800it [19:27,  5.85it/s]Epoch: 0: Step: 5801/14003, loss=2.002970, lr=0.000019
5899it [19:44,  5.86it/s]Train batch 5900
Avg. loss per last 100 batches: 1.889593
5900it [19:45,  5.86it/s]Epoch: 0: Step: 5901/14003, loss=2.312778, lr=0.000019
5999it [20:02,  5.33it/s]Train batch 6000
Avg. loss per last 100 batches: 1.953087
6000it [20:02,  5.47it/s]Epoch: 0: Step: 6001/14003, loss=1.804365, lr=0.000019
6099it [20:19,  5.86it/s]Train batch 6100
Avg. loss per last 100 batches: 1.926505
6100it [20:19,  5.85it/s]Epoch: 0: Step: 6101/14003, loss=1.667813, lr=0.000019
6199it [20:36,  5.86it/s]Train batch 6200
Avg. loss per last 100 batches: 1.885627
6200it [20:36,  5.87it/s]Epoch: 0: Step: 6201/14003, loss=2.294890, lr=0.000019
6299it [20:53,  5.84it/s]Train batch 6300
Avg. loss per last 100 batches: 1.917856
6300it [20:54,  5.85it/s]Epoch: 0: Step: 6301/14003, loss=1.555304, lr=0.000019
6399it [21:11,  5.84it/s]Train batch 6400
Avg. loss per last 100 batches: 1.921653
6400it [21:11,  5.87it/s]Epoch: 0: Step: 6401/14003, loss=1.745179, lr=0.000019
6499it [21:28,  5.83it/s]Train batch 6500
Avg. loss per last 100 batches: 1.989948
6500it [21:28,  5.83it/s]Epoch: 0: Step: 6501/14003, loss=1.384286, lr=0.000019
6599it [21:45,  5.85it/s]Train batch 6600
Avg. loss per last 100 batches: 1.905111
6600it [21:45,  5.86it/s]Epoch: 0: Step: 6601/14003, loss=1.394925, lr=0.000019
6699it [22:02,  5.85it/s]Train batch 6700
Avg. loss per last 100 batches: 1.823190
6700it [22:02,  5.85it/s]Epoch: 0: Step: 6701/14003, loss=2.416395, lr=0.000019
6799it [22:20,  5.84it/s]Train batch 6800
Avg. loss per last 100 batches: 1.925727
6800it [22:20,  5.84it/s]Epoch: 0: Step: 6801/14003, loss=1.439072, lr=0.000019
6899it [22:37,  5.87it/s]Train batch 6900
Avg. loss per last 100 batches: 1.897129
6900it [22:37,  5.86it/s]Epoch: 0: Step: 6901/14003, loss=1.899548, lr=0.000019
6999it [22:54,  5.87it/s]Train batch 7000
Avg. loss per last 100 batches: 1.925429
7000it [22:54,  5.86it/s]Epoch: 0: Step: 7001/14003, loss=1.910916, lr=0.000019
7099it [23:11,  5.34it/s]Train batch 7100
Avg. loss per last 100 batches: 1.907789
7100it [23:12,  5.48it/s]Epoch: 0: Step: 7101/14003, loss=2.067734, lr=0.000019
7199it [23:28,  5.87it/s]Train batch 7200
Avg. loss per last 100 batches: 1.918043
7200it [23:29,  5.86it/s]Epoch: 0: Step: 7201/14003, loss=1.796158, lr=0.000019
7299it [23:46,  5.87it/s]Train batch 7300
Avg. loss per last 100 batches: 1.937016
7300it [23:46,  5.87it/s]Epoch: 0: Step: 7301/14003, loss=1.277285, lr=0.000019
7399it [24:03,  5.84it/s]Train batch 7400
Avg. loss per last 100 batches: 1.883389
7400it [24:03,  5.83it/s]Epoch: 0: Step: 7401/14003, loss=2.310369, lr=0.000019
7499it [24:20,  5.89it/s]Train batch 7500
Avg. loss per last 100 batches: 1.891277
7500it [24:20,  5.88it/s]Epoch: 0: Step: 7501/14003, loss=1.658606, lr=0.000019
7599it [24:37,  5.83it/s]Train batch 7600
Avg. loss per last 100 batches: 1.862641
7600it [24:38,  5.82it/s]Epoch: 0: Step: 7601/14003, loss=1.726238, lr=0.000019
7699it [24:55,  5.85it/s]Train batch 7700
Avg. loss per last 100 batches: 1.876974
7700it [24:55,  5.84it/s]Epoch: 0: Step: 7701/14003, loss=2.212998, lr=0.000019
7799it [25:12,  5.80it/s]Train batch 7800
Avg. loss per last 100 batches: 1.903724
7800it [25:12,  5.82it/s]Epoch: 0: Step: 7801/14003, loss=2.232754, lr=0.000019
7899it [25:29,  5.84it/s]Train batch 7900
Avg. loss per last 100 batches: 1.836926
7900it [25:29,  5.83it/s]Epoch: 0: Step: 7901/14003, loss=1.774206, lr=0.000019
7999it [25:46,  5.88it/s]Train batch 8000
Avg. loss per last 100 batches: 1.849950
8000it [25:46,  5.86it/s]Epoch: 0: Step: 8001/14003, loss=2.215182, lr=0.000019
8099it [26:04,  5.86it/s]Train batch 8100
Avg. loss per last 100 batches: 1.854491
8100it [26:04,  5.86it/s]Epoch: 0: Step: 8101/14003, loss=2.402231, lr=0.000019
8199it [26:21,  5.54it/s]Train batch 8200
Avg. loss per last 100 batches: 1.830060
8200it [26:21,  5.64it/s]Epoch: 0: Step: 8201/14003, loss=1.421863, lr=0.000019
8299it [26:38,  5.86it/s]Train batch 8300
Avg. loss per last 100 batches: 1.795529
8300it [26:38,  5.86it/s]Epoch: 0: Step: 8301/14003, loss=1.752131, lr=0.000019
8399it [26:55,  5.87it/s]Train batch 8400
Avg. loss per last 100 batches: 1.831914
8400it [26:55,  5.83it/s]Epoch: 0: Step: 8401/14003, loss=1.645584, lr=0.000019
8402it [26:56,  5.80it/s]Validation: Epoch: 0 Step: 8403/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.750945 sec., loss=1.277060 
Eval step: 199 , used_time=9.549995 sec., loss=1.728568 
Eval step: 299 , used_time=14.331474 sec., loss=1.474651 
Eval step: 399 , used_time=19.163493 sec., loss=1.276027 
Eval step: 499 , used_time=23.911646 sec., loss=1.087089 
Eval step: 599 , used_time=28.917976 sec., loss=1.685296 
Eval step: 699 , used_time=33.688918 sec., loss=1.260171 
Eval step: 799 , used_time=38.472086 sec., loss=1.213818 
Eval step: 899 , used_time=43.230798 sec., loss=1.527606 
Eval step: 999 , used_time=48.038502 sec., loss=1.528828 
Eval step: 1099 , used_time=52.782984 sec., loss=1.479604 
Eval step: 1199 , used_time=57.570095 sec., loss=1.212511 
Eval step: 1299 , used_time=62.524541 sec., loss=1.663614 
Eval step: 1399 , used_time=67.303852 sec., loss=1.047450 
Eval step: 1499 , used_time=72.084929 sec., loss=1.213279 
Eval step: 1599 , used_time=76.930710 sec., loss=1.088543 
NLL Validation: loss = 1.251802. correct prediction ratio  33727/52032 ~  0.648197
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
8499it [28:34,  5.87it/s]Train batch 8500
Avg. loss per last 100 batches: 1.836891
8500it [28:35,  5.86it/s]Epoch: 0: Step: 8501/14003, loss=1.738683, lr=0.000018
8599it [28:52,  5.82it/s]Train batch 8600
Avg. loss per last 100 batches: 1.851604
8600it [28:52,  5.82it/s]Epoch: 0: Step: 8601/14003, loss=1.943802, lr=0.000018
8699it [29:09,  5.82it/s]Train batch 8700
Avg. loss per last 100 batches: 1.825797
8700it [29:09,  5.82it/s]Epoch: 0: Step: 8701/14003, loss=1.872447, lr=0.000018
8799it [29:26,  5.86it/s]Train batch 8800
Avg. loss per last 100 batches: 1.830096
8800it [29:26,  5.83it/s]Epoch: 0: Step: 8801/14003, loss=2.690072, lr=0.000018
8899it [29:43,  5.83it/s]Train batch 8900
Avg. loss per last 100 batches: 1.830213
8900it [29:44,  5.82it/s]Epoch: 0: Step: 8901/14003, loss=1.768508, lr=0.000018
8999it [30:01,  5.42it/s]Train batch 9000
Avg. loss per last 100 batches: 1.789780
9000it [30:01,  5.35it/s]Epoch: 0: Step: 9001/14003, loss=1.957207, lr=0.000018
9099it [30:18,  5.85it/s]Train batch 9100
Avg. loss per last 100 batches: 1.809129
9100it [30:18,  5.85it/s]Epoch: 0: Step: 9101/14003, loss=1.627852, lr=0.000018
9199it [30:35,  5.84it/s]Train batch 9200
Avg. loss per last 100 batches: 1.867082
9200it [30:35,  5.84it/s]Epoch: 0: Step: 9201/14003, loss=1.726453, lr=0.000018
9299it [30:52,  5.72it/s]Train batch 9300
Avg. loss per last 100 batches: 1.791848
9300it [30:53,  5.75it/s]Epoch: 0: Step: 9301/14003, loss=1.991814, lr=0.000018
9399it [31:10,  5.81it/s]Train batch 9400
Avg. loss per last 100 batches: 1.804587
9400it [31:10,  5.83it/s]Epoch: 0: Step: 9401/14003, loss=1.663341, lr=0.000018
9499it [31:27,  5.88it/s]Train batch 9500
Avg. loss per last 100 batches: 1.779804
9500it [31:27,  5.86it/s]Epoch: 0: Step: 9501/14003, loss=2.008585, lr=0.000018
9599it [31:44,  5.86it/s]Train batch 9600
Avg. loss per last 100 batches: 1.769546
9600it [31:44,  5.86it/s]Epoch: 0: Step: 9601/14003, loss=1.938528, lr=0.000018
9699it [32:01,  5.87it/s]Train batch 9700
Avg. loss per last 100 batches: 1.781747
9700it [32:01,  5.86it/s]Epoch: 0: Step: 9701/14003, loss=1.882530, lr=0.000018
9799it [32:19,  5.81it/s]Train batch 9800
Avg. loss per last 100 batches: 1.779227
9800it [32:19,  5.77it/s]Epoch: 0: Step: 9801/14003, loss=2.193347, lr=0.000018
9899it [32:36,  5.87it/s]Train batch 9900
Avg. loss per last 100 batches: 1.777056
9900it [32:36,  5.87it/s]Epoch: 0: Step: 9901/14003, loss=1.170677, lr=0.000018
9999it [32:53,  5.85it/s]Train batch 10000
Avg. loss per last 100 batches: 1.813763
10000it [32:53,  5.81it/s]Epoch: 0: Step: 10001/14003, loss=1.660816, lr=0.000018
10099it [33:10,  5.73it/s]Train batch 10100
Avg. loss per last 100 batches: 1.808993
10100it [33:10,  5.52it/s]Epoch: 0: Step: 10101/14003, loss=1.743214, lr=0.000018
10199it [33:27,  5.88it/s]Train batch 10200
Avg. loss per last 100 batches: 1.771830
10200it [33:28,  5.87it/s]Epoch: 0: Step: 10201/14003, loss=1.814696, lr=0.000018
10299it [33:45,  5.83it/s]Train batch 10300
Avg. loss per last 100 batches: 1.774219
10300it [33:45,  5.86it/s]Epoch: 0: Step: 10301/14003, loss=1.883611, lr=0.000018
10399it [34:02,  5.77it/s]Train batch 10400
Avg. loss per last 100 batches: 1.745159
10400it [34:02,  5.80it/s]Epoch: 0: Step: 10401/14003, loss=1.809499, lr=0.000018
10499it [34:19,  5.84it/s]Train batch 10500
Avg. loss per last 100 batches: 1.787140
10500it [34:19,  5.85it/s]Epoch: 0: Step: 10501/14003, loss=1.851728, lr=0.000018
10599it [34:36,  5.88it/s]Train batch 10600
Avg. loss per last 100 batches: 1.762835
10600it [34:36,  5.87it/s]Epoch: 0: Step: 10601/14003, loss=1.551319, lr=0.000018
10699it [34:53,  5.86it/s]Train batch 10700
Avg. loss per last 100 batches: 1.767126
10700it [34:54,  5.86it/s]Epoch: 0: Step: 10701/14003, loss=1.892428, lr=0.000018
10799it [35:11,  5.85it/s]Train batch 10800
Avg. loss per last 100 batches: 1.717627
10800it [35:11,  5.80it/s]Epoch: 0: Step: 10801/14003, loss=1.287408, lr=0.000018
10899it [35:28,  5.83it/s]Train batch 10900
Avg. loss per last 100 batches: 1.703094
10900it [35:28,  5.85it/s]Epoch: 0: Step: 10901/14003, loss=1.324638, lr=0.000018
10999it [35:45,  5.85it/s]Train batch 11000
Avg. loss per last 100 batches: 1.726309
11000it [35:45,  5.84it/s]Epoch: 0: Step: 11001/14003, loss=1.672710, lr=0.000018
11099it [36:02,  5.83it/s]Train batch 11100
Avg. loss per last 100 batches: 1.745281
11100it [36:02,  5.85it/s]Epoch: 0: Step: 11101/14003, loss=1.898399, lr=0.000018
11199it [36:20,  5.84it/s]Train batch 11200
Avg. loss per last 100 batches: 1.739629
11200it [36:20,  5.65it/s]Epoch: 0: Step: 11201/14003, loss=1.944805, lr=0.000018
11203it [36:20,  5.24it/s]Validation: Epoch: 0 Step: 11204/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.781114 sec., loss=1.240831 
Eval step: 199 , used_time=9.581332 sec., loss=1.555636 
Eval step: 299 , used_time=14.354289 sec., loss=1.221962 
Eval step: 399 , used_time=19.131569 sec., loss=1.109606 
Eval step: 499 , used_time=23.896816 sec., loss=1.064536 
Eval step: 599 , used_time=28.804105 sec., loss=1.611621 
Eval step: 699 , used_time=33.703498 sec., loss=1.183261 
Eval step: 799 , used_time=38.484457 sec., loss=1.107778 
Eval step: 899 , used_time=43.259282 sec., loss=1.499231 
Eval step: 999 , used_time=48.075521 sec., loss=1.408324 
Eval step: 1099 , used_time=52.809830 sec., loss=1.435553 
Eval step: 1199 , used_time=57.547176 sec., loss=1.043790 
Eval step: 1299 , used_time=62.536323 sec., loss=1.627982 
Eval step: 1399 , used_time=67.285841 sec., loss=1.035171 
Eval step: 1499 , used_time=72.053067 sec., loss=0.964756 
Eval step: 1599 , used_time=76.810915 sec., loss=0.986468 
NLL Validation: loss = 1.165400. correct prediction ratio  34783/52032 ~  0.668492
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [38:01,  5.85it/s]Train batch 11300
Avg. loss per last 100 batches: 1.756489
11300it [38:01,  5.83it/s]Epoch: 0: Step: 11301/14003, loss=1.813819, lr=0.000018
11399it [38:18,  5.86it/s]Train batch 11400
Avg. loss per last 100 batches: 1.731417
11400it [38:19,  5.82it/s]Epoch: 0: Step: 11401/14003, loss=1.608423, lr=0.000018
11499it [38:36,  5.87it/s]Train batch 11500
Avg. loss per last 100 batches: 1.672645
11500it [38:36,  5.86it/s]Epoch: 0: Step: 11501/14003, loss=2.142139, lr=0.000018
11599it [38:53,  5.86it/s]Train batch 11600
Avg. loss per last 100 batches: 1.728487
11600it [38:53,  5.85it/s]Epoch: 0: Step: 11601/14003, loss=1.363179, lr=0.000018
11699it [39:10,  5.86it/s]Train batch 11700
Avg. loss per last 100 batches: 1.719612
11700it [39:10,  5.86it/s]Epoch: 0: Step: 11701/14003, loss=1.797665, lr=0.000018
11799it [39:27,  5.86it/s]Train batch 11800
Avg. loss per last 100 batches: 1.702201
11800it [39:27,  5.86it/s]Epoch: 0: Step: 11801/14003, loss=1.645616, lr=0.000018
11899it [39:44,  5.84it/s]Train batch 11900
Avg. loss per last 100 batches: 1.766093
11900it [39:45,  5.87it/s]Epoch: 0: Step: 11901/14003, loss=1.332466, lr=0.000018
11999it [40:02,  5.31it/s]Train batch 12000
Avg. loss per last 100 batches: 1.725020
12000it [40:02,  5.34it/s]Epoch: 0: Step: 12001/14003, loss=1.773021, lr=0.000018
12099it [40:19,  5.89it/s]Train batch 12100
Avg. loss per last 100 batches: 1.707147
12100it [40:19,  5.88it/s]Epoch: 0: Step: 12101/14003, loss=1.437583, lr=0.000018
12199it [40:36,  5.85it/s]Train batch 12200
Avg. loss per last 100 batches: 1.728326
12200it [40:36,  5.86it/s]Epoch: 0: Step: 12201/14003, loss=1.300758, lr=0.000018
12299it [40:53,  5.81it/s]Train batch 12300
Avg. loss per last 100 batches: 1.708095
12300it [40:53,  5.78it/s]Epoch: 0: Step: 12301/14003, loss=1.647115, lr=0.000018
12399it [41:11,  5.89it/s]Train batch 12400
Avg. loss per last 100 batches: 1.679444
12400it [41:11,  5.89it/s]Epoch: 0: Step: 12401/14003, loss=1.979522, lr=0.000018
12499it [41:28,  5.87it/s]Train batch 12500
Avg. loss per last 100 batches: 1.653423
12500it [41:28,  5.84it/s]Epoch: 0: Step: 12501/14003, loss=1.607226, lr=0.000018
12599it [41:45,  5.86it/s]Train batch 12600
Avg. loss per last 100 batches: 1.676080
12600it [41:45,  5.85it/s]Epoch: 0: Step: 12601/14003, loss=1.744964, lr=0.000018
12699it [42:02,  5.77it/s]Train batch 12700
Avg. loss per last 100 batches: 1.710127
12700it [42:02,  5.81it/s]Epoch: 0: Step: 12701/14003, loss=2.564756, lr=0.000018
12799it [42:19,  5.86it/s]Train batch 12800
Avg. loss per last 100 batches: 1.704469
12800it [42:20,  5.85it/s]Epoch: 0: Step: 12801/14003, loss=1.503908, lr=0.000018
12899it [42:36,  5.84it/s]Train batch 12900
Avg. loss per last 100 batches: 1.668573
12900it [42:37,  5.83it/s]Epoch: 0: Step: 12901/14003, loss=2.107739, lr=0.000018
12999it [42:54,  5.81it/s]Train batch 13000
Avg. loss per last 100 batches: 1.653377
13000it [42:54,  5.81it/s]Epoch: 0: Step: 13001/14003, loss=2.329311, lr=0.000018
13099it [43:11,  5.20it/s]Train batch 13100
Avg. loss per last 100 batches: 1.734144
13100it [43:11,  5.02it/s]Epoch: 0: Step: 13101/14003, loss=1.368406, lr=0.000018
13199it [43:28,  5.84it/s]Train batch 13200
Avg. loss per last 100 batches: 1.679042
13200it [43:29,  5.84it/s]Epoch: 0: Step: 13201/14003, loss=1.657796, lr=0.000018
13299it [43:46,  5.84it/s]Train batch 13300
Avg. loss per last 100 batches: 1.706930
13300it [43:46,  5.83it/s]Epoch: 0: Step: 13301/14003, loss=1.820321, lr=0.000018
13399it [44:03,  5.86it/s]Train batch 13400
Avg. loss per last 100 batches: 1.618748
13400it [44:03,  5.82it/s]Epoch: 0: Step: 13401/14003, loss=1.446378, lr=0.000017
13499it [44:20,  5.85it/s]Train batch 13500
Avg. loss per last 100 batches: 1.673277
13500it [44:21,  5.87it/s]Epoch: 0: Step: 13501/14003, loss=1.977987, lr=0.000017
13599it [44:38,  5.81it/s]Train batch 13600
Avg. loss per last 100 batches: 1.685138
13600it [44:38,  5.76it/s]Epoch: 0: Step: 13601/14003, loss=1.456519, lr=0.000017
13699it [44:55,  5.84it/s]Train batch 13700
Avg. loss per last 100 batches: 1.639070
13700it [44:55,  5.84it/s]Epoch: 0: Step: 13701/14003, loss=1.797545, lr=0.000017
13799it [45:12,  5.78it/s]Train batch 13800
Avg. loss per last 100 batches: 1.660234
13800it [45:12,  5.82it/s]Epoch: 0: Step: 13801/14003, loss=1.684068, lr=0.000017
13899it [45:30,  5.85it/s]Train batch 13900
Avg. loss per last 100 batches: 1.618433
13900it [45:30,  5.85it/s]Epoch: 0: Step: 13901/14003, loss=2.030046, lr=0.000017
13999it [45:47,  5.81it/s]Train batch 14000
Avg. loss per last 100 batches: 1.639210
14000it [45:47,  5.82it/s]Epoch: 0: Step: 14001/14003, loss=1.210938, lr=0.000017
14003it [45:47,  5.10it/s]
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=5.019875 sec., loss=1.191932 
Eval step: 199 , used_time=9.783363 sec., loss=1.537898 
Eval step: 299 , used_time=14.569273 sec., loss=0.998065 
Eval step: 399 , used_time=19.393907 sec., loss=1.207929 
Eval step: 499 , used_time=24.229561 sec., loss=1.256543 
Eval step: 599 , used_time=29.027823 sec., loss=1.375784 
Eval step: 699 , used_time=34.084813 sec., loss=1.221601 
Eval step: 799 , used_time=38.843181 sec., loss=0.912742 
Eval step: 899 , used_time=43.646320 sec., loss=1.641658 
Eval step: 999 , used_time=48.428113 sec., loss=1.264923 
Eval step: 1099 , used_time=53.190369 sec., loss=1.358465 
Eval step: 1199 , used_time=57.975912 sec., loss=1.056330 
Eval step: 1299 , used_time=62.771969 sec., loss=1.497018 
Eval step: 1399 , used_time=67.807446 sec., loss=1.042693 
Eval step: 1499 , used_time=72.552667 sec., loss=1.156621 
Eval step: 1599 , used_time=77.409261 sec., loss=0.808557 
NLL Validation: loss = 1.109149. correct prediction ratio  35665/52032 ~  0.685444
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=2.067893
epoch total correct predictions=219717
***** Epoch 1 *****
0it [00:00, ?it/s]Epoch: 1: Step: 1/14003, loss=1.823237, lr=0.000017
99it [00:17,  5.89it/s]Train batch 100
Avg. loss per last 100 batches: 1.372792
100it [00:17,  5.88it/s]Epoch: 1: Step: 101/14003, loss=1.424456, lr=0.000017
199it [00:34,  5.84it/s]Train batch 200
Avg. loss per last 100 batches: 1.311002
200it [00:34,  5.85it/s]Epoch: 1: Step: 201/14003, loss=1.602103, lr=0.000017
299it [00:52,  5.75it/s]Train batch 300
Avg. loss per last 100 batches: 1.339201
300it [00:52,  5.79it/s]Epoch: 1: Step: 301/14003, loss=1.744887, lr=0.000017
399it [01:09,  5.83it/s]Train batch 400
Avg. loss per last 100 batches: 1.318032
400it [01:09,  5.83it/s]Epoch: 1: Step: 401/14003, loss=1.369665, lr=0.000017
499it [01:26,  5.79it/s]Train batch 500
Avg. loss per last 100 batches: 1.337781
500it [01:26,  5.82it/s]Epoch: 1: Step: 501/14003, loss=1.687671, lr=0.000017
599it [01:43,  5.86it/s]Train batch 600
Avg. loss per last 100 batches: 1.311985
600it [01:43,  5.85it/s]Epoch: 1: Step: 601/14003, loss=1.048178, lr=0.000017
699it [02:01,  5.87it/s]Train batch 700
Avg. loss per last 100 batches: 1.355146
700it [02:01,  5.85it/s]Epoch: 1: Step: 701/14003, loss=1.104468, lr=0.000017
799it [02:18,  5.88it/s]Train batch 800
Avg. loss per last 100 batches: 1.362512
800it [02:18,  5.88it/s]Epoch: 1: Step: 801/14003, loss=1.170040, lr=0.000017
899it [02:35,  5.85it/s]Train batch 900
Avg. loss per last 100 batches: 1.330052
900it [02:35,  5.85it/s]Epoch: 1: Step: 901/14003, loss=1.319674, lr=0.000017
999it [02:52,  5.36it/s]Train batch 1000
Avg. loss per last 100 batches: 1.319232
1000it [02:52,  5.34it/s]Epoch: 1: Step: 1001/14003, loss=0.935740, lr=0.000017
1099it [03:09,  5.83it/s]Train batch 1100
Avg. loss per last 100 batches: 1.427878
1100it [03:09,  5.83it/s]Epoch: 1: Step: 1101/14003, loss=1.808717, lr=0.000017
1199it [03:27,  5.89it/s]Train batch 1200
Avg. loss per last 100 batches: 1.385628
1200it [03:27,  5.89it/s]Epoch: 1: Step: 1201/14003, loss=1.910488, lr=0.000017
1299it [03:44,  5.85it/s]Train batch 1300
Avg. loss per last 100 batches: 1.343054
1300it [03:44,  5.88it/s]Epoch: 1: Step: 1301/14003, loss=1.545699, lr=0.000017
1399it [04:01,  5.85it/s]Train batch 1400
Avg. loss per last 100 batches: 1.361495
1400it [04:01,  5.85it/s]Epoch: 1: Step: 1401/14003, loss=0.982306, lr=0.000017
1499it [04:18,  5.88it/s]Train batch 1500
Avg. loss per last 100 batches: 1.316522
1500it [04:18,  5.89it/s]Epoch: 1: Step: 1501/14003, loss=1.485265, lr=0.000017
1599it [04:35,  5.86it/s]Train batch 1600
Avg. loss per last 100 batches: 1.321552
1600it [04:36,  5.86it/s]Epoch: 1: Step: 1601/14003, loss=1.756679, lr=0.000017
1699it [04:52,  5.88it/s]Train batch 1700
Avg. loss per last 100 batches: 1.307882
1700it [04:53,  5.87it/s]Epoch: 1: Step: 1701/14003, loss=1.644297, lr=0.000017
1799it [05:10,  5.88it/s]Train batch 1800
Avg. loss per last 100 batches: 1.320224
1800it [05:10,  5.87it/s]Epoch: 1: Step: 1801/14003, loss=1.230694, lr=0.000017
1899it [05:27,  5.86it/s]Train batch 1900
Avg. loss per last 100 batches: 1.368793
1900it [05:27,  5.85it/s]Epoch: 1: Step: 1901/14003, loss=0.941440, lr=0.000017
1999it [05:44,  5.89it/s]Train batch 2000
Avg. loss per last 100 batches: 1.356388
2000it [05:44,  5.88it/s]Epoch: 1: Step: 2001/14003, loss=1.584877, lr=0.000017
2099it [06:01,  5.24it/s]Train batch 2100
Avg. loss per last 100 batches: 1.348952
2100it [06:02,  5.22it/s]Epoch: 1: Step: 2101/14003, loss=1.989878, lr=0.000017
2199it [06:19,  5.88it/s]Train batch 2200
Avg. loss per last 100 batches: 1.317212
2200it [06:19,  5.89it/s]Epoch: 1: Step: 2201/14003, loss=1.652488, lr=0.000017
2299it [06:36,  5.86it/s]Train batch 2300
Avg. loss per last 100 batches: 1.314579
2300it [06:36,  5.85it/s]Epoch: 1: Step: 2301/14003, loss=1.227345, lr=0.000017
2399it [06:53,  5.88it/s]Train batch 2400
Avg. loss per last 100 batches: 1.387968
2400it [06:53,  5.86it/s]Epoch: 1: Step: 2401/14003, loss=0.978816, lr=0.000017
2499it [07:10,  5.85it/s]Train batch 2500
Avg. loss per last 100 batches: 1.326919
2500it [07:11,  5.84it/s]Epoch: 1: Step: 2501/14003, loss=1.270818, lr=0.000017
2599it [07:28,  5.85it/s]Train batch 2600
Avg. loss per last 100 batches: 1.290675
2600it [07:28,  5.86it/s]Epoch: 1: Step: 2601/14003, loss=0.903256, lr=0.000017
2699it [07:45,  5.88it/s]Train batch 2700
Avg. loss per last 100 batches: 1.315762
2700it [07:45,  5.86it/s]Epoch: 1: Step: 2701/14003, loss=1.178417, lr=0.000017
2799it [08:02,  5.86it/s]Train batch 2800
Avg. loss per last 100 batches: 1.356360
2800it [08:02,  5.87it/s]Epoch: 1: Step: 2801/14003, loss=1.297636, lr=0.000017
Validation: Epoch: 1 Step: 2801/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.770474 sec., loss=1.279347 
Eval step: 199 , used_time=9.779799 sec., loss=1.522871 
Eval step: 299 , used_time=14.536950 sec., loss=0.967161 
Eval step: 399 , used_time=19.295023 sec., loss=1.150879 
Eval step: 499 , used_time=24.052322 sec., loss=1.329628 
Eval step: 599 , used_time=28.828420 sec., loss=1.558232 
Eval step: 699 , used_time=33.601695 sec., loss=1.182456 
Eval step: 799 , used_time=38.610446 sec., loss=0.962400 
Eval step: 899 , used_time=43.357318 sec., loss=1.442263 
Eval step: 999 , used_time=48.104031 sec., loss=1.171995 
Eval step: 1099 , used_time=52.881795 sec., loss=1.438510 
Eval step: 1199 , used_time=57.643403 sec., loss=0.991261 
Eval step: 1299 , used_time=62.472150 sec., loss=1.515715 
Eval step: 1399 , used_time=67.246666 sec., loss=0.957115 
Eval step: 1499 , used_time=72.249268 sec., loss=1.085072 
Eval step: 1599 , used_time=76.997578 sec., loss=0.874552 
NLL Validation: loss = 1.079518. correct prediction ratio  36366/52032 ~  0.698916
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
2899it [09:41,  5.47it/s]Train batch 2900
Avg. loss per last 100 batches: 1.332049
2900it [09:41,  5.58it/s]Epoch: 1: Step: 2901/14003, loss=1.474257, lr=0.000017
2999it [09:58,  5.81it/s]Train batch 3000
Avg. loss per last 100 batches: 1.408909
3000it [09:58,  5.81it/s]Epoch: 1: Step: 3001/14003, loss=1.153239, lr=0.000017
3099it [10:16,  5.42it/s]Train batch 3100
Avg. loss per last 100 batches: 1.316525
3100it [10:16,  5.55it/s]Epoch: 1: Step: 3101/14003, loss=1.251855, lr=0.000017
3199it [10:33,  5.88it/s]Train batch 3200
Avg. loss per last 100 batches: 1.274547
3200it [10:33,  5.86it/s]Epoch: 1: Step: 3201/14003, loss=1.341230, lr=0.000017
3299it [10:50,  5.88it/s]Train batch 3300
Avg. loss per last 100 batches: 1.324967
3300it [10:50,  5.89it/s]Epoch: 1: Step: 3301/14003, loss=1.580603, lr=0.000017
3399it [11:07,  5.85it/s]Train batch 3400
Avg. loss per last 100 batches: 1.318588
3400it [11:07,  5.85it/s]Epoch: 1: Step: 3401/14003, loss=1.534516, lr=0.000017
3499it [11:24,  5.87it/s]Train batch 3500
Avg. loss per last 100 batches: 1.340641
3500it [11:24,  5.89it/s]Epoch: 1: Step: 3501/14003, loss=1.426461, lr=0.000017
3599it [11:41,  5.80it/s]Train batch 3600
Avg. loss per last 100 batches: 1.345865
3600it [11:42,  5.81it/s]Epoch: 1: Step: 3601/14003, loss=1.411708, lr=0.000017
3699it [11:59,  5.83it/s]Train batch 3700
Avg. loss per last 100 batches: 1.345330
3700it [11:59,  5.82it/s]Epoch: 1: Step: 3701/14003, loss=0.986787, lr=0.000017
3799it [12:16,  5.88it/s]Train batch 3800
Avg. loss per last 100 batches: 1.337157
3800it [12:16,  5.86it/s]Epoch: 1: Step: 3801/14003, loss=1.186166, lr=0.000017
3899it [12:33,  5.57it/s]Train batch 3900
Avg. loss per last 100 batches: 1.273596
3900it [12:33,  5.55it/s]Epoch: 1: Step: 3901/14003, loss=1.481816, lr=0.000017
3999it [12:50,  5.88it/s]Train batch 4000
Avg. loss per last 100 batches: 1.318166
4000it [12:50,  5.87it/s]Epoch: 1: Step: 4001/14003, loss=1.147425, lr=0.000017
4099it [13:07,  5.82it/s]Train batch 4100
Avg. loss per last 100 batches: 1.325330
4100it [13:08,  5.80it/s]Epoch: 1: Step: 4101/14003, loss=1.729333, lr=0.000017
4199it [13:25,  5.42it/s]Train batch 4200
Avg. loss per last 100 batches: 1.389560
4200it [13:25,  5.42it/s]Epoch: 1: Step: 4201/14003, loss=1.213695, lr=0.000016
4299it [13:42,  5.87it/s]Train batch 4300
Avg. loss per last 100 batches: 1.266770
4300it [13:42,  5.86it/s]Epoch: 1: Step: 4301/14003, loss=1.375420, lr=0.000016
4399it [13:59,  5.82it/s]Train batch 4400
Avg. loss per last 100 batches: 1.267594
4400it [13:59,  5.83it/s]Epoch: 1: Step: 4401/14003, loss=1.074319, lr=0.000016
4499it [14:16,  5.88it/s]Train batch 4500
Avg. loss per last 100 batches: 1.287599
4500it [14:16,  5.87it/s]Epoch: 1: Step: 4501/14003, loss=1.234896, lr=0.000016
4599it [14:33,  5.86it/s]Train batch 4600
Avg. loss per last 100 batches: 1.334075
4600it [14:34,  5.82it/s]Epoch: 1: Step: 4601/14003, loss=1.039164, lr=0.000016
4699it [14:50,  5.81it/s]Train batch 4700
Avg. loss per last 100 batches: 1.273493
4700it [14:51,  5.67it/s]Epoch: 1: Step: 4701/14003, loss=1.154938, lr=0.000016
4799it [15:08,  5.82it/s]Train batch 4800
Avg. loss per last 100 batches: 1.309985
4800it [15:08,  5.85it/s]Epoch: 1: Step: 4801/14003, loss=1.026448, lr=0.000016
4899it [15:25,  5.87it/s]Train batch 4900
Avg. loss per last 100 batches: 1.275828
4900it [15:25,  5.86it/s]Epoch: 1: Step: 4901/14003, loss=1.673682, lr=0.000016
4999it [15:42,  5.76it/s]Train batch 5000
Avg. loss per last 100 batches: 1.354443
5000it [15:42,  5.77it/s]Epoch: 1: Step: 5001/14003, loss=0.845631, lr=0.000016
5099it [15:59,  5.86it/s]Train batch 5100
Avg. loss per last 100 batches: 1.322658
5100it [15:59,  5.86it/s]Epoch: 1: Step: 5101/14003, loss=1.338574, lr=0.000016
5199it [16:17,  5.86it/s]Train batch 5200
Avg. loss per last 100 batches: 1.385229
5200it [16:17,  5.87it/s]Epoch: 1: Step: 5201/14003, loss=0.971856, lr=0.000016
5299it [16:34,  5.47it/s]Train batch 5300
Avg. loss per last 100 batches: 1.271125
5300it [16:34,  5.36it/s]Epoch: 1: Step: 5301/14003, loss=1.266682, lr=0.000016
5399it [16:51,  5.60it/s]Train batch 5400
Avg. loss per last 100 batches: 1.273350
5400it [16:51,  5.66it/s]Epoch: 1: Step: 5401/14003, loss=1.059367, lr=0.000016
5499it [17:08,  5.85it/s]Train batch 5500
Avg. loss per last 100 batches: 1.320628
5500it [17:08,  5.85it/s]Epoch: 1: Step: 5501/14003, loss=1.198774, lr=0.000016
5599it [17:25,  5.88it/s]Train batch 5600
Avg. loss per last 100 batches: 1.288553
5600it [17:25,  5.87it/s]Epoch: 1: Step: 5601/14003, loss=1.334195, lr=0.000016
5601it [17:26,  5.82it/s]Validation: Epoch: 1 Step: 5602/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.789809 sec., loss=1.338150 
Eval step: 199 , used_time=9.752232 sec., loss=1.413532 
Eval step: 299 , used_time=14.534194 sec., loss=0.860359 
Eval step: 399 , used_time=19.307498 sec., loss=0.931749 
Eval step: 499 , used_time=24.082819 sec., loss=1.426176 
Eval step: 599 , used_time=28.856967 sec., loss=1.496661 
Eval step: 699 , used_time=33.660137 sec., loss=1.107524 
Eval step: 799 , used_time=38.409160 sec., loss=0.911011 
Eval step: 899 , used_time=43.386237 sec., loss=1.379288 
Eval step: 999 , used_time=48.178404 sec., loss=1.156662 
Eval step: 1099 , used_time=52.946225 sec., loss=1.388832 
Eval step: 1199 , used_time=57.679908 sec., loss=1.056173 
Eval step: 1299 , used_time=62.437826 sec., loss=1.182096 
Eval step: 1399 , used_time=67.192032 sec., loss=1.022231 
Eval step: 1499 , used_time=72.038449 sec., loss=1.018768 
Eval step: 1599 , used_time=77.004117 sec., loss=0.904972 
NLL Validation: loss = 1.058066. correct prediction ratio  36694/52032 ~  0.705220
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:07,  5.87it/s]Train batch 5700
Avg. loss per last 100 batches: 1.344867
5700it [19:07,  5.87it/s]Epoch: 1: Step: 5701/14003, loss=1.441509, lr=0.000016
5799it [19:24,  5.87it/s]Train batch 5800
Avg. loss per last 100 batches: 1.300901
5800it [19:24,  5.86it/s]Epoch: 1: Step: 5801/14003, loss=1.396635, lr=0.000016
5899it [19:41,  5.86it/s]Train batch 5900
Avg. loss per last 100 batches: 1.337722
5900it [19:41,  5.86it/s]Epoch: 1: Step: 5901/14003, loss=1.813599, lr=0.000016
5999it [19:58,  5.84it/s]Train batch 6000
Avg. loss per last 100 batches: 1.391666
6000it [19:58,  5.86it/s]Epoch: 1: Step: 6001/14003, loss=1.305744, lr=0.000016
6099it [20:15,  5.45it/s]Train batch 6100
Avg. loss per last 100 batches: 1.323247
6100it [20:16,  5.39it/s]Epoch: 1: Step: 6101/14003, loss=0.775746, lr=0.000016
6199it [20:33,  5.89it/s]Train batch 6200
Avg. loss per last 100 batches: 1.279054
6200it [20:33,  5.88it/s]Epoch: 1: Step: 6201/14003, loss=1.172059, lr=0.000016
6299it [20:50,  5.85it/s]Train batch 6300
Avg. loss per last 100 batches: 1.359693
6300it [20:50,  5.87it/s]Epoch: 1: Step: 6301/14003, loss=0.971266, lr=0.000016
6399it [21:07,  5.87it/s]Train batch 6400
Avg. loss per last 100 batches: 1.320314
6400it [21:07,  5.88it/s]Epoch: 1: Step: 6401/14003, loss=1.365145, lr=0.000016
6499it [21:24,  5.86it/s]Train batch 6500
Avg. loss per last 100 batches: 1.277987
6500it [21:24,  5.86it/s]Epoch: 1: Step: 6501/14003, loss=1.204516, lr=0.000016
6599it [21:41,  5.84it/s]Train batch 6600
Avg. loss per last 100 batches: 1.333318
6600it [21:41,  5.84it/s]Epoch: 1: Step: 6601/14003, loss=1.159091, lr=0.000016
6699it [21:59,  5.82it/s]Train batch 6700
Avg. loss per last 100 batches: 1.223623
6700it [21:59,  5.84it/s]Epoch: 1: Step: 6701/14003, loss=1.413542, lr=0.000016
6799it [22:16,  5.88it/s]Train batch 6800
Avg. loss per last 100 batches: 1.302698
6800it [22:16,  5.87it/s]Epoch: 1: Step: 6801/14003, loss=1.010031, lr=0.000016
6899it [22:33,  5.85it/s]Train batch 6900
Avg. loss per last 100 batches: 1.262708
6900it [22:33,  5.86it/s]Epoch: 1: Step: 6901/14003, loss=1.027215, lr=0.000016
6999it [22:50,  5.88it/s]Train batch 7000
Avg. loss per last 100 batches: 1.251398
7000it [22:50,  5.88it/s]Epoch: 1: Step: 7001/14003, loss=1.401536, lr=0.000016
7099it [23:07,  5.87it/s]Train batch 7100
Avg. loss per last 100 batches: 1.299714
7100it [23:08,  5.81it/s]Epoch: 1: Step: 7101/14003, loss=1.022781, lr=0.000016
7199it [23:25,  5.30it/s]Train batch 7200
Avg. loss per last 100 batches: 1.252940
7200it [23:26,  5.35it/s]Epoch: 1: Step: 7201/14003, loss=2.429161, lr=0.000016
7299it [23:43,  5.88it/s]Train batch 7300
Avg. loss per last 100 batches: 1.251900
7300it [23:43,  5.89it/s]Epoch: 1: Step: 7301/14003, loss=1.226094, lr=0.000016
7399it [24:00,  5.88it/s]Train batch 7400
Avg. loss per last 100 batches: 1.305532
7400it [24:00,  5.87it/s]Epoch: 1: Step: 7401/14003, loss=1.508860, lr=0.000016
7499it [24:17,  5.86it/s]Train batch 7500
Avg. loss per last 100 batches: 1.313273
7500it [24:17,  5.87it/s]Epoch: 1: Step: 7501/14003, loss=1.193479, lr=0.000016
7599it [24:34,  5.87it/s]Train batch 7600
Avg. loss per last 100 batches: 1.254626
7600it [24:34,  5.86it/s]Epoch: 1: Step: 7601/14003, loss=1.378562, lr=0.000016
7699it [24:51,  5.85it/s]Train batch 7700
Avg. loss per last 100 batches: 1.251831
7700it [24:51,  5.84it/s]Epoch: 1: Step: 7701/14003, loss=1.101926, lr=0.000016
7799it [25:09,  5.85it/s]Train batch 7800
Avg. loss per last 100 batches: 1.252946
7800it [25:09,  5.85it/s]Epoch: 1: Step: 7801/14003, loss=1.274704, lr=0.000016
7899it [25:26,  5.87it/s]Train batch 7900
Avg. loss per last 100 batches: 1.302357
7900it [25:26,  5.88it/s]Epoch: 1: Step: 7901/14003, loss=1.132218, lr=0.000016
7999it [25:43,  5.79it/s]Train batch 8000
Avg. loss per last 100 batches: 1.268079
8000it [25:43,  5.82it/s]Epoch: 1: Step: 8001/14003, loss=0.916739, lr=0.000016
8099it [26:00,  5.87it/s]Train batch 8100
Avg. loss per last 100 batches: 1.304598
8100it [26:00,  5.85it/s]Epoch: 1: Step: 8101/14003, loss=0.833560, lr=0.000016
8199it [26:17,  5.89it/s]Train batch 8200
Avg. loss per last 100 batches: 1.284907
8200it [26:18,  5.89it/s]Epoch: 1: Step: 8201/14003, loss=1.247855, lr=0.000016
8299it [26:35,  5.39it/s]Train batch 8300
Avg. loss per last 100 batches: 1.291702
8300it [26:35,  5.36it/s]Epoch: 1: Step: 8301/14003, loss=0.997688, lr=0.000016
8399it [26:52,  5.80it/s]Train batch 8400
Avg. loss per last 100 batches: 1.246411
8400it [26:52,  5.81it/s]Epoch: 1: Step: 8401/14003, loss=1.179194, lr=0.000016
8402it [26:52,  5.75it/s]Validation: Epoch: 1 Step: 8403/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.863899 sec., loss=1.377228 
Eval step: 199 , used_time=9.647508 sec., loss=1.470910 
Eval step: 299 , used_time=14.622466 sec., loss=0.875477 
Eval step: 399 , used_time=19.402290 sec., loss=0.911981 
Eval step: 499 , used_time=24.149345 sec., loss=1.363799 
Eval step: 599 , used_time=28.916934 sec., loss=1.462951 
Eval step: 699 , used_time=33.690724 sec., loss=0.998129 
Eval step: 799 , used_time=38.477363 sec., loss=0.797601 
Eval step: 899 , used_time=43.227158 sec., loss=1.423067 
Eval step: 999 , used_time=48.221701 sec., loss=1.204914 
Eval step: 1099 , used_time=52.968098 sec., loss=1.460521 
Eval step: 1199 , used_time=57.723375 sec., loss=0.948178 
Eval step: 1299 , used_time=62.485837 sec., loss=1.239357 
Eval step: 1399 , used_time=67.347505 sec., loss=0.831152 
Eval step: 1499 , used_time=72.136560 sec., loss=0.948466 
Eval step: 1599 , used_time=77.055819 sec., loss=0.877020 
NLL Validation: loss = 1.021640. correct prediction ratio  37186/52032 ~  0.714676
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
8499it [28:31,  5.82it/s]Train batch 8500
Avg. loss per last 100 batches: 1.296343
8500it [28:31,  5.81it/s]Epoch: 1: Step: 8501/14003, loss=1.410935, lr=0.000016
8599it [28:48,  5.85it/s]Train batch 8600
Avg. loss per last 100 batches: 1.237439
8600it [28:48,  5.87it/s]Epoch: 1: Step: 8601/14003, loss=1.680978, lr=0.000016
8699it [29:05,  5.85it/s]Train batch 8700
Avg. loss per last 100 batches: 1.284000
8700it [29:05,  5.85it/s]Epoch: 1: Step: 8701/14003, loss=0.974301, lr=0.000016
8799it [29:22,  5.88it/s]Train batch 8800
Avg. loss per last 100 batches: 1.303484
8800it [29:23,  5.87it/s]Epoch: 1: Step: 8801/14003, loss=0.895933, lr=0.000016
8899it [29:39,  5.88it/s]Train batch 8900
Avg. loss per last 100 batches: 1.259969
8900it [29:40,  5.88it/s]Epoch: 1: Step: 8901/14003, loss=1.402853, lr=0.000016
8999it [29:57,  5.82it/s]Train batch 9000
Avg. loss per last 100 batches: 1.312763
9000it [29:57,  5.81it/s]Epoch: 1: Step: 9001/14003, loss=1.417054, lr=0.000016
9099it [30:14,  5.86it/s]Train batch 9100
Avg. loss per last 100 batches: 1.270195
9100it [30:14,  5.86it/s]Epoch: 1: Step: 9101/14003, loss=0.964475, lr=0.000015
9199it [30:31,  5.75it/s]Train batch 9200
Avg. loss per last 100 batches: 1.288890
9200it [30:31,  5.76it/s]Epoch: 1: Step: 9201/14003, loss=1.847929, lr=0.000015
9299it [30:48,  5.53it/s]Train batch 9300
Avg. loss per last 100 batches: 1.326835
9300it [30:49,  5.64it/s]Epoch: 1: Step: 9301/14003, loss=1.314024, lr=0.000015
9399it [31:06,  5.85it/s]Train batch 9400
Avg. loss per last 100 batches: 1.323701
9400it [31:06,  5.84it/s]Epoch: 1: Step: 9401/14003, loss=1.488318, lr=0.000015
9499it [31:23,  5.86it/s]Train batch 9500
Avg. loss per last 100 batches: 1.276273
9500it [31:23,  5.85it/s]Epoch: 1: Step: 9501/14003, loss=0.783731, lr=0.000015
9599it [31:40,  5.87it/s]Train batch 9600
Avg. loss per last 100 batches: 1.265876
9600it [31:40,  5.86it/s]Epoch: 1: Step: 9601/14003, loss=1.683036, lr=0.000015
9699it [31:57,  5.81it/s]Train batch 9700
Avg. loss per last 100 batches: 1.280060
9700it [31:57,  5.80it/s]Epoch: 1: Step: 9701/14003, loss=1.372023, lr=0.000015
9799it [32:14,  5.89it/s]Train batch 9800
Avg. loss per last 100 batches: 1.287459
9800it [32:15,  5.86it/s]Epoch: 1: Step: 9801/14003, loss=1.757745, lr=0.000015
9899it [32:32,  5.82it/s]Train batch 9900
Avg. loss per last 100 batches: 1.301835
9900it [32:32,  5.83it/s]Epoch: 1: Step: 9901/14003, loss=1.128913, lr=0.000015
9999it [32:49,  5.83it/s]Train batch 10000
Avg. loss per last 100 batches: 1.258553
10000it [32:49,  5.82it/s]Epoch: 1: Step: 10001/14003, loss=0.660524, lr=0.000015
10099it [33:06,  5.86it/s]Train batch 10100
Avg. loss per last 100 batches: 1.305953
10100it [33:06,  5.82it/s]Epoch: 1: Step: 10101/14003, loss=0.792683, lr=0.000015
10199it [33:23,  5.85it/s]Train batch 10200
Avg. loss per last 100 batches: 1.261852
10200it [33:23,  5.84it/s]Epoch: 1: Step: 10201/14003, loss=1.036781, lr=0.000015
10299it [33:40,  5.84it/s]Train batch 10300
Avg. loss per last 100 batches: 1.321886
10300it [33:41,  5.68it/s]Epoch: 1: Step: 10301/14003, loss=1.153144, lr=0.000015
10399it [33:58,  5.35it/s]Train batch 10400
Avg. loss per last 100 batches: 1.223818
10400it [33:58,  5.49it/s]Epoch: 1: Step: 10401/14003, loss=0.951971, lr=0.000015
10499it [34:15,  5.84it/s]Train batch 10500
Avg. loss per last 100 batches: 1.258481
10500it [34:15,  5.83it/s]Epoch: 1: Step: 10501/14003, loss=1.267290, lr=0.000015
10599it [34:33,  5.83it/s]Train batch 10600
Avg. loss per last 100 batches: 1.238887
10600it [34:33,  5.82it/s]Epoch: 1: Step: 10601/14003, loss=1.027107, lr=0.000015
10699it [34:50,  5.83it/s]Train batch 10700
Avg. loss per last 100 batches: 1.262321
10700it [34:50,  5.84it/s]Epoch: 1: Step: 10701/14003, loss=1.698809, lr=0.000015
10799it [35:07,  5.79it/s]Train batch 10800
Avg. loss per last 100 batches: 1.199917
10800it [35:07,  5.81it/s]Epoch: 1: Step: 10801/14003, loss=1.858260, lr=0.000015
10899it [35:24,  5.86it/s]Train batch 10900
Avg. loss per last 100 batches: 1.212573
10900it [35:25,  5.84it/s]Epoch: 1: Step: 10901/14003, loss=1.136069, lr=0.000015
10999it [35:42,  5.79it/s]Train batch 11000
Avg. loss per last 100 batches: 1.296321
11000it [35:42,  5.79it/s]Epoch: 1: Step: 11001/14003, loss=0.980474, lr=0.000015
11099it [35:59,  5.84it/s]Train batch 11100
Avg. loss per last 100 batches: 1.236350
11100it [35:59,  5.85it/s]Epoch: 1: Step: 11101/14003, loss=2.284737, lr=0.000015
11199it [36:16,  5.84it/s]Train batch 11200
Avg. loss per last 100 batches: 1.271324
11200it [36:17,  5.79it/s]Epoch: 1: Step: 11201/14003, loss=0.915436, lr=0.000015
11203it [36:17,  5.80it/s]Validation: Epoch: 1 Step: 11204/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.793506 sec., loss=1.397110 
Eval step: 199 , used_time=9.553847 sec., loss=1.344616 
Eval step: 299 , used_time=14.349207 sec., loss=0.837961 
Eval step: 399 , used_time=19.357481 sec., loss=0.875703 
Eval step: 499 , used_time=24.156950 sec., loss=1.346535 
Eval step: 599 , used_time=28.936727 sec., loss=1.332314 
Eval step: 699 , used_time=33.752244 sec., loss=1.086576 
Eval step: 799 , used_time=38.565391 sec., loss=0.895154 
Eval step: 899 , used_time=43.403463 sec., loss=1.453150 
Eval step: 999 , used_time=48.159793 sec., loss=1.210114 
Eval step: 1099 , used_time=53.252156 sec., loss=1.355171 
Eval step: 1199 , used_time=58.039623 sec., loss=1.009440 
Eval step: 1299 , used_time=62.799060 sec., loss=1.275573 
Eval step: 1399 , used_time=67.593322 sec., loss=0.961158 
Eval step: 1499 , used_time=72.343430 sec., loss=1.014524 
Eval step: 1599 , used_time=77.156291 sec., loss=0.841218 
NLL Validation: loss = 0.986291. correct prediction ratio  37644/52032 ~  0.723478
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [37:59,  5.81it/s]Train batch 11300
Avg. loss per last 100 batches: 1.280927
11300it [37:59,  5.82it/s]Epoch: 1: Step: 11301/14003, loss=0.874169, lr=0.000015
11399it [38:17,  5.86it/s]Train batch 11400
Avg. loss per last 100 batches: 1.260288
11400it [38:17,  5.83it/s]Epoch: 1: Step: 11401/14003, loss=1.123441, lr=0.000015
11499it [38:34,  5.83it/s]Train batch 11500
Avg. loss per last 100 batches: 1.280218
11500it [38:34,  5.83it/s]Epoch: 1: Step: 11501/14003, loss=1.059796, lr=0.000015
11599it [38:51,  5.70it/s]Train batch 11600
Avg. loss per last 100 batches: 1.253864
11600it [38:51,  5.72it/s]Epoch: 1: Step: 11601/14003, loss=0.946524, lr=0.000015
11699it [39:08,  5.77it/s]Train batch 11700
Avg. loss per last 100 batches: 1.223348
11700it [39:09,  5.77it/s]Epoch: 1: Step: 11701/14003, loss=0.899125, lr=0.000015
11799it [39:26,  5.82it/s]Train batch 11800
Avg. loss per last 100 batches: 1.238522
11800it [39:26,  5.83it/s]Epoch: 1: Step: 11801/14003, loss=1.464032, lr=0.000015
11899it [39:43,  5.85it/s]Train batch 11900
Avg. loss per last 100 batches: 1.268941
11900it [39:43,  5.83it/s]Epoch: 1: Step: 11901/14003, loss=1.336360, lr=0.000015
11999it [40:01,  5.69it/s]Train batch 12000
Avg. loss per last 100 batches: 1.232226
12000it [40:01,  5.70it/s]Epoch: 1: Step: 12001/14003, loss=1.375291, lr=0.000015
12099it [40:18,  5.69it/s]Train batch 12100
Avg. loss per last 100 batches: 1.244676
12100it [40:18,  5.71it/s]Epoch: 1: Step: 12101/14003, loss=1.263365, lr=0.000015
12199it [40:35,  5.83it/s]Train batch 12200
Avg. loss per last 100 batches: 1.270101
12200it [40:35,  5.83it/s]Epoch: 1: Step: 12201/14003, loss=1.198252, lr=0.000015
12299it [40:52,  5.78it/s]Train batch 12300
Avg. loss per last 100 batches: 1.249452
12300it [40:53,  5.80it/s]Epoch: 1: Step: 12301/14003, loss=0.902327, lr=0.000015
12399it [41:10,  5.77it/s]Train batch 12400
Avg. loss per last 100 batches: 1.259650
12400it [41:10,  5.74it/s]Epoch: 1: Step: 12401/14003, loss=1.199196, lr=0.000015
12499it [41:27,  5.84it/s]Train batch 12500
Avg. loss per last 100 batches: 1.286679
12500it [41:27,  5.85it/s]Epoch: 1: Step: 12501/14003, loss=1.588725, lr=0.000015
12599it [41:44,  5.84it/s]Train batch 12600
Avg. loss per last 100 batches: 1.276856
12600it [41:44,  5.85it/s]Epoch: 1: Step: 12601/14003, loss=1.544376, lr=0.000015
12699it [42:02,  5.83it/s]Train batch 12700
Avg. loss per last 100 batches: 1.264461
12700it [42:02,  5.84it/s]Epoch: 1: Step: 12701/14003, loss=1.060489, lr=0.000015
12799it [42:19,  5.85it/s]Train batch 12800
Avg. loss per last 100 batches: 1.246120
12800it [42:19,  5.85it/s]Epoch: 1: Step: 12801/14003, loss=1.136607, lr=0.000015
12899it [42:36,  5.83it/s]Train batch 12900
Avg. loss per last 100 batches: 1.246888
12900it [42:36,  5.80it/s]Epoch: 1: Step: 12901/14003, loss=1.154048, lr=0.000015
12999it [42:53,  5.85it/s]Train batch 13000
Avg. loss per last 100 batches: 1.275309
13000it [42:54,  5.84it/s]Epoch: 1: Step: 13001/14003, loss=1.089859, lr=0.000015
13099it [43:11,  5.57it/s]Train batch 13100
Avg. loss per last 100 batches: 1.225671
13100it [43:11,  5.44it/s]Epoch: 1: Step: 13101/14003, loss=1.267398, lr=0.000015
13199it [43:28,  5.83it/s]Train batch 13200
Avg. loss per last 100 batches: 1.215892
13200it [43:28,  5.82it/s]Epoch: 1: Step: 13201/14003, loss=1.317748, lr=0.000015
13299it [43:45,  5.82it/s]Train batch 13300
Avg. loss per last 100 batches: 1.218384
13300it [43:45,  5.83it/s]Epoch: 1: Step: 13301/14003, loss=1.253919, lr=0.000015
13399it [44:03,  5.83it/s]Train batch 13400
Avg. loss per last 100 batches: 1.228162
13400it [44:03,  5.85it/s]Epoch: 1: Step: 13401/14003, loss=1.074387, lr=0.000015
13499it [44:20,  5.79it/s]Train batch 13500
Avg. loss per last 100 batches: 1.214761
13500it [44:20,  5.79it/s]Epoch: 1: Step: 13501/14003, loss=1.448632, lr=0.000015
13599it [44:37,  5.81it/s]Train batch 13600
Avg. loss per last 100 batches: 1.193039
13600it [44:37,  5.80it/s]Epoch: 1: Step: 13601/14003, loss=0.825702, lr=0.000015
13699it [44:55,  5.80it/s]Train batch 13700
Avg. loss per last 100 batches: 1.310669
13700it [44:55,  5.79it/s]Epoch: 1: Step: 13701/14003, loss=1.586568, lr=0.000015
13799it [45:12,  5.78it/s]Train batch 13800
Avg. loss per last 100 batches: 1.252563
13800it [45:12,  5.80it/s]Epoch: 1: Step: 13801/14003, loss=1.324777, lr=0.000015
13899it [45:29,  5.81it/s]Train batch 13900
Avg. loss per last 100 batches: 1.254479
13900it [45:29,  5.81it/s]Epoch: 1: Step: 13901/14003, loss=1.330013, lr=0.000014
13999it [45:47,  5.75it/s]Train batch 14000
Avg. loss per last 100 batches: 1.198635
14000it [45:47,  5.76it/s]Epoch: 1: Step: 14001/14003, loss=1.067357, lr=0.000014
14003it [45:47,  5.10it/s]
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.816037 sec., loss=1.397578 
Eval step: 199 , used_time=9.622491 sec., loss=1.339818 
Eval step: 299 , used_time=14.445285 sec., loss=0.779534 
Eval step: 399 , used_time=19.446926 sec., loss=0.960626 
Eval step: 499 , used_time=24.270998 sec., loss=1.152524 
Eval step: 599 , used_time=29.075077 sec., loss=1.345263 
Eval step: 699 , used_time=33.928717 sec., loss=1.021518 
Eval step: 799 , used_time=38.701146 sec., loss=0.881872 
Eval step: 899 , used_time=43.500452 sec., loss=1.318108 
Eval step: 999 , used_time=48.440958 sec., loss=1.145385 
Eval step: 1099 , used_time=53.339797 sec., loss=1.429564 
Eval step: 1199 , used_time=58.125426 sec., loss=0.890182 
Eval step: 1299 , used_time=62.954205 sec., loss=1.202270 
Eval step: 1399 , used_time=67.816013 sec., loss=0.758328 
Eval step: 1499 , used_time=72.620913 sec., loss=1.157727 
Eval step: 1599 , used_time=77.456636 sec., loss=0.753146 
NLL Validation: loss = 0.960066. correct prediction ratio  38047/52032 ~  0.731223
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=1.294480
epoch total correct predictions=292550
***** Epoch 2 *****
0it [00:00, ?it/s]Epoch: 2: Step: 1/14003, loss=0.860266, lr=0.000014
99it [00:17,  5.83it/s]Train batch 100
Avg. loss per last 100 batches: 0.891950
100it [00:17,  5.83it/s]Epoch: 2: Step: 101/14003, loss=0.670121, lr=0.000014
199it [00:35,  5.82it/s]Train batch 200
Avg. loss per last 100 batches: 0.923848
200it [00:35,  5.82it/s]Epoch: 2: Step: 201/14003, loss=1.431329, lr=0.000014
299it [00:52,  5.81it/s]Train batch 300
Avg. loss per last 100 batches: 0.945138
300it [00:52,  5.82it/s]Epoch: 2: Step: 301/14003, loss=0.977929, lr=0.000014
399it [01:09,  5.78it/s]Train batch 400
Avg. loss per last 100 batches: 0.954560
400it [01:09,  5.79it/s]Epoch: 2: Step: 401/14003, loss=1.489946, lr=0.000014
499it [01:27,  5.79it/s]Train batch 500
Avg. loss per last 100 batches: 0.926010
500it [01:27,  5.80it/s]Epoch: 2: Step: 501/14003, loss=0.921382, lr=0.000014
599it [01:44,  5.77it/s]Train batch 600
Avg. loss per last 100 batches: 0.921477
600it [01:44,  5.75it/s]Epoch: 2: Step: 601/14003, loss=0.598523, lr=0.000014
699it [02:01,  5.81it/s]Train batch 700
Avg. loss per last 100 batches: 0.912652
700it [02:02,  5.69it/s]Epoch: 2: Step: 701/14003, loss=0.296026, lr=0.000014
799it [02:19,  5.82it/s]Train batch 800
Avg. loss per last 100 batches: 0.938784
800it [02:19,  5.83it/s]Epoch: 2: Step: 801/14003, loss=0.832767, lr=0.000014
899it [02:36,  5.47it/s]Train batch 900
Avg. loss per last 100 batches: 0.930345
900it [02:36,  5.58it/s]Epoch: 2: Step: 901/14003, loss=1.540563, lr=0.000014
999it [02:53,  5.81it/s]Train batch 1000
Avg. loss per last 100 batches: 0.988614
1000it [02:54,  5.81it/s]Epoch: 2: Step: 1001/14003, loss=0.690496, lr=0.000014
1099it [03:11,  5.80it/s]Train batch 1100
Avg. loss per last 100 batches: 0.947285
1100it [03:11,  5.77it/s]Epoch: 2: Step: 1101/14003, loss=0.599647, lr=0.000014
1199it [03:28,  5.82it/s]Train batch 1200
Avg. loss per last 100 batches: 0.931348
1200it [03:28,  5.80it/s]Epoch: 2: Step: 1201/14003, loss=1.043267, lr=0.000014
1299it [03:45,  5.81it/s]Train batch 1300
Avg. loss per last 100 batches: 0.970398
1300it [03:46,  5.79it/s]Epoch: 2: Step: 1301/14003, loss=1.271579, lr=0.000014
1399it [04:03,  5.82it/s]Train batch 1400
Avg. loss per last 100 batches: 0.942398
1400it [04:03,  5.82it/s]Epoch: 2: Step: 1401/14003, loss=1.478861, lr=0.000014
1499it [04:20,  5.48it/s]Train batch 1500
Avg. loss per last 100 batches: 0.943479
1500it [04:20,  5.58it/s]Epoch: 2: Step: 1501/14003, loss=0.808716, lr=0.000014
1599it [04:37,  5.82it/s]Train batch 1600
Avg. loss per last 100 batches: 0.977523
1600it [04:38,  5.81it/s]Epoch: 2: Step: 1601/14003, loss=0.863572, lr=0.000014
1699it [04:55,  5.80it/s]Train batch 1700
Avg. loss per last 100 batches: 0.990196
1700it [04:55,  5.81it/s]Epoch: 2: Step: 1701/14003, loss=0.468147, lr=0.000014
1799it [05:12,  5.70it/s]Train batch 1800
Avg. loss per last 100 batches: 0.945160
1800it [05:12,  5.72it/s]Epoch: 2: Step: 1801/14003, loss=1.059396, lr=0.000014
1899it [05:30,  5.82it/s]Train batch 1900
Avg. loss per last 100 batches: 0.948569
1900it [05:30,  5.83it/s]Epoch: 2: Step: 1901/14003, loss=0.847940, lr=0.000014
1999it [05:47,  5.75it/s]Train batch 2000
Avg. loss per last 100 batches: 0.949244
2000it [05:47,  5.76it/s]Epoch: 2: Step: 2001/14003, loss=0.688152, lr=0.000014
2099it [06:04,  5.84it/s]Train batch 2100
Avg. loss per last 100 batches: 0.953941
2100it [06:04,  5.82it/s]Epoch: 2: Step: 2101/14003, loss=0.639673, lr=0.000014
2199it [06:22,  5.81it/s]Train batch 2200
Avg. loss per last 100 batches: 0.912363
2200it [06:22,  5.82it/s]Epoch: 2: Step: 2201/14003, loss=0.925368, lr=0.000014
2299it [06:39,  5.83it/s]Train batch 2300
Avg. loss per last 100 batches: 0.921299
2300it [06:39,  5.81it/s]Epoch: 2: Step: 2301/14003, loss=1.757852, lr=0.000014
2399it [06:56,  5.82it/s]Train batch 2400
Avg. loss per last 100 batches: 0.982669
2400it [06:56,  5.82it/s]Epoch: 2: Step: 2401/14003, loss=1.105345, lr=0.000014
2499it [07:14,  5.82it/s]Train batch 2500
Avg. loss per last 100 batches: 0.913728
2500it [07:14,  5.79it/s]Epoch: 2: Step: 2501/14003, loss=0.921723, lr=0.000014
2599it [07:31,  5.83it/s]Train batch 2600
Avg. loss per last 100 batches: 0.931233
2600it [07:31,  5.82it/s]Epoch: 2: Step: 2601/14003, loss=0.751647, lr=0.000014
2699it [07:48,  5.76it/s]Train batch 2700
Avg. loss per last 100 batches: 0.928681
2700it [07:48,  5.78it/s]Epoch: 2: Step: 2701/14003, loss=0.603869, lr=0.000014
2799it [08:06,  5.81it/s]Train batch 2800
Avg. loss per last 100 batches: 0.922230
2800it [08:06,  5.80it/s]Epoch: 2: Step: 2801/14003, loss=0.855194, lr=0.000014
Validation: Epoch: 2 Step: 2801/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.815930 sec., loss=1.355566 
Eval step: 199 , used_time=9.613356 sec., loss=1.537282 
Eval step: 299 , used_time=14.472059 sec., loss=0.654213 
Eval step: 399 , used_time=19.504957 sec., loss=0.929768 
Eval step: 499 , used_time=24.351057 sec., loss=1.155792 
Eval step: 599 , used_time=29.161201 sec., loss=1.488234 
Eval step: 699 , used_time=33.996215 sec., loss=1.196906 
Eval step: 799 , used_time=38.792874 sec., loss=0.985307 
Eval step: 899 , used_time=43.706702 sec., loss=1.490045 
Eval step: 999 , used_time=48.711358 sec., loss=1.017702 
Eval step: 1099 , used_time=53.576418 sec., loss=1.318864 
Eval step: 1199 , used_time=58.407584 sec., loss=0.891711 
Eval step: 1299 , used_time=63.196739 sec., loss=1.077477 
Eval step: 1399 , used_time=68.032999 sec., loss=0.745525 
Eval step: 1499 , used_time=72.857074 sec., loss=1.292024 
Eval step: 1599 , used_time=77.695258 sec., loss=0.846767 
NLL Validation: loss = 0.974493. correct prediction ratio  38248/52032 ~  0.735086
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
2899it [09:46,  5.80it/s]Train batch 2900
Avg. loss per last 100 batches: 0.948032
2900it [09:46,  5.78it/s]Epoch: 2: Step: 2901/14003, loss=0.626854, lr=0.000014
2999it [10:03,  5.83it/s]Train batch 3000
Avg. loss per last 100 batches: 0.925800
3000it [10:04,  5.82it/s]Epoch: 2: Step: 3001/14003, loss=0.492160, lr=0.000014
3099it [10:21,  5.81it/s]Train batch 3100
Avg. loss per last 100 batches: 0.960462
3100it [10:21,  5.79it/s]Epoch: 2: Step: 3101/14003, loss=0.778958, lr=0.000014
3199it [10:38,  5.83it/s]Train batch 3200
Avg. loss per last 100 batches: 0.920021
3200it [10:38,  5.82it/s]Epoch: 2: Step: 3201/14003, loss=0.849385, lr=0.000014
3299it [10:55,  5.81it/s]Train batch 3300
Avg. loss per last 100 batches: 0.962271
3300it [10:55,  5.80it/s]Epoch: 2: Step: 3301/14003, loss=1.198482, lr=0.000014
3399it [11:13,  5.81it/s]Train batch 3400
Avg. loss per last 100 batches: 0.935514
3400it [11:13,  5.79it/s]Epoch: 2: Step: 3401/14003, loss=0.646728, lr=0.000014
3499it [11:30,  5.81it/s]Train batch 3500
Avg. loss per last 100 batches: 0.909598
3500it [11:30,  5.77it/s]Epoch: 2: Step: 3501/14003, loss=0.950277, lr=0.000014
3599it [11:47,  5.78it/s]Train batch 3600
Avg. loss per last 100 batches: 0.903741
3600it [11:48,  5.79it/s]Epoch: 2: Step: 3601/14003, loss=1.125227, lr=0.000014
3699it [12:05,  5.29it/s]Train batch 3700
Avg. loss per last 100 batches: 0.937489
3700it [12:05,  5.28it/s]Epoch: 2: Step: 3701/14003, loss=0.996102, lr=0.000014
3799it [12:22,  5.81it/s]Train batch 3800
Avg. loss per last 100 batches: 0.978887
3800it [12:22,  5.83it/s]Epoch: 2: Step: 3801/14003, loss=0.806716, lr=0.000014
3899it [12:39,  5.80it/s]Train batch 3900
Avg. loss per last 100 batches: 0.957084
3900it [12:40,  5.81it/s]Epoch: 2: Step: 3901/14003, loss=0.323924, lr=0.000014
3999it [12:57,  5.83it/s]Train batch 4000
Avg. loss per last 100 batches: 0.957903
4000it [12:57,  5.82it/s]Epoch: 2: Step: 4001/14003, loss=0.862613, lr=0.000014
4099it [13:14,  5.80it/s]Train batch 4100
Avg. loss per last 100 batches: 0.975535
4100it [13:14,  5.81it/s]Epoch: 2: Step: 4101/14003, loss=0.721569, lr=0.000014
4199it [13:31,  5.80it/s]Train batch 4200
Avg. loss per last 100 batches: 0.883836
4200it [13:31,  5.73it/s]Epoch: 2: Step: 4201/14003, loss=0.876253, lr=0.000014
4299it [13:49,  5.83it/s]Train batch 4300
Avg. loss per last 100 batches: 0.974016
4300it [13:49,  5.81it/s]Epoch: 2: Step: 4301/14003, loss=0.904853, lr=0.000014
4399it [14:06,  5.81it/s]Train batch 4400
Avg. loss per last 100 batches: 0.973491
4400it [14:06,  5.80it/s]Epoch: 2: Step: 4401/14003, loss=0.997933, lr=0.000014
4499it [14:23,  5.79it/s]Train batch 4500
Avg. loss per last 100 batches: 0.965860
4500it [14:24,  5.80it/s]Epoch: 2: Step: 4501/14003, loss=0.812714, lr=0.000014
4599it [14:41,  5.76it/s]Train batch 4600
Avg. loss per last 100 batches: 0.957451
4600it [14:41,  5.79it/s]Epoch: 2: Step: 4601/14003, loss=0.627129, lr=0.000014
4699it [14:58,  5.81it/s]Train batch 4700
Avg. loss per last 100 batches: 0.984429
4700it [14:58,  5.82it/s]Epoch: 2: Step: 4701/14003, loss=1.034222, lr=0.000013
4799it [15:15,  5.57it/s]Train batch 4800
Avg. loss per last 100 batches: 0.958706
4800it [15:16,  5.63it/s]Epoch: 2: Step: 4801/14003, loss=0.385667, lr=0.000013
4899it [15:33,  5.79it/s]Train batch 4900
Avg. loss per last 100 batches: 0.941984
4900it [15:33,  5.82it/s]Epoch: 2: Step: 4901/14003, loss=1.101450, lr=0.000013
4999it [15:50,  5.79it/s]Train batch 5000
Avg. loss per last 100 batches: 0.972193
5000it [15:50,  5.80it/s]Epoch: 2: Step: 5001/14003, loss=1.290937, lr=0.000013
5099it [16:07,  5.77it/s]Train batch 5100
Avg. loss per last 100 batches: 0.964061
5100it [16:08,  5.79it/s]Epoch: 2: Step: 5101/14003, loss=0.901293, lr=0.000013
5199it [16:25,  5.83it/s]Train batch 5200
Avg. loss per last 100 batches: 0.922138
5200it [16:25,  5.82it/s]Epoch: 2: Step: 5201/14003, loss=0.912445, lr=0.000013
5299it [16:42,  5.81it/s]Train batch 5300
Avg. loss per last 100 batches: 0.976449
5300it [16:42,  5.80it/s]Epoch: 2: Step: 5301/14003, loss=0.973536, lr=0.000013
5399it [16:59,  5.83it/s]Train batch 5400
Avg. loss per last 100 batches: 0.936446
5400it [17:00,  5.81it/s]Epoch: 2: Step: 5401/14003, loss=0.917106, lr=0.000013
5499it [17:17,  5.84it/s]Train batch 5500
Avg. loss per last 100 batches: 0.936262
5500it [17:17,  5.82it/s]Epoch: 2: Step: 5501/14003, loss=0.692159, lr=0.000013
5599it [17:34,  5.80it/s]Train batch 5600
Avg. loss per last 100 batches: 0.894272
5600it [17:34,  5.80it/s]Epoch: 2: Step: 5601/14003, loss=0.976255, lr=0.000013
5601it [17:34,  5.76it/s]Validation: Epoch: 2 Step: 5602/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.834383 sec., loss=1.418060 
Eval step: 199 , used_time=9.656027 sec., loss=1.383934 
Eval step: 299 , used_time=14.531078 sec., loss=0.804277 
Eval step: 399 , used_time=19.508683 sec., loss=0.899994 
Eval step: 499 , used_time=24.370320 sec., loss=1.299974 
Eval step: 599 , used_time=29.144142 sec., loss=1.304188 
Eval step: 699 , used_time=33.981725 sec., loss=1.096111 
Eval step: 799 , used_time=38.756085 sec., loss=0.879953 
Eval step: 899 , used_time=43.566363 sec., loss=1.431125 
Eval step: 999 , used_time=48.576444 sec., loss=1.047009 
Eval step: 1099 , used_time=53.434875 sec., loss=1.351034 
Eval step: 1199 , used_time=58.211374 sec., loss=1.034046 
Eval step: 1299 , used_time=63.005602 sec., loss=1.104801 
Eval step: 1399 , used_time=67.805737 sec., loss=0.709287 
Eval step: 1499 , used_time=72.619472 sec., loss=1.232293 
Eval step: 1599 , used_time=77.437219 sec., loss=0.876751 
NLL Validation: loss = 0.971858. correct prediction ratio  38234/52032 ~  0.734817
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:16,  5.78it/s]Train batch 5700
Avg. loss per last 100 batches: 0.954864
5700it [19:16,  5.77it/s]Epoch: 2: Step: 5701/14003, loss=1.484611, lr=0.000013
5799it [19:34,  5.83it/s]Train batch 5800
Avg. loss per last 100 batches: 0.978133
5800it [19:34,  5.81it/s]Epoch: 2: Step: 5801/14003, loss=1.366040, lr=0.000013
5899it [19:51,  5.74it/s]Train batch 5900
Avg. loss per last 100 batches: 0.925179
5900it [19:51,  5.74it/s]Epoch: 2: Step: 5901/14003, loss=1.633204, lr=0.000013
5999it [20:09,  5.79it/s]Train batch 6000
Avg. loss per last 100 batches: 0.943553
6000it [20:09,  5.81it/s]Epoch: 2: Step: 6001/14003, loss=1.117646, lr=0.000013
6099it [20:26,  5.81it/s]Train batch 6100
Avg. loss per last 100 batches: 0.999936
6100it [20:26,  5.81it/s]Epoch: 2: Step: 6101/14003, loss=0.846020, lr=0.000013
6199it [20:43,  5.81it/s]Train batch 6200
Avg. loss per last 100 batches: 0.974537
6200it [20:43,  5.78it/s]Epoch: 2: Step: 6201/14003, loss=0.786674, lr=0.000013
6299it [21:01,  5.62it/s]Train batch 6300
Avg. loss per last 100 batches: 0.948943
6300it [21:01,  5.68it/s]Epoch: 2: Step: 6301/14003, loss=0.968478, lr=0.000013
6399it [21:18,  5.81it/s]Train batch 6400
Avg. loss per last 100 batches: 0.920166
6400it [21:18,  5.83it/s]Epoch: 2: Step: 6401/14003, loss=0.804731, lr=0.000013
6499it [21:35,  5.74it/s]Train batch 6500
Avg. loss per last 100 batches: 0.947503
6500it [21:36,  5.77it/s]Epoch: 2: Step: 6501/14003, loss=1.135361, lr=0.000013
6599it [21:53,  5.83it/s]Train batch 6600
Avg. loss per last 100 batches: 0.938002
6600it [21:53,  5.82it/s]Epoch: 2: Step: 6601/14003, loss=0.548211, lr=0.000013
6699it [22:10,  5.79it/s]Train batch 6700
Avg. loss per last 100 batches: 1.001053
6700it [22:10,  5.77it/s]Epoch: 2: Step: 6701/14003, loss=0.979334, lr=0.000013
6799it [22:27,  5.78it/s]Train batch 6800
Avg. loss per last 100 batches: 0.930734
6800it [22:28,  5.79it/s]Epoch: 2: Step: 6801/14003, loss=0.829038, lr=0.000013
6899it [22:45,  5.78it/s]Train batch 6900
Avg. loss per last 100 batches: 0.916737
6900it [22:45,  5.78it/s]Epoch: 2: Step: 6901/14003, loss=0.842819, lr=0.000013
6999it [23:02,  5.74it/s]Train batch 7000
Avg. loss per last 100 batches: 0.913682
7000it [23:02,  5.73it/s]Epoch: 2: Step: 7001/14003, loss=0.939542, lr=0.000013
7099it [23:19,  5.81it/s]Train batch 7100
Avg. loss per last 100 batches: 0.920613
7100it [23:20,  5.77it/s]Epoch: 2: Step: 7101/14003, loss=0.831982, lr=0.000013
7199it [23:37,  5.79it/s]Train batch 7200
Avg. loss per last 100 batches: 0.943989
7200it [23:37,  5.81it/s]Epoch: 2: Step: 7201/14003, loss=0.574027, lr=0.000013
7299it [23:54,  5.81it/s]Train batch 7300
Avg. loss per last 100 batches: 0.917282
7300it [23:54,  5.82it/s]Epoch: 2: Step: 7301/14003, loss=0.866155, lr=0.000013
7399it [24:12,  5.40it/s]Train batch 7400
Avg. loss per last 100 batches: 0.921183
7400it [24:12,  5.37it/s]Epoch: 2: Step: 7401/14003, loss=1.478748, lr=0.000013
7499it [24:29,  5.79it/s]Train batch 7500
Avg. loss per last 100 batches: 0.937936
7500it [24:29,  5.79it/s]Epoch: 2: Step: 7501/14003, loss=1.024255, lr=0.000013
7599it [24:46,  5.71it/s]Train batch 7600
Avg. loss per last 100 batches: 0.930974
7600it [24:47,  5.66it/s]Epoch: 2: Step: 7601/14003, loss=1.093477, lr=0.000013
7699it [25:04,  5.71it/s]Train batch 7700
Avg. loss per last 100 batches: 0.960376
7700it [25:04,  5.70it/s]Epoch: 2: Step: 7701/14003, loss=1.309862, lr=0.000013
7799it [25:21,  5.80it/s]Train batch 7800
Avg. loss per last 100 batches: 0.978709
7800it [25:21,  5.81it/s]Epoch: 2: Step: 7801/14003, loss=0.642428, lr=0.000013
7899it [25:38,  5.78it/s]Train batch 7900
Avg. loss per last 100 batches: 0.959458
7900it [25:39,  5.79it/s]Epoch: 2: Step: 7901/14003, loss=1.596084, lr=0.000013
7999it [25:56,  5.77it/s]Train batch 8000
Avg. loss per last 100 batches: 0.936889
8000it [25:56,  5.78it/s]Epoch: 2: Step: 8001/14003, loss=1.000533, lr=0.000013
8099it [26:13,  5.80it/s]Train batch 8100
Avg. loss per last 100 batches: 0.948322
8100it [26:13,  5.79it/s]Epoch: 2: Step: 8101/14003, loss=0.985764, lr=0.000013
8199it [26:31,  5.70it/s]Train batch 8200
Avg. loss per last 100 batches: 0.927192
8200it [26:31,  5.73it/s]Epoch: 2: Step: 8201/14003, loss=1.087352, lr=0.000013
8299it [26:48,  5.79it/s]Train batch 8300
Avg. loss per last 100 batches: 0.888257
8300it [26:48,  5.78it/s]Epoch: 2: Step: 8301/14003, loss=0.403115, lr=0.000013
8399it [27:05,  5.81it/s]Train batch 8400
Avg. loss per last 100 batches: 0.927951
8400it [27:06,  5.80it/s]Epoch: 2: Step: 8401/14003, loss=1.106591, lr=0.000013
8402it [27:06,  5.76it/s]Validation: Epoch: 2 Step: 8403/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.872681 sec., loss=1.502743 
Eval step: 199 , used_time=9.668581 sec., loss=1.315335 
Eval step: 299 , used_time=14.512384 sec., loss=0.873278 
Eval step: 399 , used_time=19.560851 sec., loss=0.950906 
Eval step: 499 , used_time=24.395826 sec., loss=1.265663 
Eval step: 599 , used_time=29.183632 sec., loss=1.328603 
Eval step: 699 , used_time=34.086000 sec., loss=1.027556 
Eval step: 799 , used_time=38.895604 sec., loss=0.882241 
Eval step: 899 , used_time=43.720787 sec., loss=1.193729 
Eval step: 999 , used_time=48.781930 sec., loss=0.947391 
Eval step: 1099 , used_time=53.588556 sec., loss=1.310061 
Eval step: 1199 , used_time=58.406988 sec., loss=0.934803 
Eval step: 1299 , used_time=63.234627 sec., loss=1.126955 
Eval step: 1399 , used_time=68.078986 sec., loss=0.579785 
Eval step: 1499 , used_time=72.851918 sec., loss=1.125508 
Eval step: 1599 , used_time=77.685368 sec., loss=0.958076 
NLL Validation: loss = 0.945775. correct prediction ratio  38572/52032 ~  0.741313
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
8499it [28:45,  5.80it/s]Train batch 8500
Avg. loss per last 100 batches: 0.938170
8500it [28:46,  5.77it/s]Epoch: 2: Step: 8501/14003, loss=1.432169, lr=0.000013
8599it [29:03,  5.80it/s]Train batch 8600
Avg. loss per last 100 batches: 0.937712
8600it [29:03,  5.80it/s]Epoch: 2: Step: 8601/14003, loss=0.726161, lr=0.000013
8699it [29:20,  5.67it/s]Train batch 8700
Avg. loss per last 100 batches: 0.952357
8700it [29:20,  5.70it/s]Epoch: 2: Step: 8701/14003, loss=0.857244, lr=0.000013
8799it [29:38,  5.82it/s]Train batch 8800
Avg. loss per last 100 batches: 0.914258
8800it [29:38,  5.79it/s]Epoch: 2: Step: 8801/14003, loss=1.281577, lr=0.000013
8899it [29:55,  5.82it/s]Train batch 8900
Avg. loss per last 100 batches: 0.886589
8900it [29:55,  5.83it/s]Epoch: 2: Step: 8901/14003, loss=0.554126, lr=0.000013
8999it [30:12,  5.78it/s]Train batch 9000
Avg. loss per last 100 batches: 0.913568
9000it [30:13,  5.78it/s]Epoch: 2: Step: 9001/14003, loss=0.743443, lr=0.000013
9099it [30:30,  5.77it/s]Train batch 9100
Avg. loss per last 100 batches: 0.908798
9100it [30:30,  5.74it/s]Epoch: 2: Step: 9101/14003, loss=0.900032, lr=0.000013
9199it [30:47,  5.78it/s]Train batch 9200
Avg. loss per last 100 batches: 0.927894
9200it [30:47,  5.77it/s]Epoch: 2: Step: 9201/14003, loss=0.760174, lr=0.000013
9299it [31:04,  5.68it/s]Train batch 9300
Avg. loss per last 100 batches: 0.946674
9300it [31:05,  5.69it/s]Epoch: 2: Step: 9301/14003, loss=0.990024, lr=0.000013
9399it [31:22,  5.78it/s]Train batch 9400
Avg. loss per last 100 batches: 0.931794
9400it [31:22,  5.78it/s]Epoch: 2: Step: 9401/14003, loss=0.870038, lr=0.000013
9499it [31:39,  5.81it/s]Train batch 9500
Avg. loss per last 100 batches: 0.974543
9500it [31:39,  5.79it/s]Epoch: 2: Step: 9501/14003, loss=0.539070, lr=0.000013
9599it [31:56,  5.81it/s]Train batch 9600
Avg. loss per last 100 batches: 0.919443
9600it [31:57,  5.81it/s]Epoch: 2: Step: 9601/14003, loss=0.934979, lr=0.000012
9699it [32:14,  5.78it/s]Train batch 9700
Avg. loss per last 100 batches: 0.931695
9700it [32:14,  5.81it/s]Epoch: 2: Step: 9701/14003, loss=0.744323, lr=0.000012
9799it [32:31,  5.79it/s]Train batch 9800
Avg. loss per last 100 batches: 0.937919
9800it [32:31,  5.78it/s]Epoch: 2: Step: 9801/14003, loss=0.634092, lr=0.000012
9899it [32:48,  5.82it/s]Train batch 9900
Avg. loss per last 100 batches: 0.960588
9900it [32:49,  5.81it/s]Epoch: 2: Step: 9901/14003, loss=1.365484, lr=0.000012
9999it [33:06,  5.81it/s]Train batch 10000
Avg. loss per last 100 batches: 0.941637
10000it [33:06,  5.82it/s]Epoch: 2: Step: 10001/14003, loss=0.876078, lr=0.000012
10099it [33:23,  5.83it/s]Train batch 10100
Avg. loss per last 100 batches: 0.946331
10100it [33:23,  5.82it/s]Epoch: 2: Step: 10101/14003, loss=0.576382, lr=0.000012
10199it [33:41,  5.48it/s]Train batch 10200
Avg. loss per last 100 batches: 0.960187
10200it [33:41,  5.35it/s]Epoch: 2: Step: 10201/14003, loss=0.970138, lr=0.000012
10299it [33:58,  5.80it/s]Train batch 10300
Avg. loss per last 100 batches: 0.944516
10300it [33:58,  5.82it/s]Epoch: 2: Step: 10301/14003, loss=0.513505, lr=0.000012
10399it [34:15,  5.77it/s]Train batch 10400
Avg. loss per last 100 batches: 0.956726
10400it [34:16,  5.77it/s]Epoch: 2: Step: 10401/14003, loss=1.509906, lr=0.000012
10499it [34:33,  5.81it/s]Train batch 10500
Avg. loss per last 100 batches: 0.922400
10500it [34:33,  5.81it/s]Epoch: 2: Step: 10501/14003, loss=0.913555, lr=0.000012
10599it [34:50,  5.62it/s]Train batch 10600
Avg. loss per last 100 batches: 0.941011
10600it [34:50,  5.69it/s]Epoch: 2: Step: 10601/14003, loss=0.849188, lr=0.000012
10699it [35:07,  5.82it/s]Train batch 10700
Avg. loss per last 100 batches: 0.927660
10700it [35:08,  5.81it/s]Epoch: 2: Step: 10701/14003, loss=0.984303, lr=0.000012
10799it [35:25,  5.82it/s]Train batch 10800
Avg. loss per last 100 batches: 0.945698
10800it [35:25,  5.82it/s]Epoch: 2: Step: 10801/14003, loss=0.712894, lr=0.000012
10899it [35:42,  5.81it/s]Train batch 10900
Avg. loss per last 100 batches: 0.964403
10900it [35:42,  5.80it/s]Epoch: 2: Step: 10901/14003, loss=0.812590, lr=0.000012
10999it [36:00,  5.83it/s]Train batch 11000
Avg. loss per last 100 batches: 0.957893
11000it [36:00,  5.79it/s]Epoch: 2: Step: 11001/14003, loss=0.831614, lr=0.000012
11099it [36:17,  5.74it/s]Train batch 11100
Avg. loss per last 100 batches: 0.965281
11100it [36:17,  5.73it/s]Epoch: 2: Step: 11101/14003, loss=0.406509, lr=0.000012
11199it [36:34,  5.80it/s]Train batch 11200
Avg. loss per last 100 batches: 0.924838
11200it [36:35,  5.79it/s]Epoch: 2: Step: 11201/14003, loss=1.396940, lr=0.000012
11203it [36:35,  5.79it/s]Validation: Epoch: 2 Step: 11204/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.846948 sec., loss=1.630342 
Eval step: 199 , used_time=9.668633 sec., loss=1.406402 
Eval step: 299 , used_time=14.529301 sec., loss=0.789616 
Eval step: 399 , used_time=19.582364 sec., loss=0.891874 
Eval step: 499 , used_time=24.386257 sec., loss=1.157480 
Eval step: 599 , used_time=29.189790 sec., loss=1.371599 
Eval step: 699 , used_time=33.992208 sec., loss=1.190060 
Eval step: 799 , used_time=38.807462 sec., loss=0.781767 
Eval step: 899 , used_time=43.637222 sec., loss=1.512835 
Eval step: 999 , used_time=48.690365 sec., loss=0.873192 
Eval step: 1099 , used_time=53.501335 sec., loss=1.286029 
Eval step: 1199 , used_time=58.325196 sec., loss=0.855304 
Eval step: 1299 , used_time=63.103155 sec., loss=1.175677 
Eval step: 1399 , used_time=67.935263 sec., loss=0.717279 
Eval step: 1499 , used_time=72.784261 sec., loss=1.020490 
Eval step: 1599 , used_time=77.609546 sec., loss=0.877247 
NLL Validation: loss = 0.926562. correct prediction ratio  38769/52032 ~  0.745099
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [38:14,  5.80it/s]Train batch 11300
Avg. loss per last 100 batches: 0.927017
11300it [38:15,  5.80it/s]Epoch: 2: Step: 11301/14003, loss=0.552398, lr=0.000012
11399it [38:32,  5.82it/s]Train batch 11400
Avg. loss per last 100 batches: 0.899051
11400it [38:32,  5.82it/s]Epoch: 2: Step: 11401/14003, loss=1.254544, lr=0.000012
11499it [38:49,  5.77it/s]Train batch 11500
Avg. loss per last 100 batches: 0.964833
11500it [38:49,  5.77it/s]Epoch: 2: Step: 11501/14003, loss=0.671854, lr=0.000012
11599it [39:06,  5.82it/s]Train batch 11600
Avg. loss per last 100 batches: 0.865187
11600it [39:07,  5.81it/s]Epoch: 2: Step: 11601/14003, loss=0.811712, lr=0.000012
11699it [39:24,  5.79it/s]Train batch 11700
Avg. loss per last 100 batches: 0.971703
11700it [39:24,  5.80it/s]Epoch: 2: Step: 11701/14003, loss=0.625445, lr=0.000012
11799it [39:41,  5.77it/s]Train batch 11800
Avg. loss per last 100 batches: 0.882150
11800it [39:41,  5.78it/s]Epoch: 2: Step: 11801/14003, loss=0.798987, lr=0.000012
11899it [39:58,  5.80it/s]Train batch 11900
Avg. loss per last 100 batches: 0.908408
11900it [39:59,  5.79it/s]Epoch: 2: Step: 11901/14003, loss=1.121548, lr=0.000012
11999it [40:16,  5.81it/s]Train batch 12000
Avg. loss per last 100 batches: 0.935339
12000it [40:16,  5.80it/s]Epoch: 2: Step: 12001/14003, loss=1.040146, lr=0.000012
12099it [40:33,  5.54it/s]Train batch 12100
Avg. loss per last 100 batches: 0.923827
12100it [40:34,  5.62it/s]Epoch: 2: Step: 12101/14003, loss=1.136824, lr=0.000012
12199it [40:51,  5.74it/s]Train batch 12200
Avg. loss per last 100 batches: 0.930884
12200it [40:51,  5.76it/s]Epoch: 2: Step: 12201/14003, loss=0.650157, lr=0.000012
12299it [41:08,  5.82it/s]Train batch 12300
Avg. loss per last 100 batches: 0.962493
12300it [41:08,  5.82it/s]Epoch: 2: Step: 12301/14003, loss=1.291309, lr=0.000012
12399it [41:25,  5.81it/s]Train batch 12400
Avg. loss per last 100 batches: 0.907126
12400it [41:25,  5.82it/s]Epoch: 2: Step: 12401/14003, loss=0.739872, lr=0.000012
12499it [41:43,  5.80it/s]Train batch 12500
Avg. loss per last 100 batches: 0.927029
12500it [41:43,  5.81it/s]Epoch: 2: Step: 12501/14003, loss=0.866042, lr=0.000012
12599it [42:00,  5.80it/s]Train batch 12600
Avg. loss per last 100 batches: 0.946079
12600it [42:00,  5.77it/s]Epoch: 2: Step: 12601/14003, loss=0.615309, lr=0.000012
12699it [42:17,  5.79it/s]Train batch 12700
Avg. loss per last 100 batches: 0.978550
12700it [42:18,  5.79it/s]Epoch: 2: Step: 12701/14003, loss=0.712834, lr=0.000012
12799it [42:35,  5.82it/s]Train batch 12800
Avg. loss per last 100 batches: 0.943192
12800it [42:35,  5.83it/s]Epoch: 2: Step: 12801/14003, loss=1.171735, lr=0.000012
12899it [42:52,  5.72it/s]Train batch 12900
Avg. loss per last 100 batches: 0.915159
12900it [42:52,  5.70it/s]Epoch: 2: Step: 12901/14003, loss=0.842810, lr=0.000012
12999it [43:09,  5.81it/s]Train batch 13000
Avg. loss per last 100 batches: 0.932084
13000it [43:09,  5.80it/s]Epoch: 2: Step: 13001/14003, loss=0.949847, lr=0.000012
13099it [43:27,  5.79it/s]Train batch 13100
Avg. loss per last 100 batches: 0.936580
13100it [43:27,  5.82it/s]Epoch: 2: Step: 13101/14003, loss=0.548976, lr=0.000012
13199it [43:44,  5.78it/s]Train batch 13200
Avg. loss per last 100 batches: 0.932122
13200it [43:44,  5.78it/s]Epoch: 2: Step: 13201/14003, loss=0.712138, lr=0.000012
13299it [44:02,  4.69it/s]Train batch 13300
Avg. loss per last 100 batches: 0.949681
13300it [44:02,  4.96it/s]Epoch: 2: Step: 13301/14003, loss=1.080746, lr=0.000012
13399it [44:20,  5.81it/s]Train batch 13400
Avg. loss per last 100 batches: 0.896989
13400it [44:20,  5.74it/s]Epoch: 2: Step: 13401/14003, loss=1.359213, lr=0.000012
13499it [44:37,  5.81it/s]Train batch 13500
Avg. loss per last 100 batches: 0.950738
13500it [44:37,  5.81it/s]Epoch: 2: Step: 13501/14003, loss=0.828970, lr=0.000012
13599it [44:54,  5.81it/s]Train batch 13600
Avg. loss per last 100 batches: 0.951166
13600it [44:54,  5.80it/s]Epoch: 2: Step: 13601/14003, loss=1.038103, lr=0.000012
13699it [45:11,  5.84it/s]Train batch 13700
Avg. loss per last 100 batches: 0.934864
13700it [45:12,  5.82it/s]Epoch: 2: Step: 13701/14003, loss=0.836217, lr=0.000012
13799it [45:29,  5.75it/s]Train batch 13800
Avg. loss per last 100 batches: 0.947110
13800it [45:29,  5.77it/s]Epoch: 2: Step: 13801/14003, loss=1.029840, lr=0.000012
13899it [45:46,  5.79it/s]Train batch 13900
Avg. loss per last 100 batches: 0.936763
13900it [45:46,  5.77it/s]Epoch: 2: Step: 13901/14003, loss=0.723807, lr=0.000012
13999it [46:04,  5.82it/s]Train batch 14000
Avg. loss per last 100 batches: 0.962544
14000it [46:04,  5.81it/s]Epoch: 2: Step: 14001/14003, loss=1.584036, lr=0.000012
14003it [46:04,  5.06it/s]
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.831618 sec., loss=1.514103 
Eval step: 199 , used_time=9.614241 sec., loss=1.421136 
Eval step: 299 , used_time=14.681598 sec., loss=0.751395 
Eval step: 399 , used_time=19.433359 sec., loss=1.009138 
Eval step: 499 , used_time=24.251966 sec., loss=1.176712 
Eval step: 599 , used_time=29.047476 sec., loss=1.223760 
Eval step: 699 , used_time=33.852046 sec., loss=1.152945 
Eval step: 799 , used_time=38.630121 sec., loss=0.630588 
Eval step: 899 , used_time=43.451648 sec., loss=1.214574 
Eval step: 999 , used_time=48.438542 sec., loss=0.804819 
Eval step: 1099 , used_time=53.289469 sec., loss=1.387307 
Eval step: 1199 , used_time=58.074670 sec., loss=0.796054 
Eval step: 1299 , used_time=62.843868 sec., loss=1.232361 
Eval step: 1399 , used_time=67.657106 sec., loss=0.835342 
Eval step: 1499 , used_time=72.416702 sec., loss=0.983972 
Eval step: 1599 , used_time=77.437375 sec., loss=0.903817 
NLL Validation: loss = 0.907977. correct prediction ratio  39043/52032 ~  0.750365
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
New Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=0.940436
epoch total correct predictions=330736
***** Epoch 3 *****
0it [00:00, ?it/s]Epoch: 3: Step: 1/14003, loss=0.777410, lr=0.000012
99it [00:17,  5.80it/s]Train batch 100
Avg. loss per last 100 batches: 0.716710
100it [00:17,  5.80it/s]Epoch: 3: Step: 101/14003, loss=0.578640, lr=0.000012
199it [00:35,  5.84it/s]Train batch 200
Avg. loss per last 100 batches: 0.658078
200it [00:35,  5.82it/s]Epoch: 3: Step: 201/14003, loss=0.681015, lr=0.000012
299it [00:52,  5.81it/s]Train batch 300
Avg. loss per last 100 batches: 0.645563
300it [00:52,  5.79it/s]Epoch: 3: Step: 301/14003, loss=0.657526, lr=0.000012
399it [01:09,  5.83it/s]Train batch 400
Avg. loss per last 100 batches: 0.674514
400it [01:09,  5.80it/s]Epoch: 3: Step: 401/14003, loss=0.634303, lr=0.000011
499it [01:26,  5.79it/s]Train batch 500
Avg. loss per last 100 batches: 0.654084
500it [01:27,  5.79it/s]Epoch: 3: Step: 501/14003, loss=0.835230, lr=0.000011
599it [01:44,  5.76it/s]Train batch 600
Avg. loss per last 100 batches: 0.656207
600it [01:44,  5.78it/s]Epoch: 3: Step: 601/14003, loss=0.535710, lr=0.000011
699it [02:01,  5.13it/s]Train batch 700
Avg. loss per last 100 batches: 0.698189
700it [02:02,  5.28it/s]Epoch: 3: Step: 701/14003, loss=0.625639, lr=0.000011
799it [02:19,  5.80it/s]Train batch 800
Avg. loss per last 100 batches: 0.715163
800it [02:19,  5.79it/s]Epoch: 3: Step: 801/14003, loss=0.333217, lr=0.000011
899it [02:36,  5.84it/s]Train batch 900
Avg. loss per last 100 batches: 0.683630
900it [02:36,  5.84it/s]Epoch: 3: Step: 901/14003, loss=0.702637, lr=0.000011
999it [02:53,  5.81it/s]Train batch 1000
Avg. loss per last 100 batches: 0.677155
1000it [02:54,  5.82it/s]Epoch: 3: Step: 1001/14003, loss=0.599075, lr=0.000011
1099it [03:11,  5.65it/s]Train batch 1100
Avg. loss per last 100 batches: 0.755955
1100it [03:11,  5.70it/s]Epoch: 3: Step: 1101/14003, loss=0.839246, lr=0.000011
1199it [03:28,  5.81it/s]Train batch 1200
Avg. loss per last 100 batches: 0.678855
1200it [03:28,  5.82it/s]Epoch: 3: Step: 1201/14003, loss=0.240053, lr=0.000011
1299it [03:45,  5.80it/s]Train batch 1300
Avg. loss per last 100 batches: 0.698351
1300it [03:46,  5.81it/s]Epoch: 3: Step: 1301/14003, loss=0.719185, lr=0.000011
1399it [04:03,  5.78it/s]Train batch 1400
Avg. loss per last 100 batches: 0.689965
1400it [04:03,  5.80it/s]Epoch: 3: Step: 1401/14003, loss=0.969476, lr=0.000011
1499it [04:20,  5.81it/s]Train batch 1500
Avg. loss per last 100 batches: 0.708609
1500it [04:20,  5.80it/s]Epoch: 3: Step: 1501/14003, loss=0.742965, lr=0.000011
1599it [04:37,  5.80it/s]Train batch 1600
Avg. loss per last 100 batches: 0.711857
1600it [04:38,  5.79it/s]Epoch: 3: Step: 1601/14003, loss=1.166612, lr=0.000011
1699it [04:55,  5.83it/s]Train batch 1700
Avg. loss per last 100 batches: 0.694767
1700it [04:55,  5.82it/s]Epoch: 3: Step: 1701/14003, loss=0.756333, lr=0.000011
1799it [05:12,  5.78it/s]Train batch 1800
Avg. loss per last 100 batches: 0.719510
1800it [05:12,  5.77it/s]Epoch: 3: Step: 1801/14003, loss=1.045411, lr=0.000011
1899it [05:29,  5.81it/s]Train batch 1900
Avg. loss per last 100 batches: 0.736282
1900it [05:30,  5.81it/s]Epoch: 3: Step: 1901/14003, loss=0.817785, lr=0.000011
1999it [05:47,  5.81it/s]Train batch 2000
Avg. loss per last 100 batches: 0.674986
2000it [05:47,  5.82it/s]Epoch: 3: Step: 2001/14003, loss=0.666307, lr=0.000011
2099it [06:04,  5.79it/s]Train batch 2100
Avg. loss per last 100 batches: 0.665061
2100it [06:04,  5.74it/s]Epoch: 3: Step: 2101/14003, loss=0.590254, lr=0.000011
2199it [06:21,  5.79it/s]Train batch 2200
Avg. loss per last 100 batches: 0.710207
2200it [06:22,  5.78it/s]Epoch: 3: Step: 2201/14003, loss=0.522053, lr=0.000011
2299it [06:39,  5.84it/s]Train batch 2300
Avg. loss per last 100 batches: 0.739572
2300it [06:39,  5.81it/s]Epoch: 3: Step: 2301/14003, loss=0.995439, lr=0.000011
2399it [06:56,  5.78it/s]Train batch 2400
Avg. loss per last 100 batches: 0.716119
2400it [06:56,  5.78it/s]Epoch: 3: Step: 2401/14003, loss=0.857000, lr=0.000011
2499it [07:13,  5.71it/s]Train batch 2500
Avg. loss per last 100 batches: 0.702425
2500it [07:14,  5.71it/s]Epoch: 3: Step: 2501/14003, loss=0.620257, lr=0.000011
2599it [07:31,  5.66it/s]Train batch 2600
Avg. loss per last 100 batches: 0.706477
2600it [07:31,  5.69it/s]Epoch: 3: Step: 2601/14003, loss=0.944327, lr=0.000011
2699it [07:48,  5.36it/s]Train batch 2700
Avg. loss per last 100 batches: 0.649869
2700it [07:48,  5.31it/s]Epoch: 3: Step: 2701/14003, loss=0.902615, lr=0.000011
2799it [08:06,  5.81it/s]Train batch 2800
Avg. loss per last 100 batches: 0.684607
2800it [08:06,  5.80it/s]Epoch: 3: Step: 2801/14003, loss=1.081029, lr=0.000011
Validation: Epoch: 3 Step: 2801/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.835316 sec., loss=1.640168 
Eval step: 199 , used_time=9.649029 sec., loss=1.507606 
Eval step: 299 , used_time=14.746789 sec., loss=0.870624 
Eval step: 399 , used_time=19.522959 sec., loss=1.123802 
Eval step: 499 , used_time=24.335809 sec., loss=1.313957 
Eval step: 599 , used_time=29.139646 sec., loss=1.382996 
Eval step: 699 , used_time=33.941278 sec., loss=1.197372 
Eval step: 799 , used_time=38.805017 sec., loss=0.866484 
Eval step: 899 , used_time=43.615530 sec., loss=1.346884 
Eval step: 999 , used_time=48.694506 sec., loss=0.923579 
Eval step: 1099 , used_time=53.506198 sec., loss=1.469448 
Eval step: 1199 , used_time=58.321600 sec., loss=0.900944 
Eval step: 1299 , used_time=63.114076 sec., loss=1.161272 
Eval step: 1399 , used_time=67.993964 sec., loss=0.801252 
Eval step: 1499 , used_time=72.818944 sec., loss=1.045379 
Eval step: 1599 , used_time=77.892315 sec., loss=0.979944 
NLL Validation: loss = 0.965793. correct prediction ratio  38933/52032 ~  0.748251
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
2899it [09:46,  5.81it/s]Train batch 2900
Avg. loss per last 100 batches: 0.728074
2900it [09:46,  5.80it/s]Epoch: 3: Step: 2901/14003, loss=0.293460, lr=0.000011
2999it [10:03,  5.78it/s]Train batch 3000
Avg. loss per last 100 batches: 0.687114
3000it [10:03,  5.77it/s]Epoch: 3: Step: 3001/14003, loss=0.829621, lr=0.000011
3099it [10:20,  5.79it/s]Train batch 3100
Avg. loss per last 100 batches: 0.680360
3100it [10:20,  5.80it/s]Epoch: 3: Step: 3101/14003, loss=0.525733, lr=0.000011
3199it [10:38,  5.83it/s]Train batch 3200
Avg. loss per last 100 batches: 0.716382
3200it [10:38,  5.84it/s]Epoch: 3: Step: 3201/14003, loss=0.703525, lr=0.000011
3299it [10:55,  5.80it/s]Train batch 3300
Avg. loss per last 100 batches: 0.728862
3300it [10:55,  5.82it/s]Epoch: 3: Step: 3301/14003, loss=0.785372, lr=0.000011
3399it [11:12,  5.72it/s]Train batch 3400
Avg. loss per last 100 batches: 0.693014
3400it [11:13,  5.75it/s]Epoch: 3: Step: 3401/14003, loss=0.906885, lr=0.000011
3499it [11:30,  5.35it/s]Train batch 3500
Avg. loss per last 100 batches: 0.712159
3500it [11:30,  5.33it/s]Epoch: 3: Step: 3501/14003, loss=0.195253, lr=0.000011
3599it [11:47,  5.84it/s]Train batch 3600
Avg. loss per last 100 batches: 0.702837
3600it [11:47,  5.82it/s]Epoch: 3: Step: 3601/14003, loss=0.673917, lr=0.000011
3699it [12:04,  5.77it/s]Train batch 3700
Avg. loss per last 100 batches: 0.671154
3700it [12:05,  5.72it/s]Epoch: 3: Step: 3701/14003, loss=0.773774, lr=0.000011
3799it [12:22,  5.85it/s]Train batch 3800
Avg. loss per last 100 batches: 0.662144
3800it [12:22,  5.84it/s]Epoch: 3: Step: 3801/14003, loss=1.090101, lr=0.000011
3899it [12:39,  5.79it/s]Train batch 3900
Avg. loss per last 100 batches: 0.739684
3900it [12:39,  5.80it/s]Epoch: 3: Step: 3901/14003, loss=0.791635, lr=0.000011
3999it [12:56,  5.84it/s]Train batch 4000
Avg. loss per last 100 batches: 0.699296
4000it [12:56,  5.82it/s]Epoch: 3: Step: 4001/14003, loss=0.566480, lr=0.000011
4099it [13:14,  5.73it/s]Train batch 4100
Avg. loss per last 100 batches: 0.697048
4100it [13:14,  5.68it/s]Epoch: 3: Step: 4101/14003, loss=1.100953, lr=0.000011
4199it [13:31,  5.47it/s]Train batch 4200
Avg. loss per last 100 batches: 0.678983
4200it [13:31,  5.55it/s]Epoch: 3: Step: 4201/14003, loss=0.421737, lr=0.000011
4299it [13:49,  5.82it/s]Train batch 4300
Avg. loss per last 100 batches: 0.664842
4300it [13:49,  5.81it/s]Epoch: 3: Step: 4301/14003, loss=0.743565, lr=0.000011
4399it [14:07,  5.22it/s]Train batch 4400
Avg. loss per last 100 batches: 0.702624
4400it [14:07,  5.09it/s]Epoch: 3: Step: 4401/14003, loss=0.675490, lr=0.000011
4499it [14:24,  5.77it/s]Train batch 4500
Avg. loss per last 100 batches: 0.685436
4500it [14:24,  5.78it/s]Epoch: 3: Step: 4501/14003, loss=0.717190, lr=0.000011
4599it [14:42,  5.79it/s]Train batch 4600
Avg. loss per last 100 batches: 0.698232
4600it [14:42,  5.82it/s]Epoch: 3: Step: 4601/14003, loss=0.368884, lr=0.000011
4699it [14:59,  5.82it/s]Train batch 4700
Avg. loss per last 100 batches: 0.655616
4700it [14:59,  5.82it/s]Epoch: 3: Step: 4701/14003, loss=0.686847, lr=0.000011
4799it [15:16,  5.74it/s]Train batch 4800
Avg. loss per last 100 batches: 0.743749
4800it [15:16,  5.74it/s]Epoch: 3: Step: 4801/14003, loss=1.116967, lr=0.000011
4899it [15:34,  5.79it/s]Train batch 4900
Avg. loss per last 100 batches: 0.711751
4900it [15:34,  5.79it/s]Epoch: 3: Step: 4901/14003, loss=0.415743, lr=0.000011
4999it [15:51,  5.78it/s]Train batch 5000
Avg. loss per last 100 batches: 0.675339
5000it [15:51,  5.79it/s]Epoch: 3: Step: 5001/14003, loss=0.373041, lr=0.000011
5099it [16:08,  5.81it/s]Train batch 5100
Avg. loss per last 100 batches: 0.696844
5100it [16:08,  5.80it/s]Epoch: 3: Step: 5101/14003, loss=0.284966, lr=0.000011
5199it [16:26,  5.82it/s]Train batch 5200
Avg. loss per last 100 batches: 0.718292
5200it [16:26,  5.83it/s]Epoch: 3: Step: 5201/14003, loss=0.501947, lr=0.000010
5299it [16:43,  5.81it/s]Train batch 5300
Avg. loss per last 100 batches: 0.706411
5300it [16:43,  5.81it/s]Epoch: 3: Step: 5301/14003, loss=0.457794, lr=0.000010
5399it [17:00,  5.83it/s]Train batch 5400
Avg. loss per last 100 batches: 0.725187
5400it [17:00,  5.82it/s]Epoch: 3: Step: 5401/14003, loss=0.202150, lr=0.000010
5499it [17:18,  5.10it/s]Train batch 5500
Avg. loss per last 100 batches: 0.703663
5500it [17:18,  5.28it/s]Epoch: 3: Step: 5501/14003, loss=1.085713, lr=0.000010
5599it [17:35,  5.83it/s]Train batch 5600
Avg. loss per last 100 batches: 0.678424
5600it [17:35,  5.82it/s]Epoch: 3: Step: 5601/14003, loss=1.201011, lr=0.000010
5601it [17:35,  5.76it/s]Validation: Epoch: 3 Step: 5602/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.807288 sec., loss=1.658923 
Eval step: 199 , used_time=9.612594 sec., loss=1.504584 
Eval step: 299 , used_time=14.664057 sec., loss=0.723934 
Eval step: 399 , used_time=19.463145 sec., loss=1.187454 
Eval step: 499 , used_time=24.260867 sec., loss=1.139070 
Eval step: 599 , used_time=29.057745 sec., loss=1.433500 
Eval step: 699 , used_time=33.837140 sec., loss=1.205003 
Eval step: 799 , used_time=38.631108 sec., loss=1.051223 
Eval step: 899 , used_time=43.495742 sec., loss=1.273929 
Eval step: 999 , used_time=48.584646 sec., loss=0.852224 
Eval step: 1099 , used_time=53.369418 sec., loss=1.455838 
Eval step: 1199 , used_time=58.182753 sec., loss=0.894152 
Eval step: 1299 , used_time=62.945196 sec., loss=1.188398 
Eval step: 1399 , used_time=67.765562 sec., loss=0.624977 
Eval step: 1499 , used_time=72.537797 sec., loss=0.989507 
Eval step: 1599 , used_time=77.624776 sec., loss=0.906521 
NLL Validation: loss = 0.964194. correct prediction ratio  38974/52032 ~  0.749039
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:15,  5.77it/s]Train batch 5700
Avg. loss per last 100 batches: 0.705414
5700it [19:15,  5.78it/s]Epoch: 3: Step: 5701/14003, loss=0.653491, lr=0.000010
5799it [19:32,  5.80it/s]Train batch 5800
Avg. loss per last 100 batches: 0.684150
5800it [19:32,  5.80it/s]Epoch: 3: Step: 5801/14003, loss=0.889076, lr=0.000010
5899it [19:49,  5.82it/s]Train batch 5900
Avg. loss per last 100 batches: 0.690573
5900it [19:50,  5.81it/s]Epoch: 3: Step: 5901/14003, loss=1.117546, lr=0.000010
5999it [20:07,  5.83it/s]Train batch 6000
Avg. loss per last 100 batches: 0.742311
6000it [20:07,  5.83it/s]Epoch: 3: Step: 6001/14003, loss=0.806105, lr=0.000010
6099it [20:24,  5.81it/s]Train batch 6100
Avg. loss per last 100 batches: 0.707687
6100it [20:24,  5.81it/s]Epoch: 3: Step: 6101/14003, loss=0.765499, lr=0.000010
6199it [20:42,  5.80it/s]Train batch 6200
Avg. loss per last 100 batches: 0.702493
6200it [20:42,  5.81it/s]Epoch: 3: Step: 6201/14003, loss=0.709002, lr=0.000010
6299it [20:59,  5.31it/s]Train batch 6300
Avg. loss per last 100 batches: 0.696368
6300it [20:59,  5.34it/s]Epoch: 3: Step: 6301/14003, loss=0.739991, lr=0.000010
6399it [21:16,  5.78it/s]Train batch 6400
Avg. loss per last 100 batches: 0.701199
6400it [21:17,  5.78it/s]Epoch: 3: Step: 6401/14003, loss=0.473323, lr=0.000010
6499it [21:34,  5.80it/s]Train batch 6500
Avg. loss per last 100 batches: 0.729655
6500it [21:34,  5.79it/s]Epoch: 3: Step: 6501/14003, loss=1.321634, lr=0.000010
6599it [21:51,  5.80it/s]Train batch 6600
Avg. loss per last 100 batches: 0.743771
6600it [21:51,  5.82it/s]Epoch: 3: Step: 6601/14003, loss=0.953358, lr=0.000010
6699it [22:08,  5.80it/s]Train batch 6700
Avg. loss per last 100 batches: 0.715443
6700it [22:09,  5.80it/s]Epoch: 3: Step: 6701/14003, loss=0.560839, lr=0.000010
6799it [22:26,  5.77it/s]Train batch 6800
Avg. loss per last 100 batches: 0.719096
6800it [22:26,  5.78it/s]Epoch: 3: Step: 6801/14003, loss=0.714022, lr=0.000010
6899it [22:43,  5.81it/s]Train batch 6900
Avg. loss per last 100 batches: 0.717057
6900it [22:43,  5.82it/s]Epoch: 3: Step: 6901/14003, loss=0.647008, lr=0.000010
6999it [23:00,  5.77it/s]Train batch 7000
Avg. loss per last 100 batches: 0.686151
7000it [23:01,  5.77it/s]Epoch: 3: Step: 7001/14003, loss=0.848494, lr=0.000010
7099it [23:18,  5.77it/s]Train batch 7100
Avg. loss per last 100 batches: 0.709582
7100it [23:18,  5.78it/s]Epoch: 3: Step: 7101/14003, loss=0.409920, lr=0.000010
7199it [23:35,  5.78it/s]Train batch 7200
Avg. loss per last 100 batches: 0.739428
7200it [23:35,  5.77it/s]Epoch: 3: Step: 7201/14003, loss=0.741137, lr=0.000010
7299it [23:53,  5.80it/s]Train batch 7300
Avg. loss per last 100 batches: 0.702198
7300it [23:53,  5.81it/s]Epoch: 3: Step: 7301/14003, loss=0.735098, lr=0.000010
7399it [24:10,  5.75it/s]Train batch 7400
Avg. loss per last 100 batches: 0.728195
7400it [24:10,  5.76it/s]Epoch: 3: Step: 7401/14003, loss=0.733133, lr=0.000010
7499it [24:27,  5.76it/s]Train batch 7500
Avg. loss per last 100 batches: 0.736919
7500it [24:27,  5.78it/s]Epoch: 3: Step: 7501/14003, loss=0.822114, lr=0.000010
7599it [24:45,  5.80it/s]Train batch 7600
Avg. loss per last 100 batches: 0.696866
7600it [24:45,  5.81it/s]Epoch: 3: Step: 7601/14003, loss=1.409268, lr=0.000010
7699it [25:02,  5.81it/s]Train batch 7700
Avg. loss per last 100 batches: 0.655515
7700it [25:02,  5.80it/s]Epoch: 3: Step: 7701/14003, loss=1.009972, lr=0.000010
7799it [25:19,  5.80it/s]Train batch 7800
Avg. loss per last 100 batches: 0.689790
7800it [25:20,  5.79it/s]Epoch: 3: Step: 7801/14003, loss=0.661107, lr=0.000010
7899it [25:37,  5.79it/s]Train batch 7900
Avg. loss per last 100 batches: 0.759113
7900it [25:37,  5.81it/s]Epoch: 3: Step: 7901/14003, loss=0.188166, lr=0.000010
7999it [25:54,  5.82it/s]Train batch 8000
Avg. loss per last 100 batches: 0.713228
8000it [25:54,  5.81it/s]Epoch: 3: Step: 8001/14003, loss=0.430671, lr=0.000010
8099it [26:11,  5.81it/s]Train batch 8100
Avg. loss per last 100 batches: 0.730570
8100it [26:11,  5.81it/s]Epoch: 3: Step: 8101/14003, loss=0.546213, lr=0.000010
8199it [26:29,  5.79it/s]Train batch 8200
Avg. loss per last 100 batches: 0.696912
8200it [26:29,  5.77it/s]Epoch: 3: Step: 8201/14003, loss=0.409238, lr=0.000010
8299it [26:46,  5.23it/s]Train batch 8300
Avg. loss per last 100 batches: 0.747912
8300it [26:46,  5.22it/s]Epoch: 3: Step: 8301/14003, loss=0.433677, lr=0.000010
8399it [27:03,  5.80it/s]Train batch 8400
Avg. loss per last 100 batches: 0.706936
8400it [27:04,  5.80it/s]Epoch: 3: Step: 8401/14003, loss=0.545557, lr=0.000010
8402it [27:04,  5.74it/s]Validation: Epoch: 3 Step: 8403/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.832315 sec., loss=1.393531 
Eval step: 199 , used_time=9.728456 sec., loss=1.514199 
Eval step: 299 , used_time=14.830169 sec., loss=0.784167 
Eval step: 399 , used_time=19.592489 sec., loss=1.176796 
Eval step: 499 , used_time=24.465786 sec., loss=1.277309 
Eval step: 599 , used_time=29.262661 sec., loss=1.393759 
Eval step: 699 , used_time=34.083602 sec., loss=1.184167 
Eval step: 799 , used_time=38.869517 sec., loss=0.991716 
Eval step: 899 , used_time=43.877241 sec., loss=1.383009 
Eval step: 999 , used_time=48.685430 sec., loss=0.792925 
Eval step: 1099 , used_time=53.526988 sec., loss=1.357590 
Eval step: 1199 , used_time=58.352848 sec., loss=0.857268 
Eval step: 1299 , used_time=63.130993 sec., loss=1.032260 
Eval step: 1399 , used_time=67.954953 sec., loss=0.613652 
Eval step: 1499 , used_time=72.782881 sec., loss=1.120912 
Eval step: 1599 , used_time=77.873872 sec., loss=0.914528 
NLL Validation: loss = 0.941554. correct prediction ratio  39144/52032 ~  0.752306
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
8499it [28:46,  5.81it/s]Train batch 8500
Avg. loss per last 100 batches: 0.683641
8500it [28:46,  5.81it/s]Epoch: 3: Step: 8501/14003, loss=0.401672, lr=0.000010
8599it [29:03,  5.81it/s]Train batch 8600
Avg. loss per last 100 batches: 0.727887
8600it [29:04,  5.79it/s]Epoch: 3: Step: 8601/14003, loss=0.575375, lr=0.000010
8699it [29:21,  5.78it/s]Train batch 8700
Avg. loss per last 100 batches: 0.745749
8700it [29:21,  5.75it/s]Epoch: 3: Step: 8701/14003, loss=0.589828, lr=0.000010
8799it [29:38,  5.81it/s]Train batch 8800
Avg. loss per last 100 batches: 0.688898
8800it [29:38,  5.80it/s]Epoch: 3: Step: 8801/14003, loss=0.690305, lr=0.000010
8899it [29:55,  5.39it/s]Train batch 8900
Avg. loss per last 100 batches: 0.723379
8900it [29:56,  5.34it/s]Epoch: 3: Step: 8901/14003, loss=0.918110, lr=0.000010
8999it [30:13,  5.81it/s]Train batch 9000
Avg. loss per last 100 batches: 0.705621
9000it [30:13,  5.80it/s]Epoch: 3: Step: 9001/14003, loss=0.745285, lr=0.000010
9099it [30:30,  5.81it/s]Train batch 9100
Avg. loss per last 100 batches: 0.750026
9100it [30:30,  5.81it/s]Epoch: 3: Step: 9101/14003, loss=0.748405, lr=0.000010
9199it [30:48,  5.83it/s]Train batch 9200
Avg. loss per last 100 batches: 0.706467
9200it [30:48,  5.83it/s]Epoch: 3: Step: 9201/14003, loss=0.289486, lr=0.000010
9299it [31:05,  5.81it/s]Train batch 9300
Avg. loss per last 100 batches: 0.691453
9300it [31:05,  5.78it/s]Epoch: 3: Step: 9301/14003, loss=0.742333, lr=0.000010
9399it [31:22,  5.81it/s]Train batch 9400
Avg. loss per last 100 batches: 0.699860
9400it [31:22,  5.81it/s]Epoch: 3: Step: 9401/14003, loss=0.566077, lr=0.000010
9499it [31:40,  5.82it/s]Train batch 9500
Avg. loss per last 100 batches: 0.690129
9500it [31:40,  5.81it/s]Epoch: 3: Step: 9501/14003, loss=1.464631, lr=0.000010
9599it [31:57,  5.80it/s]Train batch 9600
Avg. loss per last 100 batches: 0.764280
9600it [31:57,  5.80it/s]Epoch: 3: Step: 9601/14003, loss=0.949310, lr=0.000010
9699it [32:14,  5.77it/s]Train batch 9700
Avg. loss per last 100 batches: 0.738883
9700it [32:15,  5.77it/s]Epoch: 3: Step: 9701/14003, loss=0.808026, lr=0.000010
9799it [32:32,  5.81it/s]Train batch 9800
Avg. loss per last 100 batches: 0.738772
9800it [32:32,  5.77it/s]Epoch: 3: Step: 9801/14003, loss=0.892539, lr=0.000010
9899it [32:49,  5.82it/s]Train batch 9900
Avg. loss per last 100 batches: 0.707563
9900it [32:49,  5.80it/s]Epoch: 3: Step: 9901/14003, loss=0.737611, lr=0.000010
9999it [33:07,  5.58it/s]Train batch 10000
Avg. loss per last 100 batches: 0.722416
10000it [33:07,  5.64it/s]Epoch: 3: Step: 10001/14003, loss=1.000120, lr=0.000010
10099it [33:24,  5.80it/s]Train batch 10100
Avg. loss per last 100 batches: 0.726944
10100it [33:24,  5.81it/s]Epoch: 3: Step: 10101/14003, loss=0.554775, lr=0.000009
10199it [33:41,  5.83it/s]Train batch 10200
Avg. loss per last 100 batches: 0.713919
10200it [33:42,  5.80it/s]Epoch: 3: Step: 10201/14003, loss=0.701356, lr=0.000009
10299it [33:59,  5.82it/s]Train batch 10300
Avg. loss per last 100 batches: 0.697223
10300it [33:59,  5.80it/s]Epoch: 3: Step: 10301/14003, loss=0.604419, lr=0.000009
10399it [34:16,  5.80it/s]Train batch 10400
Avg. loss per last 100 batches: 0.730353
10400it [34:16,  5.80it/s]Epoch: 3: Step: 10401/14003, loss=0.623373, lr=0.000009
10499it [34:33,  5.81it/s]Train batch 10500
Avg. loss per last 100 batches: 0.753676
10500it [34:34,  5.82it/s]Epoch: 3: Step: 10501/14003, loss=0.450607, lr=0.000009
10599it [34:51,  5.47it/s]Train batch 10600
Avg. loss per last 100 batches: 0.692908
10600it [34:51,  5.56it/s]Epoch: 3: Step: 10601/14003, loss=0.543795, lr=0.000009
10699it [35:08,  5.81it/s]Train batch 10700
Avg. loss per last 100 batches: 0.701292
10700it [35:08,  5.81it/s]Epoch: 3: Step: 10701/14003, loss=0.923045, lr=0.000009
10799it [35:26,  5.82it/s]Train batch 10800
Avg. loss per last 100 batches: 0.708978
10800it [35:26,  5.79it/s]Epoch: 3: Step: 10801/14003, loss=0.891841, lr=0.000009
10899it [35:43,  5.40it/s]Train batch 10900
Avg. loss per last 100 batches: 0.695007
10900it [35:43,  5.37it/s]Epoch: 3: Step: 10901/14003, loss=1.014019, lr=0.000009
10999it [36:00,  5.82it/s]Train batch 11000
Avg. loss per last 100 batches: 0.719276
11000it [36:00,  5.81it/s]Epoch: 3: Step: 11001/14003, loss=0.769576, lr=0.000009
11099it [36:18,  5.74it/s]Train batch 11100
Avg. loss per last 100 batches: 0.739502
11100it [36:18,  5.73it/s]Epoch: 3: Step: 11101/14003, loss=1.166277, lr=0.000009
11199it [36:35,  5.79it/s]Train batch 11200
Avg. loss per last 100 batches: 0.722268
11200it [36:35,  5.79it/s]Epoch: 3: Step: 11201/14003, loss=0.778946, lr=0.000009
11203it [36:36,  5.75it/s]Validation: Epoch: 3 Step: 11204/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.856929 sec., loss=1.449741 
Eval step: 199 , used_time=9.645904 sec., loss=1.312033 
Eval step: 299 , used_time=14.682376 sec., loss=0.780451 
Eval step: 399 , used_time=19.462826 sec., loss=1.252569 
Eval step: 499 , used_time=24.250883 sec., loss=1.277557 
Eval step: 599 , used_time=29.059493 sec., loss=1.495885 
Eval step: 699 , used_time=33.894537 sec., loss=1.209138 
Eval step: 799 , used_time=38.716669 sec., loss=0.873621 
Eval step: 899 , used_time=43.818437 sec., loss=1.426583 
Eval step: 999 , used_time=48.677918 sec., loss=0.778904 
Eval step: 1099 , used_time=53.469012 sec., loss=1.357873 
Eval step: 1199 , used_time=58.297507 sec., loss=0.807035 
Eval step: 1299 , used_time=63.093541 sec., loss=0.931193 
Eval step: 1399 , used_time=67.983264 sec., loss=0.513860 
Eval step: 1499 , used_time=72.788053 sec., loss=1.095080 
Eval step: 1599 , used_time=77.884313 sec., loss=0.965904 
NLL Validation: loss = 0.921319. correct prediction ratio  39324/52032 ~  0.755766
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [38:15,  5.80it/s]Train batch 11300
Avg. loss per last 100 batches: 0.696324
11300it [38:15,  5.78it/s]Epoch: 3: Step: 11301/14003, loss=0.729344, lr=0.000009
11399it [38:33,  5.78it/s]Train batch 11400
Avg. loss per last 100 batches: 0.731046
11400it [38:33,  5.79it/s]Epoch: 3: Step: 11401/14003, loss=0.571427, lr=0.000009
11499it [38:50,  5.76it/s]Train batch 11500
Avg. loss per last 100 batches: 0.691876
11500it [38:50,  5.76it/s]Epoch: 3: Step: 11501/14003, loss=0.962678, lr=0.000009
11599it [39:07,  5.79it/s]Train batch 11600
Avg. loss per last 100 batches: 0.710668
11600it [39:07,  5.79it/s]Epoch: 3: Step: 11601/14003, loss=0.178204, lr=0.000009
11699it [39:25,  5.24it/s]Train batch 11700
Avg. loss per last 100 batches: 0.719179
11700it [39:25,  5.22it/s]Epoch: 3: Step: 11701/14003, loss=0.311700, lr=0.000009
11799it [39:42,  5.77it/s]Train batch 11800
Avg. loss per last 100 batches: 0.672919
11800it [39:42,  5.78it/s]Epoch: 3: Step: 11801/14003, loss=0.315550, lr=0.000009
11899it [40:00,  5.80it/s]Train batch 11900
Avg. loss per last 100 batches: 0.682548
11900it [40:00,  5.80it/s]Epoch: 3: Step: 11901/14003, loss=0.571698, lr=0.000009
11999it [40:17,  5.79it/s]Train batch 12000
Avg. loss per last 100 batches: 0.692627
12000it [40:17,  5.79it/s]Epoch: 3: Step: 12001/14003, loss=0.707126, lr=0.000009
12099it [40:34,  5.81it/s]Train batch 12100
Avg. loss per last 100 batches: 0.713769
12100it [40:34,  5.80it/s]Epoch: 3: Step: 12101/14003, loss=0.728462, lr=0.000009
12199it [40:52,  5.79it/s]Train batch 12200
Avg. loss per last 100 batches: 0.701943
12200it [40:52,  5.80it/s]Epoch: 3: Step: 12201/14003, loss=0.856287, lr=0.000009
12299it [41:09,  5.76it/s]Train batch 12300
Avg. loss per last 100 batches: 0.725499
12300it [41:09,  5.77it/s]Epoch: 3: Step: 12301/14003, loss=0.351228, lr=0.000009
12399it [41:26,  5.82it/s]Train batch 12400
Avg. loss per last 100 batches: 0.747557
12400it [41:27,  5.80it/s]Epoch: 3: Step: 12401/14003, loss=0.881471, lr=0.000009
12499it [41:44,  5.79it/s]Train batch 12500
Avg. loss per last 100 batches: 0.708165
12500it [41:44,  5.79it/s]Epoch: 3: Step: 12501/14003, loss=0.684134, lr=0.000009
12599it [42:01,  5.78it/s]Train batch 12600
Avg. loss per last 100 batches: 0.716967
12600it [42:01,  5.79it/s]Epoch: 3: Step: 12601/14003, loss=0.986785, lr=0.000009
12699it [42:19,  5.80it/s]Train batch 12700
Avg. loss per last 100 batches: 0.712208
12700it [42:19,  5.81it/s]Epoch: 3: Step: 12701/14003, loss=0.404747, lr=0.000009
12799it [42:36,  5.75it/s]Train batch 12800
Avg. loss per last 100 batches: 0.675620
12800it [42:36,  5.77it/s]Epoch: 3: Step: 12801/14003, loss=0.781243, lr=0.000009
12899it [42:53,  5.82it/s]Train batch 12900
Avg. loss per last 100 batches: 0.760292
12900it [42:53,  5.82it/s]Epoch: 3: Step: 12901/14003, loss=0.613800, lr=0.000009
12999it [43:11,  5.80it/s]Train batch 13000
Avg. loss per last 100 batches: 0.659476
13000it [43:11,  5.78it/s]Epoch: 3: Step: 13001/14003, loss=0.594743, lr=0.000009
13099it [43:28,  5.81it/s]Train batch 13100
Avg. loss per last 100 batches: 0.707455
13100it [43:28,  5.82it/s]Epoch: 3: Step: 13101/14003, loss=0.619354, lr=0.000009
13199it [43:45,  5.81it/s]Train batch 13200
Avg. loss per last 100 batches: 0.708400
13200it [43:46,  5.81it/s]Epoch: 3: Step: 13201/14003, loss=0.633799, lr=0.000009
13299it [44:03,  5.77it/s]Train batch 13300
Avg. loss per last 100 batches: 0.701122
13300it [44:03,  5.78it/s]Epoch: 3: Step: 13301/14003, loss=0.648268, lr=0.000009
13399it [44:20,  5.80it/s]Train batch 13400
Avg. loss per last 100 batches: 0.744382
13400it [44:20,  5.82it/s]Epoch: 3: Step: 13401/14003, loss=0.293295, lr=0.000009
13499it [44:37,  5.81it/s]Train batch 13500
Avg. loss per last 100 batches: 0.714658
13500it [44:38,  5.83it/s]Epoch: 3: Step: 13501/14003, loss=0.861483, lr=0.000009
13599it [44:55,  5.81it/s]Train batch 13600
Avg. loss per last 100 batches: 0.707266
13600it [44:55,  5.80it/s]Epoch: 3: Step: 13601/14003, loss=0.879682, lr=0.000009
13699it [45:12,  5.38it/s]Train batch 13700
Avg. loss per last 100 batches: 0.673732
13700it [45:12,  5.38it/s]Epoch: 3: Step: 13701/14003, loss=1.012300, lr=0.000009
13799it [45:29,  5.81it/s]Train batch 13800
Avg. loss per last 100 batches: 0.720430
13800it [45:30,  5.83it/s]Epoch: 3: Step: 13801/14003, loss=0.690353, lr=0.000009
13899it [45:47,  5.78it/s]Train batch 13900
Avg. loss per last 100 batches: 0.699993
13900it [45:47,  5.79it/s]Epoch: 3: Step: 13901/14003, loss=0.621455, lr=0.000009
13999it [46:04,  5.81it/s]Train batch 14000
Avg. loss per last 100 batches: 0.704606
14000it [46:04,  5.78it/s]Epoch: 3: Step: 14001/14003, loss=0.568841, lr=0.000009
14003it [46:05,  5.06it/s]
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.810661 sec., loss=1.579929 
Eval step: 199 , used_time=9.838624 sec., loss=1.466827 
Eval step: 299 , used_time=14.716763 sec., loss=0.749925 
Eval step: 399 , used_time=19.472907 sec., loss=1.152374 
Eval step: 499 , used_time=24.276140 sec., loss=1.285578 
Eval step: 599 , used_time=29.042315 sec., loss=1.573315 
Eval step: 699 , used_time=33.855434 sec., loss=1.210230 
Eval step: 799 , used_time=38.623815 sec., loss=0.893545 
Eval step: 899 , used_time=43.704892 sec., loss=1.368979 
Eval step: 999 , used_time=48.502820 sec., loss=0.860324 
Eval step: 1099 , used_time=53.289132 sec., loss=1.379254 
Eval step: 1199 , used_time=58.082325 sec., loss=0.816239 
Eval step: 1299 , used_time=62.867921 sec., loss=1.012914 
Eval step: 1399 , used_time=67.730486 sec., loss=0.580585 
Eval step: 1499 , used_time=72.764088 sec., loss=1.090490 
Eval step: 1599 , used_time=77.623072 sec., loss=0.882315 
NLL Validation: loss = 0.922376. correct prediction ratio  39490/52032 ~  0.758956
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=0.705887
epoch total correct predictions=357136
***** Epoch 4 *****
0it [00:00, ?it/s]Epoch: 4: Step: 1/14003, loss=0.553554, lr=0.000009
99it [00:17,  5.81it/s]Train batch 100
Avg. loss per last 100 batches: 0.516690
100it [00:17,  5.80it/s]Epoch: 4: Step: 101/14003, loss=0.362010, lr=0.000009
199it [00:35,  5.80it/s]Train batch 200
Avg. loss per last 100 batches: 0.478810
200it [00:35,  5.80it/s]Epoch: 4: Step: 201/14003, loss=0.276334, lr=0.000009
299it [00:52,  5.28it/s]Train batch 300
Avg. loss per last 100 batches: 0.521480
300it [00:52,  5.19it/s]Epoch: 4: Step: 301/14003, loss=0.432094, lr=0.000009
399it [01:09,  5.82it/s]Train batch 400
Avg. loss per last 100 batches: 0.536778
400it [01:10,  5.80it/s]Epoch: 4: Step: 401/14003, loss=0.314773, lr=0.000009
499it [01:27,  5.77it/s]Train batch 500
Avg. loss per last 100 batches: 0.537766
500it [01:27,  5.79it/s]Epoch: 4: Step: 501/14003, loss=0.706344, lr=0.000009
599it [01:44,  5.79it/s]Train batch 600
Avg. loss per last 100 batches: 0.525441
600it [01:44,  5.78it/s]Epoch: 4: Step: 601/14003, loss=0.185265, lr=0.000009
699it [02:02,  5.76it/s]Train batch 700
Avg. loss per last 100 batches: 0.537499
700it [02:02,  5.77it/s]Epoch: 4: Step: 701/14003, loss=0.896726, lr=0.000009
799it [02:19,  5.79it/s]Train batch 800
Avg. loss per last 100 batches: 0.544247
800it [02:19,  5.80it/s]Epoch: 4: Step: 801/14003, loss=0.496618, lr=0.000009
899it [02:36,  5.79it/s]Train batch 900
Avg. loss per last 100 batches: 0.533041
900it [02:36,  5.80it/s]Epoch: 4: Step: 901/14003, loss=0.520420, lr=0.000008
999it [02:54,  5.78it/s]Train batch 1000
Avg. loss per last 100 batches: 0.558644
1000it [02:54,  5.78it/s]Epoch: 4: Step: 1001/14003, loss=0.495162, lr=0.000008
1099it [03:11,  5.69it/s]Train batch 1100
Avg. loss per last 100 batches: 0.550445
1100it [03:11,  5.73it/s]Epoch: 4: Step: 1101/14003, loss=0.640005, lr=0.000008
1199it [03:28,  5.80it/s]Train batch 1200
Avg. loss per last 100 batches: 0.530709
1200it [03:28,  5.79it/s]Epoch: 4: Step: 1201/14003, loss=0.249364, lr=0.000008
1299it [03:46,  5.78it/s]Train batch 1300
Avg. loss per last 100 batches: 0.508127
1300it [03:46,  5.76it/s]Epoch: 4: Step: 1301/14003, loss=0.960762, lr=0.000008
1399it [04:03,  5.64it/s]Train batch 1400
Avg. loss per last 100 batches: 0.549190
1400it [04:03,  5.69it/s]Epoch: 4: Step: 1401/14003, loss=0.452307, lr=0.000008
1499it [04:20,  5.82it/s]Train batch 1500
Avg. loss per last 100 batches: 0.508129
1500it [04:21,  5.81it/s]Epoch: 4: Step: 1501/14003, loss=0.540858, lr=0.000008
1599it [04:38,  5.80it/s]Train batch 1600
Avg. loss per last 100 batches: 0.545328
1600it [04:38,  5.76it/s]Epoch: 4: Step: 1601/14003, loss=0.602289, lr=0.000008
1699it [04:55,  5.82it/s]Train batch 1700
Avg. loss per last 100 batches: 0.527090
1700it [04:55,  5.81it/s]Epoch: 4: Step: 1701/14003, loss=1.176666, lr=0.000008
1799it [05:13,  5.79it/s]Train batch 1800
Avg. loss per last 100 batches: 0.535019
1800it [05:13,  5.78it/s]Epoch: 4: Step: 1801/14003, loss=0.560173, lr=0.000008
1899it [05:30,  5.77it/s]Train batch 1900
Avg. loss per last 100 batches: 0.564132
1900it [05:30,  5.76it/s]Epoch: 4: Step: 1901/14003, loss=0.703288, lr=0.000008
1999it [05:47,  5.77it/s]Train batch 2000
Avg. loss per last 100 batches: 0.542003
2000it [05:48,  5.78it/s]Epoch: 4: Step: 2001/14003, loss=0.718985, lr=0.000008
2099it [06:05,  5.78it/s]Train batch 2100
Avg. loss per last 100 batches: 0.559995
2100it [06:05,  5.78it/s]Epoch: 4: Step: 2101/14003, loss=0.557714, lr=0.000008
2199it [06:22,  5.79it/s]Train batch 2200
Avg. loss per last 100 batches: 0.523737
2200it [06:22,  5.79it/s]Epoch: 4: Step: 2201/14003, loss=0.344016, lr=0.000008
2299it [06:39,  5.45it/s]Train batch 2300
Avg. loss per last 100 batches: 0.575448
2300it [06:40,  5.33it/s]Epoch: 4: Step: 2301/14003, loss=0.244942, lr=0.000008
2399it [06:57,  5.80it/s]Train batch 2400
Avg. loss per last 100 batches: 0.553647
2400it [06:57,  5.81it/s]Epoch: 4: Step: 2401/14003, loss=0.373744, lr=0.000008
2499it [07:14,  5.79it/s]Train batch 2500
Avg. loss per last 100 batches: 0.546772
2500it [07:14,  5.80it/s]Epoch: 4: Step: 2501/14003, loss=0.717203, lr=0.000008
2599it [07:31,  5.78it/s]Train batch 2600
Avg. loss per last 100 batches: 0.533397
2600it [07:32,  5.78it/s]Epoch: 4: Step: 2601/14003, loss=0.621252, lr=0.000008
2699it [07:49,  5.80it/s]Train batch 2700
Avg. loss per last 100 batches: 0.503998
2700it [07:49,  5.81it/s]Epoch: 4: Step: 2701/14003, loss=0.249050, lr=0.000008
2799it [08:06,  5.83it/s]Train batch 2800
Avg. loss per last 100 batches: 0.522660
2800it [08:06,  5.81it/s]Epoch: 4: Step: 2801/14003, loss=0.604552, lr=0.000008
Validation: Epoch: 4 Step: 2801/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.823306 sec., loss=1.801223 
Eval step: 199 , used_time=9.855935 sec., loss=1.617464 
Eval step: 299 , used_time=14.672153 sec., loss=0.800979 
Eval step: 399 , used_time=19.447406 sec., loss=1.207584 
Eval step: 499 , used_time=24.327405 sec., loss=1.325495 
Eval step: 599 , used_time=29.132477 sec., loss=1.642538 
Eval step: 699 , used_time=33.927794 sec., loss=1.369892 
Eval step: 799 , used_time=38.750739 sec., loss=1.201599 
Eval step: 899 , used_time=43.794389 sec., loss=1.599225 
Eval step: 999 , used_time=48.619093 sec., loss=0.995878 
Eval step: 1099 , used_time=53.407986 sec., loss=1.433407 
Eval step: 1199 , used_time=58.253299 sec., loss=0.846096 
Eval step: 1299 , used_time=63.056123 sec., loss=1.029052 
Eval step: 1399 , used_time=67.893251 sec., loss=0.566401 
Eval step: 1499 , used_time=72.895297 sec., loss=1.276592 
Eval step: 1599 , used_time=77.719950 sec., loss=0.986952 
NLL Validation: loss = 0.988624. correct prediction ratio  39412/52032 ~  0.757457
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
2899it [09:46,  5.80it/s]Train batch 2900
Avg. loss per last 100 batches: 0.560184
2900it [09:46,  5.79it/s]Epoch: 4: Step: 2901/14003, loss=0.571809, lr=0.000008
2999it [10:03,  5.79it/s]Train batch 3000
Avg. loss per last 100 batches: 0.590018
3000it [10:04,  5.78it/s]Epoch: 4: Step: 3001/14003, loss=0.157998, lr=0.000008
3099it [10:21,  5.39it/s]Train batch 3100
Avg. loss per last 100 batches: 0.520799
3100it [10:21,  5.11it/s]Epoch: 4: Step: 3101/14003, loss=0.261629, lr=0.000008
3199it [10:38,  5.79it/s]Train batch 3200
Avg. loss per last 100 batches: 0.554380
3200it [10:38,  5.78it/s]Epoch: 4: Step: 3201/14003, loss=0.660319, lr=0.000008
3299it [10:56,  5.82it/s]Train batch 3300
Avg. loss per last 100 batches: 0.528373
3300it [10:56,  5.81it/s]Epoch: 4: Step: 3301/14003, loss=0.610633, lr=0.000008
3399it [11:13,  5.81it/s]Train batch 3400
Avg. loss per last 100 batches: 0.570093
3400it [11:13,  5.80it/s]Epoch: 4: Step: 3401/14003, loss=0.600544, lr=0.000008
3499it [11:30,  5.80it/s]Train batch 3500
Avg. loss per last 100 batches: 0.540204
3500it [11:30,  5.81it/s]Epoch: 4: Step: 3501/14003, loss=0.642350, lr=0.000008
3599it [11:48,  5.69it/s]Train batch 3600
Avg. loss per last 100 batches: 0.540887
3600it [11:48,  5.72it/s]Epoch: 4: Step: 3601/14003, loss=0.461159, lr=0.000008
3699it [12:05,  5.83it/s]Train batch 3700
Avg. loss per last 100 batches: 0.550108
3700it [12:05,  5.81it/s]Epoch: 4: Step: 3701/14003, loss=0.682829, lr=0.000008
3799it [12:22,  5.81it/s]Train batch 3800
Avg. loss per last 100 batches: 0.548363
3800it [12:23,  5.81it/s]Epoch: 4: Step: 3801/14003, loss=0.226900, lr=0.000008
3899it [12:40,  5.82it/s]Train batch 3900
Avg. loss per last 100 batches: 0.559444
3900it [12:40,  5.81it/s]Epoch: 4: Step: 3901/14003, loss=0.825492, lr=0.000008
3999it [12:57,  5.83it/s]Train batch 4000
Avg. loss per last 100 batches: 0.561381
4000it [12:57,  5.83it/s]Epoch: 4: Step: 4001/14003, loss=0.380808, lr=0.000008
4099it [13:14,  5.82it/s]Train batch 4100
Avg. loss per last 100 batches: 0.536717
4100it [13:15,  5.78it/s]Epoch: 4: Step: 4101/14003, loss=0.513861, lr=0.000008
4199it [13:32,  5.57it/s]Train batch 4200
Avg. loss per last 100 batches: 0.549355
4200it [13:32,  5.62it/s]Epoch: 4: Step: 4201/14003, loss=0.505780, lr=0.000008
4299it [13:49,  5.80it/s]Train batch 4300
Avg. loss per last 100 batches: 0.539746
4300it [13:49,  5.80it/s]Epoch: 4: Step: 4301/14003, loss=0.251133, lr=0.000008
4399it [14:07,  5.81it/s]Train batch 4400
Avg. loss per last 100 batches: 0.546457
4400it [14:07,  5.81it/s]Epoch: 4: Step: 4401/14003, loss=0.991387, lr=0.000008
4499it [14:24,  5.83it/s]Train batch 4500
Avg. loss per last 100 batches: 0.553609
4500it [14:24,  5.78it/s]Epoch: 4: Step: 4501/14003, loss=0.691127, lr=0.000008
4599it [14:41,  5.73it/s]Train batch 4600
Avg. loss per last 100 batches: 0.555360
4600it [14:42,  5.77it/s]Epoch: 4: Step: 4601/14003, loss=0.290879, lr=0.000008
4699it [14:59,  5.84it/s]Train batch 4700
Avg. loss per last 100 batches: 0.549062
4700it [14:59,  5.85it/s]Epoch: 4: Step: 4701/14003, loss=0.520654, lr=0.000008
4799it [15:16,  5.80it/s]Train batch 4800
Avg. loss per last 100 batches: 0.562652
4800it [15:16,  5.81it/s]Epoch: 4: Step: 4801/14003, loss=0.621885, lr=0.000008
4899it [15:33,  5.81it/s]Train batch 4900
Avg. loss per last 100 batches: 0.573239
4900it [15:34,  5.82it/s]Epoch: 4: Step: 4901/14003, loss=0.597475, lr=0.000008
4999it [15:51,  5.80it/s]Train batch 5000
Avg. loss per last 100 batches: 0.543666
5000it [15:51,  5.79it/s]Epoch: 4: Step: 5001/14003, loss=0.553962, lr=0.000008
5099it [16:08,  5.52it/s]Train batch 5100
Avg. loss per last 100 batches: 0.519058
5100it [16:08,  5.45it/s]Epoch: 4: Step: 5101/14003, loss=0.754305, lr=0.000008
5199it [16:25,  5.81it/s]Train batch 5200
Avg. loss per last 100 batches: 0.530983
5200it [16:26,  5.82it/s]Epoch: 4: Step: 5201/14003, loss=0.505709, lr=0.000008
5299it [16:43,  5.80it/s]Train batch 5300
Avg. loss per last 100 batches: 0.553667
5300it [16:43,  5.80it/s]Epoch: 4: Step: 5301/14003, loss=0.242904, lr=0.000008
5399it [17:00,  5.82it/s]Train batch 5400
Avg. loss per last 100 batches: 0.562412
5400it [17:00,  5.81it/s]Epoch: 4: Step: 5401/14003, loss=0.432673, lr=0.000008
5499it [17:18,  5.81it/s]Train batch 5500
Avg. loss per last 100 batches: 0.547595
5500it [17:18,  5.81it/s]Epoch: 4: Step: 5501/14003, loss=0.622572, lr=0.000008
5599it [17:35,  5.80it/s]Train batch 5600
Avg. loss per last 100 batches: 0.535799
5600it [17:35,  5.80it/s]Epoch: 4: Step: 5601/14003, loss=0.499598, lr=0.000008
5601it [17:35,  5.76it/s]Validation: Epoch: 4 Step: 5602/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.802965 sec., loss=1.711368 
Eval step: 199 , used_time=9.920147 sec., loss=1.519472 
Eval step: 299 , used_time=14.718798 sec., loss=0.680973 
Eval step: 399 , used_time=19.525776 sec., loss=1.094097 
Eval step: 499 , used_time=24.318319 sec., loss=1.235277 
Eval step: 599 , used_time=29.128618 sec., loss=1.606655 
Eval step: 699 , used_time=33.911794 sec., loss=1.259026 
Eval step: 799 , used_time=38.806930 sec., loss=1.166210 
Eval step: 899 , used_time=43.763050 sec., loss=1.618939 
Eval step: 999 , used_time=48.579516 sec., loss=0.883920 
Eval step: 1099 , used_time=53.377701 sec., loss=1.650750 
Eval step: 1199 , used_time=58.210772 sec., loss=0.881637 
Eval step: 1299 , used_time=63.004293 sec., loss=1.078083 
Eval step: 1399 , used_time=67.873763 sec., loss=0.435199 
Eval step: 1499 , used_time=72.899613 sec., loss=1.191981 
Eval step: 1599 , used_time=77.724355 sec., loss=0.998005 
NLL Validation: loss = 0.964815. correct prediction ratio  39505/52032 ~  0.759244
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:15,  5.83it/s]Train batch 5700
Avg. loss per last 100 batches: 0.541917
5700it [19:15,  5.81it/s]Epoch: 4: Step: 5701/14003, loss=0.499916, lr=0.000008
5799it [19:32,  5.80it/s]Train batch 5800
Avg. loss per last 100 batches: 0.554702
5800it [19:32,  5.79it/s]Epoch: 4: Step: 5801/14003, loss=1.196567, lr=0.000007
5899it [19:50,  5.38it/s]Train batch 5900
Avg. loss per last 100 batches: 0.536781
5900it [19:50,  5.25it/s]Epoch: 4: Step: 5901/14003, loss=0.957719, lr=0.000007
5999it [20:07,  5.82it/s]Train batch 6000
Avg. loss per last 100 batches: 0.524477
6000it [20:07,  5.83it/s]Epoch: 4: Step: 6001/14003, loss=0.471642, lr=0.000007
6099it [20:24,  5.79it/s]Train batch 6100
Avg. loss per last 100 batches: 0.550122
6100it [20:25,  5.79it/s]Epoch: 4: Step: 6101/14003, loss=0.677063, lr=0.000007
6199it [20:42,  5.81it/s]Train batch 6200
Avg. loss per last 100 batches: 0.564239
6200it [20:42,  5.80it/s]Epoch: 4: Step: 6201/14003, loss=0.577776, lr=0.000007
6299it [20:59,  5.81it/s]Train batch 6300
Avg. loss per last 100 batches: 0.541243
6300it [20:59,  5.82it/s]Epoch: 4: Step: 6301/14003, loss=0.714810, lr=0.000007
6399it [21:16,  5.81it/s]Train batch 6400
Avg. loss per last 100 batches: 0.567616
6400it [21:17,  5.81it/s]Epoch: 4: Step: 6401/14003, loss=0.231156, lr=0.000007
6499it [21:34,  5.80it/s]Train batch 6500
Avg. loss per last 100 batches: 0.572617
6500it [21:34,  5.81it/s]Epoch: 4: Step: 6501/14003, loss=0.542817, lr=0.000007
6599it [21:51,  5.83it/s]Train batch 6600
Avg. loss per last 100 batches: 0.554575
6600it [21:51,  5.81it/s]Epoch: 4: Step: 6601/14003, loss=0.453001, lr=0.000007
6699it [22:08,  5.81it/s]Train batch 6700
Avg. loss per last 100 batches: 0.534323
6700it [22:09,  5.81it/s]Epoch: 4: Step: 6701/14003, loss=0.604132, lr=0.000007
6799it [22:26,  5.81it/s]Train batch 6800
Avg. loss per last 100 batches: 0.565810
6800it [22:26,  5.82it/s]Epoch: 4: Step: 6801/14003, loss=0.658551, lr=0.000007
6899it [22:43,  5.81it/s]Train batch 6900
Avg. loss per last 100 batches: 0.561443
6900it [22:43,  5.82it/s]Epoch: 4: Step: 6901/14003, loss=0.371580, lr=0.000007
6999it [23:01,  5.46it/s]Train batch 7000
Avg. loss per last 100 batches: 0.556704
7000it [23:01,  5.56it/s]Epoch: 4: Step: 7001/14003, loss=0.943499, lr=0.000007
7099it [23:18,  5.81it/s]Train batch 7100
Avg. loss per last 100 batches: 0.559265
7100it [23:18,  5.83it/s]Epoch: 4: Step: 7101/14003, loss=0.359063, lr=0.000007
7199it [23:35,  5.77it/s]Train batch 7200
Avg. loss per last 100 batches: 0.535556
7200it [23:35,  5.79it/s]Epoch: 4: Step: 7201/14003, loss=0.340831, lr=0.000007
7299it [23:53,  5.79it/s]Train batch 7300
Avg. loss per last 100 batches: 0.562087
7300it [23:53,  5.77it/s]Epoch: 4: Step: 7301/14003, loss=0.992931, lr=0.000007
7399it [24:10,  5.76it/s]Train batch 7400
Avg. loss per last 100 batches: 0.566266
7400it [24:10,  5.78it/s]Epoch: 4: Step: 7401/14003, loss=0.494454, lr=0.000007
7499it [24:27,  5.85it/s]Train batch 7500
Avg. loss per last 100 batches: 0.569674
7500it [24:27,  5.85it/s]Epoch: 4: Step: 7501/14003, loss=0.652187, lr=0.000007
7599it [24:45,  5.79it/s]Train batch 7600
Avg. loss per last 100 batches: 0.544507
7600it [24:45,  5.79it/s]Epoch: 4: Step: 7601/14003, loss=0.310450, lr=0.000007
7699it [25:02,  5.81it/s]Train batch 7700
Avg. loss per last 100 batches: 0.586630
7700it [25:02,  5.78it/s]Epoch: 4: Step: 7701/14003, loss=0.253848, lr=0.000007
7799it [25:19,  5.79it/s]Train batch 7800
Avg. loss per last 100 batches: 0.521633
7800it [25:19,  5.80it/s]Epoch: 4: Step: 7801/14003, loss=0.598694, lr=0.000007
7899it [25:37,  5.82it/s]Train batch 7900
Avg. loss per last 100 batches: 0.512262
7900it [25:37,  5.71it/s]Epoch: 4: Step: 7901/14003, loss=1.040346, lr=0.000007
7999it [25:54,  5.82it/s]Train batch 8000
Avg. loss per last 100 batches: 0.546919
8000it [25:54,  5.77it/s]Epoch: 4: Step: 8001/14003, loss=0.903834, lr=0.000007
8099it [26:12,  5.72it/s]Train batch 8100
Avg. loss per last 100 batches: 0.545191
8100it [26:12,  5.74it/s]Epoch: 4: Step: 8101/14003, loss=0.487888, lr=0.000007
8199it [26:30,  5.80it/s]Train batch 8200
Avg. loss per last 100 batches: 0.571256
8200it [26:30,  5.79it/s]Epoch: 4: Step: 8201/14003, loss=0.375000, lr=0.000007
8299it [26:47,  5.74it/s]Train batch 8300
Avg. loss per last 100 batches: 0.571084
8300it [26:47,  5.76it/s]Epoch: 4: Step: 8301/14003, loss=0.660740, lr=0.000007
8399it [27:04,  5.79it/s]Train batch 8400
Avg. loss per last 100 batches: 0.529638
8400it [27:05,  5.81it/s]Epoch: 4: Step: 8401/14003, loss=0.600899, lr=0.000007
8402it [27:05,  5.76it/s]Validation: Epoch: 4 Step: 8403/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=5.007642 sec., loss=1.652776 
Eval step: 199 , used_time=9.853081 sec., loss=1.447629 
Eval step: 299 , used_time=14.699611 sec., loss=0.661854 
Eval step: 399 , used_time=19.462348 sec., loss=1.231448 
Eval step: 499 , used_time=24.326965 sec., loss=1.096401 
Eval step: 599 , used_time=29.119077 sec., loss=1.700580 
Eval step: 699 , used_time=33.944709 sec., loss=1.280169 
Eval step: 799 , used_time=38.985348 sec., loss=1.206384 
Eval step: 899 , used_time=43.823278 sec., loss=1.623673 
Eval step: 999 , used_time=48.624896 sec., loss=0.951237 
Eval step: 1099 , used_time=53.437079 sec., loss=1.409765 
Eval step: 1199 , used_time=58.220335 sec., loss=0.813506 
Eval step: 1299 , used_time=62.994316 sec., loss=1.141401 
Eval step: 1399 , used_time=67.941058 sec., loss=0.458857 
Eval step: 1499 , used_time=72.803350 sec., loss=1.335597 
Eval step: 1599 , used_time=77.656499 sec., loss=0.997830 
NLL Validation: loss = 0.952645. correct prediction ratio  39603/52032 ~  0.761128
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
8499it [28:47,  5.61it/s]Train batch 8500
Avg. loss per last 100 batches: 0.535025
8500it [28:47,  5.46it/s]Epoch: 4: Step: 8501/14003, loss=0.768799, lr=0.000007
8599it [29:04,  5.83it/s]Train batch 8600
Avg. loss per last 100 batches: 0.516164
8600it [29:04,  5.82it/s]Epoch: 4: Step: 8601/14003, loss=0.536204, lr=0.000007
8699it [29:21,  5.64it/s]Train batch 8700
Avg. loss per last 100 batches: 0.588985
8700it [29:22,  5.68it/s]Epoch: 4: Step: 8701/14003, loss=0.295151, lr=0.000007
8799it [29:39,  5.80it/s]Train batch 8800
Avg. loss per last 100 batches: 0.530651
8800it [29:39,  5.79it/s]Epoch: 4: Step: 8801/14003, loss=0.224638, lr=0.000007
8899it [29:56,  5.78it/s]Train batch 8900
Avg. loss per last 100 batches: 0.518372
8900it [29:56,  5.80it/s]Epoch: 4: Step: 8901/14003, loss=0.589180, lr=0.000007
8999it [30:14,  5.82it/s]Train batch 9000
Avg. loss per last 100 batches: 0.538748
9000it [30:14,  5.81it/s]Epoch: 4: Step: 9001/14003, loss=1.260419, lr=0.000007
9099it [30:31,  5.79it/s]Train batch 9100
Avg. loss per last 100 batches: 0.544821
9100it [30:31,  5.79it/s]Epoch: 4: Step: 9101/14003, loss=0.488255, lr=0.000007
9199it [30:48,  5.76it/s]Train batch 9200
Avg. loss per last 100 batches: 0.560171
9200it [30:48,  5.76it/s]Epoch: 4: Step: 9201/14003, loss=0.694314, lr=0.000007
9299it [31:06,  5.76it/s]Train batch 9300
Avg. loss per last 100 batches: 0.570682
9300it [31:06,  5.78it/s]Epoch: 4: Step: 9301/14003, loss=0.319766, lr=0.000007
9399it [31:23,  5.83it/s]Train batch 9400
Avg. loss per last 100 batches: 0.572591
9400it [31:23,  5.81it/s]Epoch: 4: Step: 9401/14003, loss=0.594442, lr=0.000007
9499it [31:41,  5.81it/s]Train batch 9500
Avg. loss per last 100 batches: 0.557158
9500it [31:41,  5.76it/s]Epoch: 4: Step: 9501/14003, loss=1.065418, lr=0.000007
9599it [31:58,  5.61it/s]Train batch 9600
Avg. loss per last 100 batches: 0.578976
9600it [31:58,  5.64it/s]Epoch: 4: Step: 9601/14003, loss=0.615129, lr=0.000007
9699it [32:15,  5.82it/s]Train batch 9700
Avg. loss per last 100 batches: 0.551793
9700it [32:15,  5.80it/s]Epoch: 4: Step: 9701/14003, loss=0.524296, lr=0.000007
9799it [32:33,  5.81it/s]Train batch 9800
Avg. loss per last 100 batches: 0.560469
9800it [32:33,  5.80it/s]Epoch: 4: Step: 9801/14003, loss=0.450284, lr=0.000007
9899it [32:50,  5.79it/s]Train batch 9900
Avg. loss per last 100 batches: 0.573115
9900it [32:50,  5.80it/s]Epoch: 4: Step: 9901/14003, loss=0.428967, lr=0.000007
9999it [33:07,  5.81it/s]Train batch 10000
Avg. loss per last 100 batches: 0.525633
10000it [33:08,  5.81it/s]Epoch: 4: Step: 10001/14003, loss=0.916095, lr=0.000007
10099it [33:25,  5.82it/s]Train batch 10100
Avg. loss per last 100 batches: 0.586761
10100it [33:25,  5.82it/s]Epoch: 4: Step: 10101/14003, loss=0.510404, lr=0.000007
10199it [33:42,  5.81it/s]Train batch 10200
Avg. loss per last 100 batches: 0.546590
10200it [33:42,  5.78it/s]Epoch: 4: Step: 10201/14003, loss=0.241598, lr=0.000007
10299it [33:59,  5.80it/s]Train batch 10300
Avg. loss per last 100 batches: 0.561364
10300it [34:00,  5.81it/s]Epoch: 4: Step: 10301/14003, loss=0.218143, lr=0.000007
10399it [34:17,  5.83it/s]Train batch 10400
Avg. loss per last 100 batches: 0.522807
10400it [34:17,  5.82it/s]Epoch: 4: Step: 10401/14003, loss=0.630232, lr=0.000007
10499it [34:34,  5.81it/s]Train batch 10500
Avg. loss per last 100 batches: 0.514608
10500it [34:34,  5.83it/s]Epoch: 4: Step: 10501/14003, loss=0.553842, lr=0.000007
10599it [34:52,  5.78it/s]Train batch 10600
Avg. loss per last 100 batches: 0.541752
10600it [34:52,  5.80it/s]Epoch: 4: Step: 10601/14003, loss=0.423457, lr=0.000006
10699it [35:09,  5.80it/s]Train batch 10700
Avg. loss per last 100 batches: 0.550932
10700it [35:09,  5.80it/s]Epoch: 4: Step: 10701/14003, loss=0.585201, lr=0.000006
10799it [35:26,  5.81it/s]Train batch 10800
Avg. loss per last 100 batches: 0.563375
10800it [35:26,  5.82it/s]Epoch: 4: Step: 10801/14003, loss=0.797733, lr=0.000006
10899it [35:44,  5.81it/s]Train batch 10900
Avg. loss per last 100 batches: 0.540903
10900it [35:44,  5.82it/s]Epoch: 4: Step: 10901/14003, loss=0.299739, lr=0.000006
10999it [36:01,  5.43it/s]Train batch 11000
Avg. loss per last 100 batches: 0.591661
11000it [36:01,  5.53it/s]Epoch: 4: Step: 11001/14003, loss=0.562021, lr=0.000006
11099it [36:18,  5.80it/s]Train batch 11100
Avg. loss per last 100 batches: 0.565960
11100it [36:19,  5.78it/s]Epoch: 4: Step: 11101/14003, loss=0.938336, lr=0.000006
11199it [36:36,  5.81it/s]Train batch 11200
Avg. loss per last 100 batches: 0.537778
11200it [36:36,  5.81it/s]Epoch: 4: Step: 11201/14003, loss=0.741607, lr=0.000006
11203it [36:36,  5.77it/s]Validation: Epoch: 4 Step: 11204/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=5.003650 sec., loss=1.807291 
Eval step: 199 , used_time=9.890274 sec., loss=1.447231 
Eval step: 299 , used_time=14.741104 sec., loss=0.586985 
Eval step: 399 , used_time=19.509876 sec., loss=1.245434 
Eval step: 499 , used_time=24.338929 sec., loss=1.082075 
Eval step: 599 , used_time=29.172810 sec., loss=1.608276 
Eval step: 699 , used_time=33.966645 sec., loss=1.277484 
Eval step: 799 , used_time=39.011534 sec., loss=1.142923 
Eval step: 899 , used_time=43.810735 sec., loss=1.711021 
Eval step: 999 , used_time=48.638075 sec., loss=0.897580 
Eval step: 1099 , used_time=53.436025 sec., loss=1.423326 
Eval step: 1199 , used_time=58.297040 sec., loss=0.885832 
Eval step: 1299 , used_time=63.089113 sec., loss=1.089480 
Eval step: 1399 , used_time=68.079166 sec., loss=0.473512 
Eval step: 1499 , used_time=72.971286 sec., loss=1.235602 
Eval step: 1599 , used_time=77.804898 sec., loss=1.047697 
NLL Validation: loss = 0.952869. correct prediction ratio  39685/52032 ~  0.762704
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [38:16,  5.64it/s]Train batch 11300
Avg. loss per last 100 batches: 0.551611
11300it [38:16,  5.44it/s]Epoch: 4: Step: 11301/14003, loss=0.478573, lr=0.000006
11399it [38:33,  5.78it/s]Train batch 11400
Avg. loss per last 100 batches: 0.607109
11400it [38:33,  5.79it/s]Epoch: 4: Step: 11401/14003, loss=1.173135, lr=0.000006
11499it [38:50,  5.60it/s]Train batch 11500
Avg. loss per last 100 batches: 0.564234
11500it [38:51,  5.45it/s]Epoch: 4: Step: 11501/14003, loss=0.682918, lr=0.000006
11599it [39:08,  5.80it/s]Train batch 11600
Avg. loss per last 100 batches: 0.578579
11600it [39:08,  5.82it/s]Epoch: 4: Step: 11601/14003, loss=0.930433, lr=0.000006
11699it [39:25,  5.80it/s]Train batch 11700
Avg. loss per last 100 batches: 0.553643
11700it [39:25,  5.81it/s]Epoch: 4: Step: 11701/14003, loss=0.750526, lr=0.000006
11799it [39:42,  5.81it/s]Train batch 11800
Avg. loss per last 100 batches: 0.574930
11800it [39:43,  5.82it/s]Epoch: 4: Step: 11801/14003, loss=0.329678, lr=0.000006
11899it [40:00,  5.82it/s]Train batch 11900
Avg. loss per last 100 batches: 0.530616
11900it [40:00,  5.79it/s]Epoch: 4: Step: 11901/14003, loss=0.464896, lr=0.000006
11999it [40:17,  5.83it/s]Train batch 12000
Avg. loss per last 100 batches: 0.520925
12000it [40:17,  5.83it/s]Epoch: 4: Step: 12001/14003, loss=0.604455, lr=0.000006
12099it [40:35,  5.82it/s]Train batch 12100
Avg. loss per last 100 batches: 0.564147
12100it [40:35,  5.79it/s]Epoch: 4: Step: 12101/14003, loss=0.405501, lr=0.000006
12199it [40:52,  5.81it/s]Train batch 12200
Avg. loss per last 100 batches: 0.523026
12200it [40:52,  5.80it/s]Epoch: 4: Step: 12201/14003, loss=0.766656, lr=0.000006
12299it [41:09,  5.80it/s]Train batch 12300
Avg. loss per last 100 batches: 0.546707
12300it [41:09,  5.81it/s]Epoch: 4: Step: 12301/14003, loss=0.382257, lr=0.000006
12399it [41:27,  5.28it/s]Train batch 12400
Avg. loss per last 100 batches: 0.564976
12400it [41:27,  5.43it/s]Epoch: 4: Step: 12401/14003, loss=0.368208, lr=0.000006
12499it [41:44,  5.81it/s]Train batch 12500
Avg. loss per last 100 batches: 0.551664
12500it [41:44,  5.80it/s]Epoch: 4: Step: 12501/14003, loss=0.769974, lr=0.000006
12599it [42:01,  5.79it/s]Train batch 12600
Avg. loss per last 100 batches: 0.608635
12600it [42:02,  5.77it/s]Epoch: 4: Step: 12601/14003, loss=0.351762, lr=0.000006
12699it [42:19,  5.80it/s]Train batch 12700
Avg. loss per last 100 batches: 0.575603
12700it [42:19,  5.79it/s]Epoch: 4: Step: 12701/14003, loss=0.248204, lr=0.000006
12799it [42:36,  5.82it/s]Train batch 12800
Avg. loss per last 100 batches: 0.516031
12800it [42:36,  5.82it/s]Epoch: 4: Step: 12801/14003, loss=0.507026, lr=0.000006
12899it [42:53,  5.81it/s]Train batch 12900
Avg. loss per last 100 batches: 0.548627
12900it [42:54,  5.82it/s]Epoch: 4: Step: 12901/14003, loss=0.860306, lr=0.000006
12999it [43:11,  5.79it/s]Train batch 13000
Avg. loss per last 100 batches: 0.562582
13000it [43:11,  5.79it/s]Epoch: 4: Step: 13001/14003, loss=0.457723, lr=0.000006
13099it [43:28,  5.82it/s]Train batch 13100
Avg. loss per last 100 batches: 0.548854
13100it [43:28,  5.78it/s]Epoch: 4: Step: 13101/14003, loss=0.792888, lr=0.000006
13199it [43:46,  5.78it/s]Train batch 13200
Avg. loss per last 100 batches: 0.547059
13200it [43:46,  5.78it/s]Epoch: 4: Step: 13201/14003, loss=0.489922, lr=0.000006
13299it [44:03,  5.78it/s]Train batch 13300
Avg. loss per last 100 batches: 0.543368
13300it [44:03,  5.78it/s]Epoch: 4: Step: 13301/14003, loss=0.147919, lr=0.000006
13399it [44:20,  5.81it/s]Train batch 13400
Avg. loss per last 100 batches: 0.543434
13400it [44:20,  5.82it/s]Epoch: 4: Step: 13401/14003, loss=0.649706, lr=0.000006
13499it [44:38,  5.77it/s]Train batch 13500
Avg. loss per last 100 batches: 0.548045
13500it [44:38,  5.79it/s]Epoch: 4: Step: 13501/14003, loss=0.758216, lr=0.000006
13599it [44:55,  5.81it/s]Train batch 13600
Avg. loss per last 100 batches: 0.534460
13600it [44:55,  5.81it/s]Epoch: 4: Step: 13601/14003, loss=0.999094, lr=0.000006
13699it [45:12,  5.80it/s]Train batch 13700
Avg. loss per last 100 batches: 0.534791
13700it [45:13,  5.78it/s]Epoch: 4: Step: 13701/14003, loss=0.404878, lr=0.000006
13799it [45:30,  5.77it/s]Train batch 13800
Avg. loss per last 100 batches: 0.539232
13800it [45:30,  5.78it/s]Epoch: 4: Step: 13801/14003, loss=0.391753, lr=0.000006
13899it [45:47,  5.78it/s]Train batch 13900
Avg. loss per last 100 batches: 0.525355
13900it [45:47,  5.79it/s]Epoch: 4: Step: 13901/14003, loss=0.444766, lr=0.000006
13999it [46:04,  5.79it/s]Train batch 14000
Avg. loss per last 100 batches: 0.543065
14000it [46:05,  5.78it/s]Epoch: 4: Step: 14001/14003, loss=0.474306, lr=0.000006
14003it [46:05,  5.06it/s]
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.900672 sec., loss=1.754653 
Eval step: 199 , used_time=9.896264 sec., loss=1.423003 
Eval step: 299 , used_time=14.678259 sec., loss=0.646842 
Eval step: 399 , used_time=19.483120 sec., loss=1.133633 
Eval step: 499 , used_time=24.269526 sec., loss=1.095579 
Eval step: 599 , used_time=29.076679 sec., loss=1.579808 
Eval step: 699 , used_time=33.876822 sec., loss=1.201370 
Eval step: 799 , used_time=38.928894 sec., loss=1.023900 
Eval step: 899 , used_time=43.769016 sec., loss=1.583312 
Eval step: 999 , used_time=48.608392 sec., loss=0.825730 
Eval step: 1099 , used_time=53.391511 sec., loss=1.469643 
Eval step: 1199 , used_time=58.205225 sec., loss=0.828674 
Eval step: 1299 , used_time=62.988704 sec., loss=1.009354 
Eval step: 1399 , used_time=67.894747 sec., loss=0.436308 
Eval step: 1499 , used_time=72.890857 sec., loss=1.338747 
Eval step: 1599 , used_time=77.727109 sec., loss=1.032641 
NLL Validation: loss = 0.941699. correct prediction ratio  39744/52032 ~  0.763838
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=0.547868
epoch total correct predictions=375370
***** Epoch 5 *****
0it [00:00, ?it/s]Epoch: 5: Step: 1/14003, loss=0.492385, lr=0.000006
99it [00:17,  5.35it/s]Train batch 100
Avg. loss per last 100 batches: 0.423476
100it [00:17,  5.22it/s]Epoch: 5: Step: 101/14003, loss=0.249822, lr=0.000006
199it [00:35,  5.80it/s]Train batch 200
Avg. loss per last 100 batches: 0.422285
200it [00:35,  5.80it/s]Epoch: 5: Step: 201/14003, loss=0.332133, lr=0.000006
299it [00:52,  5.80it/s]Train batch 300
Avg. loss per last 100 batches: 0.419437
300it [00:52,  5.82it/s]Epoch: 5: Step: 301/14003, loss=0.236827, lr=0.000006
399it [01:09,  5.82it/s]Train batch 400
Avg. loss per last 100 batches: 0.424000
400it [01:09,  5.83it/s]Epoch: 5: Step: 401/14003, loss=0.548295, lr=0.000006
499it [01:27,  5.79it/s]Train batch 500
Avg. loss per last 100 batches: 0.448887
500it [01:27,  5.78it/s]Epoch: 5: Step: 501/14003, loss=0.432925, lr=0.000006
599it [01:44,  5.81it/s]Train batch 600
Avg. loss per last 100 batches: 0.402599
600it [01:44,  5.82it/s]Epoch: 5: Step: 601/14003, loss=0.641816, lr=0.000006
699it [02:01,  5.81it/s]Train batch 700
Avg. loss per last 100 batches: 0.450540
700it [02:02,  5.81it/s]Epoch: 5: Step: 701/14003, loss=0.272613, lr=0.000006
799it [02:19,  5.67it/s]Train batch 800
Avg. loss per last 100 batches: 0.402203
800it [02:19,  5.67it/s]Epoch: 5: Step: 801/14003, loss=0.440105, lr=0.000006
899it [02:36,  5.80it/s]Train batch 900
Avg. loss per last 100 batches: 0.449939
900it [02:36,  5.81it/s]Epoch: 5: Step: 901/14003, loss=0.623968, lr=0.000006
999it [02:53,  5.80it/s]Train batch 1000
Avg. loss per last 100 batches: 0.461508
1000it [02:54,  5.76it/s]Epoch: 5: Step: 1001/14003, loss=0.888839, lr=0.000006
1099it [03:11,  5.80it/s]Train batch 1100
Avg. loss per last 100 batches: 0.454526
1100it [03:11,  5.80it/s]Epoch: 5: Step: 1101/14003, loss=0.205186, lr=0.000006
1199it [03:28,  5.57it/s]Train batch 1200
Avg. loss per last 100 batches: 0.432716
1200it [03:28,  5.64it/s]Epoch: 5: Step: 1201/14003, loss=0.253445, lr=0.000006
1299it [03:46,  5.79it/s]Train batch 1300
Avg. loss per last 100 batches: 0.431451
1300it [03:46,  5.80it/s]Epoch: 5: Step: 1301/14003, loss=0.195257, lr=0.000006
1399it [04:03,  5.67it/s]Train batch 1400
Avg. loss per last 100 batches: 0.417297
1400it [04:03,  5.71it/s]Epoch: 5: Step: 1401/14003, loss=0.227205, lr=0.000005
1499it [04:20,  5.81it/s]Train batch 1500
Avg. loss per last 100 batches: 0.422519
1500it [04:20,  5.79it/s]Epoch: 5: Step: 1501/14003, loss=0.417148, lr=0.000005
1599it [04:38,  5.78it/s]Train batch 1600
Avg. loss per last 100 batches: 0.448366
1600it [04:38,  5.77it/s]Epoch: 5: Step: 1601/14003, loss=0.413248, lr=0.000005
1699it [04:55,  5.76it/s]Train batch 1700
Avg. loss per last 100 batches: 0.431099
1700it [04:55,  5.76it/s]Epoch: 5: Step: 1701/14003, loss=0.052156, lr=0.000005
1799it [05:12,  5.80it/s]Train batch 1800
Avg. loss per last 100 batches: 0.459360
1800it [05:13,  5.78it/s]Epoch: 5: Step: 1801/14003, loss=0.687197, lr=0.000005
1899it [05:30,  5.79it/s]Train batch 1900
Avg. loss per last 100 batches: 0.454500
1900it [05:30,  5.78it/s]Epoch: 5: Step: 1901/14003, loss=0.458369, lr=0.000005
1999it [05:47,  5.80it/s]Train batch 2000
Avg. loss per last 100 batches: 0.441131
2000it [05:47,  5.81it/s]Epoch: 5: Step: 2001/14003, loss=0.331070, lr=0.000005
2099it [06:05,  5.45it/s]Train batch 2100
Avg. loss per last 100 batches: 0.420974
2100it [06:05,  5.30it/s]Epoch: 5: Step: 2101/14003, loss=0.215750, lr=0.000005
2199it [06:22,  5.78it/s]Train batch 2200
Avg. loss per last 100 batches: 0.419525
2200it [06:22,  5.80it/s]Epoch: 5: Step: 2201/14003, loss=0.414624, lr=0.000005
2299it [06:40,  5.78it/s]Train batch 2300
Avg. loss per last 100 batches: 0.466093
2300it [06:40,  5.80it/s]Epoch: 5: Step: 2301/14003, loss=0.678767, lr=0.000005
2399it [06:57,  5.71it/s]Train batch 2400
Avg. loss per last 100 batches: 0.437241
2400it [06:57,  5.74it/s]Epoch: 5: Step: 2401/14003, loss=0.451349, lr=0.000005
2499it [07:14,  5.79it/s]Train batch 2500
Avg. loss per last 100 batches: 0.469133
2500it [07:14,  5.79it/s]Epoch: 5: Step: 2501/14003, loss=0.420088, lr=0.000005
2599it [07:31,  5.77it/s]Train batch 2600
Avg. loss per last 100 batches: 0.428539
2600it [07:32,  5.77it/s]Epoch: 5: Step: 2601/14003, loss=0.599320, lr=0.000005
2699it [07:49,  5.80it/s]Train batch 2700
Avg. loss per last 100 batches: 0.453570
2700it [07:49,  5.79it/s]Epoch: 5: Step: 2701/14003, loss=0.467545, lr=0.000005
2799it [08:06,  5.82it/s]Train batch 2800
Avg. loss per last 100 batches: 0.404954
2800it [08:06,  5.80it/s]Epoch: 5: Step: 2801/14003, loss=0.293847, lr=0.000005
Validation: Epoch: 5 Step: 2801/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=5.066934 sec., loss=1.853061 
Eval step: 199 , used_time=9.890590 sec., loss=1.769845 
Eval step: 299 , used_time=14.730589 sec., loss=0.672476 
Eval step: 399 , used_time=19.503031 sec., loss=1.141536 
Eval step: 499 , used_time=24.312087 sec., loss=1.070708 
Eval step: 599 , used_time=29.092435 sec., loss=1.620667 
Eval step: 699 , used_time=34.064726 sec., loss=1.156432 
Eval step: 799 , used_time=38.964020 sec., loss=1.119128 
Eval step: 899 , used_time=43.782076 sec., loss=1.821749 
Eval step: 999 , used_time=48.576487 sec., loss=0.978305 
Eval step: 1099 , used_time=53.362622 sec., loss=1.510295 
Eval step: 1199 , used_time=58.155460 sec., loss=0.746577 
Eval step: 1299 , used_time=62.931051 sec., loss=1.192152 
Eval step: 1399 , used_time=67.966761 sec., loss=0.509654 
Eval step: 1499 , used_time=72.778719 sec., loss=1.407519 
Eval step: 1599 , used_time=77.605924 sec., loss=1.118531 
NLL Validation: loss = 0.995877. correct prediction ratio  39651/52032 ~  0.762050
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
2899it [09:48,  5.77it/s]Train batch 2900
Avg. loss per last 100 batches: 0.410068
2900it [09:49,  5.78it/s]Epoch: 5: Step: 2901/14003, loss=0.638494, lr=0.000005
2999it [10:06,  5.80it/s]Train batch 3000
Avg. loss per last 100 batches: 0.442430
3000it [10:06,  5.78it/s]Epoch: 5: Step: 3001/14003, loss=0.235398, lr=0.000005
3099it [10:23,  5.76it/s]Train batch 3100
Avg. loss per last 100 batches: 0.419672
3100it [10:23,  5.77it/s]Epoch: 5: Step: 3101/14003, loss=0.725213, lr=0.000005
3199it [10:40,  5.78it/s]Train batch 3200
Avg. loss per last 100 batches: 0.430078
3200it [10:41,  5.79it/s]Epoch: 5: Step: 3201/14003, loss=0.471744, lr=0.000005
3299it [10:58,  5.81it/s]Train batch 3300
Avg. loss per last 100 batches: 0.462568
3300it [10:58,  5.82it/s]Epoch: 5: Step: 3301/14003, loss=0.339529, lr=0.000005
3399it [11:15,  5.79it/s]Train batch 3400
Avg. loss per last 100 batches: 0.451121
3400it [11:15,  5.80it/s]Epoch: 5: Step: 3401/14003, loss=0.127476, lr=0.000005
3499it [11:33,  5.78it/s]Train batch 3500
Avg. loss per last 100 batches: 0.428767
3500it [11:33,  5.76it/s]Epoch: 5: Step: 3501/14003, loss=0.429791, lr=0.000005
3599it [11:50,  5.80it/s]Train batch 3600
Avg. loss per last 100 batches: 0.448898
3600it [11:50,  5.83it/s]Epoch: 5: Step: 3601/14003, loss=0.423330, lr=0.000005
3699it [12:07,  5.78it/s]Train batch 3700
Avg. loss per last 100 batches: 0.395772
3700it [12:07,  5.79it/s]Epoch: 5: Step: 3701/14003, loss=0.333317, lr=0.000005
3799it [12:25,  5.23it/s]Train batch 3800
Avg. loss per last 100 batches: 0.434287
3800it [12:25,  5.23it/s]Epoch: 5: Step: 3801/14003, loss=0.300077, lr=0.000005
3899it [12:42,  5.81it/s]Train batch 3900
Avg. loss per last 100 batches: 0.453058
3900it [12:42,  5.82it/s]Epoch: 5: Step: 3901/14003, loss=0.302953, lr=0.000005
3999it [12:59,  5.82it/s]Train batch 4000
Avg. loss per last 100 batches: 0.431114
4000it [13:00,  5.83it/s]Epoch: 5: Step: 4001/14003, loss=0.139678, lr=0.000005
4099it [13:17,  5.82it/s]Train batch 4100
Avg. loss per last 100 batches: 0.442749
4100it [13:17,  5.81it/s]Epoch: 5: Step: 4101/14003, loss=0.731530, lr=0.000005
4199it [13:34,  5.77it/s]Train batch 4200
Avg. loss per last 100 batches: 0.431070
4200it [13:34,  5.79it/s]Epoch: 5: Step: 4201/14003, loss=0.218493, lr=0.000005
4299it [13:51,  5.81it/s]Train batch 4300
Avg. loss per last 100 batches: 0.401571
4300it [13:52,  5.81it/s]Epoch: 5: Step: 4301/14003, loss=0.371895, lr=0.000005
4399it [14:09,  5.81it/s]Train batch 4400
Avg. loss per last 100 batches: 0.465681
4400it [14:09,  5.81it/s]Epoch: 5: Step: 4401/14003, loss=0.432800, lr=0.000005
4499it [14:26,  5.82it/s]Train batch 4500
Avg. loss per last 100 batches: 0.451081
4500it [14:26,  5.78it/s]Epoch: 5: Step: 4501/14003, loss=0.327650, lr=0.000005
4599it [14:44,  5.71it/s]Train batch 4600
Avg. loss per last 100 batches: 0.427381
4600it [14:44,  5.73it/s]Epoch: 5: Step: 4601/14003, loss=0.096206, lr=0.000005
4699it [15:01,  5.83it/s]Train batch 4700
Avg. loss per last 100 batches: 0.447800
4700it [15:01,  5.82it/s]Epoch: 5: Step: 4701/14003, loss=0.388930, lr=0.000005
4799it [15:18,  5.76it/s]Train batch 4800
Avg. loss per last 100 batches: 0.446539
4800it [15:18,  5.78it/s]Epoch: 5: Step: 4801/14003, loss=0.712632, lr=0.000005
4899it [15:36,  5.61it/s]Train batch 4900
Avg. loss per last 100 batches: 0.440029
4900it [15:36,  5.66it/s]Epoch: 5: Step: 4901/14003, loss=0.415930, lr=0.000005
4999it [15:53,  5.58it/s]Train batch 5000
Avg. loss per last 100 batches: 0.429443
5000it [15:53,  5.64it/s]Epoch: 5: Step: 5001/14003, loss=0.156273, lr=0.000005
5099it [16:10,  5.83it/s]Train batch 5100
Avg. loss per last 100 batches: 0.430260
5100it [16:11,  5.79it/s]Epoch: 5: Step: 5101/14003, loss=0.316609, lr=0.000005
5199it [16:28,  5.82it/s]Train batch 5200
Avg. loss per last 100 batches: 0.439674
5200it [16:28,  5.82it/s]Epoch: 5: Step: 5201/14003, loss=0.292011, lr=0.000005
5299it [16:45,  5.77it/s]Train batch 5300
Avg. loss per last 100 batches: 0.406256
5300it [16:45,  5.77it/s]Epoch: 5: Step: 5301/14003, loss=0.525474, lr=0.000005
5399it [17:03,  5.70it/s]Train batch 5400
Avg. loss per last 100 batches: 0.443023
5400it [17:04,  5.72it/s]Epoch: 5: Step: 5401/14003, loss=0.273147, lr=0.000005
5499it [17:21,  5.76it/s]Train batch 5500
Avg. loss per last 100 batches: 0.453670
5500it [17:21,  5.78it/s]Epoch: 5: Step: 5501/14003, loss=0.436756, lr=0.000005
5599it [17:38,  5.74it/s]Train batch 5600
Avg. loss per last 100 batches: 0.420814
5600it [17:38,  5.76it/s]Epoch: 5: Step: 5601/14003, loss=0.463391, lr=0.000005
5601it [17:39,  5.72it/s]Validation: Epoch: 5 Step: 5602/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=5.051229 sec., loss=1.860480 
Eval step: 199 , used_time=9.848813 sec., loss=1.551490 
Eval step: 299 , used_time=14.655400 sec., loss=0.697502 
Eval step: 399 , used_time=19.428919 sec., loss=1.205436 
Eval step: 499 , used_time=24.245619 sec., loss=1.240129 
Eval step: 599 , used_time=29.031819 sec., loss=1.736716 
Eval step: 699 , used_time=34.122690 sec., loss=1.230907 
Eval step: 799 , used_time=38.958900 sec., loss=1.077969 
Eval step: 899 , used_time=43.810090 sec., loss=1.790900 
Eval step: 999 , used_time=48.608055 sec., loss=1.076290 
Eval step: 1099 , used_time=53.408645 sec., loss=1.560845 
Eval step: 1199 , used_time=58.229093 sec., loss=0.878668 
Eval step: 1299 , used_time=63.062964 sec., loss=1.059375 
Eval step: 1399 , used_time=68.136693 sec., loss=0.421998 
Eval step: 1499 , used_time=72.908222 sec., loss=1.476828 
Eval step: 1599 , used_time=77.732769 sec., loss=1.054278 
NLL Validation: loss = 0.989491. correct prediction ratio  39752/52032 ~  0.763991
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:18,  5.78it/s]Train batch 5700
Avg. loss per last 100 batches: 0.424674
5700it [19:18,  5.80it/s]Epoch: 5: Step: 5701/14003, loss=0.615700, lr=0.000005
5799it [19:36,  5.80it/s]Train batch 5800
Avg. loss per last 100 batches: 0.427835
5800it [19:36,  5.81it/s]Epoch: 5: Step: 5801/14003, loss=0.508269, lr=0.000005
5899it [19:53,  5.71it/s]Train batch 5900
Avg. loss per last 100 batches: 0.424557
5900it [19:53,  5.73it/s]Epoch: 5: Step: 5901/14003, loss=0.186372, lr=0.000005
5999it [20:10,  5.80it/s]Train batch 6000
Avg. loss per last 100 batches: 0.443305
6000it [20:10,  5.81it/s]Epoch: 5: Step: 6001/14003, loss=0.567873, lr=0.000005
6099it [20:28,  5.83it/s]Train batch 6100
Avg. loss per last 100 batches: 0.414515
6100it [20:28,  5.81it/s]Epoch: 5: Step: 6101/14003, loss=0.536568, lr=0.000005
6199it [20:45,  5.74it/s]Train batch 6200
Avg. loss per last 100 batches: 0.449274
6200it [20:45,  5.74it/s]Epoch: 5: Step: 6201/14003, loss=0.296281, lr=0.000005
6299it [21:02,  5.80it/s]Train batch 6300
Avg. loss per last 100 batches: 0.434456
6300it [21:03,  5.78it/s]Epoch: 5: Step: 6301/14003, loss=0.191551, lr=0.000004
6399it [21:20,  5.79it/s]Train batch 6400
Avg. loss per last 100 batches: 0.426930
6400it [21:20,  5.78it/s]Epoch: 5: Step: 6401/14003, loss=0.673099, lr=0.000004
6499it [21:37,  5.79it/s]Train batch 6500
Avg. loss per last 100 batches: 0.414504
6500it [21:37,  5.80it/s]Epoch: 5: Step: 6501/14003, loss=0.344218, lr=0.000004
6599it [21:55,  5.42it/s]Train batch 6600
Avg. loss per last 100 batches: 0.466572
6600it [21:55,  5.52it/s]Epoch: 5: Step: 6601/14003, loss=0.439981, lr=0.000004
6699it [22:12,  5.80it/s]Train batch 6700
Avg. loss per last 100 batches: 0.448753
6700it [22:12,  5.80it/s]Epoch: 5: Step: 6701/14003, loss=0.411177, lr=0.000004
6799it [22:29,  5.80it/s]Train batch 6800
Avg. loss per last 100 batches: 0.439802
6800it [22:29,  5.79it/s]Epoch: 5: Step: 6801/14003, loss=0.123642, lr=0.000004
6899it [22:47,  5.78it/s]Train batch 6900
Avg. loss per last 100 batches: 0.432524
6900it [22:47,  5.77it/s]Epoch: 5: Step: 6901/14003, loss=0.759542, lr=0.000004
6999it [23:04,  5.77it/s]Train batch 7000
Avg. loss per last 100 batches: 0.464529
7000it [23:04,  5.77it/s]Epoch: 5: Step: 7001/14003, loss=0.657123, lr=0.000004
7099it [23:21,  5.81it/s]Train batch 7100
Avg. loss per last 100 batches: 0.413702
7100it [23:21,  5.82it/s]Epoch: 5: Step: 7101/14003, loss=0.241845, lr=0.000004
7199it [23:39,  5.76it/s]Train batch 7200
Avg. loss per last 100 batches: 0.425018
7200it [23:39,  5.75it/s]Epoch: 5: Step: 7201/14003, loss=1.267561, lr=0.000004
7299it [23:56,  5.78it/s]Train batch 7300
Avg. loss per last 100 batches: 0.465272
7300it [23:56,  5.78it/s]Epoch: 5: Step: 7301/14003, loss=0.475011, lr=0.000004
7399it [24:14,  5.76it/s]Train batch 7400
Avg. loss per last 100 batches: 0.434678
7400it [24:14,  5.77it/s]Epoch: 5: Step: 7401/14003, loss=0.301049, lr=0.000004
7499it [24:31,  5.68it/s]Train batch 7500
Avg. loss per last 100 batches: 0.459603
7500it [24:31,  5.35it/s]Epoch: 5: Step: 7501/14003, loss=0.521820, lr=0.000004
7599it [24:48,  5.72it/s]Train batch 7600
Avg. loss per last 100 batches: 0.426009
7600it [24:48,  5.71it/s]Epoch: 5: Step: 7601/14003, loss=0.558066, lr=0.000004
7699it [25:06,  5.79it/s]Train batch 7700
Avg. loss per last 100 batches: 0.468214
7700it [25:06,  5.78it/s]Epoch: 5: Step: 7701/14003, loss=0.680809, lr=0.000004
7799it [25:23,  5.81it/s]Train batch 7800
Avg. loss per last 100 batches: 0.429490
7800it [25:23,  5.80it/s]Epoch: 5: Step: 7801/14003, loss=0.294046, lr=0.000004
7899it [25:41,  5.79it/s]Train batch 7900
Avg. loss per last 100 batches: 0.424139
7900it [25:41,  5.80it/s]Epoch: 5: Step: 7901/14003, loss=0.635145, lr=0.000004
7999it [25:58,  5.77it/s]Train batch 8000
Avg. loss per last 100 batches: 0.440465
8000it [25:58,  5.77it/s]Epoch: 5: Step: 8001/14003, loss=0.631617, lr=0.000004
8099it [26:15,  5.79it/s]Train batch 8100
Avg. loss per last 100 batches: 0.475735
8100it [26:15,  5.79it/s]Epoch: 5: Step: 8101/14003, loss=0.513693, lr=0.000004
8199it [26:33,  5.80it/s]Train batch 8200
Avg. loss per last 100 batches: 0.413189
8200it [26:33,  5.64it/s]Epoch: 5: Step: 8201/14003, loss=0.317927, lr=0.000004
8299it [26:50,  5.73it/s]Train batch 8300
Avg. loss per last 100 batches: 0.432176
8300it [26:50,  5.70it/s]Epoch: 5: Step: 8301/14003, loss=0.242493, lr=0.000004
8399it [27:07,  5.79it/s]Train batch 8400
Avg. loss per last 100 batches: 0.475244
8400it [27:08,  5.78it/s]Epoch: 5: Step: 8401/14003, loss=0.397713, lr=0.000004
8402it [27:08,  5.75it/s]Validation: Epoch: 5 Step: 8403/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.918151 sec., loss=1.919106 
Eval step: 199 , used_time=9.762919 sec., loss=1.527458 
Eval step: 299 , used_time=14.598453 sec., loss=0.650005 
Eval step: 399 , used_time=19.367228 sec., loss=1.143715 
Eval step: 499 , used_time=24.213066 sec., loss=1.176111 
Eval step: 599 , used_time=28.995734 sec., loss=1.742946 
Eval step: 699 , used_time=34.100272 sec., loss=1.196974 
Eval step: 799 , used_time=38.867444 sec., loss=1.037105 
Eval step: 899 , used_time=43.734012 sec., loss=1.689151 
Eval step: 999 , used_time=48.501161 sec., loss=0.884693 
Eval step: 1099 , used_time=53.311306 sec., loss=1.500649 
Eval step: 1199 , used_time=58.080111 sec., loss=0.864149 
Eval step: 1299 , used_time=63.145976 sec., loss=1.066649 
Eval step: 1399 , used_time=67.952717 sec., loss=0.438172 
Eval step: 1499 , used_time=72.861058 sec., loss=1.490278 
Eval step: 1599 , used_time=77.635206 sec., loss=1.023340 
NLL Validation: loss = 0.984342. correct prediction ratio  39788/52032 ~  0.764683
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
8499it [28:50,  5.75it/s]Train batch 8500
Avg. loss per last 100 batches: 0.436194
8500it [28:50,  5.77it/s]Epoch: 5: Step: 8501/14003, loss=0.516804, lr=0.000004
8599it [29:07,  5.81it/s]Train batch 8600
Avg. loss per last 100 batches: 0.454795
8600it [29:07,  5.82it/s]Epoch: 5: Step: 8601/14003, loss=0.214672, lr=0.000004
8699it [29:25,  5.79it/s]Train batch 8700
Avg. loss per last 100 batches: 0.474512
8700it [29:25,  5.77it/s]Epoch: 5: Step: 8701/14003, loss=0.267389, lr=0.000004
8799it [29:42,  5.76it/s]Train batch 8800
Avg. loss per last 100 batches: 0.426214
8800it [29:42,  5.76it/s]Epoch: 5: Step: 8801/14003, loss=0.320465, lr=0.000004
8899it [29:59,  5.81it/s]Train batch 8900
Avg. loss per last 100 batches: 0.477652
8900it [29:59,  5.80it/s]Epoch: 5: Step: 8901/14003, loss=0.736201, lr=0.000004
8999it [30:16,  5.77it/s]Train batch 9000
Avg. loss per last 100 batches: 0.446260
9000it [30:17,  5.77it/s]Epoch: 5: Step: 9001/14003, loss=0.462950, lr=0.000004
9099it [30:34,  5.80it/s]Train batch 9100
Avg. loss per last 100 batches: 0.448906
9100it [30:34,  5.77it/s]Epoch: 5: Step: 9101/14003, loss=0.751262, lr=0.000004
9199it [30:51,  5.30it/s]Train batch 9200
Avg. loss per last 100 batches: 0.435070
9200it [30:52,  5.45it/s]Epoch: 5: Step: 9201/14003, loss=0.337642, lr=0.000004
9299it [31:09,  5.80it/s]Train batch 9300
Avg. loss per last 100 batches: 0.425780
9300it [31:09,  5.80it/s]Epoch: 5: Step: 9301/14003, loss=0.437847, lr=0.000004
9399it [31:26,  5.81it/s]Train batch 9400
Avg. loss per last 100 batches: 0.447716
9400it [31:26,  5.79it/s]Epoch: 5: Step: 9401/14003, loss=0.297570, lr=0.000004
9499it [31:43,  5.77it/s]Train batch 9500
Avg. loss per last 100 batches: 0.423445
9500it [31:44,  5.79it/s]Epoch: 5: Step: 9501/14003, loss=0.913521, lr=0.000004
9599it [32:01,  5.81it/s]Train batch 9600
Avg. loss per last 100 batches: 0.474500
9600it [32:01,  5.80it/s]Epoch: 5: Step: 9601/14003, loss=0.381661, lr=0.000004
9699it [32:18,  5.79it/s]Train batch 9700
Avg. loss per last 100 batches: 0.407369
9700it [32:18,  5.77it/s]Epoch: 5: Step: 9701/14003, loss=0.770314, lr=0.000004
9799it [32:36,  5.83it/s]Train batch 9800
Avg. loss per last 100 batches: 0.475163
9800it [32:36,  5.80it/s]Epoch: 5: Step: 9801/14003, loss=0.671029, lr=0.000004
9899it [32:53,  5.77it/s]Train batch 9900
Avg. loss per last 100 batches: 0.446752
9900it [32:53,  5.79it/s]Epoch: 5: Step: 9901/14003, loss=0.921316, lr=0.000004
9999it [33:10,  5.81it/s]Train batch 10000
Avg. loss per last 100 batches: 0.438863
10000it [33:11,  5.81it/s]Epoch: 5: Step: 10001/14003, loss=0.333545, lr=0.000004
10099it [33:28,  5.80it/s]Train batch 10100
Avg. loss per last 100 batches: 0.470962
10100it [33:28,  5.81it/s]Epoch: 5: Step: 10101/14003, loss=0.263933, lr=0.000004
10199it [33:45,  5.83it/s]Train batch 10200
Avg. loss per last 100 batches: 0.398101
10200it [33:45,  5.83it/s]Epoch: 5: Step: 10201/14003, loss=0.196475, lr=0.000004
10299it [34:02,  5.79it/s]Train batch 10300
Avg. loss per last 100 batches: 0.461021
10300it [34:03,  5.79it/s]Epoch: 5: Step: 10301/14003, loss=0.313889, lr=0.000004
10399it [34:20,  5.78it/s]Train batch 10400
Avg. loss per last 100 batches: 0.419513
10400it [34:20,  5.78it/s]Epoch: 5: Step: 10401/14003, loss=0.396584, lr=0.000004
10499it [34:37,  5.75it/s]Train batch 10500
Avg. loss per last 100 batches: 0.464003
10500it [34:37,  5.78it/s]Epoch: 5: Step: 10501/14003, loss=0.554964, lr=0.000004
10599it [34:54,  5.80it/s]Train batch 10600
Avg. loss per last 100 batches: 0.451074
10600it [34:55,  5.78it/s]Epoch: 5: Step: 10601/14003, loss=0.203189, lr=0.000004
10699it [35:12,  5.79it/s]Train batch 10700
Avg. loss per last 100 batches: 0.465826
10700it [35:12,  5.79it/s]Epoch: 5: Step: 10701/14003, loss=0.596696, lr=0.000004
10799it [35:29,  5.83it/s]Train batch 10800
Avg. loss per last 100 batches: 0.431326
10800it [35:29,  5.83it/s]Epoch: 5: Step: 10801/14003, loss=0.493966, lr=0.000004
10899it [35:47,  5.82it/s]Train batch 10900
Avg. loss per last 100 batches: 0.411663
10900it [35:47,  5.81it/s]Epoch: 5: Step: 10901/14003, loss=0.424691, lr=0.000004
10999it [36:04,  5.79it/s]Train batch 11000
Avg. loss per last 100 batches: 0.437322
11000it [36:04,  5.79it/s]Epoch: 5: Step: 11001/14003, loss=0.396783, lr=0.000004
11099it [36:21,  5.81it/s]Train batch 11100
Avg. loss per last 100 batches: 0.460533
11100it [36:21,  5.80it/s]Epoch: 5: Step: 11101/14003, loss=0.401639, lr=0.000003
11199it [36:39,  5.28it/s]Train batch 11200
Avg. loss per last 100 batches: 0.443819
11200it [36:39,  5.23it/s]Epoch: 5: Step: 11201/14003, loss=0.577749, lr=0.000003
11203it [36:39,  5.56it/s]Validation: Epoch: 5 Step: 11204/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.830883 sec., loss=1.949324 
Eval step: 199 , used_time=9.624161 sec., loss=1.470385 
Eval step: 299 , used_time=14.456070 sec., loss=0.704980 
Eval step: 399 , used_time=19.245907 sec., loss=1.117034 
Eval step: 499 , used_time=24.089328 sec., loss=1.147818 
Eval step: 599 , used_time=28.870097 sec., loss=1.664922 
Eval step: 699 , used_time=33.918680 sec., loss=1.186857 
Eval step: 799 , used_time=38.761383 sec., loss=1.110470 
Eval step: 899 , used_time=43.636206 sec., loss=1.540061 
Eval step: 999 , used_time=48.413667 sec., loss=0.919840 
Eval step: 1099 , used_time=53.268760 sec., loss=1.448486 
Eval step: 1199 , used_time=58.053918 sec., loss=0.861369 
Eval step: 1299 , used_time=63.090374 sec., loss=1.015061 
Eval step: 1399 , used_time=67.890739 sec., loss=0.533043 
Eval step: 1499 , used_time=72.666290 sec., loss=1.371400 
Eval step: 1599 , used_time=77.484900 sec., loss=1.113849 
NLL Validation: loss = 0.974737. correct prediction ratio  39790/52032 ~  0.764722
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [38:19,  5.77it/s]Train batch 11300
Avg. loss per last 100 batches: 0.460704
11300it [38:19,  5.77it/s]Epoch: 5: Step: 11301/14003, loss=0.678061, lr=0.000003
11399it [38:36,  5.80it/s]Train batch 11400
Avg. loss per last 100 batches: 0.432109
11400it [38:36,  5.80it/s]Epoch: 5: Step: 11401/14003, loss=0.242044, lr=0.000003
11499it [38:53,  5.75it/s]Train batch 11500
Avg. loss per last 100 batches: 0.469238
11500it [38:53,  5.76it/s]Epoch: 5: Step: 11501/14003, loss=0.346541, lr=0.000003
11599it [39:11,  5.78it/s]Train batch 11600
Avg. loss per last 100 batches: 0.421631
11600it [39:11,  5.80it/s]Epoch: 5: Step: 11601/14003, loss=0.168464, lr=0.000003
11699it [39:28,  5.76it/s]Train batch 11700
Avg. loss per last 100 batches: 0.444148
11700it [39:28,  5.78it/s]Epoch: 5: Step: 11701/14003, loss=0.813653, lr=0.000003
11799it [39:46,  5.79it/s]Train batch 11800
Avg. loss per last 100 batches: 0.482530
11800it [39:46,  5.78it/s]Epoch: 5: Step: 11801/14003, loss=0.444071, lr=0.000003
11899it [40:03,  5.77it/s]Train batch 11900
Avg. loss per last 100 batches: 0.458267
11900it [40:03,  5.78it/s]Epoch: 5: Step: 11901/14003, loss=0.809141, lr=0.000003
11999it [40:21,  5.50it/s]Train batch 12000
Avg. loss per last 100 batches: 0.456550
12000it [40:21,  5.57it/s]Epoch: 5: Step: 12001/14003, loss=0.453029, lr=0.000003
12099it [40:38,  5.80it/s]Train batch 12100
Avg. loss per last 100 batches: 0.450796
12100it [40:38,  5.80it/s]Epoch: 5: Step: 12101/14003, loss=0.586752, lr=0.000003
12199it [40:55,  5.78it/s]Train batch 12200
Avg. loss per last 100 batches: 0.443917
12200it [40:56,  5.79it/s]Epoch: 5: Step: 12201/14003, loss=0.594477, lr=0.000003
12299it [41:13,  5.77it/s]Train batch 12300
Avg. loss per last 100 batches: 0.459439
12300it [41:13,  5.57it/s]Epoch: 5: Step: 12301/14003, loss=0.422314, lr=0.000003
12399it [41:30,  5.80it/s]Train batch 12400
Avg. loss per last 100 batches: 0.442852
12400it [41:30,  5.81it/s]Epoch: 5: Step: 12401/14003, loss=0.518900, lr=0.000003
12499it [41:47,  5.80it/s]Train batch 12500
Avg. loss per last 100 batches: 0.468679
12500it [41:48,  5.81it/s]Epoch: 5: Step: 12501/14003, loss=0.465464, lr=0.000003
12599it [42:05,  5.81it/s]Train batch 12600
Avg. loss per last 100 batches: 0.428603
12600it [42:05,  5.80it/s]Epoch: 5: Step: 12601/14003, loss=0.355329, lr=0.000003
12699it [42:22,  5.79it/s]Train batch 12700
Avg. loss per last 100 batches: 0.455486
12700it [42:22,  5.63it/s]Epoch: 5: Step: 12701/14003, loss=0.246009, lr=0.000003
12799it [42:40,  5.71it/s]Train batch 12800
Avg. loss per last 100 batches: 0.459928
12800it [42:40,  5.74it/s]Epoch: 5: Step: 12801/14003, loss=0.579304, lr=0.000003
12899it [42:57,  5.49it/s]Train batch 12900
Avg. loss per last 100 batches: 0.415811
12900it [42:57,  5.38it/s]Epoch: 5: Step: 12901/14003, loss=0.555836, lr=0.000003
12999it [43:14,  5.78it/s]Train batch 13000
Avg. loss per last 100 batches: 0.439342
13000it [43:15,  5.79it/s]Epoch: 5: Step: 13001/14003, loss=0.194401, lr=0.000003
13099it [43:32,  5.81it/s]Train batch 13100
Avg. loss per last 100 batches: 0.429368
13100it [43:32,  5.80it/s]Epoch: 5: Step: 13101/14003, loss=0.714029, lr=0.000003
13199it [43:49,  5.81it/s]Train batch 13200
Avg. loss per last 100 batches: 0.454653
13200it [43:49,  5.80it/s]Epoch: 5: Step: 13201/14003, loss=0.589648, lr=0.000003
13299it [44:07,  5.83it/s]Train batch 13300
Avg. loss per last 100 batches: 0.436546
13300it [44:07,  5.84it/s]Epoch: 5: Step: 13301/14003, loss=0.505996, lr=0.000003
13399it [44:24,  5.76it/s]Train batch 13400
Avg. loss per last 100 batches: 0.410724
13400it [44:24,  5.78it/s]Epoch: 5: Step: 13401/14003, loss=0.551193, lr=0.000003
13499it [44:41,  5.72it/s]Train batch 13500
Avg. loss per last 100 batches: 0.427742
13500it [44:42,  5.68it/s]Epoch: 5: Step: 13501/14003, loss=0.854018, lr=0.000003
13599it [44:59,  5.80it/s]Train batch 13600
Avg. loss per last 100 batches: 0.431267
13600it [44:59,  5.78it/s]Epoch: 5: Step: 13601/14003, loss=0.305322, lr=0.000003
13699it [45:16,  5.78it/s]Train batch 13700
Avg. loss per last 100 batches: 0.445753
13700it [45:16,  5.78it/s]Epoch: 5: Step: 13701/14003, loss=0.203073, lr=0.000003
13799it [45:33,  5.66it/s]Train batch 13800
Avg. loss per last 100 batches: 0.435715
13800it [45:34,  5.71it/s]Epoch: 5: Step: 13801/14003, loss=0.363565, lr=0.000003
13899it [45:51,  5.81it/s]Train batch 13900
Avg. loss per last 100 batches: 0.468620
13900it [45:51,  5.81it/s]Epoch: 5: Step: 13901/14003, loss=0.607208, lr=0.000003
13999it [46:08,  5.49it/s]Train batch 14000
Avg. loss per last 100 batches: 0.456777
14000it [46:08,  5.59it/s]Epoch: 5: Step: 14001/14003, loss=0.469453, lr=0.000003
14003it [46:09,  5.06it/s]
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.861249 sec., loss=1.904927 
Eval step: 199 , used_time=9.672007 sec., loss=1.458762 
Eval step: 299 , used_time=14.520880 sec., loss=0.652800 
Eval step: 399 , used_time=19.333903 sec., loss=1.073676 
Eval step: 499 , used_time=24.183377 sec., loss=1.177578 
Eval step: 599 , used_time=28.973802 sec., loss=1.635428 
Eval step: 699 , used_time=34.061139 sec., loss=1.188938 
Eval step: 799 , used_time=38.843027 sec., loss=1.116639 
Eval step: 899 , used_time=43.642845 sec., loss=1.563023 
Eval step: 999 , used_time=48.432767 sec., loss=0.972646 
Eval step: 1099 , used_time=53.222806 sec., loss=1.425706 
Eval step: 1199 , used_time=58.027822 sec., loss=0.843360 
Eval step: 1299 , used_time=63.035907 sec., loss=1.007171 
Eval step: 1399 , used_time=67.926584 sec., loss=0.558379 
Eval step: 1499 , used_time=72.723087 sec., loss=1.404570 
Eval step: 1599 , used_time=77.545767 sec., loss=1.068573 
NLL Validation: loss = 0.966048. correct prediction ratio  39848/52032 ~  0.765836
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=0.440131
epoch total correct predictions=388072
***** Epoch 6 *****
0it [00:00, ?it/s]Epoch: 6: Step: 1/14003, loss=0.291488, lr=0.000003
99it [00:17,  5.79it/s]Train batch 100
Avg. loss per last 100 batches: 0.376285
100it [00:17,  5.79it/s]Epoch: 6: Step: 101/14003, loss=0.638514, lr=0.000003
199it [00:35,  5.80it/s]Train batch 200
Avg. loss per last 100 batches: 0.373041
200it [00:35,  5.79it/s]Epoch: 6: Step: 201/14003, loss=0.362396, lr=0.000003
299it [00:52,  5.75it/s]Train batch 300
Avg. loss per last 100 batches: 0.361119
300it [00:52,  5.74it/s]Epoch: 6: Step: 301/14003, loss=0.717965, lr=0.000003
399it [01:09,  5.79it/s]Train batch 400
Avg. loss per last 100 batches: 0.379998
400it [01:09,  5.79it/s]Epoch: 6: Step: 401/14003, loss=0.370695, lr=0.000003
499it [01:27,  5.80it/s]Train batch 500
Avg. loss per last 100 batches: 0.383452
500it [01:27,  5.81it/s]Epoch: 6: Step: 501/14003, loss=0.408114, lr=0.000003
599it [01:44,  5.73it/s]Train batch 600
Avg. loss per last 100 batches: 0.381501
600it [01:44,  5.71it/s]Epoch: 6: Step: 601/14003, loss=0.135618, lr=0.000003
699it [02:01,  5.78it/s]Train batch 700
Avg. loss per last 100 batches: 0.384230
700it [02:02,  5.79it/s]Epoch: 6: Step: 701/14003, loss=0.949099, lr=0.000003
799it [02:19,  5.74it/s]Train batch 800
Avg. loss per last 100 batches: 0.385601
800it [02:19,  5.74it/s]Epoch: 6: Step: 801/14003, loss=0.107990, lr=0.000003
899it [02:36,  5.81it/s]Train batch 900
Avg. loss per last 100 batches: 0.380040
900it [02:36,  5.81it/s]Epoch: 6: Step: 901/14003, loss=0.575861, lr=0.000003
999it [02:54,  5.82it/s]Train batch 1000
Avg. loss per last 100 batches: 0.393228
1000it [02:54,  5.80it/s]Epoch: 6: Step: 1001/14003, loss=0.460683, lr=0.000003
1099it [03:11,  5.76it/s]Train batch 1100
Avg. loss per last 100 batches: 0.390453
1100it [03:11,  5.57it/s]Epoch: 6: Step: 1101/14003, loss=0.654853, lr=0.000003
1199it [03:28,  5.80it/s]Train batch 1200
Avg. loss per last 100 batches: 0.370232
1200it [03:28,  5.82it/s]Epoch: 6: Step: 1201/14003, loss=0.248181, lr=0.000003
1299it [03:46,  5.71it/s]Train batch 1300
Avg. loss per last 100 batches: 0.377381
1300it [03:46,  5.68it/s]Epoch: 6: Step: 1301/14003, loss=0.229656, lr=0.000003
1399it [04:03,  5.80it/s]Train batch 1400
Avg. loss per last 100 batches: 0.361328
1400it [04:03,  5.80it/s]Epoch: 6: Step: 1401/14003, loss=0.058256, lr=0.000003
1499it [04:20,  5.80it/s]Train batch 1500
Avg. loss per last 100 batches: 0.343449
1500it [04:21,  5.79it/s]Epoch: 6: Step: 1501/14003, loss=0.626988, lr=0.000003
1599it [04:38,  5.86it/s]Train batch 1600
Avg. loss per last 100 batches: 0.371077
1600it [04:38,  5.84it/s]Epoch: 6: Step: 1601/14003, loss=0.341479, lr=0.000003
1699it [04:55,  5.33it/s]Train batch 1700
Avg. loss per last 100 batches: 0.374491
1700it [04:55,  5.26it/s]Epoch: 6: Step: 1701/14003, loss=0.344544, lr=0.000003
1799it [05:12,  5.81it/s]Train batch 1800
Avg. loss per last 100 batches: 0.391360
1800it [05:13,  5.83it/s]Epoch: 6: Step: 1801/14003, loss=0.141909, lr=0.000003
1899it [05:30,  5.80it/s]Train batch 1900
Avg. loss per last 100 batches: 0.403111
1900it [05:30,  5.80it/s]Epoch: 6: Step: 1901/14003, loss=0.215227, lr=0.000003
1999it [05:47,  5.73it/s]Train batch 2000
Avg. loss per last 100 batches: 0.357645
2000it [05:47,  5.70it/s]Epoch: 6: Step: 2001/14003, loss=0.779049, lr=0.000002
2099it [06:05,  5.82it/s]Train batch 2100
Avg. loss per last 100 batches: 0.367227
2100it [06:05,  5.82it/s]Epoch: 6: Step: 2101/14003, loss=0.236884, lr=0.000002
2199it [06:22,  5.77it/s]Train batch 2200
Avg. loss per last 100 batches: 0.385002
2200it [06:22,  5.78it/s]Epoch: 6: Step: 2201/14003, loss=0.147658, lr=0.000002
2299it [06:39,  5.79it/s]Train batch 2300
Avg. loss per last 100 batches: 0.385528
2300it [06:40,  5.78it/s]Epoch: 6: Step: 2301/14003, loss=0.370054, lr=0.000002
2399it [06:57,  5.78it/s]Train batch 2400
Avg. loss per last 100 batches: 0.350241
2400it [06:57,  5.76it/s]Epoch: 6: Step: 2401/14003, loss=0.524996, lr=0.000002
2499it [07:14,  5.84it/s]Train batch 2500
Avg. loss per last 100 batches: 0.379335
2500it [07:14,  5.83it/s]Epoch: 6: Step: 2501/14003, loss=0.321190, lr=0.000002
2599it [07:31,  5.80it/s]Train batch 2600
Avg. loss per last 100 batches: 0.387565
2600it [07:32,  5.79it/s]Epoch: 6: Step: 2601/14003, loss=0.192113, lr=0.000002
2699it [07:49,  5.80it/s]Train batch 2700
Avg. loss per last 100 batches: 0.361393
2700it [07:49,  5.79it/s]Epoch: 6: Step: 2701/14003, loss=0.263840, lr=0.000002
2799it [08:06,  5.71it/s]Train batch 2800
Avg. loss per last 100 batches: 0.379226
2800it [08:06,  5.75it/s]Epoch: 6: Step: 2801/14003, loss=0.270527, lr=0.000002
Validation: Epoch: 6 Step: 2801/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.805838 sec., loss=1.941501 
Eval step: 199 , used_time=9.600674 sec., loss=1.582618 
Eval step: 299 , used_time=14.432313 sec., loss=0.672507 
Eval step: 399 , used_time=19.199362 sec., loss=1.099471 
Eval step: 499 , used_time=24.007082 sec., loss=1.146892 
Eval step: 599 , used_time=28.994844 sec., loss=1.842271 
Eval step: 699 , used_time=33.799318 sec., loss=1.246813 
Eval step: 799 , used_time=38.600051 sec., loss=1.223729 
Eval step: 899 , used_time=43.426829 sec., loss=1.663741 
Eval step: 999 , used_time=48.204099 sec., loss=1.030612 
Eval step: 1099 , used_time=52.993988 sec., loss=1.606289 
Eval step: 1199 , used_time=57.753861 sec., loss=0.859172 
Eval step: 1299 , used_time=62.756805 sec., loss=1.063049 
Eval step: 1399 , used_time=67.535247 sec., loss=0.529209 
Eval step: 1499 , used_time=72.318986 sec., loss=1.472647 
Eval step: 1599 , used_time=77.147462 sec., loss=1.128795 
NLL Validation: loss = 1.010724. correct prediction ratio  39843/52032 ~  0.765740
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
2899it [09:48,  5.77it/s]Train batch 2900
Avg. loss per last 100 batches: 0.351346
2900it [09:48,  5.77it/s]Epoch: 6: Step: 2901/14003, loss=0.464200, lr=0.000002
2999it [10:05,  5.81it/s]Train batch 3000
Avg. loss per last 100 batches: 0.392742
3000it [10:06,  5.81it/s]Epoch: 6: Step: 3001/14003, loss=0.541230, lr=0.000002
3099it [10:23,  5.82it/s]Train batch 3100
Avg. loss per last 100 batches: 0.354296
3100it [10:23,  5.81it/s]Epoch: 6: Step: 3101/14003, loss=0.238063, lr=0.000002
3199it [10:40,  5.79it/s]Train batch 3200
Avg. loss per last 100 batches: 0.370049
3200it [10:40,  5.79it/s]Epoch: 6: Step: 3201/14003, loss=0.400051, lr=0.000002
3299it [10:57,  5.82it/s]Train batch 3300
Avg. loss per last 100 batches: 0.359104
3300it [10:58,  5.79it/s]Epoch: 6: Step: 3301/14003, loss=0.732717, lr=0.000002
3399it [11:15,  5.32it/s]Train batch 3400
Avg. loss per last 100 batches: 0.365868
3400it [11:15,  5.32it/s]Epoch: 6: Step: 3401/14003, loss=0.895876, lr=0.000002
3499it [11:32,  5.81it/s]Train batch 3500
Avg. loss per last 100 batches: 0.401799
3500it [11:32,  5.83it/s]Epoch: 6: Step: 3501/14003, loss=0.084777, lr=0.000002
3599it [11:50,  5.81it/s]Train batch 3600
Avg. loss per last 100 batches: 0.371061
3600it [11:50,  5.79it/s]Epoch: 6: Step: 3601/14003, loss=0.190085, lr=0.000002
3699it [12:07,  5.81it/s]Train batch 3700
Avg. loss per last 100 batches: 0.389829
3700it [12:07,  5.81it/s]Epoch: 6: Step: 3701/14003, loss=0.381465, lr=0.000002
3799it [12:24,  5.80it/s]Train batch 3800
Avg. loss per last 100 batches: 0.387869
3800it [12:24,  5.80it/s]Epoch: 6: Step: 3801/14003, loss=0.338502, lr=0.000002
3899it [12:41,  5.81it/s]Train batch 3900
Avg. loss per last 100 batches: 0.376570
3900it [12:42,  5.80it/s]Epoch: 6: Step: 3901/14003, loss=0.680821, lr=0.000002
3999it [12:59,  5.77it/s]Train batch 4000
Avg. loss per last 100 batches: 0.378212
4000it [12:59,  5.79it/s]Epoch: 6: Step: 4001/14003, loss=0.639595, lr=0.000002
4099it [13:16,  5.82it/s]Train batch 4100
Avg. loss per last 100 batches: 0.387755
4100it [13:16,  5.83it/s]Epoch: 6: Step: 4101/14003, loss=0.331569, lr=0.000002
4199it [13:34,  5.80it/s]Train batch 4200
Avg. loss per last 100 batches: 0.353975
4200it [13:34,  5.80it/s]Epoch: 6: Step: 4201/14003, loss=0.234292, lr=0.000002
4299it [13:51,  5.80it/s]Train batch 4300
Avg. loss per last 100 batches: 0.407276
4300it [13:51,  5.77it/s]Epoch: 6: Step: 4301/14003, loss=0.281987, lr=0.000002
4399it [14:08,  5.81it/s]Train batch 4400
Avg. loss per last 100 batches: 0.379651
4400it [14:08,  5.80it/s]Epoch: 6: Step: 4401/14003, loss=0.373765, lr=0.000002
4499it [14:26,  5.73it/s]Train batch 4500
Avg. loss per last 100 batches: 0.367261
4500it [14:26,  5.76it/s]Epoch: 6: Step: 4501/14003, loss=0.627779, lr=0.000002
4599it [14:43,  5.80it/s]Train batch 4600
Avg. loss per last 100 batches: 0.409008
4600it [14:43,  5.79it/s]Epoch: 6: Step: 4601/14003, loss=0.431468, lr=0.000002
4699it [15:00,  5.79it/s]Train batch 4700
Avg. loss per last 100 batches: 0.400860
4700it [15:01,  5.80it/s]Epoch: 6: Step: 4701/14003, loss=0.195656, lr=0.000002
4799it [15:18,  5.80it/s]Train batch 4800
Avg. loss per last 100 batches: 0.353688
4800it [15:18,  5.81it/s]Epoch: 6: Step: 4801/14003, loss=0.473746, lr=0.000002
4899it [15:35,  5.80it/s]Train batch 4900
Avg. loss per last 100 batches: 0.353883
4900it [15:36,  5.81it/s]Epoch: 6: Step: 4901/14003, loss=0.098707, lr=0.000002
4999it [15:53,  5.81it/s]Train batch 5000
Avg. loss per last 100 batches: 0.368294
5000it [15:53,  5.80it/s]Epoch: 6: Step: 5001/14003, loss=0.097355, lr=0.000002
5099it [16:10,  5.80it/s]Train batch 5100
Avg. loss per last 100 batches: 0.384755
5100it [16:10,  5.81it/s]Epoch: 6: Step: 5101/14003, loss=0.189721, lr=0.000002
5199it [16:27,  5.79it/s]Train batch 5200
Avg. loss per last 100 batches: 0.383211
5200it [16:27,  5.78it/s]Epoch: 6: Step: 5201/14003, loss=0.441282, lr=0.000002
5299it [16:45,  5.76it/s]Train batch 5300
Avg. loss per last 100 batches: 0.386284
5300it [16:45,  5.78it/s]Epoch: 6: Step: 5301/14003, loss=0.602783, lr=0.000002
5399it [17:02,  5.08it/s]Train batch 5400
Avg. loss per last 100 batches: 0.409854
5400it [17:02,  5.09it/s]Epoch: 6: Step: 5401/14003, loss=0.451196, lr=0.000002
5499it [17:20,  5.82it/s]Train batch 5500
Avg. loss per last 100 batches: 0.384937
5500it [17:20,  5.84it/s]Epoch: 6: Step: 5501/14003, loss=0.204764, lr=0.000002
5599it [17:37,  5.78it/s]Train batch 5600
Avg. loss per last 100 batches: 0.372102
5600it [17:37,  5.80it/s]Epoch: 6: Step: 5601/14003, loss=0.171924, lr=0.000002
5601it [17:37,  5.76it/s]Validation: Epoch: 6 Step: 5602/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.848059 sec., loss=1.954340 
Eval step: 199 , used_time=9.701497 sec., loss=1.590954 
Eval step: 299 , used_time=14.554454 sec., loss=0.744165 
Eval step: 399 , used_time=19.323611 sec., loss=1.125714 
Eval step: 499 , used_time=24.130567 sec., loss=1.165930 
Eval step: 599 , used_time=29.171473 sec., loss=1.789713 
Eval step: 699 , used_time=33.979460 sec., loss=1.217461 
Eval step: 799 , used_time=38.741925 sec., loss=1.223634 
Eval step: 899 , used_time=43.538327 sec., loss=1.654874 
Eval step: 999 , used_time=48.306100 sec., loss=0.940319 
Eval step: 1099 , used_time=53.086898 sec., loss=1.574337 
Eval step: 1199 , used_time=57.929416 sec., loss=0.878291 
Eval step: 1299 , used_time=62.926636 sec., loss=1.006483 
Eval step: 1399 , used_time=67.760992 sec., loss=0.483807 
Eval step: 1499 , used_time=72.553342 sec., loss=1.489913 
Eval step: 1599 , used_time=77.380366 sec., loss=1.179803 
NLL Validation: loss = 1.008736. correct prediction ratio  39818/52032 ~  0.765260
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
5699it [19:16,  5.82it/s]Train batch 5700
Avg. loss per last 100 batches: 0.331009
5700it [19:17,  5.83it/s]Epoch: 6: Step: 5701/14003, loss=0.381957, lr=0.000002
5799it [19:34,  5.78it/s]Train batch 5800
Avg. loss per last 100 batches: 0.391931
5800it [19:34,  5.72it/s]Epoch: 6: Step: 5801/14003, loss=0.587655, lr=0.000002
5899it [19:51,  5.79it/s]Train batch 5900
Avg. loss per last 100 batches: 0.394843
5900it [19:51,  5.79it/s]Epoch: 6: Step: 5901/14003, loss=0.119864, lr=0.000002
5999it [20:09,  5.82it/s]Train batch 6000
Avg. loss per last 100 batches: 0.355454
6000it [20:09,  5.81it/s]Epoch: 6: Step: 6001/14003, loss=0.695550, lr=0.000002
6099it [20:26,  5.82it/s]Train batch 6100
Avg. loss per last 100 batches: 0.390199
6100it [20:26,  5.81it/s]Epoch: 6: Step: 6101/14003, loss=0.063215, lr=0.000002
6199it [20:43,  5.38it/s]Train batch 6200
Avg. loss per last 100 batches: 0.364326
6200it [20:43,  5.34it/s]Epoch: 6: Step: 6201/14003, loss=0.260076, lr=0.000002
6299it [21:01,  5.81it/s]Train batch 6300
Avg. loss per last 100 batches: 0.358315
6300it [21:01,  5.80it/s]Epoch: 6: Step: 6301/14003, loss=0.990973, lr=0.000002
6399it [21:18,  5.80it/s]Train batch 6400
Avg. loss per last 100 batches: 0.423177
6400it [21:18,  5.77it/s]Epoch: 6: Step: 6401/14003, loss=0.641781, lr=0.000002
6499it [21:35,  5.79it/s]Train batch 6500
Avg. loss per last 100 batches: 0.404033
6500it [21:35,  5.78it/s]Epoch: 6: Step: 6501/14003, loss=0.267277, lr=0.000002
6599it [21:53,  5.78it/s]Train batch 6600
Avg. loss per last 100 batches: 0.393978
6600it [21:53,  5.80it/s]Epoch: 6: Step: 6601/14003, loss=0.383242, lr=0.000002
6699it [22:10,  5.81it/s]Train batch 6700
Avg. loss per last 100 batches: 0.378600
6700it [22:10,  5.81it/s]Epoch: 6: Step: 6701/14003, loss=0.296147, lr=0.000002
6799it [22:27,  5.81it/s]Train batch 6800
Avg. loss per last 100 batches: 0.394453
6800it [22:27,  5.82it/s]Epoch: 6: Step: 6801/14003, loss=0.869251, lr=0.000001
6899it [22:45,  5.81it/s]Train batch 6900
Avg. loss per last 100 batches: 0.383369
6900it [22:45,  5.76it/s]Epoch: 6: Step: 6901/14003, loss=0.141084, lr=0.000001
6999it [23:02,  5.81it/s]Train batch 7000
Avg. loss per last 100 batches: 0.375625
7000it [23:02,  5.80it/s]Epoch: 6: Step: 7001/14003, loss=0.129110, lr=0.000001
7099it [23:19,  5.82it/s]Train batch 7100
Avg. loss per last 100 batches: 0.386616
7100it [23:19,  5.81it/s]Epoch: 6: Step: 7101/14003, loss=0.196502, lr=0.000001
7199it [23:37,  5.80it/s]Train batch 7200
Avg. loss per last 100 batches: 0.359904
7200it [23:37,  5.80it/s]Epoch: 6: Step: 7201/14003, loss=0.438742, lr=0.000001
7299it [23:54,  5.41it/s]Train batch 7300
Avg. loss per last 100 batches: 0.388076
7300it [23:54,  5.53it/s]Epoch: 6: Step: 7301/14003, loss=0.329079, lr=0.000001
7399it [24:11,  5.80it/s]Train batch 7400
Avg. loss per last 100 batches: 0.371747
7400it [24:11,  5.78it/s]Epoch: 6: Step: 7401/14003, loss=0.469664, lr=0.000001
7499it [24:29,  5.77it/s]Train batch 7500
Avg. loss per last 100 batches: 0.411410
7500it [24:29,  5.80it/s]Epoch: 6: Step: 7501/14003, loss=0.422282, lr=0.000001
7599it [24:46,  5.77it/s]Train batch 7600
Avg. loss per last 100 batches: 0.379103
7600it [24:46,  5.78it/s]Epoch: 6: Step: 7601/14003, loss=0.532753, lr=0.000001
7699it [25:03,  5.80it/s]Train batch 7700
Avg. loss per last 100 batches: 0.375265
7700it [25:03,  5.80it/s]Epoch: 6: Step: 7701/14003, loss=0.338344, lr=0.000001
7799it [25:21,  5.83it/s]Train batch 7800
Avg. loss per last 100 batches: 0.380552
7800it [25:21,  5.82it/s]Epoch: 6: Step: 7801/14003, loss=0.342022, lr=0.000001
7899it [25:38,  5.82it/s]Train batch 7900
Avg. loss per last 100 batches: 0.349514
7900it [25:38,  5.83it/s]Epoch: 6: Step: 7901/14003, loss=0.393169, lr=0.000001
7999it [25:55,  5.81it/s]Train batch 8000
Avg. loss per last 100 batches: 0.361394
8000it [25:55,  5.79it/s]Epoch: 6: Step: 8001/14003, loss=0.167887, lr=0.000001
8099it [26:13,  5.81it/s]Train batch 8100
Avg. loss per last 100 batches: 0.361639
8100it [26:13,  5.82it/s]Epoch: 6: Step: 8101/14003, loss=0.706336, lr=0.000001
8199it [26:30,  5.70it/s]Train batch 8200
Avg. loss per last 100 batches: 0.370654
8200it [26:30,  5.74it/s]Epoch: 6: Step: 8201/14003, loss=0.446299, lr=0.000001
8299it [26:47,  5.78it/s]Train batch 8300
Avg. loss per last 100 batches: 0.401178
8300it [26:48,  5.75it/s]Epoch: 6: Step: 8301/14003, loss=0.527974, lr=0.000001
8399it [27:05,  5.78it/s]Train batch 8400
Avg. loss per last 100 batches: 0.399159
8400it [27:05,  5.77it/s]Epoch: 6: Step: 8401/14003, loss=0.252728, lr=0.000001
8402it [27:05,  5.74it/s]Validation: Epoch: 6 Step: 8403/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.798589 sec., loss=1.931035 
Eval step: 199 , used_time=9.625752 sec., loss=1.576107 
Eval step: 299 , used_time=14.414365 sec., loss=0.728509 
Eval step: 399 , used_time=19.203264 sec., loss=1.124568 
Eval step: 499 , used_time=23.978023 sec., loss=1.233869 
Eval step: 599 , used_time=28.963420 sec., loss=1.782220 
Eval step: 699 , used_time=33.783159 sec., loss=1.213470 
Eval step: 799 , used_time=38.583943 sec., loss=1.254439 
Eval step: 899 , used_time=43.442733 sec., loss=1.679322 
Eval step: 999 , used_time=48.271215 sec., loss=0.974525 
Eval step: 1099 , used_time=53.049033 sec., loss=1.580313 
Eval step: 1199 , used_time=57.861062 sec., loss=0.856196 
Eval step: 1299 , used_time=62.853167 sec., loss=1.026749 
Eval step: 1399 , used_time=67.670430 sec., loss=0.520620 
Eval step: 1499 , used_time=72.491636 sec., loss=1.492705 
Eval step: 1599 , used_time=77.308600 sec., loss=1.214328 
NLL Validation: loss = 1.003496. correct prediction ratio  39814/52032 ~  0.765183
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
8499it [28:44,  5.80it/s]Train batch 8500
Avg. loss per last 100 batches: 0.372653
8500it [28:45,  5.80it/s]Epoch: 6: Step: 8501/14003, loss=0.383288, lr=0.000001
8599it [29:02,  4.61it/s]Train batch 8600
Avg. loss per last 100 batches: 0.365776
8600it [29:03,  4.92it/s]Epoch: 6: Step: 8601/14003, loss=0.562991, lr=0.000001
8699it [29:20,  5.82it/s]Train batch 8700
Avg. loss per last 100 batches: 0.382932
8700it [29:20,  5.82it/s]Epoch: 6: Step: 8701/14003, loss=0.649835, lr=0.000001
8799it [29:37,  5.80it/s]Train batch 8800
Avg. loss per last 100 batches: 0.364012
8800it [29:37,  5.81it/s]Epoch: 6: Step: 8801/14003, loss=0.228696, lr=0.000001
8899it [29:55,  5.77it/s]Train batch 8900
Avg. loss per last 100 batches: 0.372518
8900it [29:55,  5.77it/s]Epoch: 6: Step: 8901/14003, loss=0.208173, lr=0.000001
8999it [30:12,  5.34it/s]Train batch 9000
Avg. loss per last 100 batches: 0.350637
9000it [30:12,  5.22it/s]Epoch: 6: Step: 9001/14003, loss=0.338231, lr=0.000001
9099it [30:29,  5.82it/s]Train batch 9100
Avg. loss per last 100 batches: 0.356985
9100it [30:30,  5.78it/s]Epoch: 6: Step: 9101/14003, loss=0.375456, lr=0.000001
9199it [30:47,  5.74it/s]Train batch 9200
Avg. loss per last 100 batches: 0.357194
9200it [30:47,  5.72it/s]Epoch: 6: Step: 9201/14003, loss=0.399355, lr=0.000001
9299it [31:04,  5.87it/s]Train batch 9300
Avg. loss per last 100 batches: 0.416807
9300it [31:04,  5.85it/s]Epoch: 6: Step: 9301/14003, loss=0.410982, lr=0.000001
9399it [31:21,  5.85it/s]Train batch 9400
Avg. loss per last 100 batches: 0.370872
9400it [31:22,  5.86it/s]Epoch: 6: Step: 9401/14003, loss=0.177485, lr=0.000001
9499it [31:38,  5.90it/s]Train batch 9500
Avg. loss per last 100 batches: 0.377071
9500it [31:39,  5.89it/s]Epoch: 6: Step: 9501/14003, loss=0.518462, lr=0.000001
9599it [31:56,  5.86it/s]Train batch 9600
Avg. loss per last 100 batches: 0.378306
9600it [31:56,  5.88it/s]Epoch: 6: Step: 9601/14003, loss=0.820099, lr=0.000001
9699it [32:13,  5.86it/s]Train batch 9700
Avg. loss per last 100 batches: 0.344066
9700it [32:13,  5.86it/s]Epoch: 6: Step: 9701/14003, loss=0.689509, lr=0.000001
9799it [32:30,  5.79it/s]Train batch 9800
Avg. loss per last 100 batches: 0.386238
9800it [32:30,  5.81it/s]Epoch: 6: Step: 9801/14003, loss=0.042864, lr=0.000001
9899it [32:48,  5.80it/s]Train batch 9900
Avg. loss per last 100 batches: 0.369654
9900it [32:48,  5.79it/s]Epoch: 6: Step: 9901/14003, loss=0.478855, lr=0.000001
9999it [33:05,  5.88it/s]Train batch 10000
Avg. loss per last 100 batches: 0.382171
10000it [33:05,  5.86it/s]Epoch: 6: Step: 10001/14003, loss=0.274430, lr=0.000001
10099it [33:22,  5.23it/s]Train batch 10100
Avg. loss per last 100 batches: 0.374682
10100it [33:22,  5.28it/s]Epoch: 6: Step: 10101/14003, loss=0.762557, lr=0.000001
10199it [33:39,  5.90it/s]Train batch 10200
Avg. loss per last 100 batches: 0.377451
10200it [33:39,  5.89it/s]Epoch: 6: Step: 10201/14003, loss=0.653616, lr=0.000001
10299it [33:57,  5.85it/s]Train batch 10300
Avg. loss per last 100 batches: 0.384974
10300it [33:57,  5.86it/s]Epoch: 6: Step: 10301/14003, loss=0.217226, lr=0.000001
10399it [34:14,  5.88it/s]Train batch 10400
Avg. loss per last 100 batches: 0.371100
10400it [34:14,  5.87it/s]Epoch: 6: Step: 10401/14003, loss=0.640794, lr=0.000001
10499it [34:31,  5.83it/s]Train batch 10500
Avg. loss per last 100 batches: 0.347985
10500it [34:31,  5.83it/s]Epoch: 6: Step: 10501/14003, loss=0.465206, lr=0.000001
10599it [34:48,  5.78it/s]Train batch 10600
Avg. loss per last 100 batches: 0.358873
10600it [34:48,  5.79it/s]Epoch: 6: Step: 10601/14003, loss=0.598738, lr=0.000001
10699it [35:06,  5.86it/s]Train batch 10700
Avg. loss per last 100 batches: 0.395556
10700it [35:06,  5.87it/s]Epoch: 6: Step: 10701/14003, loss=0.379413, lr=0.000001
10799it [35:23,  5.83it/s]Train batch 10800
Avg. loss per last 100 batches: 0.367251
10800it [35:23,  5.86it/s]Epoch: 6: Step: 10801/14003, loss=0.286647, lr=0.000001
10899it [35:40,  5.85it/s]Train batch 10900
Avg. loss per last 100 batches: 0.360310
10900it [35:40,  5.85it/s]Epoch: 6: Step: 10901/14003, loss=0.276654, lr=0.000001
10999it [35:57,  5.84it/s]Train batch 11000
Avg. loss per last 100 batches: 0.390622
11000it [35:57,  5.83it/s]Epoch: 6: Step: 11001/14003, loss=0.204412, lr=0.000001
11099it [36:15,  5.85it/s]Train batch 11100
Avg. loss per last 100 batches: 0.352553
11100it [36:15,  5.84it/s]Epoch: 6: Step: 11101/14003, loss=0.570967, lr=0.000001
11199it [36:32,  5.27it/s]Train batch 11200
Avg. loss per last 100 batches: 0.349808
11200it [36:32,  5.28it/s]Epoch: 6: Step: 11201/14003, loss=0.363927, lr=0.000001
11203it [36:33,  5.50it/s]Validation: Epoch: 6 Step: 11204/14003
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=4.776473 sec., loss=1.932485 
Eval step: 199 , used_time=9.565411 sec., loss=1.573137 
Eval step: 299 , used_time=14.370882 sec., loss=0.701446 
Eval step: 399 , used_time=19.126268 sec., loss=1.135846 
Eval step: 499 , used_time=23.896415 sec., loss=1.186443 
Eval step: 599 , used_time=28.892208 sec., loss=1.844033 
Eval step: 699 , used_time=33.636624 sec., loss=1.211475 
Eval step: 799 , used_time=38.389806 sec., loss=1.234845 
Eval step: 899 , used_time=43.123085 sec., loss=1.714799 
Eval step: 999 , used_time=47.891346 sec., loss=0.962569 
Eval step: 1099 , used_time=52.649246 sec., loss=1.560684 
Eval step: 1199 , used_time=57.414246 sec., loss=0.887180 
Eval step: 1299 , used_time=62.363451 sec., loss=1.008957 
Eval step: 1399 , used_time=67.151223 sec., loss=0.494060 
Eval step: 1499 , used_time=71.931832 sec., loss=1.517037 
Eval step: 1599 , used_time=76.734871 sec., loss=1.193815 
NLL Validation: loss = 1.007591. correct prediction ratio  39872/52032 ~  0.766298
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
11299it [38:13,  5.86it/s]Train batch 11300
Avg. loss per last 100 batches: 0.356734
11300it [38:13,  5.86it/s]Epoch: 6: Step: 11301/14003, loss=0.112078, lr=0.000001
11399it [38:30,  5.85it/s]Train batch 11400
Avg. loss per last 100 batches: 0.382179
11400it [38:30,  5.84it/s]Epoch: 6: Step: 11401/14003, loss=0.324351, lr=0.000001
11499it [38:47,  5.79it/s]Train batch 11500
Avg. loss per last 100 batches: 0.351733
11500it [38:47,  5.80it/s]Epoch: 6: Step: 11501/14003, loss=0.324449, lr=0.000001
11599it [39:04,  5.86it/s]Train batch 11600
Avg. loss per last 100 batches: 0.368689
11600it [39:05,  5.86it/s]Epoch: 6: Step: 11601/14003, loss=0.602926, lr=0.000000
11699it [39:22,  5.83it/s]Train batch 11700
Avg. loss per last 100 batches: 0.393897
11700it [39:22,  5.85it/s]Epoch: 6: Step: 11701/14003, loss=0.358122, lr=0.000000
11799it [39:39,  5.86it/s]Train batch 11800
Avg. loss per last 100 batches: 0.365287
11800it [39:39,  5.85it/s]Epoch: 6: Step: 11801/14003, loss=0.763758, lr=0.000000
11899it [39:56,  5.84it/s]Train batch 11900
Avg. loss per last 100 batches: 0.396699
11900it [39:57,  5.82it/s]Epoch: 6: Step: 11901/14003, loss=0.379067, lr=0.000000
11999it [40:14,  5.45it/s]Train batch 12000
Avg. loss per last 100 batches: 0.396629
12000it [40:14,  5.55it/s]Epoch: 6: Step: 12001/14003, loss=0.381902, lr=0.000000
12099it [40:31,  5.77it/s]Train batch 12100
Avg. loss per last 100 batches: 0.375481
12100it [40:31,  5.68it/s]Epoch: 6: Step: 12101/14003, loss=0.447948, lr=0.000000
12199it [40:48,  5.78it/s]Train batch 12200
Avg. loss per last 100 batches: 0.367455
12200it [40:48,  5.79it/s]Epoch: 6: Step: 12201/14003, loss=0.334190, lr=0.000000
12299it [41:05,  5.83it/s]Train batch 12300
Avg. loss per last 100 batches: 0.405108
12300it [41:06,  5.83it/s]Epoch: 6: Step: 12301/14003, loss=0.139814, lr=0.000000
12399it [41:23,  5.82it/s]Train batch 12400
Avg. loss per last 100 batches: 0.384780
12400it [41:23,  5.82it/s]Epoch: 6: Step: 12401/14003, loss=0.222498, lr=0.000000
12499it [41:40,  5.88it/s]Train batch 12500
Avg. loss per last 100 batches: 0.406844
12500it [41:40,  5.89it/s]Epoch: 6: Step: 12501/14003, loss=0.690745, lr=0.000000
12599it [41:57,  5.83it/s]Train batch 12600
Avg. loss per last 100 batches: 0.322573
12600it [41:57,  5.84it/s]Epoch: 6: Step: 12601/14003, loss=0.536221, lr=0.000000
12699it [42:14,  5.85it/s]Train batch 12700
Avg. loss per last 100 batches: 0.357626
12700it [42:15,  5.85it/s]Epoch: 6: Step: 12701/14003, loss=0.286697, lr=0.000000
12799it [42:32,  5.72it/s]Train batch 12800
Avg. loss per last 100 batches: 0.382581
12800it [42:32,  5.75it/s]Epoch: 6: Step: 12801/14003, loss=0.335284, lr=0.000000
12899it [42:49,  5.80it/s]Train batch 12900
Avg. loss per last 100 batches: 0.405539
12900it [42:49,  5.81it/s]Epoch: 6: Step: 12901/14003, loss=0.178005, lr=0.000000
12999it [43:06,  5.87it/s]Train batch 13000
Avg. loss per last 100 batches: 0.388379
13000it [43:06,  5.86it/s]Epoch: 6: Step: 13001/14003, loss=0.301245, lr=0.000000
13099it [43:23,  5.37it/s]Train batch 13100
Avg. loss per last 100 batches: 0.381393
13100it [43:24,  5.50it/s]Epoch: 6: Step: 13101/14003, loss=0.281853, lr=0.000000
13199it [43:41,  5.84it/s]Train batch 13200
Avg. loss per last 100 batches: 0.366434
13200it [43:41,  5.83it/s]Epoch: 6: Step: 13201/14003, loss=0.208222, lr=0.000000
13299it [43:58,  5.87it/s]Train batch 13300
Avg. loss per last 100 batches: 0.366755
13300it [43:58,  5.86it/s]Epoch: 6: Step: 13301/14003, loss=0.193912, lr=0.000000
13399it [44:15,  5.86it/s]Train batch 13400
Avg. loss per last 100 batches: 0.374437
13400it [44:15,  5.87it/s]Epoch: 6: Step: 13401/14003, loss=0.121376, lr=0.000000
13499it [44:32,  5.76it/s]Train batch 13500
Avg. loss per last 100 batches: 0.391128
13500it [44:32,  5.78it/s]Epoch: 6: Step: 13501/14003, loss=0.239139, lr=0.000000
13599it [44:49,  5.83it/s]Train batch 13600
Avg. loss per last 100 batches: 0.395467
13600it [44:50,  5.81it/s]Epoch: 6: Step: 13601/14003, loss=0.237372, lr=0.000000
13699it [45:07,  5.88it/s]Train batch 13700
Avg. loss per last 100 batches: 0.396007
13700it [45:07,  5.88it/s]Epoch: 6: Step: 13701/14003, loss=0.240388, lr=0.000000
13799it [45:24,  5.88it/s]Train batch 13800
Avg. loss per last 100 batches: 0.359562
13800it [45:24,  5.89it/s]Epoch: 6: Step: 13801/14003, loss=0.182104, lr=0.000000
13899it [45:41,  5.48it/s]Train batch 13900
Avg. loss per last 100 batches: 0.370179
13900it [45:41,  5.60it/s]Epoch: 6: Step: 13901/14003, loss=0.345759, lr=0.000000
13999it [45:58,  5.87it/s]Train batch 14000
Avg. loss per last 100 batches: 0.391612
14000it [45:59,  5.87it/s]Epoch: 6: Step: 14001/14003, loss=0.662003, lr=0.000000
14003it [45:59,  5.07it/s]
NLL validation ...
Reading file /kaggle/working/valid.json
Aggregated data size: 52020
Total cleaned data size: 52020
Eval step: 99 , used_time=5.040357 sec., loss=1.926440 
Eval step: 199 , used_time=9.786434 sec., loss=1.566864 
Eval step: 299 , used_time=14.555201 sec., loss=0.695892 
Eval step: 399 , used_time=19.283724 sec., loss=1.116672 
Eval step: 499 , used_time=24.053953 sec., loss=1.166471 
Eval step: 599 , used_time=28.788050 sec., loss=1.834331 
Eval step: 699 , used_time=33.802073 sec., loss=1.206329 
Eval step: 799 , used_time=38.538212 sec., loss=1.243915 
Eval step: 899 , used_time=43.359785 sec., loss=1.706002 
Eval step: 999 , used_time=48.156498 sec., loss=0.951116 
Eval step: 1099 , used_time=52.975339 sec., loss=1.571010 
Eval step: 1199 , used_time=57.718356 sec., loss=0.887493 
Eval step: 1299 , used_time=62.491503 sec., loss=1.015562 
Eval step: 1399 , used_time=67.490198 sec., loss=0.500806 
Eval step: 1499 , used_time=72.252268 sec., loss=1.516585 
Eval step: 1599 , used_time=77.008089 sec., loss=1.188924 
NLL Validation: loss = 1.007437. correct prediction ratio  39859/52032 ~  0.766048
Saved checkpoint at checkpoints/biencoder/dpr_biencoder_trained.bin
Saved checkpoint to checkpoints/biencoder/dpr_biencoder_trained.bin
Av Loss per epoch=0.376795
epoch total correct predictions=396140
Training finished. Best validation checkpoint checkpoints/biencoder/dpr_biencoder_trained.bin